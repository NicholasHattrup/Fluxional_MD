Torch device: cuda
Successfully loaded the data set of type ASEDataset(1012)...
Replace string dataset_forces_rms to 0.037664994597435
Replace string dataset_per_atom_total_energy_mean to -20.318891525268555
Atomic outputs are scaled by: [H, B, C, O: 0.037665], shifted by [H, B, C, O: -20.318892].
Replace string dataset_forces_rms to 0.037664994597435
Initially outputs are globally scaled by: 0.037664994597435, total_energy are globally shifted by None.
Successfully built the network...
Number of weights: 598312
! Starting training ...
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
      0    10        0.777        0.777     0.000689       0.0221       0.0332       0.0169            0       0.0267       0.0146       0.0244            0       0.0395       0.0213       0.0329     0.000865
      0    20        0.979        0.979     2.28e-05       0.0275       0.0373       0.0178            0       0.0361        0.018       0.0235            0       0.0463       0.0233      0.00586     0.000154
      0    30         0.88         0.88     0.000415       0.0233       0.0353       0.0153            0       0.0306       0.0153        0.022            0        0.044        0.022       0.0195     0.000514
      0    40         1.08         1.08     5.88e-05       0.0284       0.0392       0.0165            0        0.039       0.0185       0.0227            0       0.0496       0.0241       0.0102     0.000269
      0    50         1.06         1.06     0.000185       0.0288       0.0387       0.0197            0       0.0369       0.0189       0.0265            0       0.0471       0.0245       0.0123     0.000323
      0    60         1.08         1.07     2.29e-05       0.0298       0.0391       0.0208            0       0.0379       0.0196       0.0281            0       0.0467        0.025      0.00536     0.000141
      0    70        0.767        0.767     0.000249       0.0233        0.033       0.0152            0       0.0306       0.0153       0.0192            0       0.0417       0.0203       0.0186     0.000491
      0    80        0.988        0.988      9.5e-05       0.0281       0.0374       0.0198            0       0.0354       0.0184       0.0262            0       0.0452       0.0238       0.0107     0.000281
      0    90         0.92         0.92     2.51e-05       0.0271       0.0361       0.0172            0       0.0361       0.0177       0.0234            0       0.0446       0.0227      0.00612     0.000161
      0   100        0.962        0.962     0.000153       0.0269       0.0369       0.0166            0       0.0362       0.0176       0.0226            0       0.0462       0.0229       0.0171      0.00045
      0   110         1.11         1.11     0.000212       0.0302       0.0396       0.0205            0       0.0389       0.0198       0.0269            0       0.0483       0.0251       0.0169     0.000445
      0   120         1.16         1.16     0.000117       0.0295       0.0405       0.0225            0       0.0359       0.0195       0.0297            0       0.0482        0.026       0.0139     0.000365
      0   130        0.961        0.961     2.45e-05       0.0277       0.0369       0.0176            0       0.0368       0.0182       0.0232            0       0.0459        0.023      0.00587     0.000155
      0   140         1.21         1.21     7.49e-05       0.0308       0.0414       0.0201            0       0.0404       0.0202       0.0263            0       0.0513       0.0259       0.0107     0.000283
      0   142         1.09         1.09     1.59e-05       0.0299       0.0393       0.0209            0       0.0379       0.0196       0.0277            0       0.0473        0.025      0.00557     0.000147
  Initialization     #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Initial Validation          0    4.764    0.005        0.998     0.000124        0.998       0.0274       0.0376       0.0183            0       0.0357        0.018       0.0244            0       0.0464       0.0236       0.0117     0.000307
Wall time: 4.764068638993194
! Best model        0    0.998
training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
      1    10        0.748        0.741      0.00653       0.0224       0.0324       0.0144            0       0.0297       0.0147       0.0199            0       0.0405       0.0201        0.114      0.00299
      1    20        0.677         0.66       0.0168       0.0221       0.0306       0.0109            0       0.0321       0.0143       0.0138            0       0.0401        0.018        0.185      0.00488
      1    30        0.664        0.664     0.000385       0.0221       0.0307        0.012            0       0.0311       0.0144       0.0155            0       0.0396       0.0184       0.0266       0.0007
      1    40        0.627        0.626     0.000137       0.0211       0.0298       0.0106            0       0.0306       0.0137       0.0133            0       0.0391       0.0175       0.0153     0.000404
      1    50        0.523        0.522      0.00116       0.0187       0.0272      0.00956            0       0.0269       0.0122       0.0116            0       0.0359       0.0158       0.0476      0.00125
      1    60        0.439        0.438     0.000896       0.0172       0.0249      0.00796            0       0.0254       0.0111       0.0101            0        0.033       0.0144       0.0425      0.00112
      1    70        0.393        0.393     2.18e-05       0.0154       0.0236      0.00654            0       0.0234      0.00999      0.00828            0       0.0316       0.0133       0.0053     0.000139
      1    80        0.276        0.276     0.000458        0.013       0.0198      0.00589            0       0.0194      0.00844       0.0076            0       0.0263       0.0113       0.0293     0.000772
      1    90         0.21        0.209      0.00102       0.0122       0.0172      0.00627            0       0.0175      0.00793      0.00809            0       0.0224       0.0102       0.0455       0.0012
      1   100        0.189        0.189     0.000747       0.0117       0.0164      0.00689            0       0.0161      0.00767      0.00834            0       0.0211      0.00982        0.038        0.001
      1   110        0.127        0.126      0.00103      0.00928       0.0134      0.00506            0       0.0131      0.00605      0.00631            0       0.0174      0.00791       0.0457       0.0012
      1   120        0.102        0.102     0.000125      0.00841        0.012      0.00507            0       0.0114      0.00549      0.00633            0       0.0155      0.00727       0.0154     0.000406
      1   130       0.0845       0.0825      0.00198       0.0079       0.0108      0.00471            0       0.0108      0.00516      0.00599            0       0.0138      0.00659       0.0636      0.00167
      1   140       0.0581       0.0581     9.62e-06      0.00683      0.00908      0.00422            0      0.00919      0.00447      0.00536            0       0.0114       0.0056      0.00402     0.000106
      1   142       0.0454       0.0454     3.97e-05      0.00596      0.00803      0.00421            0      0.00754      0.00392      0.00514            0      0.00993      0.00502      0.00781     0.000206
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
      1    10       0.0886       0.0886     7.14e-06      0.00806       0.0112      0.00476            0        0.011      0.00526      0.00593            0       0.0144      0.00677      0.00376     9.89e-05
      1    20        0.066        0.066     4.66e-06      0.00698      0.00968       0.0041            0      0.00958      0.00456      0.00506            0       0.0124      0.00583      0.00244     6.42e-05
      1    30       0.0792       0.0792     9.98e-06      0.00752       0.0106      0.00428            0       0.0104       0.0049      0.00542            0       0.0137      0.00636      0.00302     7.93e-05
      1    40       0.0752       0.0752     8.78e-06      0.00763       0.0103      0.00466            0       0.0103      0.00498       0.0059            0       0.0131      0.00633      0.00381       0.0001
      1    50       0.0792       0.0792     5.71e-06      0.00802       0.0106      0.00498            0       0.0108      0.00524      0.00608            0       0.0134       0.0065      0.00305     8.03e-05
      1    60       0.0588       0.0588     1.98e-05      0.00662      0.00913      0.00409            0       0.0089      0.00433      0.00497            0       0.0117      0.00555      0.00463     0.000122
      1    61        0.102        0.102     1.48e-05       0.0088        0.012      0.00524            0        0.012      0.00575      0.00668            0       0.0153      0.00734      0.00316     8.31e-05
  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train               1   14.828    0.005        0.385      0.00263        0.388       0.0153       0.0234      0.00823            0       0.0217      0.00998       0.0116            0       0.0303        0.014       0.0475      0.00125
! Validation          1   14.828    0.005       0.0738      1.3e-05       0.0739      0.00739       0.0102      0.00446            0         0.01      0.00483      0.00563            0        0.013      0.00623      0.00428     0.000113
Wall time: 14.828644312976394
! Best model        1    0.074
training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
      2    10       0.0459       0.0459     6.09e-05      0.00604      0.00807      0.00397            0      0.00792      0.00396      0.00496            0       0.0101      0.00501       0.0107     0.000282
      2    20       0.0481       0.0481     4.05e-06      0.00593      0.00826      0.00359            0      0.00803      0.00387      0.00464            0       0.0105      0.00505      0.00217     5.72e-05
      2    30       0.0436        0.043     0.000659      0.00575      0.00781      0.00352            0      0.00775      0.00376      0.00453            0      0.00987       0.0048       0.0363     0.000955
      2    40       0.0364       0.0364     1.09e-05      0.00535      0.00718      0.00345            0      0.00706       0.0035      0.00447            0      0.00895      0.00447      0.00424     0.000111
      2    50       0.0348       0.0348     1.54e-06      0.00528      0.00702      0.00318            0      0.00716      0.00345        0.004            0      0.00891       0.0043      0.00132     3.47e-05
      2    60       0.0373       0.0372     2.93e-05      0.00552      0.00727      0.00355            0      0.00728      0.00361      0.00441            0       0.0091       0.0045      0.00765     0.000201
      2    70        0.035        0.035     7.05e-06      0.00529      0.00705      0.00338            0        0.007      0.00346      0.00423            0      0.00884      0.00436      0.00284     7.48e-05
      2    80       0.0305       0.0303     0.000256      0.00493      0.00655      0.00331            0      0.00639      0.00323      0.00421            0       0.0081       0.0041       0.0227     0.000597
      2    90       0.0375       0.0375     9.23e-06       0.0055      0.00729      0.00375            0      0.00707      0.00361      0.00482            0      0.00895      0.00459      0.00376     9.89e-05
      2   100       0.0328       0.0328     8.99e-06      0.00522      0.00682      0.00336            0      0.00689      0.00342      0.00432            0      0.00846      0.00426      0.00381       0.0001
      2   110       0.0318       0.0318     1.21e-05      0.00514      0.00672      0.00354            0      0.00658      0.00337      0.00446            0      0.00824      0.00423      0.00459     0.000121
      2   120       0.0318       0.0318     3.58e-06      0.00505      0.00672      0.00323            0      0.00668      0.00331        0.004            0      0.00845      0.00415      0.00259     6.81e-05
      2   130       0.0237       0.0237     4.58e-06      0.00444      0.00579      0.00328            0      0.00548      0.00292      0.00404            0        0.007      0.00368      0.00258     6.78e-05
      2   140       0.0217       0.0217     3.84e-05      0.00421      0.00554      0.00285            0      0.00544      0.00276      0.00369            0       0.0068      0.00349      0.00847     0.000223
      2   142       0.0369       0.0368     9.22e-05      0.00574      0.00723      0.00431            0      0.00703      0.00378      0.00543            0      0.00853      0.00465       0.0138     0.000362
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
      2    10        0.036        0.036     4.54e-06       0.0051      0.00714      0.00303            0      0.00697      0.00333      0.00387            0      0.00914      0.00434       0.0028     7.36e-05
      2    20       0.0232       0.0232     4.95e-06      0.00428      0.00574      0.00268            0      0.00572       0.0028      0.00339            0      0.00723      0.00354      0.00293     7.71e-05
      2    30       0.0259       0.0259     3.23e-06      0.00447      0.00606      0.00278            0      0.00599      0.00292      0.00361            0      0.00762      0.00374       0.0024     6.33e-05
      2    40       0.0263       0.0263     3.47e-06      0.00458       0.0061      0.00319            0      0.00583      0.00301      0.00419            0      0.00742      0.00387      0.00205      5.4e-05
      2    50       0.0243       0.0243     3.96e-07      0.00457      0.00587      0.00322            0      0.00579        0.003       0.0041            0      0.00709      0.00373     0.000867     2.28e-05
      2    60       0.0212       0.0212      1.1e-05      0.00401      0.00548      0.00246            0       0.0054      0.00262      0.00319            0      0.00693      0.00337      0.00365     9.61e-05
      2    61       0.0316       0.0316     1.16e-06      0.00505      0.00669      0.00362            0      0.00634      0.00332      0.00458            0      0.00814      0.00424      0.00148      3.9e-05
  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train               2   23.469    0.005       0.0386     0.000122       0.0387      0.00549       0.0074       0.0036            0       0.0072       0.0036      0.00466            0      0.00919      0.00462       0.0113     0.000298
! Validation          2   23.469    0.005       0.0263     4.39e-06       0.0263      0.00452      0.00611      0.00296            0      0.00592      0.00296       0.0039            0      0.00756      0.00382      0.00241     6.33e-05
Wall time: 23.469966990000103
! Best model        2    0.026
training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
      3    10       0.0253       0.0253     6.54e-05      0.00448      0.00599      0.00277            0      0.00603      0.00293      0.00358            0      0.00753       0.0037       0.0112     0.000295
      3    20       0.0268       0.0268     2.39e-05      0.00465      0.00616      0.00291            0      0.00622      0.00304      0.00369            0      0.00774      0.00381      0.00687     0.000181
      3    30       0.0248       0.0245     0.000327      0.00444      0.00589      0.00292            0      0.00581      0.00291      0.00372            0      0.00732      0.00368       0.0258     0.000678
      3    40       0.0185       0.0185     4.99e-06      0.00379      0.00512      0.00255            0      0.00491      0.00249      0.00338            0      0.00629      0.00323      0.00248     6.52e-05
      3    50       0.0198       0.0194     0.000354       0.0039      0.00525      0.00264            0      0.00503      0.00256      0.00342            0      0.00646      0.00329       0.0269     0.000708
      3    60       0.0181       0.0178     0.000235      0.00369      0.00503      0.00267            0       0.0046      0.00242      0.00346            0      0.00611      0.00319       0.0218     0.000574
      3    70       0.0282       0.0279     0.000351      0.00495      0.00629      0.00391            0      0.00588      0.00326      0.00474            0      0.00741      0.00405       0.0267     0.000703
      3    80       0.0269       0.0266     0.000236      0.00468      0.00615      0.00305            0      0.00614      0.00306      0.00384            0      0.00765      0.00383       0.0219     0.000575
      3    90       0.0162       0.0162     4.76e-06      0.00365       0.0048      0.00267            0      0.00453       0.0024      0.00342            0      0.00576      0.00306      0.00255     6.71e-05
      3   100       0.0244       0.0242     0.000163      0.00453      0.00586      0.00328            0      0.00566      0.00298      0.00412            0      0.00706      0.00373       0.0181     0.000476
      3   110       0.0278       0.0271     0.000663      0.00481       0.0062       0.0037            0      0.00582      0.00317      0.00463            0      0.00733      0.00399       0.0367     0.000966
      3   120       0.0199       0.0199     6.99e-06        0.004      0.00532      0.00264            0      0.00523      0.00262      0.00342            0      0.00657      0.00333       0.0033     8.67e-05
      3   130       0.0188       0.0187     0.000111      0.00403      0.00515      0.00307            0      0.00489      0.00265      0.00384            0      0.00609      0.00331       0.0148     0.000389
      3   140       0.0148       0.0147     0.000138      0.00354      0.00457      0.00268            0      0.00432      0.00233      0.00333            0      0.00545      0.00293       0.0166     0.000437
      3   142       0.0169       0.0169     2.54e-05      0.00381      0.00489      0.00283            0      0.00469      0.00251      0.00355            0      0.00584      0.00313      0.00698     0.000184
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
      3    10       0.0244       0.0244      2.9e-06      0.00425      0.00588      0.00257            0      0.00577      0.00278       0.0033            0      0.00748      0.00359      0.00215     5.65e-05
      3    20       0.0151       0.0151     4.37e-06      0.00346      0.00462      0.00226            0      0.00455      0.00227      0.00289            0      0.00576      0.00288       0.0027      7.1e-05
      3    30       0.0163       0.0163     5.87e-06       0.0036      0.00481      0.00239            0      0.00468      0.00236      0.00321            0      0.00589      0.00303      0.00243     6.39e-05
      3    40       0.0169       0.0169     3.61e-06      0.00369       0.0049      0.00265            0      0.00463      0.00242      0.00344            0      0.00591      0.00312      0.00226     5.94e-05
      3    50       0.0164       0.0164     2.25e-07      0.00378      0.00483      0.00279            0      0.00467      0.00249      0.00358            0      0.00573       0.0031     0.000586     1.54e-05
      3    60       0.0132       0.0132     6.05e-06      0.00315      0.00433      0.00204            0      0.00415      0.00206      0.00272            0      0.00538       0.0027       0.0031     8.16e-05
      3    61       0.0191       0.0191     2.91e-07      0.00394       0.0052      0.00299            0       0.0048      0.00259      0.00385            0      0.00617      0.00334      0.00058     1.53e-05
  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train               3   32.185    0.005       0.0229     0.000136        0.023      0.00428       0.0057        0.003            0      0.00543      0.00281      0.00393            0      0.00692      0.00361       0.0135     0.000355
! Validation          3   32.185    0.005       0.0168     3.49e-06       0.0169      0.00363      0.00489      0.00253            0      0.00461      0.00238       0.0034            0      0.00592      0.00311      0.00207     5.44e-05
Wall time: 32.18574076000368
! Best model        3    0.017
training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
      4    10       0.0159       0.0158     3.44e-05      0.00352      0.00474      0.00255            0       0.0044      0.00232      0.00329            0      0.00574      0.00301      0.00795     0.000209
      4    20       0.0146       0.0146     2.88e-05      0.00351      0.00455      0.00248            0      0.00445      0.00231      0.00318            0       0.0055      0.00289      0.00741     0.000195
      4    30       0.0169       0.0168     2.81e-05      0.00387      0.00489      0.00327            0      0.00441      0.00256      0.00401            0      0.00556      0.00319       0.0075     0.000197
      4    40       0.0391        0.039     7.03e-05      0.00503      0.00744       0.0046            0      0.00542      0.00334      0.00726            0       0.0076      0.00495       0.0118      0.00031
      4    50       0.0152       0.0151        7e-05      0.00342      0.00463      0.00232            0      0.00441      0.00224      0.00299            0      0.00572       0.0029       0.0117     0.000308
      4    60       0.0132       0.0131     6.65e-05      0.00329      0.00431      0.00242            0      0.00406      0.00216      0.00316            0      0.00512      0.00276       0.0113     0.000297
      4    70       0.0127       0.0127     4.26e-05      0.00316      0.00424      0.00224            0      0.00399      0.00208      0.00296            0      0.00513      0.00269      0.00914     0.000241
      4    80        0.012       0.0119     8.41e-05      0.00319      0.00411      0.00241            0      0.00389       0.0021      0.00315            0      0.00481      0.00265        0.013     0.000343
      4    90       0.0364       0.0361      0.00029       0.0047      0.00716        0.004            0      0.00533      0.00311      0.00632            0      0.00783      0.00472       0.0241     0.000635
      4   100       0.0464       0.0464     1.26e-05      0.00577      0.00811      0.00548            0      0.00603      0.00384       0.0079            0       0.0083       0.0054      0.00471     0.000124
      4   110       0.0208       0.0207     4.65e-05      0.00409      0.00542      0.00264            0      0.00539      0.00268      0.00346            0      0.00671      0.00339      0.00962     0.000253
      4   120       0.0158       0.0158     7.36e-06      0.00364      0.00473      0.00266            0      0.00453       0.0024      0.00358            0      0.00557      0.00305      0.00377     9.93e-05
      4   130       0.0129       0.0128     8.69e-05      0.00328      0.00427      0.00231            0      0.00415      0.00215      0.00299            0      0.00515      0.00271        0.013     0.000342
      4   140       0.0171        0.017     2.85e-05      0.00381      0.00491       0.0026            0       0.0049       0.0025      0.00329            0      0.00601       0.0031      0.00714     0.000188
      4   142        0.016       0.0158     0.000217      0.00368      0.00474      0.00271            0      0.00456      0.00242      0.00344            0      0.00566      0.00303       0.0209     0.000549
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
      4    10       0.0184       0.0184     2.26e-06      0.00372      0.00511      0.00237            0      0.00494      0.00244      0.00308            0      0.00642      0.00317      0.00192     5.04e-05
      4    20       0.0118       0.0118     2.08e-06      0.00302      0.00409      0.00203            0      0.00391      0.00198      0.00263            0      0.00505      0.00256      0.00192     5.04e-05
      4    30       0.0126       0.0125      6.1e-06      0.00314      0.00422      0.00217            0      0.00401      0.00206      0.00297            0      0.00509      0.00269      0.00321     8.45e-05
      4    40        0.013        0.013     1.93e-06      0.00321      0.00429      0.00233            0        0.004      0.00211      0.00304            0      0.00517      0.00273      0.00192     5.04e-05
      4    50       0.0127       0.0127     9.19e-07       0.0033      0.00424      0.00247            0      0.00405      0.00217      0.00323            0      0.00498      0.00274      0.00109     2.86e-05
      4    60      0.00968      0.00968     2.37e-06      0.00271      0.00371      0.00181            0      0.00352      0.00178      0.00247            0      0.00454      0.00234      0.00204     5.36e-05
      4    61       0.0141       0.0141     2.07e-06      0.00338      0.00447      0.00268            0      0.00401      0.00223      0.00352            0      0.00518       0.0029      0.00195     5.14e-05
  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train               4   40.812    0.005       0.0168     7.47e-05       0.0169      0.00366      0.00488      0.00264            0      0.00458      0.00241      0.00355            0      0.00582      0.00313      0.00963     0.000253
! Validation          4   40.812    0.005       0.0129     2.77e-06       0.0129      0.00316      0.00427      0.00227            0      0.00395      0.00208      0.00312            0      0.00509      0.00274      0.00207     5.44e-05
Wall time: 40.8128831369977
! Best model        4    0.013
training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
      5    10       0.0136       0.0136     7.19e-06      0.00335      0.00439      0.00238            0      0.00422       0.0022      0.00308            0      0.00529      0.00279      0.00284     7.48e-05
      5    20       0.0136       0.0136     1.63e-06      0.00331      0.00439      0.00251            0      0.00403      0.00218      0.00329            0      0.00518      0.00282      0.00139     3.66e-05
      5    30       0.0387       0.0387     8.07e-06        0.005      0.00741      0.00417            0      0.00575      0.00331      0.00662            0      0.00805      0.00489      0.00302     7.93e-05
      5    40       0.0127       0.0127      4.5e-05      0.00323      0.00424      0.00225            0      0.00412      0.00212      0.00293            0      0.00515      0.00269      0.00941     0.000248
      5    50        0.013        0.013     1.15e-05      0.00329      0.00429      0.00252            0      0.00399      0.00217       0.0033            0      0.00502      0.00277      0.00464     0.000122
      5    60        0.015        0.015     6.62e-06      0.00351      0.00461      0.00238            0      0.00453      0.00231      0.00309            0      0.00563      0.00291      0.00275     7.23e-05
      5    70       0.0127       0.0127     2.76e-05      0.00323      0.00424      0.00227            0      0.00409      0.00212      0.00302            0       0.0051      0.00271      0.00712     0.000187
      5    80        0.011       0.0107     0.000242       0.0031       0.0039      0.00247            0      0.00366      0.00204      0.00308            0      0.00451      0.00253       0.0221     0.000583
      5    90         0.02       0.0196     0.000386       0.0042      0.00527      0.00311            0      0.00518      0.00276      0.00385            0      0.00629      0.00338       0.0281     0.000739
      5   100       0.0115       0.0114     7.05e-05        0.003      0.00402      0.00208            0      0.00383      0.00197      0.00281            0      0.00486      0.00256        0.012     0.000315
      5   110       0.0118       0.0117     8.77e-05       0.0031      0.00407      0.00256            0      0.00358      0.00205      0.00331            0      0.00466      0.00265        0.013     0.000343
      5   120       0.0135       0.0135     4.22e-05      0.00348      0.00437        0.003            0      0.00391       0.0023      0.00368            0       0.0049      0.00286      0.00911      0.00024
      5   130      0.00883      0.00882     8.77e-06      0.00275      0.00354      0.00226            0       0.0032      0.00182      0.00283            0      0.00407       0.0023      0.00365     9.61e-05
      5   140       0.0118       0.0118     7.31e-06      0.00314      0.00409      0.00223            0      0.00395      0.00206      0.00294            0      0.00489      0.00261      0.00364     9.57e-05
      5   142       0.0113       0.0112     5.22e-05      0.00301      0.00399      0.00212            0      0.00382      0.00198      0.00276            0      0.00483      0.00253       0.0101     0.000266
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
      5    10       0.0152       0.0152     3.12e-06      0.00338      0.00464      0.00223            0      0.00441      0.00221      0.00291            0      0.00577       0.0029      0.00222     5.85e-05
      5    20         0.01         0.01     2.45e-06      0.00277      0.00377      0.00187            0      0.00359      0.00182      0.00247            0      0.00465      0.00237      0.00199     5.24e-05
      5    30       0.0105       0.0105     6.21e-06      0.00286      0.00386      0.00205            0      0.00359      0.00188       0.0028            0      0.00461      0.00247       0.0032     8.42e-05
      5    40       0.0108       0.0108     1.93e-06      0.00291      0.00392      0.00211            0      0.00363      0.00191      0.00281            0      0.00469       0.0025      0.00182     4.79e-05
      5    50       0.0104       0.0104        1e-06      0.00296      0.00384      0.00226            0      0.00359      0.00195        0.003            0      0.00446      0.00249      0.00117     3.08e-05
      5    60      0.00779      0.00779     2.18e-06      0.00244      0.00332      0.00165            0      0.00315       0.0016      0.00231            0      0.00402      0.00211       0.0019     5.01e-05
      5    61       0.0117       0.0117     2.25e-06      0.00311      0.00407      0.00247            0       0.0037      0.00205      0.00326            0      0.00469      0.00265        0.002     5.26e-05
  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train               5   49.448    0.005       0.0137     7.25e-05       0.0138       0.0033      0.00441      0.00245            0      0.00407      0.00217      0.00332            0       0.0052      0.00284      0.00955     0.000251
! Validation          5   49.448    0.005       0.0107     2.93e-06       0.0107      0.00287       0.0039      0.00211            0      0.00356      0.00189      0.00293            0       0.0046      0.00251      0.00208     5.48e-05
Wall time: 49.44842911500018
! Best model        5    0.011
training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
      6    10       0.0114       0.0114     6.12e-06      0.00303      0.00403       0.0021            0      0.00387      0.00199      0.00269            0      0.00493      0.00254      0.00302     7.93e-05
      6    20      0.00966      0.00963     2.58e-05      0.00288       0.0037      0.00247            0      0.00325      0.00191      0.00313            0      0.00414      0.00242      0.00713     0.000188
      6    30       0.0129       0.0128     9.38e-05      0.00331      0.00426      0.00226            0      0.00426      0.00217      0.00292            0      0.00517       0.0027       0.0136     0.000357
      6    40       0.0143       0.0137     0.000612      0.00337      0.00441       0.0023            0      0.00434      0.00221      0.00293            0      0.00541      0.00278       0.0354     0.000931
      6    50       0.0104       0.0102     0.000126      0.00292      0.00381       0.0023            0      0.00347      0.00192      0.00299            0      0.00442      0.00247        0.016      0.00042
      6    60       0.0149       0.0145     0.000351      0.00365      0.00454      0.00297            0      0.00426      0.00241      0.00369            0      0.00519      0.00296       0.0267     0.000703
      6    70       0.0126       0.0126     1.81e-05      0.00334      0.00422      0.00271            0      0.00391      0.00221      0.00346            0      0.00481      0.00276      0.00587     0.000155
      6    80        0.012       0.0118     0.000153       0.0032      0.00409      0.00273            0      0.00363      0.00212      0.00346            0      0.00459      0.00268       0.0174     0.000458
      6    90       0.0164       0.0164     1.73e-06      0.00386      0.00483      0.00333            0      0.00434      0.00255      0.00408            0      0.00541      0.00316      0.00171      4.5e-05
      6   100      0.00915      0.00913      2.1e-05      0.00273       0.0036      0.00188            0       0.0035      0.00179      0.00251            0      0.00435      0.00229      0.00629     0.000165
      6   110      0.00954      0.00947     7.57e-05       0.0028      0.00366      0.00207            0      0.00345      0.00184      0.00276            0      0.00432      0.00236        0.012     0.000316
      6   120       0.0101       0.0101     7.41e-06      0.00283      0.00379      0.00224            0      0.00337      0.00187      0.00289            0      0.00445      0.00245      0.00306     8.06e-05
      6   130       0.0106       0.0105      3.1e-05      0.00302      0.00387      0.00249            0      0.00349        0.002      0.00317            0      0.00441      0.00252      0.00769     0.000202
      6   140        0.011        0.011     1.08e-05      0.00296      0.00395      0.00204            0      0.00379      0.00194       0.0027            0      0.00481       0.0025      0.00436     0.000115
      6   142      0.00961      0.00955     5.32e-05      0.00281      0.00368        0.002            0      0.00354      0.00185      0.00265            0      0.00441      0.00235       0.0101     0.000266
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
      6    10       0.0132       0.0132     3.99e-06      0.00315      0.00433      0.00213            0      0.00407      0.00207      0.00281            0      0.00533      0.00271      0.00247     6.49e-05
      6    20      0.00894      0.00893     2.75e-06      0.00262      0.00356      0.00175            0       0.0034      0.00172      0.00235            0      0.00437      0.00224       0.0021     5.53e-05
      6    30      0.00933      0.00933     6.28e-06      0.00269      0.00364      0.00197            0      0.00335      0.00177      0.00268            0      0.00432      0.00233       0.0032     8.42e-05
      6    40      0.00944      0.00943        2e-06       0.0027      0.00366      0.00198            0      0.00335      0.00178      0.00266            0      0.00437      0.00234       0.0017     4.47e-05
      6    50      0.00898      0.00898     8.62e-07      0.00273      0.00357      0.00211            0      0.00329       0.0018      0.00283            0      0.00413      0.00232      0.00114     2.99e-05
      6    60      0.00675      0.00675     2.19e-06      0.00227      0.00309      0.00156            0      0.00292      0.00149      0.00221            0      0.00371      0.00197      0.00198      5.2e-05
      6    61       0.0106       0.0106     2.29e-06      0.00297      0.00388      0.00235            0      0.00353      0.00196      0.00312            0      0.00445      0.00252      0.00195     5.14e-05
  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train               6   58.084    0.005        0.013     8.67e-05       0.0131      0.00325       0.0043      0.00249            0      0.00393      0.00214      0.00337            0        0.005      0.00279       0.0103     0.000272
! Validation          6   58.084    0.005      0.00944     3.02e-06      0.00944      0.00268      0.00366      0.00199            0      0.00331      0.00177      0.00281            0      0.00428      0.00236      0.00207     5.45e-05
Wall time: 58.084352326986846
! Best model        6    0.009
training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
      7    10       0.0105       0.0105     5.66e-05        0.003      0.00385      0.00246            0      0.00349      0.00198      0.00315            0      0.00439      0.00251       0.0105     0.000275
      7    20       0.0306       0.0305     0.000125      0.00428      0.00658      0.00409            0      0.00446      0.00285      0.00672            0      0.00645      0.00439       0.0158     0.000415
      7    30       0.0215        0.021     0.000494      0.00453      0.00546      0.00486            0      0.00423      0.00303      0.00579            0      0.00514      0.00364       0.0316     0.000831
      7    40       0.0145       0.0145     6.14e-05      0.00343      0.00453      0.00197            0      0.00474      0.00224      0.00269            0       0.0057       0.0028       0.0112     0.000294
      7    50      0.00963      0.00959     3.53e-05      0.00276      0.00369      0.00199            0      0.00344      0.00181      0.00262            0      0.00444      0.00235      0.00845     0.000222
      7    60       0.0311       0.0311      3.7e-05      0.00421      0.00664      0.00389            0      0.00449      0.00279      0.00652            0      0.00675      0.00442      0.00829     0.000218
      7    70       0.0106       0.0106     1.85e-05      0.00288      0.00388      0.00197            0       0.0037      0.00189      0.00272            0      0.00468      0.00247      0.00529     0.000139
      7    80      0.00964      0.00963     1.12e-05      0.00277       0.0037      0.00205            0      0.00342      0.00182      0.00268            0      0.00442      0.00236       0.0043     0.000113
      7    90      0.00671       0.0067     1.01e-05      0.00239      0.00308      0.00183            0      0.00289      0.00158      0.00238            0       0.0036      0.00199      0.00417      0.00011
      7   100      0.00953      0.00951     2.01e-05      0.00284      0.00367      0.00241            0      0.00324      0.00188      0.00301            0      0.00418       0.0024      0.00619     0.000163
      7   110      0.00882      0.00882     4.06e-06      0.00269      0.00354      0.00207            0      0.00326      0.00178      0.00281            0      0.00408       0.0023      0.00269     7.07e-05
      7   120      0.00888      0.00888     6.82e-07      0.00263      0.00355      0.00199            0      0.00321      0.00173      0.00258            0      0.00423      0.00227      0.00104     2.73e-05
      7   130       0.0104       0.0104     5.47e-05      0.00294      0.00383      0.00237            0      0.00345      0.00194      0.00309            0       0.0044       0.0025       0.0104     0.000273
      7   140      0.00808        0.008     8.78e-05      0.00258      0.00337      0.00193            0      0.00316       0.0017      0.00256            0      0.00396      0.00217       0.0132     0.000347
      7   142      0.00945      0.00934     0.000118      0.00283      0.00364      0.00196            0      0.00362      0.00186      0.00251            0      0.00442      0.00231       0.0155     0.000409
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
      7    10       0.0118       0.0117     4.46e-06      0.00296      0.00408      0.00203            0       0.0038      0.00195      0.00271            0      0.00501      0.00257      0.00256     6.75e-05
      7    20        0.008        0.008      2.6e-06      0.00247      0.00337      0.00165            0       0.0032      0.00162      0.00226            0      0.00412      0.00213      0.00193     5.08e-05
      7    30      0.00829      0.00828     5.83e-06      0.00252      0.00343      0.00188            0      0.00309      0.00166      0.00258            0      0.00404      0.00221      0.00311     8.19e-05
      7    40      0.00827      0.00827     2.02e-06      0.00252      0.00342      0.00188            0      0.00309      0.00166      0.00254            0      0.00406       0.0022      0.00162     4.27e-05
      7    50      0.00777      0.00777     9.88e-07      0.00252      0.00332      0.00199            0        0.003      0.00167      0.00268            0       0.0038      0.00216      0.00128     3.37e-05
      7    60      0.00589      0.00588     1.91e-06      0.00213      0.00289       0.0015            0       0.0027       0.0014      0.00212            0      0.00344      0.00185      0.00181     4.75e-05
      7    61      0.00945      0.00945     2.22e-06      0.00282      0.00366      0.00223            0      0.00334      0.00186      0.00299            0      0.00418      0.00239      0.00189     4.98e-05
  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train               7   66.712    0.005       0.0106     4.78e-05       0.0106      0.00289      0.00388      0.00223            0      0.00349      0.00191      0.00308            0      0.00447      0.00252      0.00749     0.000197
! Validation          7   66.712    0.005      0.00838     2.99e-06      0.00839      0.00252      0.00345       0.0019            0      0.00307      0.00166       0.0027            0        0.004      0.00223      0.00204     5.36e-05
Wall time: 66.7124297839764
! Best model        7    0.008
training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
      8    10      0.00807      0.00803     3.29e-05      0.00256      0.00338      0.00198            0      0.00309      0.00169      0.00265            0      0.00391      0.00219      0.00791     0.000208
      8    20      0.00948      0.00947     5.04e-06       0.0028      0.00367      0.00213            0       0.0034      0.00184       0.0028            0       0.0043      0.00237      0.00286     7.52e-05
      8    30       0.0079       0.0079     8.25e-06      0.00262      0.00335      0.00203            0      0.00315      0.00173      0.00264            0      0.00387      0.00217       0.0033     8.67e-05
      8    40      0.00949      0.00949     3.69e-06      0.00277      0.00367      0.00224            0      0.00324      0.00183        0.003            0      0.00418      0.00239      0.00244     6.42e-05
      8    50       0.0071      0.00709     8.78e-06      0.00245      0.00317       0.0018            0      0.00304      0.00161      0.00232            0      0.00378      0.00203      0.00336     8.83e-05
      8    60      0.00766      0.00765     2.87e-06      0.00252      0.00329       0.0019            0      0.00307      0.00166       0.0025            0      0.00387      0.00212      0.00236      6.2e-05
      8    70       0.0137       0.0136     0.000131      0.00352      0.00439       0.0027            0      0.00426      0.00232      0.00331            0      0.00518      0.00283       0.0162     0.000426
      8    80       0.0103       0.0103     4.63e-05      0.00301      0.00382      0.00259            0      0.00339      0.00199      0.00317            0      0.00431       0.0025      0.00956     0.000252
      8    90      0.00813      0.00806     7.12e-05      0.00265      0.00338      0.00225            0      0.00301      0.00176      0.00289            0      0.00377      0.00222        0.012     0.000315
      8   100      0.00873      0.00867     5.98e-05      0.00273      0.00351      0.00206            0      0.00334       0.0018      0.00267            0      0.00412      0.00226       0.0109     0.000286
      8   110      0.00889      0.00882     6.15e-05      0.00279      0.00354      0.00283            0      0.00276      0.00186      0.00357            0      0.00351      0.00236        0.011      0.00029
      8   120      0.00812      0.00811     4.54e-06      0.00266      0.00339      0.00194            0      0.00331      0.00175      0.00247            0      0.00405      0.00217      0.00264     6.94e-05
      8   130      0.00924      0.00919     4.37e-05       0.0027      0.00361      0.00179            0      0.00351      0.00177      0.00242            0      0.00442      0.00228      0.00914     0.000241
      8   140      0.00839      0.00831     7.88e-05      0.00265      0.00343      0.00214            0      0.00311      0.00175      0.00279            0      0.00392      0.00224       0.0127     0.000334
      8   142       0.0398       0.0397     3.18e-05      0.00496      0.00751      0.00487            0      0.00503       0.0033       0.0074            0       0.0076        0.005      0.00783     0.000206
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
      8    10       0.0104       0.0104     3.59e-06      0.00279      0.00384      0.00195            0      0.00354      0.00183      0.00263            0      0.00467      0.00243      0.00228     6.01e-05
      8    20      0.00719      0.00719     2.59e-06      0.00234      0.00319      0.00157            0      0.00302      0.00153      0.00218            0      0.00389      0.00202      0.00175     4.59e-05
      8    30      0.00746      0.00746     4.93e-06      0.00237      0.00325       0.0018            0      0.00289      0.00156      0.00248            0      0.00381       0.0021      0.00294     7.74e-05
      8    40      0.00734      0.00734     1.78e-06      0.00236      0.00323      0.00179            0      0.00288      0.00155      0.00243            0       0.0038      0.00208       0.0014     3.69e-05
      8    50      0.00684      0.00684     1.31e-06      0.00235      0.00312      0.00187            0      0.00278      0.00155      0.00255            0      0.00355      0.00203      0.00139     3.66e-05
      8    60      0.00521      0.00521     1.72e-06        0.002      0.00272      0.00144            0      0.00251      0.00132      0.00204            0      0.00321      0.00175      0.00155     4.08e-05
      8    61      0.00859      0.00859     2.62e-06      0.00268      0.00349      0.00212            0      0.00319      0.00177      0.00287            0      0.00397      0.00228      0.00203     5.34e-05
  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train               8   75.332    0.005      0.00997     5.07e-05         0.01       0.0028      0.00375      0.00217            0      0.00336      0.00184      0.00299            0      0.00431      0.00243       0.0085     0.000224
! Validation          8   75.332    0.005      0.00754     2.95e-06      0.00754      0.00238      0.00327      0.00182            0      0.00288      0.00157      0.00261            0      0.00376      0.00213      0.00203     5.34e-05
Wall time: 75.33232656097971
! Best model        8    0.008
training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
      9    10       0.0197       0.0195     0.000196      0.00399      0.00526      0.00216            0      0.00564       0.0026       0.0028            0      0.00675      0.00318       0.0199     0.000525
      9    20      0.00822      0.00817      5.4e-05      0.00263       0.0034      0.00203            0      0.00316      0.00173      0.00264            0      0.00397       0.0022       0.0101     0.000265
      9    30      0.00766      0.00765     8.24e-06      0.00253      0.00329      0.00203            0      0.00298      0.00167      0.00267            0      0.00377      0.00215      0.00322     8.48e-05
      9    40      0.00903      0.00896     7.22e-05      0.00274      0.00356      0.00238            0      0.00307      0.00182      0.00305            0      0.00397      0.00234       0.0119     0.000314
      9    50      0.00793      0.00792     1.65e-05      0.00256      0.00335      0.00194            0      0.00312      0.00168      0.00255            0      0.00393      0.00216      0.00505     0.000133
      9    60      0.00809      0.00806     2.95e-05      0.00258      0.00338      0.00176            0      0.00331      0.00169      0.00235            0      0.00409      0.00215      0.00764     0.000201
      9    70       0.0125       0.0125     1.04e-05      0.00315      0.00421      0.00194            0      0.00425      0.00206      0.00259            0      0.00526      0.00262      0.00403     0.000106
      9    80      0.00779      0.00779     5.23e-06      0.00251      0.00332       0.0018            0      0.00315      0.00165      0.00246            0      0.00394      0.00213      0.00293     7.71e-05
      9    90       0.0121       0.0117     0.000338      0.00299      0.00408      0.00179            0      0.00406      0.00195       0.0024            0      0.00514      0.00251       0.0263     0.000692
      9   100      0.00805      0.00797      7.9e-05      0.00255      0.00336      0.00187            0      0.00316      0.00168      0.00253            0      0.00396      0.00216       0.0127     0.000333
      9   110      0.00783      0.00759     0.000241      0.00254      0.00328      0.00199            0      0.00303      0.00167      0.00269            0      0.00374      0.00214       0.0222     0.000584
      9   120      0.00749      0.00749     4.31e-06      0.00248      0.00326      0.00195            0      0.00296      0.00164      0.00261            0      0.00375      0.00212      0.00271     7.13e-05
      9   130      0.00815      0.00811     3.97e-05      0.00248      0.00339      0.00186            0      0.00305      0.00163      0.00253            0      0.00401      0.00218       0.0084     0.000221
      9   140      0.00796      0.00792     4.35e-05      0.00262      0.00335       0.0022            0      0.00299      0.00173      0.00281            0      0.00377       0.0022      0.00901     0.000237
      9   142      0.00594      0.00594     5.77e-06      0.00219       0.0029      0.00191            0      0.00243      0.00145      0.00254            0      0.00319      0.00191      0.00236     6.21e-05
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
      9    10      0.00937      0.00936     3.64e-06      0.00263      0.00364      0.00186            0      0.00332      0.00173      0.00255            0       0.0044      0.00232      0.00233     6.14e-05
      9    20      0.00656      0.00656     2.46e-06      0.00223      0.00305      0.00153            0      0.00287      0.00147      0.00212            0       0.0037      0.00194      0.00172     4.53e-05
      9    30      0.00679      0.00678     4.93e-06      0.00226       0.0031      0.00173            0      0.00273      0.00149      0.00241            0      0.00362      0.00201        0.003      7.9e-05
      9    40      0.00669      0.00669     1.63e-06      0.00225      0.00308      0.00173            0      0.00272      0.00148      0.00235            0      0.00361      0.00199      0.00134     3.53e-05
      9    50      0.00619      0.00619     1.34e-06      0.00223      0.00296      0.00179            0      0.00262      0.00147      0.00245            0      0.00336      0.00194       0.0014     3.69e-05
      9    60      0.00473      0.00473     1.71e-06       0.0019      0.00259       0.0014            0      0.00235      0.00125        0.002            0      0.00303      0.00167      0.00149     3.92e-05
      9    61      0.00789      0.00789      2.8e-06      0.00256      0.00335      0.00203            0      0.00304      0.00169      0.00279            0      0.00378      0.00219      0.00215     5.66e-05
  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train               9   83.958    0.005      0.00989     8.18e-05      0.00997      0.00278      0.00375      0.00217            0      0.00333      0.00183      0.00301            0      0.00431      0.00244       0.0104     0.000273
! Validation          9   83.958    0.005      0.00691      2.9e-06      0.00691      0.00227      0.00313      0.00176            0      0.00272      0.00149      0.00255            0      0.00358      0.00204      0.00203     5.33e-05
Wall time: 83.9591156669776
! Best model        9    0.007
training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     10    10       0.0075       0.0075     3.87e-06       0.0025      0.00326      0.00205            0      0.00292      0.00165      0.00266            0      0.00372      0.00213       0.0026     6.84e-05
     10    20      0.00607      0.00601     5.99e-05       0.0023      0.00292      0.00194            0      0.00262      0.00152      0.00252            0      0.00324      0.00192       0.0109     0.000286
     10    30      0.00586      0.00585     1.31e-05      0.00218      0.00288      0.00173            0      0.00258      0.00144      0.00237            0      0.00327      0.00188      0.00503     0.000132
     10    40      0.00647      0.00646     3.72e-06      0.00228      0.00303      0.00174            0      0.00277       0.0015      0.00229            0      0.00357      0.00195      0.00237     6.23e-05
     10    50      0.00652      0.00652      7.4e-06      0.00234      0.00304      0.00182            0      0.00281      0.00154      0.00242            0      0.00351      0.00198      0.00381       0.0001
     10    60      0.00883      0.00882     1.35e-05      0.00266      0.00354      0.00183            0      0.00341      0.00175       0.0025            0      0.00426      0.00225      0.00488     0.000128
     10    70      0.00866      0.00859     7.05e-05      0.00262      0.00349      0.00194            0      0.00324      0.00173      0.00257            0      0.00415      0.00224       0.0118      0.00031
     10    80       0.0339       0.0338     6.13e-05      0.00441      0.00692      0.00378            0      0.00499      0.00292      0.00602            0      0.00765      0.00455       0.0109     0.000288
     10    90      0.00716      0.00709      6.9e-05      0.00243      0.00317       0.0021            0      0.00273      0.00161      0.00274            0      0.00351      0.00208       0.0115     0.000302
     10   100       0.0125       0.0123     0.000129      0.00344      0.00418      0.00315            0       0.0037      0.00228      0.00374            0      0.00455      0.00276       0.0162     0.000426
     10   110      0.00788      0.00781     6.33e-05      0.00253      0.00333      0.00193            0      0.00308      0.00167      0.00266            0      0.00383      0.00216       0.0109     0.000288
     10   120      0.00895      0.00892     2.68e-05       0.0027      0.00356      0.00197            0      0.00336      0.00178      0.00255            0      0.00427      0.00227      0.00721      0.00019
     10   130      0.00848      0.00835      0.00013       0.0027      0.00344      0.00242            0      0.00296      0.00179      0.00302            0      0.00378      0.00227       0.0162     0.000425
     10   140      0.00674      0.00672      1.5e-05       0.0024      0.00309      0.00214            0      0.00263      0.00159      0.00276            0      0.00336      0.00204      0.00459     0.000121
     10   142      0.00849      0.00834     0.000145      0.00254      0.00344       0.0019            0      0.00312      0.00167      0.00251            0       0.0041       0.0022       0.0171      0.00045
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     10    10      0.00851      0.00851     3.35e-06      0.00249      0.00347       0.0018            0      0.00312      0.00164      0.00248            0      0.00417      0.00222      0.00236      6.2e-05
     10    20      0.00597      0.00597     2.69e-06      0.00214      0.00291      0.00149            0      0.00272       0.0014      0.00206            0       0.0035      0.00185      0.00188     4.95e-05
     10    30      0.00623      0.00622     4.53e-06      0.00216      0.00297      0.00167            0       0.0026      0.00142      0.00234            0      0.00344      0.00193      0.00291     7.65e-05
     10    40      0.00609      0.00608     1.48e-06      0.00215      0.00294      0.00168            0      0.00257      0.00142      0.00228            0      0.00342       0.0019       0.0014     3.69e-05
     10    50      0.00554      0.00554      1.8e-06      0.00211       0.0028      0.00172            0      0.00246      0.00139      0.00237            0      0.00314      0.00184      0.00167      4.4e-05
     10    60      0.00432      0.00432     1.58e-06      0.00182      0.00247      0.00137            0      0.00222       0.0012      0.00195            0      0.00287       0.0016      0.00123     3.24e-05
     10    61      0.00722      0.00721     2.99e-06      0.00245       0.0032      0.00197            0      0.00287      0.00162      0.00271            0      0.00358       0.0021      0.00221     5.82e-05
  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              10   92.579    0.005      0.00889     5.11e-05      0.00894      0.00263      0.00355      0.00208            0      0.00313      0.00174       0.0029            0      0.00405      0.00232      0.00787     0.000207
! Validation         10   92.579    0.005      0.00635     2.93e-06      0.00635      0.00217        0.003      0.00171            0      0.00257      0.00143      0.00248            0       0.0034      0.00196      0.00206     5.42e-05
Wall time: 92.5801963690028
! Best model       10    0.006
training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     11    10      0.00749      0.00749     3.98e-06      0.00243      0.00326      0.00186            0      0.00296       0.0016      0.00249            0      0.00382       0.0021       0.0027      7.1e-05
     11    20      0.00565      0.00564      9.5e-06      0.00212      0.00283      0.00154            0      0.00265      0.00139      0.00209            0      0.00336      0.00182      0.00385     0.000101
     11    30       0.0077      0.00764     5.85e-05      0.00259      0.00329      0.00205            0      0.00307      0.00171      0.00262            0       0.0038      0.00214       0.0107     0.000282
     11    40      0.00564      0.00563      1.5e-05      0.00214      0.00283      0.00164            0      0.00258      0.00141       0.0022            0      0.00329      0.00183      0.00502     0.000132
     11    50      0.00586      0.00571     0.000148      0.00218      0.00285       0.0016            0       0.0027      0.00143      0.00218            0      0.00333      0.00184       0.0173     0.000456
     11    60       0.0076      0.00732     0.000276      0.00246      0.00322      0.00194            0      0.00292      0.00162      0.00261            0      0.00369       0.0021       0.0237     0.000624
     11    70      0.00584      0.00584     3.17e-06      0.00226      0.00288      0.00216            0      0.00234       0.0015      0.00271            0      0.00302      0.00191      0.00214     5.62e-05
     11    80      0.00732      0.00704     0.000279      0.00254      0.00316      0.00221            0      0.00284      0.00168      0.00272            0      0.00351      0.00208       0.0237     0.000624
     11    90      0.00592      0.00587      5.1e-05      0.00221      0.00289      0.00169            0      0.00268      0.00145      0.00235            0       0.0033      0.00188      0.00975     0.000257
     11   100      0.00799      0.00797     1.81e-05      0.00253      0.00336       0.0019            0      0.00311      0.00167      0.00255            0      0.00396      0.00217      0.00582     0.000153
     11   110      0.00603      0.00591     0.000122      0.00219       0.0029      0.00171            0      0.00261      0.00144      0.00235            0      0.00331      0.00189       0.0156     0.000412
     11   120      0.00934      0.00932     2.54e-05      0.00293      0.00364      0.00276            0      0.00308      0.00195       0.0034            0      0.00384      0.00241      0.00658     0.000173
     11   130       0.0114       0.0113     0.000129      0.00302        0.004      0.00193            0        0.004      0.00198      0.00255            0      0.00496       0.0025       0.0161     0.000424
     11   140      0.00787      0.00766     0.000205      0.00252       0.0033      0.00222            0      0.00279      0.00167      0.00274            0      0.00373      0.00216       0.0205     0.000538
     11   142       0.0461        0.046     2.48e-05       0.0053      0.00808       0.0054            0       0.0052      0.00354       0.0081            0      0.00806      0.00539      0.00708     0.000186
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     11    10      0.00767      0.00767     3.47e-06      0.00236       0.0033      0.00175            0      0.00292      0.00156      0.00242            0      0.00392      0.00211      0.00236      6.2e-05
     11    20      0.00557      0.00557     2.42e-06      0.00207      0.00281      0.00145            0      0.00262      0.00136      0.00201            0      0.00337      0.00179      0.00184     4.85e-05
     11    30      0.00573      0.00573     4.27e-06      0.00208      0.00285      0.00161            0      0.00249      0.00137      0.00227            0      0.00329      0.00185      0.00281     7.39e-05
     11    40      0.00566      0.00566     1.59e-06      0.00208      0.00283      0.00164            0      0.00248      0.00137      0.00222            0      0.00329      0.00184      0.00144     3.79e-05
     11    50      0.00504      0.00503     1.66e-06      0.00201      0.00267      0.00165            0      0.00233      0.00133      0.00228            0      0.00298      0.00175       0.0016     4.21e-05
     11    60      0.00401      0.00401     1.56e-06      0.00175      0.00239      0.00135            0       0.0021      0.00115      0.00191            0      0.00275      0.00155      0.00125     3.28e-05
     11    61      0.00665      0.00665     2.62e-06      0.00234      0.00307      0.00191            0      0.00273      0.00155      0.00263            0      0.00342      0.00202      0.00206     5.42e-05
  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              11  101.271    0.005      0.00799     6.22e-05      0.00805      0.00246      0.00334      0.00199            0      0.00288      0.00163       0.0028            0      0.00377      0.00219      0.00922     0.000243
! Validation         11  101.271    0.005      0.00587     2.74e-06      0.00587      0.00208      0.00289      0.00167            0      0.00245      0.00137      0.00242            0      0.00324      0.00189      0.00199     5.24e-05
Wall time: 101.272163059999
! Best model       11    0.006
training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     12    10      0.00875      0.00872     3.28e-05       0.0027      0.00352      0.00178            0      0.00353      0.00177      0.00231            0      0.00432      0.00221       0.0076       0.0002
     12    20      0.00869      0.00869     4.36e-06      0.00259      0.00351       0.0018            0       0.0033       0.0017      0.00242            0      0.00426      0.00223      0.00292     7.68e-05
     12    30       0.0106       0.0106     5.06e-06      0.00307      0.00388      0.00282            0       0.0033      0.00204      0.00357            0      0.00415      0.00257      0.00231     6.07e-05
     12    40      0.00744      0.00735     8.97e-05      0.00249      0.00323       0.0021            0      0.00284      0.00164      0.00269            0      0.00364      0.00211       0.0131     0.000345
     12    50      0.00865      0.00859     5.93e-05      0.00278      0.00349      0.00209            0      0.00341      0.00183       0.0026            0      0.00414      0.00224       0.0109     0.000288
     12    60      0.00954      0.00939     0.000148       0.0029      0.00365       0.0026            0      0.00317      0.00192      0.00316            0      0.00404       0.0024       0.0173     0.000455
     12    70      0.00598      0.00596     2.91e-05      0.00225      0.00291      0.00169            0      0.00276      0.00148      0.00218            0      0.00343      0.00187      0.00757     0.000199
     12    80      0.00554      0.00554     1.76e-06      0.00212       0.0028      0.00181            0       0.0024       0.0014      0.00241            0      0.00311      0.00184      0.00157     4.14e-05
     12    90        0.013        0.013      5.4e-05      0.00322      0.00429      0.00216            0      0.00418      0.00211      0.00268            0      0.00534      0.00267       0.0102      0.00027
     12   100      0.00846      0.00846     4.85e-06      0.00272      0.00346      0.00222            0      0.00317      0.00179      0.00277            0      0.00398      0.00225      0.00277     7.29e-05
     12   110      0.00477      0.00476     9.22e-06      0.00195       0.0026      0.00141            0      0.00244      0.00128      0.00191            0      0.00309      0.00167      0.00426     0.000112
     12   120       0.0063       0.0063        3e-06      0.00231      0.00299      0.00181            0      0.00276      0.00152      0.00235            0      0.00347      0.00194      0.00228     6.01e-05
     12   130      0.00621      0.00609     0.000121      0.00228      0.00294      0.00194            0      0.00259      0.00151      0.00251            0      0.00328      0.00193       0.0156      0.00041
     12   140      0.00611      0.00603      7.6e-05      0.00221      0.00293      0.00185            0      0.00253      0.00146      0.00245            0      0.00329      0.00192       0.0123     0.000325
     12   142      0.00588       0.0057     0.000183       0.0022      0.00284      0.00191            0      0.00246      0.00146      0.00248            0      0.00313      0.00187       0.0192     0.000505
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     12    10      0.00706      0.00706     3.01e-06      0.00226      0.00316       0.0017            0      0.00277      0.00149      0.00235            0      0.00375      0.00203      0.00229     6.04e-05
     12    20      0.00513      0.00513     2.33e-06      0.00199       0.0027      0.00141            0       0.0025       0.0013      0.00195            0      0.00323      0.00173      0.00182     4.79e-05
     12    30       0.0053      0.00529     3.88e-06      0.00199      0.00274      0.00156            0      0.00237      0.00131      0.00219            0      0.00315      0.00178      0.00267     7.04e-05
     12    40      0.00524      0.00524     1.37e-06      0.00201      0.00273       0.0016            0      0.00239      0.00133      0.00216            0      0.00315      0.00177      0.00143     3.76e-05
     12    50      0.00461      0.00461     1.87e-06      0.00193      0.00256      0.00161            0      0.00222      0.00127      0.00222            0      0.00283      0.00168      0.00168     4.43e-05
     12    60       0.0037      0.00369     1.59e-06      0.00168      0.00229      0.00132            0      0.00201      0.00111      0.00185            0      0.00262      0.00149      0.00122     3.21e-05
     12    61      0.00613      0.00613     3.21e-06      0.00224      0.00295      0.00185            0      0.00259      0.00148      0.00255            0      0.00326      0.00194      0.00223     5.86e-05
  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              12  111.019    0.005      0.00819     7.15e-05      0.00826      0.00253      0.00341      0.00198            0      0.00301      0.00167      0.00275            0      0.00391      0.00222      0.00971     0.000255
! Validation         12  111.019    0.005      0.00547     2.65e-06      0.00547        0.002      0.00278      0.00162            0      0.00234      0.00132      0.00236            0      0.00311      0.00183      0.00198     5.21e-05
Wall time: 111.02014369799872
! Best model       12    0.005
training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     13    10      0.00686      0.00678     8.89e-05      0.00237       0.0031      0.00173            0      0.00294      0.00156      0.00227            0      0.00369      0.00199       0.0131     0.000345
     13    20      0.00681      0.00681     1.94e-06      0.00232      0.00311      0.00158            0      0.00298      0.00152      0.00208            0       0.0038      0.00196      0.00157     4.14e-05
     13    30       0.0064       0.0064     4.87e-06      0.00232      0.00301       0.0018            0      0.00279      0.00153      0.00231            0      0.00353      0.00195      0.00259     6.81e-05
     13    40      0.00658      0.00657     7.45e-06      0.00235      0.00305        0.002            0      0.00267      0.00155      0.00253            0      0.00346        0.002      0.00355     9.35e-05
     13    50      0.00622      0.00615     6.54e-05      0.00226      0.00295      0.00165            0      0.00281      0.00149      0.00225            0      0.00347      0.00191       0.0115     0.000303
     13    60      0.00889      0.00877     0.000115       0.0028      0.00353      0.00242            0      0.00315      0.00185        0.003            0      0.00394      0.00231       0.0152       0.0004
     13    70      0.00621      0.00615     6.06e-05      0.00225      0.00295      0.00163            0      0.00282      0.00148      0.00212            0      0.00354      0.00189        0.011      0.00029
     13    80       0.0057      0.00569     6.45e-06      0.00212      0.00284      0.00169            0      0.00251       0.0014       0.0022            0      0.00331      0.00184      0.00332     8.74e-05
     13    90      0.00527      0.00527     1.28e-06      0.00207      0.00273      0.00145            0      0.00263      0.00136      0.00193            0       0.0033      0.00174       0.0015     3.95e-05
     13   100      0.00561       0.0056     1.58e-05      0.00212      0.00282      0.00149            0      0.00268      0.00139      0.00206            0      0.00336       0.0018       0.0053     0.000139
     13   110      0.00492      0.00492      6.3e-06      0.00202      0.00264      0.00157            0      0.00242      0.00133      0.00216            0      0.00301      0.00172       0.0026     6.84e-05
     13   120      0.00583      0.00583     7.04e-06      0.00219      0.00287      0.00173            0       0.0026      0.00144      0.00233            0      0.00329      0.00187      0.00327     8.61e-05
     13   130      0.00461       0.0046     6.06e-06      0.00191      0.00255      0.00147            0      0.00231      0.00126      0.00202            0      0.00295      0.00166      0.00305     8.03e-05
     13   140       0.0061       0.0061     2.03e-06      0.00235      0.00294      0.00191            0      0.00275      0.00155      0.00238            0      0.00337      0.00192       0.0019     5.01e-05
     13   142      0.00571      0.00569     2.11e-05      0.00214      0.00284      0.00147            0      0.00275      0.00141      0.00189            0      0.00348      0.00179      0.00631     0.000166
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     13    10       0.0064      0.00639     3.57e-06      0.00216      0.00301      0.00165            0      0.00262      0.00143      0.00228            0      0.00354      0.00194      0.00239      6.3e-05
     13    20      0.00479      0.00479     2.24e-06      0.00192      0.00261      0.00138            0      0.00241      0.00126      0.00189            0      0.00311      0.00167      0.00172     4.53e-05
     13    30      0.00494      0.00493     3.76e-06      0.00192      0.00265      0.00151            0      0.00228      0.00127      0.00212            0      0.00304      0.00172      0.00256     6.75e-05
     13    40      0.00489      0.00489     1.48e-06      0.00195      0.00263      0.00155            0       0.0023      0.00128      0.00209            0      0.00304      0.00171      0.00133      3.5e-05
     13    50      0.00426      0.00426     1.54e-06      0.00185      0.00246      0.00156            0      0.00211      0.00123      0.00216            0       0.0027      0.00162      0.00156     4.11e-05
     13    60      0.00343      0.00343     1.48e-06      0.00163       0.0022      0.00129            0      0.00193      0.00107      0.00181            0      0.00251      0.00144      0.00129     3.41e-05
     13    61      0.00569      0.00569      2.4e-06      0.00215      0.00284      0.00178            0      0.00247      0.00142      0.00247            0      0.00314      0.00187      0.00188     4.94e-05
  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              13  120.860    0.005      0.00766      4.2e-05       0.0077      0.00242       0.0033      0.00191            0      0.00288      0.00159      0.00268            0      0.00376      0.00215      0.00712     0.000187
! Validation         13  120.860    0.005      0.00511      2.4e-06      0.00512      0.00193      0.00269      0.00158            0      0.00224      0.00127      0.00231            0        0.003      0.00177      0.00185     4.87e-05
Wall time: 120.86078826498124
! Best model       13    0.005
training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     14    10      0.00538      0.00537     1.49e-05      0.00213      0.00276      0.00185            0      0.00238      0.00141      0.00236            0      0.00307      0.00181       0.0052     0.000137
     14    20      0.00394      0.00393     6.76e-06       0.0018      0.00236      0.00148            0      0.00208      0.00119      0.00199            0      0.00265      0.00155      0.00298     7.84e-05
     14    30      0.00446      0.00445      9.4e-06      0.00195      0.00251      0.00153            0      0.00232      0.00128      0.00199            0       0.0029      0.00163      0.00397     0.000104
     14    40       0.0049      0.00489     7.39e-06      0.00197      0.00263      0.00158            0      0.00233       0.0013      0.00216            0        0.003      0.00172      0.00367     9.67e-05
     14    50      0.00548      0.00542     5.13e-05      0.00217      0.00277      0.00188            0      0.00243      0.00144      0.00245            0      0.00304      0.00183      0.00997     0.000262
     14    60       0.0262       0.0262     2.41e-06      0.00357       0.0061      0.00342            0      0.00371      0.00238      0.00593            0      0.00625      0.00406      0.00188     4.95e-05
     14    70      0.00635      0.00635     4.56e-06      0.00235        0.003      0.00174            0      0.00289      0.00154      0.00226            0      0.00353      0.00193      0.00244     6.42e-05
     14    80      0.00514      0.00512     2.03e-05      0.00206      0.00269      0.00162            0      0.00245      0.00136      0.00214            0      0.00311      0.00175       0.0061     0.000161
     14    90      0.00481      0.00481     1.51e-06        0.002      0.00261      0.00177            0      0.00221      0.00133      0.00234            0      0.00283      0.00172      0.00155     4.08e-05
     14   100      0.00478      0.00477     1.29e-05      0.00198       0.0026      0.00172            0      0.00222      0.00131      0.00231            0      0.00284      0.00172      0.00469     0.000123
     14   110      0.00743      0.00743     4.53e-06      0.00243      0.00325      0.00175            0      0.00304       0.0016      0.00233            0      0.00389      0.00207       0.0024     6.33e-05
     14   120      0.00675      0.00671     4.03e-05      0.00242      0.00308        0.002            0       0.0028       0.0016      0.00246            0      0.00355        0.002      0.00885     0.000233
     14   130      0.00621      0.00615     5.85e-05      0.00233      0.00295      0.00194            0      0.00269      0.00154      0.00245            0      0.00334      0.00193       0.0107     0.000282
     14   140      0.00672      0.00672     4.53e-06      0.00235      0.00309      0.00157            0      0.00306      0.00154      0.00208            0      0.00377      0.00195      0.00233     6.14e-05
     14   142      0.00625      0.00623      1.6e-05      0.00236      0.00297      0.00255            0      0.00218      0.00158      0.00315            0      0.00281      0.00199      0.00535     0.000141
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     14    10       0.0058       0.0058     3.35e-06      0.00207      0.00287      0.00161            0      0.00249      0.00137      0.00221            0      0.00335      0.00185       0.0024     6.33e-05
     14    20      0.00443      0.00443     2.16e-06      0.00185      0.00251      0.00135            0      0.00231      0.00122      0.00184            0      0.00298      0.00161      0.00179     4.72e-05
     14    30      0.00453      0.00452     3.39e-06      0.00183      0.00253      0.00146            0      0.00217      0.00121      0.00205            0       0.0029      0.00165      0.00243     6.39e-05
     14    40      0.00452      0.00452     1.46e-06      0.00187      0.00253      0.00151            0      0.00219      0.00123      0.00202            0      0.00292      0.00165       0.0014     3.69e-05
     14    50      0.00384      0.00383     1.61e-06      0.00175      0.00233      0.00151            0      0.00198      0.00116      0.00207            0      0.00254      0.00154      0.00161     4.24e-05
     14    60      0.00314      0.00313     1.46e-06      0.00157      0.00211      0.00126            0      0.00185      0.00103      0.00175            0      0.00238      0.00138      0.00126     3.31e-05
     14    61      0.00522      0.00522     2.55e-06      0.00204      0.00272      0.00172            0      0.00233      0.00135      0.00238            0      0.00299      0.00179      0.00194      5.1e-05
  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              14  130.227    0.005      0.00665     1.93e-05      0.00667      0.00224      0.00307      0.00179            0      0.00265      0.00148      0.00255            0      0.00348      0.00201      0.00504     0.000133
! Validation         14  130.227    0.005      0.00473     2.33e-06      0.00473      0.00184      0.00259      0.00153            0      0.00213      0.00122      0.00225            0      0.00286       0.0017      0.00186     4.88e-05
Wall time: 130.22769240598427
! Best model       14    0.005
training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     15    10      0.00747      0.00744     3.11e-05      0.00255      0.00325      0.00245            0      0.00264      0.00169      0.00306            0      0.00341      0.00216      0.00714     0.000188
     15    20      0.00612      0.00612     7.45e-06      0.00219      0.00295      0.00157            0      0.00275      0.00144      0.00212            0      0.00353      0.00188      0.00363     9.54e-05
     15    30      0.00619      0.00617      2.1e-05      0.00226      0.00296      0.00167            0      0.00279      0.00149      0.00221            0       0.0035       0.0019      0.00616     0.000162
     15    40      0.00492      0.00492     2.52e-06      0.00196      0.00264      0.00138            0      0.00248      0.00129      0.00197            0      0.00313       0.0017      0.00186     4.88e-05
     15    50      0.00488      0.00483     4.35e-05      0.00199      0.00262      0.00171            0      0.00223      0.00131      0.00227            0       0.0029      0.00172      0.00942     0.000248
     15    60      0.00898      0.00896     1.97e-05      0.00289      0.00357      0.00283            0      0.00294      0.00192      0.00343            0      0.00369      0.00237      0.00632     0.000166
     15    70       0.0071      0.00709     6.88e-06      0.00252      0.00317      0.00208            0      0.00291      0.00166      0.00267            0      0.00356      0.00208      0.00309     8.13e-05
     15    80      0.00433      0.00433     6.44e-06      0.00191      0.00248      0.00177            0      0.00203      0.00127      0.00231            0      0.00262      0.00164      0.00343     9.03e-05
     15    90      0.00379      0.00377     2.44e-05      0.00178      0.00231      0.00155            0      0.00198      0.00118      0.00204            0      0.00253      0.00152      0.00688     0.000181
     15   100      0.00412      0.00411     5.31e-06      0.00181      0.00242      0.00138            0      0.00219      0.00119      0.00191            0      0.00279      0.00157      0.00266        7e-05
     15   110       0.0235       0.0235      9.8e-06      0.00339      0.00577      0.00331            0      0.00347      0.00226      0.00603            0      0.00552      0.00385      0.00397     0.000104
     15   120      0.00475      0.00473      2.1e-05        0.002      0.00259      0.00158            0      0.00238      0.00132      0.00203            0        0.003      0.00168      0.00615     0.000162
     15   130       0.0141       0.0141     3.09e-06      0.00358      0.00447      0.00256            0       0.0045      0.00235      0.00305            0      0.00544      0.00283      0.00229     6.04e-05
     15   140      0.00909      0.00901     7.68e-05      0.00276      0.00358      0.00178            0      0.00364      0.00181      0.00234            0       0.0044      0.00225       0.0124     0.000327
     15   142       0.0069      0.00686     3.77e-05      0.00228      0.00312      0.00147            0      0.00301      0.00149      0.00188            0      0.00391      0.00193      0.00877     0.000231
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     15    10      0.00533      0.00532     2.85e-06        0.002      0.00275      0.00158            0      0.00237      0.00132      0.00215            0      0.00319      0.00178      0.00226     5.94e-05
     15    20      0.00414      0.00414     2.22e-06       0.0018      0.00242       0.0013            0      0.00224      0.00118      0.00179            0      0.00288      0.00156      0.00181     4.75e-05
     15    30      0.00421       0.0042      3.2e-06      0.00176      0.00244      0.00141            0      0.00208      0.00116      0.00199            0      0.00279      0.00159      0.00239      6.3e-05
     15    40       0.0042       0.0042     1.27e-06       0.0018      0.00244      0.00146            0      0.00211      0.00119      0.00196            0       0.0028      0.00159       0.0014     3.69e-05
     15    50      0.00352      0.00352     1.67e-06      0.00168      0.00223      0.00145            0      0.00188      0.00111      0.00199            0      0.00243      0.00147      0.00162     4.27e-05
     15    60       0.0029       0.0029     1.35e-06      0.00151      0.00203      0.00122            0      0.00177     0.000998       0.0017            0      0.00228      0.00133      0.00125     3.28e-05
     15    61      0.00489      0.00489     2.46e-06      0.00196      0.00263      0.00167            0      0.00222       0.0013      0.00231            0      0.00289      0.00174      0.00192     5.06e-05
  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              15  140.045    0.005       0.0069     2.22e-05      0.00692      0.00229      0.00313      0.00189            0      0.00265      0.00151      0.00267            0      0.00349      0.00205      0.00556     0.000146
! Validation         15  140.045    0.005      0.00442     2.17e-06      0.00442      0.00178       0.0025      0.00148            0      0.00204      0.00117      0.00218            0      0.00276      0.00165      0.00181     4.76e-05
Wall time: 140.04600691999076
! Best model       15    0.004
training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     16    10      0.00664      0.00657     6.63e-05      0.00229      0.00305      0.00198            0      0.00257      0.00152      0.00259            0      0.00342        0.002       0.0116     0.000305
     16    20      0.00575      0.00568     7.41e-05      0.00217      0.00284      0.00166            0      0.00263      0.00143      0.00222            0      0.00329      0.00184       0.0121     0.000318
     16    30      0.00705      0.00702     3.23e-05      0.00251      0.00315      0.00236            0      0.00265      0.00167      0.00288            0      0.00339      0.00209      0.00785     0.000207
     16    40       0.0113       0.0112     0.000132      0.00302      0.00398      0.00172            0      0.00419      0.00197      0.00221            0      0.00507      0.00243       0.0163      0.00043
     16    50      0.00676      0.00674     1.79e-05      0.00229      0.00309      0.00163            0      0.00289      0.00151      0.00215            0      0.00374      0.00196      0.00586     0.000154
     16    60      0.00594      0.00593     1.34e-05      0.00221       0.0029      0.00163            0      0.00273      0.00145      0.00221            0       0.0034      0.00187      0.00504     0.000133
     16    70       0.0255       0.0254     2.82e-05      0.00358      0.00601      0.00332            0      0.00381      0.00238      0.00562            0      0.00634      0.00399      0.00741     0.000195
     16    80       0.0109       0.0109     1.54e-05       0.0031      0.00394      0.00242            0      0.00372      0.00205      0.00296            0      0.00464      0.00253      0.00548     0.000144
     16    90       0.0075      0.00749     1.13e-05      0.00244      0.00326      0.00201            0      0.00282      0.00161      0.00255            0      0.00379      0.00211      0.00472     0.000124
     16   100      0.00742      0.00737     4.97e-05      0.00262      0.00323      0.00295            0      0.00233      0.00176      0.00355            0      0.00292      0.00216      0.00974     0.000256
     16   110      0.00497      0.00493     3.21e-05      0.00202      0.00265      0.00157            0      0.00242      0.00133      0.00207            0      0.00307      0.00171      0.00808     0.000213
     16   120      0.00351       0.0035     1.13e-05      0.00168      0.00223      0.00143            0      0.00189      0.00111      0.00196            0      0.00245      0.00147      0.00455      0.00012
     16   130      0.00498      0.00498     1.31e-06      0.00202      0.00266      0.00159            0       0.0024      0.00133       0.0021            0      0.00307      0.00172      0.00144     3.79e-05
     16   140      0.00445      0.00445     4.79e-06       0.0019      0.00251      0.00162            0      0.00215      0.00126      0.00216            0      0.00279      0.00165      0.00266        7e-05
     16   142      0.00409      0.00409      1.8e-06      0.00178      0.00241      0.00146            0      0.00206      0.00117      0.00203            0       0.0027      0.00158      0.00191     5.03e-05
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     16    10      0.00511      0.00511     2.77e-06      0.00195      0.00269      0.00156            0      0.00231      0.00129       0.0021            0      0.00313      0.00174      0.00226     5.94e-05
     16    20      0.00398      0.00398     1.91e-06      0.00176      0.00238      0.00128            0      0.00219      0.00116      0.00174            0      0.00283      0.00152      0.00165     4.34e-05
     16    30      0.00401      0.00401     2.66e-06      0.00173      0.00238      0.00139            0      0.00203      0.00114      0.00195            0      0.00272      0.00155      0.00215     5.65e-05
     16    40      0.00411      0.00411     1.08e-06      0.00178      0.00242      0.00145            0      0.00208      0.00117      0.00193            0      0.00278      0.00157      0.00128     3.37e-05
     16    50      0.00336      0.00336      1.5e-06      0.00164      0.00218      0.00143            0      0.00184      0.00109      0.00195            0      0.00237      0.00144      0.00151     3.98e-05
     16    60      0.00279      0.00279     1.22e-06      0.00148      0.00199       0.0012            0      0.00174     0.000978      0.00167            0      0.00224       0.0013      0.00123     3.24e-05
     16    61      0.00468      0.00467     2.05e-06      0.00191      0.00258      0.00163            0      0.00217      0.00127      0.00226            0      0.00283       0.0017      0.00174     4.58e-05
  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              16  149.679    0.005      0.00749     4.42e-05      0.00753      0.00237      0.00326      0.00184            0      0.00285      0.00156      0.00257            0      0.00378      0.00212      0.00768     0.000202
! Validation         16  149.679    0.005      0.00424     1.89e-06      0.00424      0.00174      0.00245      0.00145            0      0.00199      0.00115      0.00214            0       0.0027      0.00161      0.00169     4.45e-05
Wall time: 149.67955460198573
! Best model       16    0.004
training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     17    10       0.0104       0.0103     2.71e-05      0.00305      0.00383      0.00296            0      0.00312      0.00203      0.00359            0      0.00403      0.00254       0.0073     0.000192
     17    20       0.0055      0.00548     1.48e-05      0.00218      0.00279      0.00188            0      0.00244      0.00144       0.0024            0       0.0031      0.00183      0.00461     0.000121
     17    30      0.00454      0.00454      2.6e-06      0.00193      0.00254      0.00146            0      0.00236      0.00127      0.00193            0      0.00298      0.00164      0.00168     4.43e-05
     17    40       0.0259       0.0259     1.17e-05      0.00393      0.00606      0.00368            0      0.00415      0.00261      0.00559            0      0.00646      0.00402      0.00441     0.000116
     17    50      0.00544      0.00534     9.22e-05      0.00207      0.00275       0.0014            0      0.00267      0.00136      0.00183            0      0.00338      0.00173       0.0136     0.000358
     17    60      0.00546      0.00538     7.82e-05      0.00202      0.00276       0.0016            0       0.0024      0.00133      0.00221            0      0.00318       0.0018       0.0125     0.000328
     17    70      0.00417       0.0041     6.21e-05      0.00187      0.00241      0.00154            0      0.00218      0.00124      0.00208            0      0.00268      0.00159       0.0111     0.000293
     17    80      0.00388      0.00387     1.63e-05      0.00179      0.00234      0.00153            0      0.00202      0.00118      0.00207            0      0.00256      0.00154      0.00538     0.000142
     17    90      0.00544      0.00543     1.28e-05      0.00211      0.00278      0.00145            0       0.0027      0.00138      0.00194            0      0.00336      0.00176      0.00472     0.000124
     17   100      0.00541      0.00535     5.69e-05      0.00204      0.00276      0.00151            0       0.0025      0.00134      0.00204            0      0.00327      0.00177       0.0105     0.000277
     17   110      0.00501      0.00499     2.64e-05      0.00211      0.00266       0.0018            0      0.00238       0.0014      0.00227            0      0.00297      0.00175      0.00687     0.000181
     17   120      0.00621      0.00621     8.64e-07      0.00229      0.00297      0.00168            0      0.00284      0.00151      0.00212            0      0.00356      0.00189      0.00105     2.76e-05
     17   130      0.00451      0.00442     8.06e-05      0.00192      0.00251      0.00169            0      0.00213      0.00127      0.00214            0      0.00279      0.00164       0.0127     0.000335
     17   140      0.00434      0.00434     5.29e-06      0.00193      0.00248      0.00159            0      0.00224      0.00128      0.00198            0      0.00286      0.00161       0.0028     7.36e-05
     17   142      0.00331      0.00328     3.42e-05      0.00164      0.00216      0.00153            0      0.00174      0.00109      0.00201            0      0.00228      0.00143      0.00834      0.00022
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     17    10      0.00464      0.00464     2.46e-06      0.00187      0.00256      0.00151            0      0.00218      0.00123      0.00203            0      0.00296      0.00167      0.00212     5.59e-05
     17    20      0.00375      0.00374     1.89e-06      0.00171       0.0023      0.00125            0      0.00213      0.00113       0.0017            0      0.00274      0.00148       0.0017     4.47e-05
     17    30      0.00373      0.00373     2.44e-06      0.00167       0.0023      0.00135            0      0.00196       0.0011      0.00189            0      0.00262       0.0015      0.00206     5.43e-05
     17    40      0.00385      0.00385     1.02e-06      0.00172      0.00234       0.0014            0      0.00201      0.00114      0.00187            0      0.00269      0.00152      0.00128     3.37e-05
     17    50      0.00309      0.00309     1.42e-06      0.00157      0.00209      0.00137            0      0.00175      0.00104      0.00188            0      0.00227      0.00138       0.0015     3.95e-05
     17    60       0.0026       0.0026     1.14e-06      0.00144      0.00192      0.00116            0      0.00169      0.00095      0.00161            0      0.00216      0.00126      0.00116     3.05e-05
     17    61      0.00432      0.00432     1.76e-06      0.00183      0.00248      0.00156            0      0.00207      0.00121      0.00217            0      0.00272      0.00163      0.00163      4.3e-05
  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              17  159.371    0.005       0.0061     3.45e-05      0.00614      0.00215      0.00294      0.00175            0       0.0025      0.00142      0.00248            0      0.00331      0.00193      0.00689     0.000181
! Validation         17  159.371    0.005      0.00397     1.74e-06      0.00398      0.00168      0.00237      0.00141            0      0.00191      0.00111      0.00209            0      0.00261      0.00156      0.00163     4.29e-05
Wall time: 159.37217911399784
! Best model       17    0.004
training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     18    10      0.00344      0.00344     2.16e-06      0.00166      0.00221       0.0013            0      0.00199       0.0011      0.00174            0      0.00255      0.00143       0.0016     4.21e-05
     18    20      0.00341      0.00341     2.75e-06      0.00164       0.0022       0.0014            0      0.00187      0.00109      0.00194            0      0.00241      0.00145      0.00219     5.75e-05
     18    30      0.00791      0.00789     2.28e-05      0.00256      0.00335      0.00215            0      0.00292      0.00169      0.00265            0      0.00386      0.00217      0.00649     0.000171
     18    40      0.00417      0.00416     1.64e-06      0.00182      0.00243      0.00144            0      0.00216       0.0012      0.00201            0      0.00276      0.00159      0.00146     3.85e-05
     18    50        0.014       0.0138     0.000191      0.00372      0.00442      0.00348            0      0.00394      0.00247      0.00409            0       0.0047      0.00293       0.0197     0.000519
     18    60      0.00881      0.00866     0.000154      0.00275       0.0035      0.00231            0      0.00314      0.00182       0.0029            0      0.00397      0.00229       0.0176     0.000464
     18    70      0.00492      0.00491     4.69e-06        0.002      0.00264      0.00144            0       0.0025      0.00132      0.00187            0      0.00318      0.00168      0.00297     7.81e-05
     18    80      0.00594      0.00594     2.31e-06      0.00213       0.0029      0.00141            0      0.00278       0.0014      0.00185            0       0.0036      0.00182      0.00206     5.43e-05
     18    90      0.00354      0.00353     2.86e-06      0.00171      0.00224      0.00131            0      0.00208      0.00113      0.00169            0      0.00264      0.00144       0.0021     5.53e-05
     18   100      0.00631      0.00631     5.73e-06      0.00232      0.00299      0.00165            0      0.00292      0.00153      0.00205            0      0.00364      0.00189      0.00316     8.32e-05
     18   110      0.00409      0.00407     2.09e-05       0.0018       0.0024      0.00146            0       0.0021      0.00119      0.00195            0      0.00274      0.00157      0.00642     0.000169
     18   120      0.00362      0.00362     9.67e-07      0.00172      0.00226      0.00133            0      0.00207      0.00113      0.00178            0      0.00262      0.00147      0.00116     3.05e-05
     18   130       0.0049      0.00488     2.55e-05      0.00207      0.00263      0.00178            0      0.00233      0.00137      0.00219            0      0.00297      0.00172      0.00698     0.000184
     18   140      0.00363      0.00362     1.76e-06      0.00179      0.00227      0.00178            0      0.00181       0.0012      0.00224            0      0.00229      0.00151      0.00181     4.75e-05
     18   142      0.00457      0.00456     1.12e-05      0.00203      0.00254      0.00177            0      0.00227      0.00135      0.00222            0       0.0028      0.00167      0.00478     0.000126
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     18    10      0.00433      0.00433     2.47e-06       0.0018      0.00248      0.00146            0      0.00211      0.00119      0.00196            0      0.00286      0.00161      0.00208     5.46e-05
     18    20      0.00357      0.00357     1.76e-06      0.00168      0.00225      0.00122            0      0.00209       0.0011      0.00165            0      0.00268      0.00144      0.00162     4.27e-05
     18    30      0.00346      0.00345     2.24e-06       0.0016      0.00221       0.0013            0      0.00187      0.00106      0.00183            0      0.00251      0.00145      0.00197     5.17e-05
     18    40      0.00365      0.00364     9.29e-07      0.00167      0.00227      0.00136            0      0.00195       0.0011      0.00182            0      0.00262      0.00148      0.00116     3.05e-05
     18    50      0.00289      0.00289     1.19e-06      0.00152      0.00202      0.00134            0      0.00169      0.00101      0.00181            0       0.0022      0.00134      0.00142     3.73e-05
     18    60       0.0024       0.0024     9.73e-07      0.00139      0.00185      0.00113            0      0.00163      0.00092      0.00156            0      0.00207      0.00121      0.00107     2.83e-05
     18    61       0.0041       0.0041     1.61e-06      0.00178      0.00241      0.00151            0      0.00202      0.00118       0.0021            0      0.00266      0.00159      0.00154     4.06e-05
  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              18  169.178    0.005      0.00622     2.84e-05      0.00625      0.00216      0.00297      0.00176            0      0.00251      0.00142      0.00248            0      0.00335      0.00194      0.00564     0.000149
! Validation         18  169.178    0.005      0.00376     1.52e-06      0.00376      0.00162      0.00231      0.00137            0      0.00185      0.00107      0.00203            0      0.00253      0.00152      0.00151     3.98e-05
Wall time: 169.17841604098794
! Best model       18    0.004
training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     19    10       0.0036      0.00359     1.27e-05      0.00171      0.00226      0.00139            0        0.002      0.00113       0.0018            0       0.0026      0.00147      0.00498     0.000131
     19    20      0.00266      0.00265     9.01e-06      0.00148      0.00194      0.00116            0      0.00177     0.000976      0.00157            0      0.00222      0.00126      0.00415     0.000109
     19    30      0.00426      0.00426     7.92e-06       0.0019      0.00246      0.00154            0      0.00222      0.00125      0.00199            0      0.00281       0.0016       0.0038     9.99e-05
     19    40      0.00305      0.00305     2.61e-06      0.00159      0.00208      0.00147            0       0.0017      0.00106      0.00192            0      0.00222      0.00138      0.00227     5.98e-05
     19    50      0.00314      0.00314     6.52e-06       0.0016      0.00211      0.00124            0      0.00192      0.00105      0.00163            0      0.00246      0.00136      0.00322     8.48e-05
     19    60      0.00315      0.00314     1.61e-05      0.00161      0.00211      0.00136            0      0.00182      0.00106      0.00182            0      0.00234      0.00139      0.00533      0.00014
     19    70      0.00551      0.00549     1.84e-05      0.00215      0.00279      0.00164            0      0.00262      0.00142      0.00206            0      0.00331      0.00179      0.00579     0.000152
     19    80       0.0166       0.0165     2.22e-05      0.00361      0.00484      0.00187            0      0.00518      0.00235      0.00239            0      0.00628      0.00289      0.00618     0.000163
     19    90      0.00868      0.00864     4.34e-05      0.00265       0.0035      0.00143            0      0.00375      0.00173      0.00192            0      0.00447      0.00213      0.00929     0.000244
     19   100      0.00571       0.0057      9.5e-06      0.00221      0.00284      0.00163            0      0.00272      0.00145      0.00213            0      0.00336      0.00183      0.00354     9.32e-05
     19   110      0.00415      0.00414     6.69e-06      0.00184      0.00242      0.00144            0      0.00219      0.00121      0.00189            0      0.00282      0.00157      0.00326     8.58e-05
     19   120      0.00471      0.00469     1.83e-05      0.00202      0.00258      0.00153            0      0.00247      0.00133      0.00195            0      0.00304      0.00166      0.00607      0.00016
     19   130      0.00367      0.00366     1.59e-05      0.00179      0.00228      0.00143            0       0.0021      0.00118      0.00186            0       0.0026      0.00149      0.00557     0.000146
     19   140       0.0246       0.0246     2.94e-05      0.00359       0.0059      0.00352            0      0.00366      0.00239      0.00628            0      0.00554      0.00394      0.00767     0.000202
     19   142      0.00831       0.0083      1.1e-05      0.00277      0.00343      0.00271            0      0.00282      0.00185      0.00324            0      0.00359      0.00228      0.00458      0.00012
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     19    10      0.00403      0.00403     2.48e-06      0.00174      0.00239      0.00142            0      0.00203      0.00115       0.0019            0      0.00276      0.00155       0.0021     5.53e-05
     19    20      0.00339      0.00339     1.62e-06      0.00163      0.00219      0.00119            0      0.00204      0.00107      0.00161            0      0.00261      0.00141      0.00154     4.05e-05
     19    30      0.00325      0.00325     2.08e-06      0.00155      0.00215      0.00127            0      0.00181      0.00103      0.00177            0      0.00243       0.0014      0.00187     4.91e-05
     19    40      0.00347      0.00347     8.83e-07      0.00163      0.00222      0.00132            0       0.0019      0.00108      0.00176            0      0.00256      0.00144      0.00116     3.05e-05
     19    50      0.00271      0.00271      1.1e-06      0.00147      0.00196      0.00129            0      0.00164     0.000977      0.00175            0      0.00213      0.00129      0.00133      3.5e-05
     19    60      0.00229      0.00229     9.98e-07      0.00137       0.0018      0.00109            0      0.00161     0.000902      0.00152            0      0.00202      0.00118      0.00118     3.12e-05
     19    61      0.00389      0.00388     1.45e-06      0.00173      0.00235      0.00147            0      0.00196      0.00115      0.00204            0      0.00259      0.00154      0.00146     3.85e-05
  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              19  178.842    0.005      0.00595     2.88e-05      0.00598       0.0021       0.0029      0.00172            0      0.00244      0.00139      0.00246            0      0.00325       0.0019      0.00625     0.000164
! Validation         19  178.842    0.005      0.00357     1.38e-06      0.00357      0.00158      0.00225      0.00134            0      0.00179      0.00104      0.00198            0      0.00247      0.00148      0.00144     3.79e-05
Wall time: 178.84289605999948
! Best model       19    0.004
training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     20    10      0.00474      0.00469     4.18e-05      0.00199      0.00258      0.00159            0      0.00236      0.00132      0.00196            0      0.00303      0.00166      0.00913      0.00024
     20    20      0.00537      0.00532     4.63e-05      0.00209      0.00275      0.00151            0      0.00261      0.00137      0.00202            0      0.00327      0.00176      0.00968     0.000255
     20    30      0.00515      0.00514     1.09e-05      0.00201       0.0027      0.00153            0      0.00244      0.00132      0.00197            0      0.00322      0.00173      0.00443     0.000117
     20    40      0.00343      0.00343     4.08e-06      0.00171      0.00221      0.00138            0      0.00201      0.00113      0.00181            0      0.00251      0.00144       0.0026     6.84e-05
     20    50      0.00424      0.00423     3.16e-06      0.00186      0.00245      0.00135            0      0.00232      0.00122       0.0018            0      0.00292      0.00157      0.00238     6.26e-05
     20    60      0.00309      0.00308     1.37e-05      0.00152      0.00209      0.00122            0      0.00179        0.001      0.00167            0      0.00241      0.00136      0.00518     0.000136
     20    70       0.0034      0.00339     4.19e-06      0.00167      0.00219      0.00138            0      0.00192       0.0011      0.00191            0      0.00242      0.00144       0.0024     6.33e-05
     20    80       0.0031       0.0031     1.66e-06      0.00157       0.0021      0.00133            0      0.00179      0.00104      0.00173            0      0.00238      0.00137      0.00155     4.08e-05
     20    90      0.00322      0.00321     9.43e-06      0.00163      0.00213       0.0014            0      0.00183      0.00108      0.00185            0      0.00236       0.0014      0.00397     0.000104
     20   100      0.00487      0.00487     8.32e-07        0.002      0.00263      0.00128            0      0.00265      0.00131      0.00168            0      0.00325      0.00165      0.00105     2.76e-05
     20   110      0.00531       0.0052     0.000108      0.00215      0.00272      0.00206            0      0.00224      0.00143      0.00258            0      0.00284       0.0018       0.0146     0.000384
     20   120      0.00902      0.00901     2.69e-06      0.00295      0.00358      0.00265            0      0.00322      0.00196      0.00317            0      0.00391      0.00236      0.00199     5.24e-05
     20   130      0.00458      0.00458     8.04e-06      0.00189      0.00255       0.0015            0      0.00224      0.00125      0.00194            0      0.00299      0.00164      0.00393     0.000103
     20   140      0.00277      0.00276     1.07e-05      0.00155      0.00198      0.00127            0       0.0018      0.00102      0.00164            0      0.00224      0.00129       0.0043     0.000113
     20   142      0.00885      0.00883      2.4e-05      0.00292      0.00354      0.00256            0      0.00324      0.00193      0.00307            0      0.00392      0.00233      0.00682     0.000179
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     20    10      0.00367      0.00367     2.26e-06      0.00167      0.00228      0.00138            0      0.00194      0.00111      0.00184            0      0.00262      0.00148      0.00201      5.3e-05
     20    20      0.00318      0.00318     1.49e-06      0.00159      0.00212      0.00116            0      0.00196      0.00104      0.00156            0      0.00252      0.00136      0.00149     3.92e-05
     20    30      0.00303      0.00302     1.81e-06      0.00151      0.00207      0.00124            0      0.00175     0.000995      0.00171            0      0.00235      0.00135      0.00177     4.66e-05
     20    40      0.00325      0.00325     6.57e-07      0.00158      0.00215      0.00128            0      0.00185      0.00104       0.0017            0      0.00248      0.00139        0.001     2.63e-05
     20    50      0.00252      0.00252      9.5e-07      0.00142      0.00189      0.00124            0      0.00157     0.000938      0.00168            0      0.00206      0.00125      0.00122     3.21e-05
     20    60      0.00214      0.00214     8.82e-07      0.00133      0.00174      0.00107            0      0.00156     0.000877      0.00147            0      0.00195      0.00114      0.00107     2.83e-05
     20    61      0.00362      0.00362     1.15e-06      0.00166      0.00226       0.0014            0       0.0019       0.0011      0.00195            0      0.00252      0.00149      0.00127     3.33e-05
  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              20  188.613    0.005      0.00502     1.93e-05      0.00504      0.00192      0.00267      0.00156            0      0.00224      0.00126      0.00225            0      0.00299      0.00175      0.00489     0.000129
! Validation         20  188.613    0.005      0.00335     1.23e-06      0.00335      0.00152      0.00218       0.0013            0      0.00173      0.00101      0.00192            0      0.00239      0.00144      0.00135     3.56e-05
Wall time: 188.61361182798282
! Best model       20    0.003
training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     21    10      0.00722       0.0072     1.74e-05      0.00241       0.0032      0.00217            0      0.00262       0.0016      0.00271            0      0.00358       0.0021      0.00562     0.000148
     21    20      0.00509      0.00502     7.46e-05      0.00214      0.00267      0.00213            0      0.00216      0.00143      0.00254            0      0.00278      0.00177       0.0123     0.000323
     21    30      0.00447      0.00444     2.96e-05      0.00193      0.00251       0.0017            0      0.00215      0.00128      0.00214            0       0.0028      0.00165      0.00769     0.000202
     21    40      0.00496      0.00489      6.3e-05       0.0021      0.00264      0.00231            0       0.0019       0.0014      0.00282            0      0.00245      0.00176       0.0113     0.000298
     21    50      0.00452      0.00451     8.02e-06      0.00196      0.00253      0.00154            0      0.00234      0.00129        0.002            0      0.00293      0.00164      0.00382     0.000101
     21    60      0.00529      0.00527     1.94e-05      0.00207      0.00273      0.00179            0      0.00233      0.00137      0.00228            0      0.00309      0.00179      0.00602     0.000158
     21    70      0.00518      0.00518     1.16e-06      0.00214      0.00271      0.00158            0      0.00264      0.00141      0.00195            0      0.00325      0.00173      0.00107     2.83e-05
     21    80       0.0033       0.0033     1.28e-06      0.00165      0.00216       0.0016            0       0.0017       0.0011      0.00204            0      0.00227      0.00144      0.00142     3.73e-05
     21    90       0.0032      0.00319     1.99e-06      0.00162      0.00213      0.00138            0      0.00184      0.00107      0.00184            0      0.00236       0.0014       0.0019     5.01e-05
     21   100      0.00523      0.00522     8.26e-06      0.00216      0.00272      0.00205            0      0.00225      0.00143      0.00245            0      0.00294       0.0018      0.00399     0.000105
     21   110      0.00981      0.00972     8.99e-05      0.00312      0.00371      0.00279            0      0.00341      0.00207      0.00333            0      0.00403      0.00245       0.0135     0.000357
     21   120      0.00576      0.00571     5.84e-05      0.00218      0.00285      0.00163            0      0.00267      0.00143        0.002            0      0.00343      0.00181       0.0108     0.000284
     21   130      0.00398      0.00397     1.18e-05      0.00188      0.00237      0.00132            0      0.00239      0.00123      0.00163            0      0.00288       0.0015      0.00481     0.000127
     21   140      0.00486      0.00485     5.45e-06      0.00198      0.00262      0.00141            0       0.0025       0.0013      0.00188            0      0.00315      0.00167      0.00317     8.35e-05
     21   142      0.00353      0.00353     9.61e-07      0.00177      0.00224       0.0015            0      0.00202      0.00117      0.00185            0      0.00253      0.00146       0.0011     2.89e-05
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     21    10      0.00351      0.00351     1.98e-06      0.00164      0.00223      0.00135            0       0.0019      0.00108       0.0018            0      0.00256      0.00145      0.00188     4.95e-05
     21    20      0.00307      0.00307     1.31e-06      0.00155      0.00209      0.00114            0      0.00192      0.00102      0.00153            0      0.00248      0.00134      0.00139     3.66e-05
     21    30      0.00285      0.00285     1.58e-06      0.00146      0.00201      0.00121            0      0.00169     0.000968      0.00167            0      0.00228      0.00131      0.00167      4.4e-05
     21    40      0.00317      0.00316     5.54e-07      0.00156      0.00212      0.00126            0      0.00183      0.00103      0.00167            0      0.00245      0.00137     0.000964     2.54e-05
     21    50       0.0024       0.0024      8.4e-07      0.00139      0.00185      0.00122            0      0.00153     0.000918      0.00164            0      0.00201      0.00122      0.00111     2.92e-05
     21    60      0.00208      0.00208     7.95e-07      0.00132      0.00172      0.00106            0      0.00155     0.000869      0.00144            0      0.00193      0.00112      0.00105     2.76e-05
     21    61      0.00347      0.00347      1.2e-06      0.00163      0.00222      0.00137            0      0.00187      0.00108      0.00189            0      0.00248      0.00146      0.00139     3.65e-05
  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              21  198.342    0.005      0.00578     1.95e-05       0.0058      0.00209      0.00287       0.0017            0      0.00245      0.00138      0.00239            0      0.00323      0.00187      0.00505     0.000133
! Validation         21  198.342    0.005      0.00321      1.1e-06      0.00321      0.00149      0.00213      0.00127            0      0.00169     0.000985      0.00188            0      0.00233      0.00141      0.00129     3.38e-05
Wall time: 198.34309963398846
! Best model       21    0.003
training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     22    10      0.00346      0.00344     2.23e-05      0.00171      0.00221      0.00145            0      0.00194      0.00113      0.00188            0      0.00247      0.00145      0.00659     0.000173
     22    20      0.00992      0.00991     1.66e-05      0.00276      0.00375      0.00225            0      0.00322      0.00183      0.00315            0      0.00421      0.00246      0.00562     0.000148
     22    30      0.00279      0.00278     1.35e-05      0.00149      0.00198      0.00117            0      0.00177      0.00098      0.00147            0      0.00235      0.00127      0.00522     0.000137
     22    40      0.00273      0.00272     2.79e-06      0.00149      0.00197      0.00128            0      0.00169     0.000988      0.00169            0      0.00219      0.00129      0.00222     5.85e-05
     22    50      0.00267      0.00267     1.53e-06      0.00148      0.00195      0.00117            0      0.00176     0.000977      0.00159            0      0.00222      0.00127      0.00145     3.82e-05
     22    60      0.00273      0.00272     7.96e-06      0.00149      0.00197      0.00114            0      0.00181     0.000982      0.00153            0      0.00229      0.00127      0.00386     0.000102
     22    70      0.00281      0.00279     1.85e-05      0.00147      0.00199      0.00118            0      0.00174     0.000972      0.00154            0      0.00232      0.00129      0.00607      0.00016
     22    80      0.00274      0.00274     1.73e-06      0.00153      0.00197       0.0013            0      0.00173      0.00101      0.00171            0      0.00218       0.0013      0.00176     4.63e-05
     22    90      0.00326      0.00326     1.79e-06      0.00165      0.00215       0.0013            0      0.00197      0.00109      0.00171            0      0.00248       0.0014      0.00183     4.82e-05
     22   100      0.00208      0.00207     4.99e-06      0.00132      0.00171      0.00109            0      0.00153     0.000873      0.00142            0      0.00194      0.00112      0.00298     7.84e-05
     22   110      0.00264      0.00263     4.74e-06      0.00144      0.00193      0.00109            0      0.00175     0.000947      0.00153            0      0.00223      0.00126      0.00289     7.61e-05
     22   120       0.0027       0.0027     1.68e-06      0.00149      0.00196      0.00135            0      0.00161     0.000986      0.00174            0      0.00214      0.00129      0.00114     2.99e-05
     22   130       0.0129       0.0128     6.22e-05      0.00317      0.00426      0.00157            0      0.00461      0.00206      0.00199            0      0.00556      0.00252        0.011     0.000289
     22   140       0.0189       0.0186     0.000211      0.00363      0.00514      0.00135            0      0.00569      0.00235       0.0017            0       0.0069      0.00287       0.0208     0.000546
     22   142       0.0163       0.0162     5.68e-05      0.00379       0.0048      0.00246            0      0.00498      0.00248      0.00304            0      0.00595        0.003       0.0107     0.000281
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     22    10       0.0032       0.0032     1.91e-06      0.00157      0.00213      0.00131            0       0.0018      0.00104      0.00173            0      0.00244      0.00139      0.00189     4.98e-05
     22    20      0.00286      0.00286     1.15e-06       0.0015      0.00201      0.00112            0      0.00185     0.000991      0.00149            0      0.00239      0.00129      0.00128     3.37e-05
     22    30      0.00263      0.00262     1.45e-06      0.00141      0.00193      0.00118            0      0.00163     0.000935      0.00161            0      0.00218      0.00126      0.00155     4.08e-05
     22    40      0.00294      0.00294     4.81e-07       0.0015      0.00204      0.00122            0      0.00176     0.000991       0.0016            0      0.00237      0.00132     0.000879     2.31e-05
     22    50      0.00226      0.00225     7.29e-07      0.00134      0.00179      0.00117            0      0.00149     0.000885      0.00158            0      0.00196      0.00118      0.00107     2.83e-05
     22    60       0.0019       0.0019     7.69e-07      0.00127      0.00164      0.00102            0      0.00148     0.000836      0.00139            0      0.00184      0.00108      0.00103      2.7e-05
     22    61      0.00321      0.00321     9.07e-07      0.00156      0.00213       0.0013            0      0.00178      0.00103      0.00181            0      0.00239       0.0014      0.00119     3.13e-05
  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              22  208.040    0.005       0.0051     1.87e-05      0.00512      0.00184      0.00268      0.00147            0      0.00218      0.00122      0.00216            0      0.00308      0.00175      0.00448     0.000118
! Validation         22  208.040    0.005      0.00302     9.92e-07      0.00302      0.00144      0.00207      0.00123            0      0.00163     0.000951      0.00183            0      0.00226      0.00136      0.00122     3.21e-05
Wall time: 208.0403925489809
! Best model       22    0.003
training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     23    10       0.0127       0.0127      4.7e-06      0.00312      0.00425       0.0018            0      0.00431      0.00204      0.00223            0      0.00546      0.00256      0.00297     7.81e-05
     23    20      0.00563      0.00563      9.2e-07      0.00217      0.00283       0.0013            0      0.00296      0.00142      0.00171            0      0.00354      0.00175      0.00123     3.24e-05
     23    30      0.00383      0.00382     1.87e-05      0.00181      0.00233      0.00145            0      0.00213      0.00119      0.00185            0      0.00269      0.00151      0.00605     0.000159
     23    40      0.00454      0.00454     2.13e-06      0.00201      0.00254      0.00205            0      0.00196      0.00134      0.00257            0      0.00251      0.00169      0.00194     5.11e-05
     23    50      0.00289      0.00289     1.75e-06      0.00156      0.00203      0.00111            0      0.00197      0.00103      0.00139            0      0.00246      0.00128      0.00153     4.02e-05
     23    60       0.0234       0.0234     5.35e-06      0.00333      0.00576      0.00309            0      0.00355      0.00221      0.00574            0      0.00578      0.00384      0.00284     7.48e-05
     23    70      0.00467      0.00465     1.23e-05      0.00195      0.00257      0.00126            0      0.00257      0.00128      0.00169            0      0.00316      0.00162      0.00488     0.000128
     23    80      0.00277      0.00276     1.24e-05      0.00152      0.00198      0.00116            0      0.00184        0.001      0.00155            0      0.00229      0.00128      0.00497     0.000131
     23    90       0.0028      0.00279     6.61e-06      0.00152      0.00199      0.00115            0      0.00184     0.000998      0.00151            0      0.00234      0.00128      0.00341     8.96e-05
     23   100      0.00476      0.00475     4.44e-06       0.0021       0.0026      0.00196            0      0.00222       0.0014      0.00234            0      0.00281      0.00172      0.00297     7.81e-05
     23   110      0.00292      0.00291     3.18e-06      0.00149      0.00203      0.00113            0      0.00182     0.000984       0.0015            0      0.00241      0.00131      0.00245     6.46e-05
     23   120      0.00293      0.00293     5.32e-07      0.00161      0.00204      0.00132            0      0.00186      0.00106      0.00169            0      0.00231      0.00133     0.000793     2.09e-05
     23   130      0.00406      0.00404     2.63e-05      0.00183      0.00239      0.00166            0      0.00199      0.00122      0.00213            0      0.00261      0.00158      0.00725     0.000191
     23   140      0.00311      0.00311     6.04e-07      0.00163       0.0021      0.00117            0      0.00204      0.00107      0.00151            0      0.00252      0.00134     0.000989      2.6e-05
     23   142      0.00312      0.00311     3.57e-06      0.00166       0.0021      0.00149            0      0.00182       0.0011      0.00186            0       0.0023      0.00139      0.00248     6.53e-05
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     23    10      0.00304      0.00303     1.99e-06      0.00152      0.00207      0.00126            0      0.00175        0.001      0.00168            0      0.00238      0.00135      0.00186     4.88e-05
     23    20      0.00279      0.00279     1.03e-06      0.00148      0.00199      0.00109            0      0.00183     0.000975      0.00145            0      0.00237      0.00127      0.00122     3.21e-05
     23    30      0.00257      0.00257     1.18e-06       0.0014      0.00191      0.00116            0      0.00161     0.000923      0.00157            0      0.00217      0.00125      0.00142     3.73e-05
     23    40      0.00285      0.00285     3.27e-07      0.00148      0.00201      0.00118            0      0.00174     0.000976      0.00156            0      0.00235       0.0013     0.000696     1.83e-05
     23    50      0.00219      0.00219      6.2e-07      0.00131      0.00176      0.00114            0      0.00147     0.000871      0.00154            0      0.00194      0.00116     0.000952     2.51e-05
     23    60      0.00184      0.00184     5.86e-07      0.00124      0.00162     0.000984            0      0.00147     0.000819      0.00133            0      0.00183      0.00106     0.000891     2.35e-05
     23    61      0.00306      0.00306     9.15e-07      0.00152      0.00208      0.00126            0      0.00174        0.001      0.00175            0      0.00235      0.00137      0.00121     3.17e-05
  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              23  217.726    0.005      0.00531     2.08e-05      0.00533      0.00193      0.00275      0.00152            0       0.0023      0.00128       0.0022            0      0.00316      0.00179      0.00506     0.000133
! Validation         23  217.726    0.005      0.00293     8.69e-07      0.00293      0.00141      0.00204      0.00119            0       0.0016     0.000932      0.00179            0      0.00224      0.00134      0.00111     2.92e-05
Wall time: 217.72653125200304
! Best model       23    0.003
training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     24    10      0.00235      0.00234     9.08e-06      0.00141      0.00182       0.0012            0       0.0016     0.000932      0.00153            0      0.00205      0.00119      0.00425     0.000112
     24    20      0.00221      0.00221     2.08e-06      0.00135      0.00177     0.000972            0      0.00169     0.000888      0.00126            0      0.00213      0.00113      0.00184     4.85e-05
     24    30      0.00402      0.00401     2.31e-06      0.00182      0.00239      0.00151            0       0.0021       0.0012      0.00188            0      0.00277      0.00155      0.00194     5.11e-05
     24    40      0.00279      0.00278     1.37e-05      0.00154      0.00198      0.00128            0      0.00178      0.00102      0.00164            0      0.00225       0.0013      0.00511     0.000135
     24    50      0.00329      0.00329      2.4e-06      0.00165      0.00216      0.00131            0      0.00195      0.00109      0.00178            0      0.00245      0.00141      0.00187     4.91e-05
     24    60      0.00533      0.00531     1.89e-05      0.00223      0.00274      0.00169            0      0.00272      0.00147      0.00205            0      0.00324      0.00177      0.00619     0.000163
     24    70      0.00286      0.00286     7.67e-06      0.00156      0.00201      0.00133            0      0.00176      0.00103      0.00173            0      0.00224      0.00132       0.0037     9.73e-05
     24    80       0.0029       0.0029     3.24e-06      0.00158      0.00203       0.0013            0      0.00184      0.00105      0.00168            0       0.0023      0.00133      0.00228     6.01e-05
     24    90       0.0241       0.0241     1.92e-06      0.00318      0.00585      0.00308            0      0.00327      0.00212      0.00579            0      0.00591       0.0039      0.00162     4.27e-05
     24   100      0.00316      0.00315     9.34e-06      0.00158      0.00211       0.0012            0      0.00192      0.00104      0.00163            0      0.00247      0.00137      0.00389     0.000102
     24   110      0.00775      0.00775     1.49e-06      0.00268      0.00332      0.00204            0      0.00325      0.00176      0.00248            0      0.00392      0.00213      0.00164      4.3e-05
     24   120      0.00434      0.00433     7.49e-07      0.00189      0.00248      0.00126            0      0.00245      0.00124      0.00157            0      0.00307      0.00155      0.00101     2.67e-05
     24   130      0.00458      0.00455     3.04e-05      0.00188      0.00254      0.00117            0      0.00253      0.00123      0.00152            0      0.00319      0.00157      0.00764     0.000201
     24   140      0.00615      0.00614     6.69e-06       0.0022      0.00295      0.00117            0      0.00312      0.00143      0.00157            0      0.00379      0.00179      0.00313     8.22e-05
     24   142      0.00381      0.00381     9.87e-07      0.00181      0.00232      0.00114            0      0.00241      0.00118      0.00151            0      0.00286      0.00146      0.00134     3.53e-05
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     24    10      0.00282      0.00282     1.77e-06      0.00146        0.002      0.00123            0      0.00167     0.000967      0.00163            0      0.00228       0.0013      0.00171      4.5e-05
     24    20      0.00268      0.00268      9.8e-07      0.00145      0.00195      0.00108            0      0.00179     0.000956      0.00141            0      0.00233      0.00125      0.00123     3.24e-05
     24    30      0.00239      0.00239     1.12e-06      0.00135      0.00184      0.00112            0      0.00155      0.00089      0.00151            0       0.0021       0.0012      0.00135     3.57e-05
     24    40      0.00273      0.00273     3.43e-07      0.00145      0.00197      0.00117            0      0.00171     0.000957      0.00152            0       0.0023      0.00127     0.000684      1.8e-05
     24    50      0.00207      0.00207     5.49e-07      0.00128      0.00171       0.0011            0      0.00144     0.000847      0.00148            0       0.0019      0.00113     0.000879     2.31e-05
     24    60      0.00176      0.00176     6.44e-07      0.00121      0.00158     0.000965            0      0.00144     0.000801       0.0013            0      0.00179      0.00103     0.000916     2.41e-05
     24    61      0.00289      0.00288     7.44e-07      0.00147      0.00202      0.00122            0       0.0017     0.000972      0.00169            0      0.00228      0.00132      0.00107     2.81e-05
  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              24  227.408    0.005      0.00477     8.06e-06      0.00478      0.00184       0.0026      0.00143            0      0.00221      0.00121      0.00211            0      0.00298      0.00169      0.00335     8.83e-05
! Validation         24  227.408    0.005      0.00279     7.86e-07      0.00279      0.00137      0.00199      0.00116            0      0.00156     0.000906      0.00175            0      0.00218      0.00131      0.00105     2.77e-05
Wall time: 227.40853409300325
! Best model       24    0.003
training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     25    10      0.00806      0.00806     7.52e-06      0.00231      0.00338      0.00218            0      0.00242      0.00153      0.00339            0      0.00337      0.00225      0.00389     0.000102
     25    20       0.0242       0.0242      6.3e-06      0.00344      0.00586      0.00311            0      0.00373      0.00228      0.00559            0      0.00609      0.00389      0.00342     8.99e-05
     25    30      0.00358      0.00358     6.95e-07      0.00172      0.00225       0.0012            0      0.00219      0.00113      0.00156            0      0.00273      0.00143      0.00104     2.73e-05
     25    40      0.00261      0.00261     6.43e-07      0.00148      0.00192      0.00127            0      0.00166     0.000978      0.00163            0      0.00215      0.00126      0.00109     2.86e-05
     25    50      0.00239      0.00239     1.05e-06      0.00143      0.00184      0.00127            0      0.00157     0.000947      0.00162            0      0.00202      0.00121      0.00118     3.12e-05
     25    60       0.0033      0.00328     2.43e-05      0.00165      0.00216      0.00117            0      0.00208      0.00108      0.00155            0      0.00259      0.00138      0.00696     0.000183
     25    70      0.00267      0.00267     1.31e-06      0.00142      0.00195      0.00104            0      0.00176     0.000932       0.0014            0      0.00233      0.00124      0.00138     3.63e-05
     25    80      0.00323      0.00323     7.65e-07       0.0017      0.00214      0.00162            0      0.00177      0.00113      0.00201            0      0.00226      0.00142     0.000964     2.54e-05
     25    90       0.0043       0.0043     2.28e-06      0.00193      0.00247      0.00152            0       0.0023      0.00128      0.00184            0      0.00292      0.00159      0.00199     5.24e-05
     25   100      0.00298      0.00298     6.38e-07      0.00155      0.00206      0.00119            0      0.00188      0.00102       0.0016            0      0.00239      0.00133      0.00105     2.76e-05
     25   110       0.0194       0.0194     2.74e-05       0.0029      0.00524      0.00294            0      0.00286      0.00193      0.00553            0      0.00497       0.0035      0.00743     0.000196
     25   120      0.00321       0.0032     2.14e-06      0.00161      0.00213      0.00138            0      0.00182      0.00107      0.00171            0      0.00245      0.00139      0.00198      5.2e-05
     25   130       0.0225       0.0225     4.57e-06      0.00302      0.00565      0.00303            0      0.00301      0.00201      0.00574            0      0.00556      0.00377      0.00306     8.06e-05
     25   140      0.00395      0.00388     6.88e-05      0.00179      0.00235      0.00122            0      0.00231      0.00118      0.00154            0      0.00288      0.00147       0.0117     0.000308
     25   142      0.00335      0.00335     5.41e-07      0.00165      0.00218      0.00106            0      0.00218      0.00108      0.00142            0      0.00269      0.00137     0.000854     2.25e-05
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     25    10      0.00261      0.00261      1.7e-06      0.00141      0.00192      0.00119            0       0.0016      0.00093      0.00158            0      0.00219      0.00126      0.00171      4.5e-05
     25    20      0.00253      0.00253     9.01e-07      0.00141       0.0019      0.00106            0      0.00173      0.00093      0.00138            0      0.00226      0.00121      0.00114     2.99e-05
     25    30      0.00224      0.00224     9.83e-07      0.00131      0.00178      0.00108            0      0.00151     0.000865      0.00146            0      0.00203      0.00116      0.00126     3.31e-05
     25    40      0.00257      0.00257     3.31e-07      0.00141      0.00191      0.00113            0      0.00165     0.000929      0.00147            0      0.00224      0.00123     0.000732     1.93e-05
     25    50      0.00194      0.00194     6.06e-07      0.00124      0.00166      0.00106            0       0.0014     0.000819      0.00142            0      0.00185      0.00109      0.00094     2.47e-05
     25    60      0.00164      0.00164      4.7e-07      0.00118      0.00153     0.000941            0      0.00139     0.000779      0.00125            0      0.00174     0.000997     0.000818     2.15e-05
     25    61      0.00272      0.00272     5.59e-07      0.00143      0.00196      0.00117            0      0.00166     0.000943      0.00162            0      0.00223      0.00128     0.000946     2.49e-05
  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              25  237.234    0.005      0.00408     1.01e-05      0.00409      0.00172      0.00241      0.00142            0      0.00199      0.00114      0.00207            0      0.00267      0.00158      0.00376     9.89e-05
! Validation         25  237.234    0.005      0.00264     7.13e-07      0.00264      0.00133      0.00194      0.00113            0      0.00151     0.000879       0.0017            0      0.00212      0.00128      0.00101     2.67e-05
Wall time: 237.23531997198006
! Best model       25    0.003
training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     26    10       0.0025       0.0025     2.31e-06      0.00148      0.00188      0.00125            0      0.00168     0.000977      0.00156            0      0.00213      0.00123      0.00181     4.75e-05
     26    20      0.00264      0.00264     1.04e-06      0.00151      0.00193      0.00126            0      0.00173     0.000997       0.0016            0      0.00219      0.00126      0.00131     3.44e-05
     26    30      0.00232      0.00231     2.12e-06      0.00142      0.00181      0.00138            0      0.00146     0.000944      0.00172            0      0.00189       0.0012      0.00146     3.85e-05
     26    40      0.00972       0.0097     2.16e-05      0.00311      0.00371       0.0034            0      0.00285      0.00208      0.00395            0      0.00348      0.00248      0.00629     0.000165
     26    50      0.00484      0.00484     2.35e-07      0.00207      0.00262      0.00145            0      0.00263      0.00136      0.00184            0      0.00316      0.00167     0.000623     1.64e-05
     26    60      0.00259      0.00258     2.93e-06      0.00143      0.00191      0.00115            0      0.00168     0.000941      0.00151            0      0.00222      0.00124      0.00212     5.59e-05
     26    70      0.00205      0.00204     1.49e-05      0.00126       0.0017     0.000986            0       0.0015     0.000828      0.00133            0      0.00197       0.0011      0.00548     0.000144
     26    80      0.00208      0.00207      1.1e-05      0.00136      0.00171      0.00117            0      0.00153     0.000901      0.00147            0      0.00191      0.00113      0.00455      0.00012
     26    90      0.00248      0.00246     1.92e-05      0.00142      0.00187      0.00104            0      0.00176     0.000933      0.00134            0      0.00224      0.00119      0.00619     0.000163
     26   100      0.00364      0.00362     2.07e-05      0.00182      0.00227      0.00175            0      0.00188      0.00121      0.00212            0      0.00239       0.0015       0.0062     0.000163
     26   110      0.00345      0.00338     7.48e-05      0.00172      0.00219      0.00128            0      0.00212      0.00113      0.00166            0      0.00258      0.00141       0.0124     0.000325
     26   120      0.00362      0.00361        1e-05      0.00176      0.00226      0.00132            0      0.00216      0.00116      0.00167            0      0.00269      0.00145      0.00446     0.000117
     26   130      0.00177      0.00177     6.31e-07      0.00122      0.00159     0.000985            0      0.00144     0.000808      0.00126            0      0.00183      0.00103        0.001     2.63e-05
     26   140      0.00211      0.00211     3.83e-06      0.00136      0.00173      0.00107            0      0.00161     0.000894      0.00134            0      0.00202      0.00112      0.00258     6.78e-05
     26   142      0.00274      0.00274     1.52e-06      0.00152      0.00197      0.00136            0      0.00167      0.00101      0.00173            0      0.00217       0.0013       0.0013     3.43e-05
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     26    10      0.00242      0.00242     1.37e-06      0.00135      0.00185      0.00115            0      0.00153     0.000893      0.00153            0       0.0021      0.00121      0.00156     4.11e-05
     26    20      0.00241      0.00241     7.21e-07      0.00138      0.00185      0.00104            0      0.00168     0.000906      0.00134            0      0.00221      0.00118      0.00104     2.73e-05
     26    30       0.0021       0.0021     9.26e-07      0.00126      0.00173      0.00105            0      0.00145     0.000836      0.00141            0      0.00197      0.00113      0.00126     3.31e-05
     26    40      0.00245      0.00245     2.86e-07      0.00137      0.00186       0.0011            0      0.00161     0.000904      0.00142            0      0.00218       0.0012     0.000696     1.83e-05
     26    50      0.00183      0.00183     5.73e-07       0.0012      0.00161      0.00103            0      0.00136     0.000797      0.00138            0       0.0018      0.00106     0.000903     2.38e-05
     26    60      0.00157      0.00157     4.73e-07      0.00116      0.00149     0.000926            0      0.00137     0.000764      0.00123            0       0.0017     0.000975      0.00083     2.18e-05
     26    61      0.00253      0.00253     5.88e-07      0.00137      0.00189      0.00112            0       0.0016     0.000907      0.00156            0      0.00215      0.00124      0.00101     2.65e-05
  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              26  246.946    0.005      0.00382      1.4e-05      0.00384      0.00165      0.00233      0.00137            0      0.00191      0.00109      0.00202            0      0.00258      0.00153      0.00403     0.000106
! Validation         26  246.946    0.005      0.00251     6.64e-07      0.00251      0.00129      0.00189      0.00109            0      0.00146     0.000852      0.00166            0      0.00207      0.00124     0.000977     2.57e-05
Wall time: 246.94730060300208
! Best model       26    0.003
training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     27    10      0.00294      0.00294     3.58e-06      0.00152      0.00204      0.00117            0      0.00182     0.000999      0.00154            0      0.00241      0.00131      0.00264     6.94e-05
     27    20      0.00285      0.00284     8.91e-06      0.00155      0.00201      0.00112            0      0.00194      0.00102      0.00141            0      0.00242      0.00128      0.00388     0.000102
     27    30      0.00212      0.00211     1.32e-05      0.00131      0.00173      0.00101            0      0.00158     0.000864       0.0013            0      0.00204      0.00111       0.0052     0.000137
     27    40       0.0033       0.0033     1.56e-07      0.00174      0.00216      0.00173            0      0.00174      0.00116      0.00213            0      0.00219      0.00144     0.000415     1.09e-05
     27    50      0.00305      0.00304     1.44e-06      0.00157      0.00208      0.00137            0      0.00174      0.00104      0.00178            0      0.00231      0.00136      0.00162     4.27e-05
     27    60      0.00226      0.00226     1.16e-06      0.00135      0.00179      0.00114            0      0.00155     0.000896      0.00143            0      0.00206      0.00116       0.0014     3.69e-05
     27    70      0.00582      0.00581     6.46e-06      0.00234      0.00287      0.00186            0      0.00278      0.00155      0.00229            0      0.00331      0.00187      0.00359     9.44e-05
     27    80      0.00262      0.00262     3.92e-06      0.00145      0.00193      0.00105            0      0.00181     0.000953      0.00135            0      0.00233      0.00123      0.00242     6.36e-05
     27    90      0.00415      0.00415     5.48e-07      0.00193      0.00243      0.00147            0      0.00233      0.00127      0.00176            0      0.00289      0.00155     0.000891     2.35e-05
     27   100      0.00431       0.0043     1.11e-05      0.00202      0.00247      0.00159            0      0.00241      0.00133      0.00191            0      0.00288       0.0016      0.00469     0.000123
     27   110      0.00363      0.00362      6.5e-06       0.0018      0.00227      0.00124            0      0.00229      0.00118      0.00155            0      0.00276      0.00144      0.00364     9.57e-05
     27   120      0.00249      0.00248     6.48e-06      0.00141      0.00188      0.00112            0      0.00168     0.000933      0.00146            0      0.00218      0.00121      0.00356     9.38e-05
     27   130      0.00472      0.00471     7.12e-06      0.00215      0.00258      0.00225            0      0.00206      0.00144      0.00263            0      0.00255      0.00172      0.00378     9.96e-05
     27   140      0.00397      0.00397     1.39e-06      0.00185      0.00237      0.00123            0      0.00241      0.00121      0.00151            0      0.00294      0.00148      0.00154     4.05e-05
     27   142      0.00823      0.00823     9.66e-07      0.00243      0.00342      0.00249            0      0.00237      0.00162      0.00371            0      0.00313      0.00228       0.0011     2.89e-05
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     27    10      0.00224      0.00224     1.41e-06       0.0013      0.00178      0.00111            0      0.00147      0.00086      0.00148            0      0.00201      0.00116      0.00156     4.11e-05
     27    20       0.0023       0.0023      8.1e-07      0.00134      0.00181      0.00102            0      0.00163     0.000883      0.00131            0      0.00216      0.00116      0.00112     2.96e-05
     27    30      0.00197      0.00197     8.05e-07      0.00123      0.00167      0.00102            0      0.00141      0.00081      0.00136            0      0.00191      0.00109      0.00117     3.08e-05
     27    40      0.00232      0.00232     2.27e-07      0.00133      0.00181      0.00106            0      0.00157     0.000876      0.00138            0      0.00213      0.00117     0.000598     1.57e-05
     27    50      0.00174      0.00174     5.07e-07      0.00116      0.00157     0.000986            0      0.00132      0.00077      0.00133            0      0.00177      0.00103     0.000818     2.15e-05
     27    60      0.00149      0.00149     4.87e-07      0.00112      0.00145     0.000906            0      0.00132     0.000741       0.0012            0      0.00165     0.000949     0.000854     2.25e-05
     27    61      0.00239      0.00239      5.5e-07      0.00134      0.00184      0.00108            0      0.00157     0.000884       0.0015            0      0.00211       0.0012     0.000992     2.61e-05
  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              27  256.634    0.005      0.00391     5.07e-06      0.00392      0.00167      0.00235      0.00135            0      0.00196       0.0011      0.00197            0      0.00265      0.00154      0.00253     6.65e-05
! Validation         27  256.634    0.005      0.00239        6e-07      0.00239      0.00125      0.00184      0.00106            0      0.00143     0.000828      0.00162            0      0.00202      0.00121     0.000931     2.45e-05
Wall time: 256.63445827699616
! Best model       27    0.002
training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     28    10      0.00266      0.00264     1.67e-05      0.00149      0.00194      0.00107            0      0.00187     0.000982      0.00137            0      0.00233      0.00123      0.00577     0.000152
     28    20      0.00228      0.00228      1.5e-07      0.00134       0.0018      0.00104            0      0.00161     0.000883      0.00136            0      0.00212      0.00116     0.000439     1.16e-05
     28    30      0.00216      0.00213     3.07e-05      0.00132      0.00174      0.00107            0      0.00155     0.000874      0.00138            0        0.002      0.00113      0.00793     0.000209
     28    40      0.00173      0.00171     1.83e-05      0.00119      0.00156     0.000966            0       0.0014     0.000788      0.00125            0      0.00179      0.00101      0.00593     0.000156
     28    50      0.00163      0.00163     1.02e-06      0.00119      0.00152     0.000935            0      0.00142     0.000785      0.00118            0      0.00177     0.000983      0.00121     3.18e-05
     28    60      0.00345      0.00343     1.79e-05      0.00166      0.00221     0.000981            0      0.00228      0.00109      0.00126            0      0.00279      0.00135      0.00605     0.000159
     28    70      0.00253      0.00253     5.59e-07      0.00151      0.00189      0.00155            0      0.00147      0.00101      0.00187            0      0.00191      0.00126     0.000745     1.96e-05
     28    80      0.00273      0.00273     6.03e-06      0.00153      0.00197      0.00138            0      0.00167      0.00101      0.00174            0      0.00215       0.0013      0.00314     8.26e-05
     28    90      0.00135      0.00135     3.19e-06      0.00109      0.00138      0.00102            0      0.00115     0.000723      0.00129            0      0.00146     0.000917      0.00244     6.42e-05
     28   100      0.00419      0.00417     2.35e-05      0.00194      0.00243       0.0018            0      0.00206      0.00129      0.00217            0      0.00264       0.0016      0.00677     0.000178
     28   110      0.00232      0.00232        6e-07      0.00146      0.00182      0.00147            0      0.00145     0.000973      0.00178            0      0.00185      0.00121     0.000867     2.28e-05
     28   120      0.00258      0.00256     2.18e-05      0.00143      0.00191      0.00112            0       0.0017     0.000941      0.00139            0      0.00227      0.00122      0.00658     0.000173
     28   130      0.00291       0.0029     1.24e-06      0.00153      0.00203      0.00112            0      0.00189        0.001       0.0015            0      0.00241       0.0013      0.00121     3.18e-05
     28   140      0.00323      0.00323     4.06e-06      0.00165      0.00214      0.00143            0      0.00185      0.00109      0.00177            0      0.00243       0.0014      0.00245     6.46e-05
     28   142      0.00334      0.00333     5.49e-06      0.00162      0.00217      0.00112            0      0.00207      0.00106      0.00147            0      0.00265      0.00137      0.00315      8.3e-05
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     28    10      0.00213      0.00213     1.32e-06      0.00126      0.00174      0.00107            0      0.00143     0.000836      0.00144            0      0.00197      0.00114      0.00154     4.05e-05
     28    20       0.0022       0.0022     6.45e-07      0.00132      0.00177      0.00101            0      0.00159     0.000867      0.00129            0      0.00211      0.00113        0.001     2.63e-05
     28    30      0.00184      0.00184     7.37e-07      0.00119      0.00162      0.00099            0      0.00137     0.000786      0.00131            0      0.00185      0.00105      0.00107     2.83e-05
     28    40       0.0022       0.0022     2.26e-07      0.00129      0.00177      0.00103            0      0.00153     0.000854      0.00134            0      0.00208      0.00114      0.00061     1.61e-05
     28    50      0.00165      0.00165     4.39e-07      0.00113      0.00153     0.000956            0      0.00129     0.000748      0.00128            0      0.00172        0.001      0.00072      1.9e-05
     28    60      0.00143      0.00143     4.17e-07      0.00111      0.00143     0.000899            0       0.0013     0.000733      0.00117            0      0.00162     0.000931     0.000793     2.09e-05
     28    61      0.00224      0.00224     4.67e-07      0.00129      0.00178      0.00104            0      0.00151     0.000852      0.00144            0      0.00204      0.00116      0.00087     2.29e-05
  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              28  266.367    0.005      0.00376     7.01e-06      0.00377      0.00164      0.00231      0.00136            0      0.00189      0.00108        0.002            0      0.00256      0.00152      0.00305     8.03e-05
! Validation         28  266.367    0.005      0.00229     5.31e-07      0.00229      0.00122       0.0018      0.00103            0      0.00139     0.000807      0.00159            0      0.00198      0.00119     0.000873      2.3e-05
Wall time: 266.36843430798035
! Best model       28    0.002
training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     29    10      0.00221      0.00221     8.45e-07      0.00132      0.00177      0.00103            0      0.00158      0.00087      0.00132            0       0.0021      0.00114      0.00106     2.79e-05
     29    20       0.0021       0.0021     1.04e-06      0.00133      0.00173       0.0011            0      0.00154     0.000878      0.00141            0      0.00197      0.00113      0.00121     3.18e-05
     29    30      0.00294      0.00293     6.91e-06      0.00152      0.00204      0.00107            0      0.00192     0.000996      0.00141            0      0.00247      0.00129      0.00366     9.64e-05
     29    40      0.00521      0.00521     2.17e-06      0.00221      0.00272      0.00233            0      0.00211      0.00148      0.00276            0      0.00268      0.00181      0.00177     4.66e-05
     29    50      0.00302      0.00286     0.000155      0.00159      0.00202      0.00139            0      0.00177      0.00105      0.00172            0      0.00225      0.00132       0.0178     0.000469
     29    60      0.00337      0.00336     4.73e-06      0.00168      0.00218      0.00117            0      0.00213       0.0011      0.00147            0      0.00267      0.00138        0.003      7.9e-05
     29    70      0.00393      0.00393     1.23e-06      0.00179      0.00236      0.00103            0      0.00247      0.00117      0.00136            0      0.00299      0.00145      0.00126     3.31e-05
     29    80      0.00243      0.00242     8.22e-06      0.00138      0.00185       0.0011            0      0.00164     0.000913      0.00141            0      0.00218       0.0012      0.00399     0.000105
     29    90      0.00176      0.00175     7.19e-06      0.00121      0.00158     0.000988            0      0.00141     0.000799      0.00127            0      0.00181      0.00103      0.00369      9.7e-05
     29   100      0.00333      0.00333     8.37e-06      0.00166      0.00217       0.0011            0      0.00216      0.00108      0.00136            0       0.0027      0.00135      0.00409     0.000108
     29   110      0.00895      0.00893      1.6e-05      0.00254      0.00356      0.00126            0      0.00369      0.00165      0.00161            0      0.00466      0.00209      0.00568     0.000149
     29   120      0.00524      0.00524     3.42e-06      0.00216      0.00273      0.00183            0      0.00246      0.00143      0.00228            0      0.00307      0.00178      0.00256     6.75e-05
     29   130       0.0073      0.00729     2.57e-06      0.00239      0.00322      0.00124            0      0.00343      0.00156      0.00168            0      0.00414      0.00194      0.00182     4.79e-05
     29   140      0.00383      0.00383     2.29e-06      0.00176      0.00233      0.00106            0      0.00239      0.00115      0.00139            0      0.00293      0.00144      0.00177     4.66e-05
     29   142      0.00434      0.00434     5.31e-06      0.00185      0.00248      0.00118            0      0.00244      0.00121       0.0015            0      0.00311      0.00154      0.00319     8.41e-05
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     29    10      0.00208      0.00207     1.17e-06      0.00125      0.00172      0.00106            0      0.00142     0.000828      0.00142            0      0.00194      0.00112      0.00149     3.92e-05
     29    20       0.0022       0.0022     6.52e-07      0.00132      0.00177     0.000999            0       0.0016     0.000868      0.00127            0      0.00212      0.00113        0.001     2.63e-05
     29    30      0.00181       0.0018     7.78e-07      0.00117       0.0016     0.000971            0      0.00135     0.000772      0.00129            0      0.00183      0.00104      0.00112     2.96e-05
     29    40      0.00219      0.00219     1.43e-07      0.00129      0.00176      0.00102            0      0.00154     0.000852      0.00133            0      0.00208      0.00113     0.000513     1.35e-05
     29    50       0.0016       0.0016     4.65e-07      0.00111      0.00151     0.000927            0      0.00127     0.000732      0.00126            0       0.0017     0.000985     0.000793     2.09e-05
     29    60      0.00141      0.00141     3.73e-07      0.00109      0.00141     0.000887            0      0.00128     0.000721      0.00116            0      0.00161     0.000923     0.000757     1.99e-05
     29    61      0.00217      0.00217     5.37e-07      0.00127      0.00176      0.00102            0      0.00149     0.000836      0.00141            0      0.00202      0.00114     0.000992     2.61e-05
  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              29  276.172    0.005      0.00469     1.27e-05       0.0047      0.00181      0.00258       0.0014            0      0.00218      0.00119      0.00207            0      0.00296      0.00168       0.0038       0.0001
! Validation         29  276.172    0.005      0.00223     5.18e-07      0.00224       0.0012      0.00178      0.00101            0      0.00137     0.000793      0.00156            0      0.00196      0.00117     0.000855     2.25e-05
Wall time: 276.1728185619868
! Best model       29    0.002
training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     30    10       0.0029       0.0029     2.25e-06      0.00153      0.00203      0.00113            0       0.0019      0.00101      0.00141            0      0.00246      0.00129      0.00203     5.33e-05
     30    20      0.00268      0.00267     1.06e-06      0.00153      0.00195      0.00123            0       0.0018      0.00101      0.00153            0      0.00226      0.00126      0.00112     2.96e-05
     30    30      0.00243      0.00243      1.8e-06      0.00145      0.00186      0.00109            0      0.00178     0.000957       0.0014            0      0.00219       0.0012      0.00192     5.04e-05
     30    40      0.00143      0.00143     5.23e-08      0.00111      0.00143      0.00089            0      0.00131     0.000733      0.00111            0      0.00166     0.000923     0.000293     7.71e-06
     30    50      0.00209      0.00209     8.41e-07      0.00131      0.00172      0.00104            0      0.00155     0.000862      0.00134            0        0.002      0.00111      0.00122     3.21e-05
     30    60        0.004        0.004     1.28e-06      0.00176      0.00238      0.00138            0      0.00211      0.00116      0.00173            0      0.00284      0.00152      0.00155     4.08e-05
     30    70      0.00251      0.00251     8.92e-07       0.0015      0.00189      0.00145            0      0.00155        0.001      0.00177            0      0.00198      0.00125      0.00106     2.79e-05
     30    80      0.00579      0.00578     7.23e-06      0.00228      0.00286      0.00167            0      0.00283       0.0015      0.00206            0      0.00343      0.00183      0.00356     9.38e-05
     30    90      0.00418      0.00416      1.9e-05      0.00179      0.00243      0.00122            0       0.0023      0.00117      0.00152            0      0.00302      0.00151      0.00603     0.000159
     30   100       0.0044      0.00439     6.84e-06      0.00198       0.0025      0.00155            0      0.00237      0.00131      0.00195            0       0.0029      0.00162      0.00361     9.51e-05
     30   110      0.00749      0.00749     4.74e-06      0.00268      0.00326      0.00238            0      0.00294      0.00177      0.00279            0      0.00363      0.00214      0.00273      7.2e-05
     30   120      0.00454      0.00453     9.03e-06       0.0019      0.00253      0.00119            0      0.00255      0.00124      0.00151            0      0.00318      0.00157      0.00399     0.000105
     30   130      0.00253      0.00252     1.02e-05      0.00143      0.00189      0.00105            0      0.00178     0.000943      0.00138            0      0.00225      0.00121      0.00437     0.000115
     30   140      0.00146      0.00146      2.6e-07      0.00109      0.00144     0.000946            0      0.00122     0.000722      0.00123            0       0.0016     0.000944     0.000586     1.54e-05
     30   142      0.00182      0.00182     4.39e-07      0.00126      0.00161      0.00101            0      0.00149     0.000834      0.00131            0      0.00184      0.00105     0.000834      2.2e-05
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     30    10      0.00198      0.00198     1.08e-06      0.00122      0.00168      0.00102            0      0.00141     0.000808      0.00137            0      0.00191      0.00109      0.00135     3.57e-05
     30    20      0.00217      0.00217     4.75e-07       0.0013      0.00175     0.000971            0      0.00159     0.000854      0.00124            0      0.00211      0.00112      0.00083     2.18e-05
     30    30      0.00173      0.00173     5.41e-07      0.00115      0.00157     0.000957            0      0.00132     0.000759      0.00126            0       0.0018      0.00102     0.000891     2.35e-05
     30    40      0.00212      0.00212     1.03e-07      0.00127      0.00173     0.000996            0      0.00152     0.000838      0.00129            0      0.00205      0.00111     0.000403     1.06e-05
     30    50      0.00151      0.00151     4.07e-07      0.00108      0.00147     0.000903            0      0.00124     0.000715      0.00123            0      0.00165     0.000959     0.000659     1.73e-05
     30    60      0.00136      0.00136     2.67e-07      0.00107      0.00139     0.000861            0      0.00126     0.000707      0.00112            0      0.00159     0.000904     0.000659     1.73e-05
     30    61      0.00206      0.00206     3.37e-07      0.00123      0.00171     0.000994            0      0.00145     0.000814      0.00137            0      0.00197      0.00111     0.000793     2.09e-05
  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              30  285.984    0.005      0.00407     7.28e-06      0.00407      0.00169       0.0024      0.00134            0      0.00201      0.00112      0.00199            0      0.00272      0.00157      0.00295     7.77e-05
! Validation         30  285.984    0.005      0.00217     4.15e-07      0.00217      0.00118      0.00175     0.000984            0      0.00135     0.000778      0.00153            0      0.00193      0.00116     0.000756     1.99e-05
Wall time: 285.98443068098277
! Best model       30    0.002
training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     31    10       0.0023      0.00229      6.1e-06      0.00142       0.0018      0.00158            0      0.00127     0.000949      0.00197            0      0.00164       0.0012      0.00328     8.64e-05
     31    20      0.00209      0.00208     1.03e-05      0.00129      0.00172      0.00104            0      0.00151      0.00085      0.00135            0      0.00199      0.00111      0.00458      0.00012
     31    30      0.00377      0.00376     4.67e-06      0.00184      0.00231      0.00168            0      0.00199      0.00122      0.00209            0      0.00249      0.00153       0.0028     7.36e-05
     31    40      0.00299      0.00298     1.01e-06       0.0016      0.00206       0.0015            0      0.00168      0.00106      0.00187            0      0.00221      0.00136      0.00131     3.44e-05
     31    50      0.00221      0.00221     1.96e-06      0.00137      0.00177     0.000928            0      0.00177     0.000898      0.00123            0      0.00214      0.00112      0.00173     4.56e-05
     31    60      0.00209      0.00208     4.96e-06      0.00128      0.00172     0.000873            0      0.00165     0.000839      0.00116            0       0.0021      0.00109      0.00311     8.19e-05
     31    70      0.00263      0.00263     1.19e-06      0.00156      0.00193      0.00157            0      0.00155      0.00104      0.00185            0        0.002      0.00128      0.00137      3.6e-05
     31    80      0.00374      0.00373     1.87e-05      0.00185       0.0023      0.00177            0      0.00193      0.00123      0.00212            0      0.00245      0.00152      0.00605     0.000159
     31    90      0.00263      0.00263     4.46e-06      0.00153      0.00193      0.00123            0       0.0018      0.00101      0.00154            0      0.00222      0.00126       0.0027      7.1e-05
     31   100      0.00225      0.00225     5.02e-06      0.00141      0.00179       0.0013            0      0.00152     0.000939      0.00159            0      0.00194      0.00118      0.00315     8.29e-05
     31   110      0.00696      0.00693     2.25e-05      0.00246      0.00314      0.00223            0      0.00266      0.00163      0.00277            0      0.00343      0.00207      0.00664     0.000175
     31   120      0.00341      0.00341     9.77e-07      0.00167       0.0022      0.00123            0      0.00208       0.0011      0.00156            0      0.00264       0.0014      0.00117     3.08e-05
     31   130      0.00192      0.00191     6.11e-06      0.00129      0.00165      0.00122            0      0.00135     0.000857      0.00151            0      0.00176      0.00109      0.00343     9.03e-05
     31   140      0.00254      0.00253     7.85e-06      0.00144       0.0019      0.00101            0      0.00183     0.000947      0.00127            0      0.00232       0.0012      0.00399     0.000105
     31   142       0.0025       0.0025     4.68e-06       0.0014      0.00188     0.000983            0      0.00177     0.000917      0.00127            0       0.0023      0.00119      0.00303     7.98e-05
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     31    10      0.00184      0.00184     1.04e-06      0.00118      0.00161      0.00099            0      0.00135     0.000781      0.00132            0      0.00184      0.00105      0.00129     3.41e-05
     31    20      0.00206      0.00206     4.04e-07      0.00127      0.00171     0.000952            0      0.00155     0.000833      0.00121            0      0.00206      0.00109     0.000793     2.09e-05
     31    30      0.00162      0.00161     4.53e-07      0.00111      0.00151     0.000929            0      0.00127     0.000734      0.00122            0      0.00174     0.000985     0.000854     2.25e-05
     31    40      0.00199      0.00199     7.98e-08      0.00123      0.00168      0.00097            0      0.00147     0.000814      0.00126            0      0.00199      0.00108     0.000354     9.32e-06
     31    50      0.00143      0.00143     2.25e-07      0.00104      0.00143     0.000868            0       0.0012     0.000689      0.00118            0      0.00161     0.000932     0.000488     1.28e-05
     31    60       0.0013       0.0013     2.46e-07      0.00105      0.00136     0.000842            0      0.00123      0.00069      0.00109            0      0.00155     0.000883     0.000623     1.64e-05
     31    61      0.00192      0.00192     2.88e-07      0.00119      0.00165     0.000955            0       0.0014     0.000784      0.00132            0       0.0019      0.00107     0.000748     1.97e-05
  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              31  295.763    0.005      0.00393     9.24e-06      0.00394      0.00166      0.00236      0.00133            0      0.00196       0.0011      0.00198            0      0.00266      0.00155      0.00343     9.04e-05
! Validation         31  295.763    0.005      0.00209      3.6e-07      0.00209      0.00115      0.00172     0.000958            0      0.00132     0.000759      0.00151            0      0.00189      0.00113     0.000691     1.82e-05
Wall time: 295.76401779599837
! Best model       31    0.002
training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     32    10      0.00503      0.00503      1.2e-06      0.00207      0.00267      0.00153            0      0.00256      0.00136      0.00182            0      0.00325      0.00169      0.00139     3.66e-05
     32    20      0.00746      0.00744     2.18e-05      0.00244      0.00325      0.00208            0      0.00277      0.00162      0.00247            0      0.00382       0.0021      0.00656     0.000173
     32    30       0.0028       0.0028     3.33e-07       0.0015      0.00199      0.00102            0      0.00193     0.000983      0.00128            0      0.00247      0.00125      0.00072      1.9e-05
     32    40       0.0029      0.00288      1.7e-05      0.00155      0.00202      0.00114            0      0.00192      0.00102      0.00143            0      0.00243      0.00129      0.00588     0.000155
     32    50      0.00182       0.0018     1.95e-05      0.00128       0.0016      0.00116            0      0.00139     0.000849      0.00144            0      0.00173      0.00106       0.0063     0.000166
     32    60      0.00293      0.00286     7.03e-05      0.00157      0.00201      0.00109            0      0.00201      0.00103      0.00138            0      0.00245      0.00128        0.012     0.000316
     32    70      0.00259      0.00255     4.49e-05      0.00149       0.0019      0.00108            0      0.00185     0.000978       0.0014            0      0.00226      0.00122      0.00955     0.000251
     32    80      0.00235      0.00234     1.35e-05      0.00137      0.00182     0.000996            0      0.00171     0.000902      0.00123            0      0.00222      0.00115      0.00518     0.000136
     32    90      0.00206      0.00204     1.53e-05      0.00126       0.0017      0.00087            0      0.00161     0.000827      0.00117            0      0.00207      0.00108      0.00548     0.000144
     32   100      0.00191       0.0019     8.29e-06      0.00121      0.00164     0.000837            0      0.00155     0.000796      0.00109            0      0.00201      0.00103      0.00411     0.000108
     32   110      0.00284      0.00284     4.44e-06      0.00155      0.00201      0.00113            0      0.00194      0.00102      0.00143            0      0.00241      0.00128      0.00295     7.77e-05
     32   120      0.00206      0.00205     1.04e-05      0.00128      0.00171     0.000935            0      0.00158      0.00084       0.0012            0      0.00206      0.00109      0.00443     0.000117
     32   130      0.00175      0.00175     1.08e-06      0.00121      0.00158        0.001            0      0.00139     0.000798      0.00129            0      0.00179      0.00103       0.0014     3.69e-05
     32   140      0.00151       0.0015     1.32e-05       0.0011      0.00146     0.000866            0      0.00132     0.000728      0.00112            0       0.0017     0.000943        0.005     0.000132
     32   142      0.00143      0.00143     2.03e-07      0.00109      0.00142     0.000866            0       0.0013     0.000721      0.00112            0      0.00165     0.000923     0.000631     1.66e-05
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     32    10      0.00174      0.00174     1.11e-06      0.00115      0.00157     0.000956            0      0.00132     0.000758      0.00128            0      0.00179      0.00103      0.00134     3.53e-05
     32    20      0.00201      0.00201     4.54e-07      0.00124      0.00169     0.000927            0      0.00152     0.000816      0.00118            0      0.00204      0.00107     0.000842     2.22e-05
     32    30      0.00154      0.00154     5.09e-07      0.00109      0.00148     0.000909            0      0.00125     0.000719      0.00119            0       0.0017     0.000962     0.000879     2.31e-05
     32    40      0.00192      0.00192     1.05e-07      0.00121      0.00165     0.000949            0      0.00144     0.000796      0.00123            0      0.00195      0.00106     0.000403     1.06e-05
     32    50      0.00138      0.00138     2.79e-07      0.00102       0.0014     0.000838            0      0.00118     0.000672      0.00115            0      0.00159     0.000914     0.000537     1.41e-05
     32    60      0.00125      0.00125     2.57e-07      0.00102      0.00133     0.000818            0      0.00121     0.000675      0.00106            0      0.00153     0.000864     0.000647      1.7e-05
     32    61      0.00183      0.00183     3.94e-07      0.00116      0.00161     0.000926            0      0.00137     0.000766      0.00127            0      0.00187      0.00105     0.000839     2.21e-05
! Train              32  305.542    0.005      0.00352     1.06e-05      0.00353      0.00155      0.00224      0.00123            0      0.00184      0.00102      0.00186            0      0.00253      0.00146      0.00376      9.9e-05
! Validation         32  305.542    0.005      0.00201     3.73e-07      0.00201      0.00112      0.00169     0.000934            0      0.00129      0.00074      0.00148            0      0.00186      0.00111     0.000714     1.88e-05
Wall time: 305.542505616002
! Best model       32    0.002
training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     33    10      0.00165      0.00165     4.34e-06      0.00121      0.00153      0.00109            0      0.00131       0.0008      0.00137            0      0.00166      0.00101      0.00278     7.32e-05
     33    20      0.00135      0.00135     1.39e-06      0.00108      0.00138     0.000918            0      0.00122     0.000713      0.00117            0      0.00155     0.000907      0.00143     3.76e-05
     33    30      0.00157      0.00156     1.12e-06      0.00116      0.00149     0.000982            0      0.00132     0.000767      0.00124            0      0.00169     0.000974      0.00133      3.5e-05
     33    40      0.00139      0.00138     1.08e-05      0.00111       0.0014     0.000919            0      0.00127     0.000731      0.00115            0      0.00159     0.000914      0.00442     0.000116
     33    50      0.00201        0.002     1.09e-05      0.00128      0.00168        0.001            0      0.00153     0.000845      0.00127            0      0.00198      0.00108       0.0045     0.000119
     33    60      0.00209      0.00204     4.99e-05      0.00128       0.0017     0.000881            0      0.00163     0.000838      0.00111            0      0.00209      0.00107       0.0101     0.000266
     33    70      0.00215      0.00211     3.76e-05      0.00131      0.00173      0.00113            0      0.00148      0.00087      0.00142            0      0.00197      0.00113      0.00876     0.000231
     33    80      0.00185      0.00185     1.03e-06      0.00122      0.00162      0.00107            0      0.00136     0.000809      0.00135            0      0.00183      0.00106      0.00135     3.57e-05
     33    90      0.00146      0.00145     4.83e-06      0.00111      0.00144     0.000918            0      0.00129     0.000736      0.00116            0      0.00165     0.000934      0.00304        8e-05
     33   100      0.00405      0.00404     1.23e-05      0.00199      0.00239      0.00185            0      0.00211      0.00132      0.00217            0      0.00258      0.00158      0.00468     0.000123
     33   110      0.00266      0.00266     4.31e-06      0.00151      0.00194      0.00138            0      0.00163        0.001      0.00176            0      0.00209      0.00128      0.00286     7.52e-05
     33   120      0.00544      0.00543     1.85e-05      0.00212      0.00277      0.00146            0      0.00271      0.00139      0.00183            0      0.00341      0.00174       0.0057      0.00015
     33   130      0.00445      0.00445     1.13e-06       0.0021      0.00251      0.00184            0      0.00233      0.00139      0.00219            0      0.00277      0.00165       0.0015     3.95e-05
     33   140      0.00564      0.00564     3.91e-07      0.00211      0.00283      0.00125            0      0.00289      0.00138      0.00164            0      0.00358      0.00174     0.000659     1.73e-05
     33   142      0.00971      0.00968     2.77e-05       0.0031      0.00371      0.00296            0      0.00323      0.00206      0.00352            0      0.00387      0.00246      0.00751     0.000198
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     33    10      0.00165      0.00165     1.08e-06      0.00112      0.00153     0.000934            0      0.00128     0.000737      0.00125            0      0.00174     0.000997      0.00128     3.37e-05
     33    20      0.00192      0.00192     3.69e-07      0.00122      0.00165     0.000918            0      0.00148     0.000801      0.00116            0      0.00199      0.00105     0.000781     2.06e-05
     33    30      0.00146      0.00146     4.58e-07      0.00106      0.00144     0.000882            0      0.00123     0.000703      0.00115            0      0.00166     0.000934     0.000842     2.22e-05
     33    40      0.00182      0.00182     7.56e-08      0.00117       0.0016     0.000915            0      0.00141     0.000774      0.00118            0      0.00191      0.00103     0.000317     8.35e-06
     33    50      0.00131      0.00131     2.85e-07     0.000999      0.00136     0.000822            0      0.00116      0.00066      0.00111            0      0.00156      0.00089     0.000537     1.41e-05
     33    60      0.00117      0.00117     2.35e-07     0.000991      0.00129     0.000807            0      0.00116     0.000655      0.00104            0      0.00148      0.00084     0.000647      1.7e-05
     33    61      0.00171      0.00171     3.41e-07      0.00112      0.00156     0.000894            0      0.00133     0.000742      0.00122            0       0.0018      0.00101     0.000748     1.97e-05
  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              33  315.350    0.005      0.00338     1.25e-05      0.00339       0.0015      0.00218      0.00121            0      0.00176     0.000989      0.00186            0      0.00244      0.00143      0.00392     0.000103
! Validation         33  315.350    0.005      0.00193     3.56e-07      0.00193      0.00109      0.00166     0.000911            0      0.00126     0.000722      0.00146            0      0.00182      0.00109     0.000699     1.84e-05
Wall time: 315.35037514098804
! Best model       33    0.002
training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     34    10       0.0088      0.00879     4.11e-06      0.00274      0.00353      0.00233            0       0.0031      0.00181      0.00312            0      0.00386      0.00233      0.00255     6.71e-05
     34    20      0.00596      0.00596     1.49e-06      0.00222      0.00291      0.00131            0      0.00303      0.00145      0.00168            0      0.00368      0.00179      0.00149     3.92e-05
     34    30      0.00468      0.00463     5.32e-05      0.00203      0.00256      0.00131            0      0.00269      0.00133      0.00165            0      0.00317      0.00161       0.0103     0.000272
     34    40      0.00694      0.00693     9.58e-06      0.00231      0.00314      0.00126            0      0.00326      0.00151      0.00167            0      0.00402       0.0019      0.00413     0.000109
     34    50      0.00259      0.00259     8.99e-07      0.00147      0.00192      0.00114            0      0.00177     0.000972      0.00142            0      0.00227      0.00123      0.00114     2.99e-05
     34    60      0.00246      0.00244     1.41e-05      0.00138      0.00186     0.000935            0      0.00178     0.000905      0.00121            0      0.00229      0.00117      0.00535     0.000141
     34    70       0.0017      0.00169     1.12e-05      0.00117      0.00155     0.000911            0      0.00141     0.000774      0.00118            0      0.00182        0.001      0.00474     0.000125
     34    80      0.00164      0.00164     3.48e-07      0.00117      0.00153     0.000954            0      0.00137     0.000774      0.00122            0      0.00176     0.000992     0.000684      1.8e-05
     34    90      0.00151      0.00151     3.22e-06      0.00111      0.00146     0.000945            0      0.00127     0.000737      0.00128            0      0.00161     0.000963      0.00247     6.49e-05
     34   100      0.00177      0.00176     7.71e-06       0.0012      0.00158     0.000944            0      0.00142     0.000788      0.00124            0      0.00184      0.00102      0.00393     0.000103
     34   110       0.0035       0.0035     3.74e-07      0.00167      0.00223      0.00103            0      0.00225      0.00109      0.00129            0      0.00282      0.00137     0.000684      1.8e-05
     34   120      0.00266      0.00265     8.47e-06      0.00146      0.00194      0.00104            0      0.00184      0.00096      0.00131            0      0.00237      0.00123      0.00389     0.000102
     34   130      0.00182      0.00182     6.07e-07      0.00125      0.00161     0.000967            0      0.00151     0.000824      0.00123            0      0.00188      0.00104     0.000964     2.54e-05
     34   140       0.0026       0.0026     3.57e-06      0.00154      0.00192      0.00122            0      0.00183      0.00102      0.00151            0      0.00223      0.00124      0.00222     5.85e-05
     34   142      0.00175      0.00174     1.14e-05      0.00121      0.00157     0.000764            0       0.0016     0.000789     0.000942            0      0.00197     0.000972      0.00476     0.000125
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     34    10       0.0016       0.0016     8.28e-07       0.0011      0.00151      0.00092            0      0.00127      0.00073      0.00123            0      0.00172     0.000983      0.00117     3.08e-05
     34    20      0.00185      0.00185     3.03e-07      0.00119      0.00162     0.000901            0      0.00146     0.000786      0.00114            0      0.00195      0.00103     0.000684      1.8e-05
     34    30      0.00141       0.0014     4.54e-07      0.00104      0.00141     0.000874            0       0.0012     0.000691      0.00114            0      0.00162     0.000919     0.000842     2.22e-05
     34    40       0.0018       0.0018     7.71e-08      0.00117       0.0016      0.00092            0       0.0014     0.000774      0.00118            0       0.0019      0.00103     0.000366     9.64e-06
     34    50      0.00126      0.00126     2.35e-07      0.00098      0.00134     0.000808            0      0.00114     0.000648       0.0011            0      0.00152     0.000874     0.000488     1.28e-05
     34    60      0.00116      0.00116     2.02e-07     0.000986      0.00128     0.000803            0      0.00115     0.000651      0.00103            0      0.00147     0.000834     0.000598     1.57e-05
     34    61      0.00167      0.00167     3.39e-07      0.00111      0.00154     0.000885            0      0.00131     0.000732      0.00121            0      0.00178     0.000997     0.000809     2.13e-05
  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              34  324.982    0.005      0.00403     8.87e-06      0.00403      0.00167      0.00239      0.00136            0      0.00195      0.00111      0.00206            0      0.00266      0.00157      0.00337     8.86e-05
! Validation         34  324.982    0.005       0.0019     3.27e-07       0.0019      0.00108      0.00164     0.000899            0      0.00124     0.000713      0.00144            0       0.0018      0.00108     0.000662     1.74e-05
Wall time: 324.9823964909883
! Best model       34    0.002
training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     35    10      0.00159      0.00159     4.19e-06      0.00114       0.0015     0.000865            0      0.00138     0.000749      0.00116            0      0.00175     0.000971      0.00291     7.65e-05
     35    20      0.00156      0.00156     3.27e-06      0.00118      0.00149      0.00109            0      0.00126     0.000782      0.00134            0       0.0016     0.000982       0.0025     6.59e-05
     35    30      0.00148      0.00147     2.98e-06      0.00112      0.00145      0.00104            0       0.0012     0.000745      0.00132            0      0.00155     0.000957      0.00233     6.14e-05
     35    40      0.00175      0.00174     7.44e-06      0.00119      0.00157     0.000799            0      0.00154     0.000779      0.00103            0      0.00193     0.000988      0.00382     0.000101
     35    50      0.00168      0.00168     6.07e-07      0.00121      0.00154     0.000859            0      0.00153     0.000797       0.0011            0      0.00185     0.000985      0.00101     2.67e-05
     35    60      0.00331       0.0033     3.51e-06      0.00159      0.00216     0.000851            0      0.00226      0.00104       0.0011            0       0.0028       0.0013      0.00256     6.75e-05
     35    70      0.00278      0.00278     2.23e-07      0.00152      0.00198     0.000924            0      0.00206     0.000995      0.00117            0       0.0025      0.00122     0.000537     1.41e-05
     35    80       0.0173       0.0173     1.02e-05      0.00421      0.00495      0.00375            0      0.00462      0.00279      0.00434            0      0.00544      0.00326      0.00439     0.000116
     35    90      0.00536      0.00536     1.83e-06      0.00198      0.00276     0.000959            0      0.00291      0.00129      0.00121            0      0.00362      0.00161      0.00186     4.88e-05
     35   100       0.0208       0.0207     3.22e-05      0.00352      0.00543      0.00308            0      0.00392      0.00233      0.00508            0      0.00572       0.0036      0.00804     0.000212
     35   110      0.00483      0.00483     3.78e-07        0.002      0.00262      0.00117            0      0.00275      0.00131      0.00147            0      0.00333       0.0016     0.000696     1.83e-05
     35   120      0.00284      0.00283     1.34e-05      0.00153        0.002      0.00126            0      0.00177      0.00101      0.00159            0      0.00231       0.0013      0.00522     0.000137
     35   130      0.00169      0.00169     1.17e-06      0.00119      0.00155     0.000848            0       0.0015     0.000784      0.00108            0      0.00188     0.000984      0.00137      3.6e-05
     35   140      0.00154      0.00153     1.36e-05      0.00111      0.00147       0.0008            0      0.00138     0.000728      0.00105            0      0.00177      0.00094      0.00515     0.000136
     35   142      0.00148      0.00148     3.17e-06      0.00114      0.00145     0.000887            0      0.00136      0.00075      0.00114            0      0.00168     0.000939      0.00248     6.53e-05
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     35    10      0.00157      0.00157     9.09e-07      0.00109      0.00149     0.000905            0      0.00125      0.00072      0.00121            0      0.00171     0.000973      0.00123     3.24e-05
     35    20      0.00187      0.00187     2.38e-07       0.0012      0.00163       0.0009            0      0.00147     0.000791      0.00114            0      0.00197      0.00104      0.00061     1.61e-05
     35    30      0.00137      0.00137     3.93e-07      0.00103      0.00139     0.000861            0      0.00118      0.00068      0.00111            0      0.00161     0.000907     0.000745     1.96e-05
     35    40       0.0018       0.0018     5.92e-08      0.00117       0.0016     0.000917            0       0.0014     0.000771      0.00117            0       0.0019      0.00102     0.000293     7.71e-06
     35    50      0.00123      0.00123     2.31e-07      0.00097      0.00132     0.000792            0      0.00113     0.000641      0.00108            0      0.00151     0.000861     0.000513     1.35e-05
     35    60      0.00115      0.00115     1.96e-07     0.000983      0.00127     0.000805            0      0.00114     0.000649      0.00103            0      0.00146      0.00083     0.000598     1.57e-05
     35    61      0.00158      0.00158     2.85e-07      0.00109       0.0015     0.000867            0      0.00129     0.000718      0.00119            0      0.00173     0.000971     0.000732     1.93e-05
  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              35  334.641    0.005      0.00367     8.83e-06      0.00368      0.00157      0.00228       0.0012            0      0.00191      0.00103      0.00183            0      0.00263      0.00149       0.0033     8.69e-05
! Validation         35  334.641    0.005      0.00185      2.9e-07      0.00185      0.00107      0.00162     0.000887            0      0.00123     0.000704      0.00143            0      0.00178      0.00107     0.000622     1.64e-05
Wall time: 334.6418645269878
! Best model       35    0.002
training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     36    10      0.00128      0.00128     7.44e-07      0.00101      0.00135     0.000784            0      0.00121     0.000665      0.00102            0      0.00159      0.00087     0.000964     2.54e-05
     36    20      0.00131       0.0013     1.95e-06      0.00105      0.00136     0.000867            0      0.00122     0.000694       0.0011            0      0.00156     0.000887      0.00192     5.04e-05
     36    30      0.00184      0.00184     2.95e-06       0.0012      0.00162     0.000847            0      0.00152     0.000791      0.00108            0      0.00198      0.00102      0.00228     6.01e-05
     36    40      0.00341      0.00341     2.64e-07      0.00166       0.0022       0.0012            0      0.00206      0.00109      0.00152            0      0.00266       0.0014     0.000696     1.83e-05
     36    50      0.00393      0.00389     3.87e-05      0.00189      0.00235      0.00161            0      0.00213      0.00125      0.00193            0      0.00267      0.00153       0.0089     0.000234
     36    60      0.00228      0.00227     1.09e-05      0.00134       0.0018      0.00106            0       0.0016     0.000886      0.00142            0      0.00207      0.00117      0.00466     0.000123
     36    70       0.0014      0.00139     3.73e-06       0.0011      0.00141     0.000979            0      0.00121     0.000729      0.00121            0      0.00156     0.000923      0.00247     6.49e-05
     36    80       0.0155       0.0155     1.12e-06      0.00297      0.00469      0.00325            0      0.00273      0.00199      0.00489            0       0.0045      0.00313      0.00107     2.83e-05
     36    90       0.0192       0.0192     8.29e-06      0.00312      0.00522      0.00288            0      0.00333      0.00207      0.00535            0      0.00509      0.00348      0.00406     0.000107
     36   100      0.00282       0.0028     1.33e-05       0.0015      0.00199     0.000928            0      0.00202     0.000982      0.00116            0      0.00252      0.00123      0.00516     0.000136
     36   110      0.00933      0.00931     2.02e-05      0.00296      0.00364      0.00206            0      0.00378      0.00195      0.00244            0      0.00444       0.0023       0.0063     0.000166
     36   120      0.00447      0.00447     5.75e-06      0.00185      0.00252     0.000898            0      0.00271       0.0012      0.00114            0       0.0033      0.00148      0.00302     7.93e-05
     36   130      0.00223      0.00215     8.12e-05      0.00134      0.00175      0.00104            0       0.0016     0.000881      0.00135            0      0.00204      0.00113       0.0129     0.000338
     36   140      0.00162       0.0016     1.25e-05      0.00114      0.00151     0.000894            0      0.00137     0.000755      0.00115            0      0.00177     0.000974        0.005     0.000132
     36   142       0.0022       0.0022     5.17e-06      0.00134      0.00177      0.00105            0      0.00161     0.000887      0.00134            0      0.00207      0.00114      0.00317     8.35e-05
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     36    10      0.00148      0.00148     1.02e-06      0.00106      0.00145     0.000885            0      0.00122       0.0007      0.00119            0      0.00165     0.000946      0.00128     3.37e-05
     36    20      0.00182      0.00182     2.72e-07      0.00119      0.00161      0.00089            0      0.00146     0.000782      0.00112            0      0.00194      0.00102     0.000671     1.77e-05
     36    30      0.00132      0.00132     3.65e-07      0.00102      0.00137     0.000841            0      0.00117     0.000671      0.00109            0      0.00158     0.000889     0.000708     1.86e-05
     36    40      0.00173      0.00173     6.45e-08      0.00116      0.00157     0.000903            0      0.00138     0.000762      0.00115            0      0.00186        0.001     0.000317     8.35e-06
     36    50       0.0012       0.0012     2.24e-07     0.000954       0.0013     0.000775            0      0.00112      0.00063      0.00105            0       0.0015     0.000849     0.000537     1.41e-05
     36    60      0.00112      0.00112     2.15e-07     0.000977      0.00126     0.000808            0      0.00113     0.000646      0.00103            0      0.00144     0.000822      0.00061     1.61e-05
     36    61      0.00157      0.00157     3.37e-07      0.00108      0.00149     0.000842            0       0.0013     0.000714      0.00116            0      0.00174     0.000965     0.000778     2.05e-05
  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              36  344.311    0.005      0.00352     1.31e-05      0.00353      0.00154      0.00224      0.00115            0      0.00188      0.00101      0.00176            0      0.00259      0.00145      0.00396     0.000104
! Validation         36  344.311    0.005       0.0018     2.88e-07       0.0018      0.00105       0.0016     0.000874            0      0.00121     0.000694      0.00141            0      0.00175      0.00105     0.000624     1.64e-05
Wall time: 344.3115367019782
! Best model       36    0.002
training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     37    10      0.00225      0.00225     2.24e-06      0.00137      0.00179      0.00101            0      0.00168     0.000899      0.00127            0      0.00215      0.00114      0.00186     4.88e-05
     37    20      0.00158      0.00158     5.73e-07      0.00118       0.0015        0.001            0      0.00133     0.000778      0.00123            0       0.0017     0.000979     0.000964     2.54e-05
     37    30      0.00181       0.0018     5.87e-06      0.00121       0.0016     0.000846            0      0.00153     0.000793      0.00112            0      0.00193      0.00102      0.00343     9.03e-05
     37    40       0.0087      0.00869      1.3e-05      0.00286      0.00351       0.0031            0      0.00265      0.00192       0.0036            0      0.00343      0.00234      0.00499     0.000131
     37    50      0.00391      0.00389     2.46e-05      0.00177      0.00235      0.00143            0      0.00208      0.00117      0.00178            0      0.00277      0.00151      0.00696     0.000183
     37    60      0.00295      0.00293     1.45e-05      0.00157      0.00204      0.00162            0      0.00154      0.00105      0.00209            0      0.00199      0.00136      0.00533      0.00014
     37    70      0.00195      0.00195     7.23e-07      0.00125      0.00166     0.000954            0      0.00151     0.000822      0.00123            0      0.00198      0.00107        0.001     2.63e-05
     37    80      0.00185      0.00185     5.25e-06      0.00123      0.00162     0.000828            0      0.00158     0.000804      0.00106            0      0.00199      0.00102      0.00327     8.61e-05
     37    90      0.00143      0.00143     7.33e-07      0.00105      0.00142      0.00082            0      0.00127     0.000695      0.00107            0      0.00168     0.000916       0.0011     2.89e-05
     37   100      0.00153      0.00152     4.69e-06      0.00108      0.00147     0.000923            0      0.00122     0.000715      0.00119            0      0.00168     0.000957      0.00306     8.06e-05
     37   110      0.00116      0.00115     3.46e-06      0.00101      0.00128      0.00087            0      0.00113     0.000667      0.00109            0      0.00143     0.000839      0.00264     6.94e-05
     37   120      0.00192      0.00191     8.64e-06      0.00124      0.00165      0.00094            0      0.00152     0.000819      0.00116            0      0.00198      0.00105      0.00416      0.00011
     37   130      0.00142      0.00142      4.3e-07      0.00109      0.00142     0.000752            0       0.0014     0.000716     0.000953            0      0.00174     0.000896     0.000854     2.25e-05
     37   140      0.00128      0.00127     2.63e-06      0.00102      0.00134     0.000842            0      0.00117     0.000671       0.0011            0      0.00153     0.000878      0.00226     5.94e-05
     37   142       0.0327       0.0327     5.24e-07      0.00389      0.00681      0.00413            0      0.00366       0.0026      0.00713            0      0.00651      0.00455     0.000916     2.41e-05
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     37    10      0.00141      0.00141     1.09e-06      0.00104      0.00141     0.000867            0       0.0012     0.000688      0.00116            0      0.00161     0.000923      0.00127     3.34e-05
     37    20      0.00175      0.00175     2.73e-07      0.00116      0.00158     0.000866            0      0.00142     0.000761      0.00109            0      0.00191        0.001     0.000671     1.77e-05
     37    30      0.00124      0.00124     3.65e-07     0.000979      0.00133     0.000816            0      0.00113     0.000647      0.00106            0      0.00153     0.000863     0.000781     2.06e-05
     37    40      0.00162      0.00162     6.18e-08      0.00112      0.00152     0.000868            0      0.00134     0.000736      0.00111            0      0.00181     0.000973     0.000281     7.39e-06
     37    50      0.00113      0.00113     1.33e-07     0.000926      0.00127     0.000749            0      0.00108     0.000611      0.00101            0      0.00146     0.000824     0.000403     1.06e-05
     37    60      0.00105      0.00105     1.48e-07     0.000942      0.00122      0.00077            0       0.0011     0.000622     0.000987            0       0.0014     0.000794       0.0005     1.32e-05
     37    61      0.00145      0.00145     3.32e-07      0.00103      0.00143      0.00081            0      0.00123      0.00068      0.00111            0      0.00167     0.000927     0.000717     1.89e-05
  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              37  354.119    0.005      0.00311     7.72e-06      0.00311      0.00141      0.00207      0.00113            0      0.00165     0.000929      0.00178            0       0.0023      0.00136      0.00313     8.24e-05
! Validation         37  354.119    0.005      0.00174     2.73e-07      0.00174      0.00102      0.00157     0.000849            0      0.00118     0.000675      0.00139            0      0.00172      0.00103     0.000599     1.58e-05
Wall time: 354.1201491789834
! Best model       37    0.002
training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     38    10      0.00453      0.00452     1.83e-05      0.00193      0.00253      0.00141            0       0.0024      0.00127      0.00178            0      0.00305      0.00161      0.00608      0.00016
     38    20      0.00299      0.00299     3.59e-06      0.00167      0.00206      0.00161            0      0.00172      0.00111      0.00192            0      0.00218      0.00136      0.00248     6.52e-05
     38    30      0.00126      0.00125     5.14e-06      0.00104      0.00133     0.000877            0      0.00118     0.000686      0.00108            0      0.00152     0.000868      0.00317     8.35e-05
     38    40      0.00731       0.0073     8.81e-06       0.0026      0.00322      0.00214            0      0.00302      0.00172      0.00253            0      0.00373      0.00209      0.00399     0.000105
     38    50      0.00327      0.00326     5.75e-06      0.00158      0.00215      0.00104            0      0.00206      0.00103      0.00138            0      0.00266      0.00135      0.00336     8.83e-05
     38    60      0.00183      0.00183     5.72e-06      0.00123      0.00161     0.000907            0      0.00153     0.000812      0.00115            0      0.00193      0.00103      0.00325     8.54e-05
     38    70       0.0182       0.0182     1.58e-06      0.00292      0.00508      0.00276            0      0.00307      0.00194      0.00526            0      0.00491      0.00339      0.00173     4.56e-05
     38    80      0.00546      0.00545     5.53e-06        0.002      0.00278      0.00183            0      0.00216      0.00133      0.00268            0      0.00287      0.00185      0.00333     8.77e-05
     38    90       0.0031       0.0031     1.92e-06      0.00166       0.0021      0.00124            0      0.00203      0.00109      0.00156            0      0.00248      0.00135      0.00182     4.79e-05
     38   100      0.00246      0.00246     8.09e-07      0.00146      0.00187      0.00123            0      0.00167     0.000969      0.00157            0       0.0021      0.00122      0.00126     3.31e-05
     38   110      0.00198      0.00198     1.09e-06      0.00132      0.00168      0.00101            0       0.0016     0.000872      0.00129            0      0.00196      0.00108      0.00127     3.34e-05
     38   120      0.00142      0.00142     1.26e-06      0.00107      0.00142     0.000883            0      0.00124     0.000708      0.00116            0      0.00162     0.000925      0.00154     4.05e-05
     38   130      0.00104      0.00104     3.25e-07      0.00093      0.00122     0.000726            0      0.00111     0.000613     0.000937            0      0.00142     0.000786     0.000769     2.02e-05
     38   140      0.00119      0.00119     1.64e-07     0.000986       0.0013     0.000757            0      0.00119      0.00065     0.000989            0      0.00152     0.000838     0.000464     1.22e-05
     38   142     0.000987     0.000986     9.28e-07     0.000915      0.00118     0.000791            0      0.00103     0.000606      0.00104            0       0.0013     0.000779      0.00122     3.21e-05
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     38    10      0.00138      0.00138     9.56e-07      0.00104       0.0014     0.000858            0       0.0012     0.000685      0.00114            0      0.00159     0.000913      0.00123     3.24e-05
     38    20      0.00171      0.00171     2.48e-07      0.00114      0.00156     0.000859            0       0.0014     0.000753      0.00108            0      0.00189     0.000991     0.000635     1.67e-05
     38    30      0.00123      0.00123     3.59e-07     0.000968      0.00132     0.000806            0      0.00111      0.00064      0.00104            0      0.00153     0.000856     0.000708     1.86e-05
     38    40      0.00158      0.00158     4.97e-08      0.00111      0.00149      0.00086            0      0.00133     0.000729      0.00109            0      0.00178     0.000958     0.000281     7.39e-06
     38    50      0.00108      0.00108     2.13e-07     0.000903      0.00124     0.000733            0      0.00106     0.000596     0.000994            0      0.00142     0.000804     0.000525     1.38e-05
     38    60        0.001        0.001     1.52e-07     0.000924      0.00119     0.000768            0      0.00106     0.000611     0.000982            0      0.00136     0.000779     0.000537     1.41e-05
     38    61       0.0014       0.0014     3.11e-07      0.00102      0.00141     0.000798            0      0.00122     0.000673       0.0011            0      0.00164     0.000914     0.000778     2.05e-05
  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              38  363.821    0.005      0.00368     9.06e-06      0.00368      0.00158      0.00229      0.00124            0      0.00189      0.00104      0.00188            0       0.0026      0.00149      0.00311     8.19e-05
! Validation         38  363.821    0.005      0.00171     2.57e-07      0.00171      0.00101      0.00156      0.00084            0      0.00116     0.000667      0.00137            0       0.0017      0.00103     0.000581     1.53e-05
Wall time: 363.82159651399706
! Best model       38    0.002
training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     39    10       0.0021       0.0021     1.78e-06      0.00137      0.00173      0.00132            0       0.0014     0.000909      0.00161            0      0.00183      0.00114      0.00179     4.72e-05
     39    20       0.0014      0.00139     9.01e-06      0.00106       0.0014       0.0009            0      0.00121     0.000704      0.00118            0      0.00158     0.000919      0.00428     0.000113
     39    30      0.00106      0.00105     2.74e-06     0.000958      0.00122     0.000781            0      0.00112     0.000633     0.000985            0       0.0014     0.000796      0.00229     6.04e-05
     39    40      0.00272      0.00272     8.74e-07      0.00147      0.00196     0.000908            0      0.00198     0.000963      0.00113            0      0.00249      0.00121      0.00117     3.08e-05
     39    50      0.00194      0.00194     2.95e-07      0.00124      0.00166     0.000771            0      0.00166      0.00081     0.000975            0      0.00209      0.00102     0.000623     1.64e-05
     39    60      0.00144      0.00143     5.62e-06      0.00107      0.00143      0.00079            0      0.00133     0.000705      0.00102            0      0.00171      0.00091      0.00334      8.8e-05
     39    70      0.00161       0.0016     4.76e-06      0.00114      0.00151     0.000834            0      0.00142     0.000752      0.00108            0      0.00181     0.000963      0.00304        8e-05
     39    80      0.00119      0.00118      4.1e-06     0.000986       0.0013      0.00078            0      0.00117      0.00065      0.00102            0       0.0015      0.00084      0.00284     7.48e-05
     39    90      0.00183      0.00183     1.08e-07      0.00127      0.00161      0.00101            0      0.00151     0.000837      0.00126            0      0.00187      0.00104     0.000415     1.09e-05
     39   100      0.00309      0.00309     9.03e-08      0.00163       0.0021      0.00131            0      0.00191      0.00107      0.00166            0      0.00242      0.00136     0.000378     9.96e-06
     39   110      0.00235      0.00234     1.17e-05      0.00136      0.00182     0.000855            0      0.00182     0.000892      0.00107            0       0.0023      0.00112      0.00483     0.000127
     39   120      0.00249      0.00249     2.47e-06      0.00143      0.00188     0.000828            0      0.00197     0.000931      0.00104            0       0.0024      0.00114      0.00197     5.17e-05
     39   130      0.00544      0.00544     1.29e-06      0.00204      0.00278      0.00107            0      0.00292      0.00133      0.00134            0      0.00361      0.00165      0.00162     4.27e-05
     39   140      0.00298      0.00297     8.88e-06      0.00157      0.00205      0.00112            0      0.00198      0.00103      0.00139            0       0.0025       0.0013      0.00425     0.000112
     39   142       0.0014       0.0014     5.54e-07      0.00107      0.00141     0.000878            0      0.00123     0.000704      0.00108            0      0.00165     0.000911      0.00108     2.84e-05
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     39    10      0.00129      0.00129     7.41e-07        0.001      0.00135     0.000847            0      0.00115     0.000664      0.00113            0      0.00153     0.000886      0.00111     2.92e-05
     39    20      0.00164      0.00164      2.5e-07      0.00112      0.00153     0.000842            0      0.00137     0.000738      0.00106            0      0.00185      0.00097     0.000647      1.7e-05
     39    30      0.00117      0.00117     3.99e-07      0.00095      0.00129     0.000786            0       0.0011     0.000628      0.00101            0      0.00149     0.000835     0.000732     1.93e-05
     39    40      0.00149      0.00149     9.88e-08      0.00108      0.00146     0.000842            0      0.00129     0.000711      0.00107            0      0.00173     0.000933     0.000366     9.64e-06
     39    50      0.00102      0.00102     1.91e-07     0.000878       0.0012     0.000716            0      0.00102      0.00058     0.000969            0      0.00138     0.000783     0.000513     1.35e-05
     39    60     0.000948     0.000948     1.93e-07     0.000897      0.00116     0.000743            0      0.00104     0.000593     0.000951            0      0.00132     0.000757     0.000598     1.57e-05
     39    61      0.00132      0.00132     2.77e-07     0.000996      0.00137     0.000779            0      0.00119     0.000657      0.00107            0      0.00159     0.000888     0.000717     1.89e-05
  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              39  373.254    0.005      0.00316      4.9e-06      0.00316      0.00145      0.00212      0.00113            0      0.00174     0.000958      0.00176            0      0.00239      0.00139      0.00257     6.76e-05
! Validation         39  373.254    0.005      0.00165     2.55e-07      0.00165     0.000985      0.00153     0.000822            0      0.00113     0.000651      0.00136            0      0.00167      0.00101     0.000589     1.55e-05
Wall time: 373.2542714419833
! Best model       39    0.002
training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     40    10      0.00187      0.00186     5.89e-06      0.00121      0.00163     0.000905            0      0.00148     0.000794      0.00114            0      0.00196      0.00103      0.00341     8.96e-05
     40    20      0.00323      0.00322     9.72e-06      0.00172      0.00214       0.0013            0       0.0021      0.00113      0.00162            0      0.00251      0.00138      0.00428     0.000113
     40    30      0.00336      0.00336      6.4e-07      0.00176      0.00218      0.00156            0      0.00195      0.00117      0.00189            0      0.00241      0.00144      0.00109     2.86e-05
     40    40      0.00317      0.00316     8.09e-06      0.00155      0.00212     0.000956            0      0.00209      0.00101      0.00123            0      0.00267       0.0013      0.00391     0.000103
     40    50      0.00231       0.0023     8.99e-06       0.0014      0.00181      0.00106            0      0.00171     0.000925      0.00137            0      0.00213      0.00117      0.00398     0.000105
     40    60      0.00586      0.00586     1.82e-06      0.00212      0.00288      0.00117            0      0.00298      0.00138      0.00157            0      0.00368      0.00175      0.00171      4.5e-05
     40    70       0.0025      0.00249     1.24e-05       0.0014      0.00188     0.000941            0      0.00181     0.000918      0.00122            0      0.00232      0.00118      0.00499     0.000131
     40    80         0.02       0.0199     7.31e-06      0.00293      0.00532      0.00285            0      0.00301      0.00195      0.00574            0      0.00491      0.00355       0.0038     9.99e-05
     40    90      0.00205      0.00204     1.55e-06      0.00132       0.0017      0.00105            0      0.00157     0.000874      0.00132            0      0.00199       0.0011       0.0016     4.21e-05
     40   100      0.00112      0.00112     8.24e-08      0.00097      0.00126     0.000776            0      0.00114      0.00064     0.000985            0      0.00146     0.000817     0.000366     9.64e-06
     40   110      0.00137      0.00137     9.52e-07      0.00109      0.00139      0.00103            0      0.00115     0.000727       0.0013            0      0.00147     0.000924      0.00125     3.28e-05
     40   120     0.000895     0.000895     6.03e-07     0.000873      0.00113     0.000707            0      0.00102     0.000576     0.000871            0      0.00131     0.000729      0.00107     2.83e-05
     40   130      0.00137      0.00136     4.35e-06      0.00104      0.00139      0.00083            0      0.00123     0.000687      0.00107            0      0.00163     0.000899      0.00293     7.71e-05
     40   140      0.00247      0.00247     3.18e-07      0.00153      0.00187      0.00116            0      0.00186      0.00101      0.00141            0      0.00221      0.00121     0.000745     1.96e-05
     40   142      0.00259      0.00259     9.81e-07      0.00146      0.00192     0.000958            0       0.0019     0.000954      0.00124            0      0.00236       0.0012      0.00112     2.94e-05
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     40    10       0.0013       0.0013      9.4e-07      0.00101      0.00136     0.000839            0      0.00116     0.000667      0.00112            0      0.00154     0.000885      0.00122     3.21e-05
     40    20      0.00163      0.00163     2.39e-07      0.00111      0.00152     0.000844            0      0.00135     0.000733      0.00106            0      0.00183     0.000966      0.00061     1.61e-05
     40    30      0.00114      0.00114     3.33e-07     0.000936      0.00127     0.000774            0      0.00108     0.000619     0.000997            0      0.00147     0.000824     0.000696     1.83e-05
     40    40      0.00145      0.00145     7.56e-08      0.00107      0.00143     0.000841            0      0.00127     0.000704      0.00106            0       0.0017     0.000921      0.00033     8.67e-06
     40    50     0.000988     0.000988     1.24e-07     0.000863      0.00118     0.000705            0      0.00101      0.00057     0.000954            0      0.00136     0.000771     0.000391     1.03e-05
     40    60     0.000947     0.000947     1.61e-07     0.000897      0.00116      0.00075            0      0.00103     0.000593     0.000957            0      0.00131     0.000757     0.000537     1.41e-05
     40    61      0.00128      0.00128     2.91e-07      0.00098      0.00135     0.000763            0      0.00118     0.000646      0.00105            0      0.00157     0.000872     0.000748     1.97e-05
  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              40  381.946    0.005      0.00303      6.4e-06      0.00304      0.00141      0.00208      0.00112            0      0.00168     0.000933      0.00175            0      0.00233      0.00136      0.00287     7.55e-05
! Validation         40  381.946    0.005      0.00161     2.36e-07      0.00161     0.000974      0.00151     0.000816            0      0.00112     0.000644      0.00135            0      0.00165     0.000998     0.000557     1.46e-05
Wall time: 381.9471272029914
! Best model       40    0.002
training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     41    10      0.00146      0.00146     8.06e-07      0.00109      0.00144     0.000809            0      0.00135     0.000719      0.00103            0      0.00173     0.000919      0.00112     2.96e-05
     41    20      0.00116      0.00116     9.83e-07      0.00101      0.00128     0.000849            0      0.00116      0.00067      0.00104            0      0.00147     0.000837      0.00114     2.99e-05
     41    30      0.00104      0.00104     8.92e-07      0.00095      0.00121     0.000756            0      0.00112     0.000627     0.000954            0       0.0014     0.000786      0.00116     3.05e-05
     41    40      0.00103      0.00103     1.02e-06     0.000925      0.00121     0.000713            0      0.00111     0.000609     0.000959            0      0.00139     0.000784      0.00134     3.53e-05
     41    50       0.0026      0.00259     4.19e-06      0.00145      0.00192     0.000871            0      0.00198     0.000949      0.00111            0      0.00242      0.00118      0.00275     7.23e-05
     41    60      0.00175      0.00173     2.01e-05      0.00115      0.00157     0.000779            0      0.00149     0.000755        0.001            0      0.00194     0.000981      0.00635     0.000167
     41    70      0.00104      0.00101     2.63e-05     0.000925       0.0012     0.000735            0       0.0011      0.00061     0.000947            0      0.00139     0.000779      0.00731     0.000192
     41    80      0.00646      0.00646     4.94e-06      0.00247      0.00303      0.00221            0      0.00269      0.00164      0.00263            0      0.00334      0.00199      0.00275     7.23e-05
     41    90      0.00215      0.00214     7.08e-06      0.00137      0.00174      0.00105            0      0.00165     0.000902      0.00131            0      0.00206      0.00112      0.00374     9.83e-05
     41   100      0.00414      0.00413     8.68e-06      0.00192      0.00242      0.00183            0        0.002      0.00128      0.00218            0      0.00262       0.0016      0.00358     9.41e-05
     41   110      0.00371      0.00371      4.2e-07      0.00177      0.00229      0.00149            0      0.00203      0.00117      0.00186            0      0.00262       0.0015     0.000842     2.22e-05
     41   120      0.00303      0.00298     4.37e-05      0.00164      0.00206      0.00163            0      0.00164      0.00109      0.00204            0      0.00207      0.00137      0.00942     0.000248
     41   130      0.00142      0.00141     8.85e-06      0.00109      0.00142     0.000938            0      0.00122     0.000721      0.00122            0      0.00157     0.000931      0.00419      0.00011
     41   140      0.00193      0.00193     1.43e-06      0.00126      0.00165      0.00104            0      0.00146     0.000835       0.0013            0      0.00191      0.00107      0.00156     4.11e-05
     41   142      0.00153      0.00152     1.21e-05      0.00112      0.00147     0.000827            0      0.00138     0.000736      0.00105            0      0.00176     0.000937      0.00488     0.000128
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     41    10      0.00126      0.00126     1.03e-06     0.000999      0.00134     0.000829            0      0.00115      0.00066       0.0011            0      0.00151     0.000872      0.00127     3.34e-05
     41    20      0.00161      0.00161        2e-07      0.00111      0.00151     0.000835            0      0.00137     0.000734      0.00105            0      0.00183     0.000959     0.000537     1.41e-05
     41    30      0.00109      0.00109     3.53e-07     0.000921      0.00125     0.000762            0      0.00106     0.000609     0.000985            0      0.00144     0.000808     0.000745     1.96e-05
     41    40      0.00141      0.00141     5.02e-08      0.00105      0.00141     0.000833            0      0.00125     0.000696      0.00105            0      0.00168     0.000908     0.000256     6.75e-06
     41    50     0.000954     0.000954     1.74e-07     0.000849      0.00116     0.000694            0     0.000989     0.000561     0.000947            0      0.00133     0.000758     0.000427     1.12e-05
     41    60     0.000948     0.000948     1.41e-07     0.000893      0.00116     0.000738            0      0.00103      0.00059     0.000947            0      0.00132     0.000756     0.000488     1.28e-05
     41    61      0.00127      0.00127      2.5e-07     0.000983      0.00134     0.000756            0      0.00119     0.000648      0.00104            0      0.00157     0.000869     0.000687     1.81e-05
  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              41  391.622    0.005      0.00349     6.75e-06       0.0035      0.00153      0.00223      0.00125            0      0.00179      0.00101       0.0019            0      0.00248      0.00146      0.00285     7.49e-05
! Validation         41  391.622    0.005      0.00159     2.39e-07      0.00159     0.000967       0.0015     0.000806            0      0.00111     0.000639      0.00134            0      0.00163      0.00099     0.000557     1.46e-05
Wall time: 391.62295816797996
! Best model       41    0.002
training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     42    10      0.00436      0.00436     1.11e-07      0.00177      0.00249     0.000923            0      0.00253      0.00115      0.00117            0      0.00324      0.00147      0.00033     8.67e-06
     42    20      0.00247      0.00244     2.72e-05      0.00143      0.00186     0.000877            0      0.00193     0.000935      0.00111            0      0.00234      0.00115      0.00742     0.000195
     42    30      0.00424      0.00422     1.93e-05      0.00181      0.00245      0.00111            0      0.00245      0.00119      0.00146            0      0.00308      0.00151      0.00624     0.000164
     42    40      0.00184      0.00181     3.42e-05      0.00124       0.0016     0.000957            0       0.0015      0.00082       0.0012            0      0.00189      0.00103      0.00836      0.00022
     42    50      0.00224      0.00224     2.29e-06      0.00135      0.00178      0.00092            0      0.00174     0.000887      0.00118            0      0.00218      0.00112      0.00204     5.36e-05
     42    60      0.00162      0.00161      1.3e-05      0.00117      0.00151        0.001            0      0.00133     0.000777      0.00123            0      0.00172     0.000984      0.00507     0.000133
     42    70      0.00144      0.00144        2e-06      0.00109      0.00143     0.000726            0      0.00142     0.000714     0.000933            0      0.00176     0.000897      0.00197     5.17e-05
     42    80      0.00193      0.00193     2.66e-06      0.00125      0.00166     0.000814            0      0.00165      0.00082      0.00102            0      0.00207      0.00103      0.00205      5.4e-05
     42    90      0.00164      0.00163     9.47e-06      0.00119      0.00152     0.000951            0       0.0014     0.000783      0.00116            0      0.00178     0.000981       0.0043     0.000113
     42   100      0.00452      0.00452     2.21e-06      0.00208      0.00253      0.00162            0       0.0025      0.00137      0.00193            0      0.00297      0.00163      0.00209     5.49e-05
     42   110       0.0017      0.00169        1e-05      0.00117      0.00155     0.000955            0      0.00137     0.000775      0.00124            0      0.00179      0.00101      0.00452     0.000119
     42   120      0.00211      0.00208     3.34e-05      0.00132      0.00172        0.001            0       0.0016     0.000867      0.00128            0      0.00203       0.0011      0.00813     0.000214
     42   130      0.00176      0.00172     3.49e-05       0.0012      0.00156     0.000962            0      0.00142     0.000794      0.00124            0      0.00181      0.00102      0.00842     0.000222
     42   140      0.00214      0.00212     1.25e-05      0.00136      0.00174     0.000877            0       0.0018     0.000893      0.00108            0      0.00216      0.00108       0.0049     0.000129
     42   142      0.00207      0.00206     7.95e-06      0.00135      0.00171      0.00111            0      0.00156     0.000891       0.0014            0      0.00194      0.00112      0.00401     0.000105
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     42    10      0.00121      0.00121     7.87e-07     0.000977      0.00131     0.000807            0      0.00113     0.000646      0.00107            0      0.00149     0.000854       0.0011     2.89e-05
     42    20       0.0016       0.0016     2.23e-07       0.0011      0.00151     0.000827            0      0.00135     0.000725      0.00104            0      0.00183     0.000956     0.000586     1.54e-05
     42    30      0.00106      0.00105     2.78e-07       0.0009      0.00122     0.000756            0      0.00103     0.000595      0.00097            0      0.00141     0.000794     0.000549     1.45e-05
     42    40      0.00141      0.00141     9.03e-08      0.00105      0.00142     0.000818            0      0.00126     0.000692      0.00103            0      0.00169     0.000906     0.000342     8.99e-06
     42    50      0.00091     0.000909     1.39e-07     0.000833      0.00114     0.000677            0     0.000972      0.00055     0.000919            0       0.0013      0.00074     0.000378     9.96e-06
     42    60     0.000909     0.000909     1.22e-07     0.000875      0.00114     0.000729            0      0.00101     0.000579      0.00093            0      0.00129     0.000741     0.000403     1.06e-05
     42    61      0.00119      0.00119     2.55e-07     0.000946       0.0013     0.000728            0      0.00114     0.000624        0.001            0      0.00152     0.000841     0.000702     1.85e-05
  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              42  401.287    0.005      0.00307     1.01e-05      0.00308      0.00145      0.00209      0.00111            0      0.00175     0.000952      0.00171            0      0.00238      0.00136      0.00384     0.000101
! Validation         42  401.287    0.005      0.00155     2.08e-07      0.00155     0.000949      0.00148     0.000793            0      0.00109     0.000627      0.00133            0      0.00161      0.00098     0.000516     1.36e-05
Wall time: 401.2873842509871
! Best model       42    0.002
training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     43    10      0.00115      0.00115     4.88e-06     0.000962      0.00128     0.000757            0      0.00115     0.000634      0.00101            0      0.00148     0.000828      0.00311     8.19e-05
     43    20      0.00121      0.00121     3.64e-06     0.000973      0.00131     0.000735            0      0.00119     0.000641     0.000964            0      0.00156     0.000841      0.00271     7.13e-05
     43    30     0.000931     0.000928     3.22e-06     0.000884      0.00115     0.000738            0      0.00102     0.000585      0.00092            0      0.00132     0.000746       0.0025     6.59e-05
     43    40      0.00127      0.00126     5.05e-06      0.00103      0.00134     0.000823            0      0.00122     0.000681      0.00108            0      0.00154     0.000872      0.00315     8.29e-05
     43    50      0.00202        0.002     2.07e-05      0.00123      0.00168     0.000822            0      0.00161     0.000809      0.00108            0      0.00208      0.00105      0.00643     0.000169
     43    60      0.00146      0.00145     5.48e-06       0.0011      0.00144      0.00083            0      0.00135     0.000725      0.00106            0       0.0017     0.000922      0.00325     8.54e-05
     43    70      0.00119      0.00119     7.96e-07     0.000995       0.0013     0.000771            0       0.0012     0.000656      0.00101            0      0.00151     0.000839      0.00111     2.92e-05
     43    80       0.0213       0.0213     1.79e-05      0.00304      0.00549       0.0033            0       0.0028      0.00203      0.00602            0      0.00496      0.00366      0.00597     0.000157
     43    90      0.00369      0.00369     3.39e-07       0.0018      0.00229      0.00154            0      0.00204      0.00119      0.00188            0       0.0026      0.00149     0.000732     1.93e-05
     43   100       0.0197       0.0197     2.22e-07      0.00293      0.00529      0.00289            0      0.00297      0.00195      0.00536            0      0.00522      0.00353     0.000488     1.28e-05
     43   110      0.00213      0.00213     1.12e-06      0.00133      0.00174      0.00103            0      0.00159     0.000874      0.00132            0      0.00204      0.00112      0.00117     3.08e-05
     43   120      0.00129      0.00129     2.93e-07      0.00104      0.00135     0.000804            0      0.00126     0.000687      0.00102            0      0.00159      0.00087     0.000623     1.64e-05
     43   130      0.00193      0.00192     1.03e-05      0.00126      0.00165      0.00074            0      0.00173     0.000823     0.000954            0      0.00208      0.00101      0.00458      0.00012
     43   140      0.00208      0.00208     1.36e-06      0.00135      0.00172      0.00128            0       0.0014     0.000895      0.00156            0      0.00185      0.00114      0.00127     3.34e-05
     43   142      0.00173      0.00173     5.41e-07      0.00118      0.00157     0.000821            0      0.00151     0.000775      0.00107            0       0.0019     0.000991     0.000834      2.2e-05
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     43    10      0.00114      0.00114     7.58e-07     0.000947      0.00127     0.000789            0      0.00109     0.000626      0.00105            0      0.00144      0.00083       0.0011     2.89e-05
     43    20      0.00154      0.00154     2.29e-07      0.00108      0.00148     0.000819            0      0.00131      0.00071      0.00103            0      0.00179     0.000938     0.000598     1.57e-05
     43    30      0.00102      0.00102     2.66e-07     0.000892       0.0012     0.000752            0      0.00102      0.00059     0.000959            0      0.00139     0.000782     0.000586     1.54e-05
     43    40      0.00135      0.00135     6.39e-08      0.00102      0.00139     0.000804            0      0.00122     0.000675      0.00101            0      0.00165     0.000887     0.000293     7.71e-06
     43    50     0.000874     0.000874     2.15e-07      0.00082      0.00111     0.000675            0     0.000951     0.000542     0.000902            0      0.00127     0.000725     0.000464     1.22e-05
     43    60     0.000887     0.000887     1.56e-07     0.000872      0.00112     0.000729            0        0.001     0.000576     0.000927            0      0.00127     0.000733     0.000513     1.35e-05
     43    61      0.00113      0.00113     2.58e-07     0.000923      0.00127     0.000706            0      0.00112     0.000608     0.000975            0      0.00148     0.000818     0.000717     1.89e-05
  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              43  411.038    0.005      0.00275     6.12e-06      0.00276      0.00133      0.00198      0.00105            0      0.00159      0.00088      0.00168            0      0.00221       0.0013      0.00285     7.49e-05
! Validation         43  411.038    0.005      0.00151     2.16e-07      0.00151     0.000933      0.00147     0.000785            0      0.00107     0.000617      0.00132            0      0.00159     0.000968     0.000532      1.4e-05
Wall time: 411.03892618700047
! Best model       43    0.002
training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     44    10      0.00314      0.00313      1.5e-05      0.00156      0.00211     0.000877            0      0.00217      0.00102       0.0011            0      0.00271      0.00127      0.00552     0.000145
     44    20      0.00135      0.00133     1.61e-05      0.00102      0.00137     0.000742            0      0.00128     0.000673     0.000977            0      0.00165     0.000877      0.00569      0.00015
     44    30      0.00109      0.00109     9.08e-07     0.000945      0.00124     0.000724            0      0.00114     0.000623     0.000944            0      0.00146     0.000801      0.00122     3.21e-05
     44    40      0.00231      0.00231     1.86e-06       0.0014      0.00181     0.000999            0      0.00176     0.000919      0.00123            0      0.00221      0.00114      0.00167      4.4e-05
     44    50      0.00304      0.00304     5.09e-07      0.00166      0.00208      0.00151            0       0.0018       0.0011      0.00179            0       0.0023      0.00137     0.000854     2.25e-05
     44    60      0.00321      0.00321     6.51e-07      0.00167      0.00213       0.0013            0      0.00201       0.0011      0.00157            0      0.00253      0.00137     0.000977     2.57e-05
     44    70      0.00307      0.00304     3.08e-05      0.00157      0.00208      0.00118            0      0.00191      0.00103      0.00149            0      0.00249      0.00133      0.00774     0.000204
     44    80      0.00436      0.00435     1.36e-05      0.00189      0.00248      0.00135            0      0.00237      0.00124      0.00159            0      0.00307      0.00155      0.00524     0.000138
     44    90      0.00162      0.00161     1.08e-05      0.00115      0.00151     0.000785            0      0.00148     0.000756     0.000979            0      0.00187     0.000949      0.00447     0.000118
     44   100      0.00132      0.00131     1.72e-05      0.00104      0.00136     0.000732            0      0.00131      0.00068     0.000967            0      0.00164     0.000868      0.00593     0.000156
     44   110      0.00159      0.00159     1.29e-06      0.00116       0.0015     0.000842            0      0.00144     0.000761      0.00106            0      0.00181     0.000958      0.00155     4.08e-05
     44   120      0.00111      0.00111     7.69e-07     0.000953      0.00125     0.000629            0      0.00124     0.000624     0.000808            0      0.00155     0.000785      0.00121     3.18e-05
     44   130       0.0021       0.0021     4.03e-07      0.00134      0.00173     0.000854            0      0.00177     0.000876      0.00109            0      0.00214      0.00108     0.000757     1.99e-05
     44   140      0.00154      0.00154     3.39e-07      0.00113      0.00148     0.000764            0      0.00146     0.000741      0.00097            0      0.00182     0.000929     0.000537     1.41e-05
     44   142      0.00107      0.00107     7.77e-07     0.000932      0.00123     0.000743            0       0.0011     0.000615     0.000941            0      0.00145     0.000795       0.0012     3.16e-05
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     44    10      0.00111      0.00111     7.69e-07     0.000939      0.00125     0.000784            0      0.00108     0.000621      0.00104            0      0.00142      0.00082       0.0011     2.89e-05
     44    20      0.00151      0.00151     2.41e-07      0.00107      0.00147     0.000821            0       0.0013     0.000707      0.00103            0      0.00177     0.000933     0.000635     1.67e-05
     44    30     0.000984     0.000983     2.99e-07     0.000869      0.00118     0.000735            0      0.00099     0.000575     0.000943            0      0.00136     0.000768     0.000659     1.73e-05
     44    40      0.00134      0.00134     1.05e-07      0.00102      0.00138     0.000816            0      0.00121     0.000675      0.00102            0      0.00164     0.000885     0.000354     9.32e-06
     44    50     0.000859     0.000859     1.45e-07     0.000812       0.0011     0.000667            0     0.000943     0.000537     0.000894            0      0.00126     0.000719     0.000427     1.12e-05
     44    60     0.000877     0.000877     1.58e-07     0.000869      0.00112     0.000737            0     0.000989     0.000575     0.000936            0      0.00125      0.00073     0.000513     1.35e-05
     44    61      0.00112      0.00112     2.39e-07     0.000917      0.00126     0.000702            0      0.00111     0.000604      0.00097            0      0.00147     0.000813     0.000671     1.77e-05
  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              44  420.887    0.005      0.00295     7.09e-06      0.00296      0.00139      0.00205      0.00107            0      0.00169     0.000917      0.00172            0      0.00231      0.00134      0.00292     7.67e-05
! Validation         44  420.887    0.005      0.00148     2.19e-07      0.00148     0.000923      0.00145     0.000778            0      0.00105     0.000611       0.0013            0      0.00157     0.000959     0.000538     1.42e-05
Wall time: 420.8873724619916
! Best model       44    0.001
training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     45    10      0.00153      0.00153     2.24e-06       0.0011      0.00147     0.000757            0      0.00141     0.000721     0.000954            0      0.00181     0.000923      0.00204     5.36e-05
     45    20      0.00124      0.00123     3.44e-06     0.000991      0.00132     0.000798            0      0.00116     0.000654      0.00103            0      0.00154     0.000857      0.00256     6.75e-05
     45    30      0.00105      0.00105     2.55e-06     0.000933      0.00122     0.000698            0      0.00114     0.000614     0.000902            0      0.00145     0.000784       0.0022     5.78e-05
     45    40     0.000974     0.000969     4.95e-06     0.000876      0.00117     0.000682            0      0.00105     0.000577     0.000899            0      0.00137     0.000757      0.00311     8.19e-05
     45    50      0.00177      0.00177     4.46e-06       0.0012      0.00158     0.000734            0      0.00162     0.000784     0.000927            0        0.002     0.000975      0.00302     7.93e-05
     45    60      0.00114      0.00113     1.67e-05      0.00103      0.00126      0.00098            0      0.00107     0.000683       0.0012            0      0.00132     0.000839       0.0058     0.000153
     45    70      0.00256      0.00255     1.15e-05       0.0015       0.0019       0.0014            0      0.00159     0.000998      0.00167            0      0.00209      0.00125      0.00476     0.000125
     45    80      0.00121       0.0012      1.3e-05      0.00101       0.0013     0.000785            0      0.00121     0.000664     0.000989            0      0.00153     0.000841      0.00515     0.000136
     45    90      0.00121      0.00121     4.24e-06      0.00103      0.00131     0.000952            0      0.00111     0.000686      0.00119            0      0.00141     0.000865      0.00286     7.52e-05
     45   100      0.00444      0.00443      3.4e-06       0.0019      0.00251      0.00112            0      0.00259      0.00124      0.00149            0      0.00316      0.00155      0.00234     6.17e-05
     45   110      0.00224      0.00223     1.64e-05      0.00131      0.00178     0.000819            0      0.00175     0.000856      0.00105            0      0.00224       0.0011      0.00562     0.000148
     45   120      0.00209      0.00209     1.87e-06      0.00129      0.00172     0.000942            0       0.0016     0.000847      0.00119            0      0.00209      0.00109      0.00178     4.69e-05
     45   130      0.00356      0.00355     3.93e-06      0.00163      0.00224     0.000862            0      0.00232      0.00106      0.00111            0      0.00291      0.00134      0.00269     7.07e-05
     45   140       0.0017       0.0017     9.07e-06      0.00118      0.00155     0.000791            0      0.00153     0.000774     0.000961            0      0.00193     0.000965       0.0043     0.000113
     45   142       0.0032      0.00318     1.78e-05      0.00158      0.00212      0.00103            0      0.00207      0.00103      0.00136            0      0.00263      0.00133      0.00602     0.000158
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     45    10      0.00104      0.00104     6.95e-07     0.000911      0.00121     0.000781            0      0.00103     0.000603      0.00103            0      0.00136     0.000797      0.00106     2.79e-05
     45    20      0.00147      0.00147     2.47e-07      0.00106      0.00144     0.000815            0      0.00128     0.000697      0.00102            0      0.00174     0.000918     0.000659     1.73e-05
     45    30      0.00096      0.00096     2.31e-07     0.000866      0.00117     0.000719            0     0.000998     0.000572     0.000922            0      0.00135     0.000757     0.000574     1.51e-05
     45    40      0.00128      0.00128     1.29e-07        0.001      0.00135       0.0008            0      0.00119     0.000663        0.001            0       0.0016     0.000867     0.000391     1.03e-05
     45    50     0.000813     0.000813     1.69e-07     0.000788      0.00107      0.00065            0     0.000912     0.000521     0.000869            0      0.00123     0.000699     0.000439     1.16e-05
     45    60     0.000861     0.000861     1.67e-07      0.00086      0.00111     0.000726            0      0.00098     0.000569     0.000922            0      0.00125     0.000723     0.000513     1.35e-05
     45    61      0.00106      0.00106     2.31e-07     0.000896      0.00123     0.000681            0      0.00109      0.00059     0.000945            0      0.00144     0.000794     0.000671     1.77e-05
  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              45  430.729    0.005      0.00263     5.52e-06      0.00263      0.00129      0.00193      0.00102            0      0.00154     0.000854      0.00165            0      0.00215      0.00127      0.00266     7.01e-05
! Validation         45  430.729    0.005      0.00144     2.04e-07      0.00144     0.000907      0.00143     0.000766            0      0.00103       0.0006      0.00129            0      0.00155     0.000946     0.000517     1.36e-05
Wall time: 430.72989179199794
! Best model       45    0.001
training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     46    10      0.00223       0.0022     3.61e-05      0.00141      0.00177      0.00111            0      0.00167     0.000927      0.00133            0      0.00208      0.00114      0.00857     0.000226
     46    20       0.0018      0.00176     3.47e-05      0.00124      0.00158     0.000934            0      0.00151     0.000814      0.00116            0      0.00188      0.00101      0.00837      0.00022
     46    30      0.00195      0.00191     4.58e-05      0.00125      0.00164     0.000839            0      0.00162     0.000821      0.00106            0      0.00203      0.00103      0.00968     0.000255
     46    40      0.00107      0.00107     1.88e-06     0.000954      0.00123     0.000807            0      0.00109     0.000631      0.00103            0      0.00139     0.000804      0.00186     4.88e-05
     46    50     0.000858     0.000858      8.4e-08     0.000834       0.0011     0.000666            0     0.000985      0.00055     0.000886            0      0.00127     0.000718      0.00033     8.67e-06
     46    60     0.000846     0.000846     1.75e-07     0.000843       0.0011     0.000655            0      0.00101     0.000556     0.000826            0      0.00129     0.000705     0.000513     1.35e-05
     46    70     0.000801     0.000799     2.35e-06     0.000807      0.00106     0.000665            0     0.000935     0.000533     0.000875            0      0.00121     0.000695      0.00208     5.46e-05
     46    80     0.000938     0.000938     1.76e-07     0.000858      0.00115     0.000646            0      0.00105     0.000565      0.00085            0      0.00137      0.00074     0.000415     1.09e-05
     46    90      0.00955      0.00955     4.84e-06      0.00303      0.00368      0.00321            0      0.00286      0.00202      0.00374            0      0.00363      0.00246      0.00258     6.78e-05
     46   100      0.00274      0.00274     3.61e-07      0.00147      0.00197      0.00103            0      0.00187     0.000966      0.00131            0      0.00241      0.00124     0.000818     2.15e-05
     46   110      0.00372      0.00371     7.99e-06      0.00172      0.00229      0.00143            0      0.00198      0.00114      0.00179            0      0.00267      0.00149      0.00376     9.89e-05
     46   120      0.00193      0.00191     1.92e-05      0.00129      0.00165      0.00112            0      0.00145     0.000857      0.00139            0      0.00185      0.00108      0.00613     0.000161
     46   130      0.00151      0.00151     4.08e-07      0.00113      0.00146     0.000984            0      0.00126     0.000748       0.0012            0      0.00167     0.000956     0.000793     2.09e-05
     46   140      0.00152      0.00152     1.29e-06      0.00111      0.00147       0.0008            0      0.00138     0.000727      0.00102            0      0.00178     0.000932      0.00159     4.18e-05
     46   142       0.0076      0.00758     1.71e-05      0.00222      0.00328      0.00248            0      0.00198      0.00149       0.0038            0      0.00273      0.00218      0.00588     0.000155
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     46    10      0.00103      0.00103     7.41e-07     0.000908      0.00121     0.000764            0      0.00104     0.000601      0.00101            0      0.00136      0.00079      0.00111     2.92e-05
     46    20      0.00146      0.00146     2.08e-07      0.00106      0.00144     0.000811            0      0.00128     0.000697      0.00101            0      0.00174     0.000917     0.000562     1.48e-05
     46    30     0.000964     0.000964     2.82e-07     0.000862      0.00117      0.00072            0      0.00099      0.00057     0.000926            0      0.00135     0.000759     0.000671     1.77e-05
     46    40      0.00127      0.00127     5.86e-08        0.001      0.00134     0.000799            0      0.00119     0.000662     0.000999            0      0.00159     0.000862     0.000269     7.07e-06
     46    50     0.000808     0.000808     1.75e-07     0.000788      0.00107     0.000651            0     0.000911     0.000521     0.000872            0      0.00122     0.000698     0.000427     1.12e-05
     46    60     0.000862     0.000862     1.19e-07     0.000859      0.00111     0.000725            0      0.00098     0.000568     0.000922            0      0.00125     0.000723     0.000476     1.25e-05
     46    61      0.00106      0.00106     2.85e-07     0.000895      0.00122     0.000684            0      0.00108      0.00059     0.000945            0      0.00143     0.000791     0.000732     1.93e-05
  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              46  440.550    0.005      0.00338     1.01e-05      0.00339      0.00146      0.00218      0.00115            0      0.00174     0.000965      0.00185            0      0.00245      0.00143      0.00343     9.02e-05
! Validation         46  440.550    0.005      0.00143     1.98e-07      0.00143     0.000901      0.00143     0.000762            0      0.00103     0.000596      0.00129            0      0.00154     0.000942     0.000507     1.33e-05
Wall time: 440.5504735939903
! Best model       46    0.001
training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     47    10      0.00307      0.00307     2.22e-06      0.00164      0.00209      0.00129            0      0.00195      0.00108      0.00161            0      0.00244      0.00135      0.00206     5.43e-05
     47    20      0.00291       0.0029     3.44e-06      0.00149      0.00203     0.000744            0      0.00217      0.00097     0.000965            0      0.00264       0.0012      0.00237     6.23e-05
     47    30      0.00179      0.00179     1.74e-06      0.00121      0.00159     0.000857            0      0.00153     0.000796      0.00111            0      0.00193      0.00101      0.00142     3.73e-05
     47    40      0.00181      0.00181     5.99e-06      0.00124       0.0016     0.000822            0      0.00161     0.000811      0.00104            0      0.00197        0.001      0.00347     9.12e-05
     47    50      0.00257      0.00256      1.4e-05      0.00144      0.00191     0.000903            0      0.00192     0.000942      0.00115            0      0.00239      0.00118      0.00525     0.000138
     47    60      0.00172      0.00172     2.61e-07      0.00123      0.00156      0.00093            0       0.0015     0.000809      0.00116            0      0.00185        0.001     0.000647      1.7e-05
     47    70       0.0016       0.0016     2.96e-07      0.00115       0.0015     0.000894            0      0.00137     0.000756      0.00116            0      0.00176     0.000973     0.000708     1.86e-05
     47    80      0.00105      0.00104     1.17e-05      0.00092      0.00121     0.000662            0      0.00115     0.000605     0.000873            0      0.00145     0.000775      0.00488     0.000128
     47    90       0.0028      0.00279     2.49e-06      0.00149      0.00199      0.00122            0      0.00173     0.000986      0.00147            0      0.00236      0.00128      0.00198      5.2e-05
     47   100      0.00164      0.00163     1.11e-05      0.00113      0.00152     0.000675            0      0.00153     0.000737     0.000857            0      0.00193     0.000929      0.00472     0.000124
     47   110      0.00171      0.00171     7.18e-06      0.00115      0.00156     0.000797            0      0.00147     0.000755      0.00102            0      0.00192     0.000977      0.00382     0.000101
     47   120      0.00258      0.00258     1.24e-07      0.00148      0.00191      0.00103            0      0.00188      0.00097      0.00129            0      0.00234      0.00121     0.000305     8.03e-06
     47   130      0.00308      0.00305     2.33e-05      0.00165      0.00208       0.0014            0      0.00187      0.00109      0.00168            0      0.00239      0.00136      0.00686     0.000181
     47   140      0.00227      0.00224     3.03e-05       0.0014      0.00178      0.00111            0      0.00167     0.000924       0.0014            0      0.00207      0.00116      0.00784     0.000206
     47   142      0.00176      0.00174     2.04e-05      0.00123      0.00157     0.000801            0      0.00161     0.000803     0.000993            0      0.00195     0.000981      0.00643     0.000169
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     47    10      0.00104      0.00104     6.33e-07     0.000919      0.00121      0.00078            0      0.00104     0.000608      0.00102            0      0.00136     0.000795     0.000952     2.51e-05
     47    20      0.00148      0.00148     1.93e-07      0.00106      0.00145     0.000807            0      0.00128     0.000696      0.00101            0      0.00175      0.00092     0.000586     1.54e-05
     47    30     0.000929     0.000928     2.16e-07      0.00084      0.00115     0.000702            0     0.000965     0.000556     0.000905            0      0.00133     0.000745     0.000574     1.51e-05
     47    40      0.00127      0.00127     7.45e-08      0.00101      0.00134     0.000798            0       0.0012     0.000665     0.000992            0       0.0016     0.000863     0.000269     7.07e-06
     47    50     0.000787     0.000787     1.45e-07     0.000777      0.00106     0.000638            0     0.000903     0.000514     0.000855            0      0.00121     0.000688     0.000439     1.16e-05
     47    60     0.000881     0.000881      1.4e-07     0.000869      0.00112     0.000728            0     0.000997     0.000575     0.000925            0      0.00127     0.000731     0.000488     1.28e-05
     47    61      0.00103      0.00103     1.29e-07     0.000887      0.00121     0.000671            0      0.00108     0.000584     0.000927            0      0.00141      0.00078     0.000473     1.24e-05
  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              47  450.293    0.005      0.00292     6.53e-06      0.00293      0.00141      0.00204      0.00112            0      0.00167     0.000928      0.00174            0      0.00227      0.00134      0.00285     7.51e-05
! Validation         47  450.293    0.005      0.00141     1.78e-07      0.00141     0.000895      0.00141     0.000756            0      0.00102     0.000592      0.00128            0      0.00153     0.000935     0.000484     1.27e-05
Wall time: 450.29392696599825
! Best model       47    0.001
training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     48    10      0.00274      0.00274     1.35e-06      0.00145      0.00197      0.00102            0      0.00185     0.000955      0.00133            0      0.00241      0.00125      0.00132     3.47e-05
     48    20      0.00428      0.00425     2.85e-05      0.00204      0.00246      0.00195            0      0.00213      0.00136      0.00228            0       0.0026      0.00163      0.00757     0.000199
     48    30      0.00386      0.00386     2.23e-06      0.00174      0.00234      0.00111            0       0.0023      0.00114      0.00142            0      0.00293      0.00145      0.00173     4.56e-05
     48    40      0.00253      0.00253      3.1e-06      0.00144       0.0019      0.00103            0      0.00181     0.000949      0.00131            0       0.0023       0.0012      0.00243     6.39e-05
     48    50      0.00479      0.00478     1.07e-05      0.00213       0.0026      0.00246            0      0.00183      0.00143      0.00285            0      0.00236      0.00174       0.0043     0.000113
     48    60      0.00149      0.00147     2.62e-05      0.00109      0.00144     0.000898            0      0.00127     0.000723      0.00115            0      0.00166     0.000937      0.00734     0.000193
     48    70       0.0015       0.0015     8.44e-06       0.0011      0.00146     0.000754            0      0.00141      0.00072     0.000954            0      0.00179     0.000916      0.00411     0.000108
     48    80      0.00127      0.00127     1.72e-06      0.00107      0.00134     0.000802            0      0.00131     0.000703      0.00103            0      0.00157     0.000866      0.00181     4.75e-05
     48    90      0.00147      0.00147     2.35e-06      0.00116      0.00144      0.00106            0      0.00124     0.000769      0.00129            0      0.00157     0.000953      0.00209     5.49e-05
     48   100      0.00118      0.00117     7.68e-06     0.000985      0.00129     0.000782            0      0.00117      0.00065      0.00101            0       0.0015     0.000836      0.00387     0.000102
     48   110      0.00308      0.00307     5.89e-06      0.00168      0.00209      0.00166            0      0.00169      0.00112      0.00198            0      0.00218      0.00139      0.00326     8.58e-05
     48   120      0.00205      0.00203     2.56e-05      0.00131       0.0017      0.00103            0      0.00157     0.000866      0.00129            0      0.00199      0.00109      0.00719     0.000189
     48   130      0.00134      0.00134     1.88e-06      0.00104      0.00138     0.000685            0      0.00135     0.000679     0.000873            0      0.00171     0.000862      0.00186     4.88e-05
     48   140      0.00114      0.00113     5.78e-06     0.000947      0.00127     0.000734            0      0.00114     0.000624     0.000983            0      0.00148     0.000821      0.00343     9.03e-05
     48   142      0.00117      0.00117     4.45e-06     0.000989      0.00129     0.000753            0       0.0012     0.000651     0.000929            0      0.00154     0.000823      0.00299     7.87e-05
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     48    10      0.00101      0.00101     6.85e-07     0.000902      0.00119     0.000761            0      0.00103     0.000597      0.00101            0      0.00134     0.000783      0.00104     2.73e-05
     48    20      0.00145      0.00145     1.96e-07      0.00105      0.00143       0.0008            0      0.00127     0.000689        0.001            0      0.00173     0.000911     0.000562     1.48e-05
     48    30     0.000898     0.000898     2.38e-07     0.000834      0.00113     0.000697            0     0.000959     0.000552     0.000896            0       0.0013     0.000733     0.000562     1.48e-05
     48    40      0.00123      0.00123     6.45e-08     0.000983      0.00132     0.000787            0      0.00116     0.000649     0.000982            0      0.00157     0.000849     0.000305     8.03e-06
     48    50     0.000774     0.000773     1.37e-07     0.000766      0.00105     0.000623            0     0.000896     0.000506     0.000837            0      0.00121     0.000681     0.000403     1.06e-05
     48    60      0.00082      0.00082     1.22e-07     0.000832      0.00108       0.0007            0     0.000951      0.00055     0.000904            0      0.00121     0.000706     0.000452     1.19e-05
     48    61     0.000979     0.000979     1.73e-07     0.000869      0.00118     0.000655            0      0.00106     0.000572     0.000905            0      0.00138     0.000761     0.000595     1.57e-05
  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              48  459.932    0.005      0.00277     7.92e-06      0.00278      0.00136      0.00198       0.0011            0      0.00159     0.000898      0.00173            0      0.00219      0.00131      0.00328     8.63e-05
! Validation         48  459.932    0.005      0.00138     1.71e-07      0.00138      0.00088       0.0014     0.000744            0        0.001     0.000582      0.00127            0      0.00151     0.000926     0.000479     1.26e-05
Wall time: 459.9332475589763
! Best model       48    0.001
training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     49    10      0.00108      0.00108     1.64e-07     0.000939      0.00124     0.000794            0      0.00107     0.000621      0.00105            0      0.00139     0.000813     0.000415     1.09e-05
     49    20     0.000956     0.000954     1.22e-06     0.000877      0.00116     0.000653            0      0.00108     0.000577      0.00083            0       0.0014     0.000742      0.00149     3.92e-05
     49    30       0.0015       0.0015     4.11e-07      0.00111      0.00146     0.000848            0      0.00134     0.000731      0.00109            0      0.00173     0.000939     0.000781     2.06e-05
     49    40      0.00252      0.00252     2.34e-06      0.00147      0.00189     0.000969            0      0.00192     0.000964      0.00124            0      0.00232      0.00119      0.00183     4.82e-05
     49    50      0.00187      0.00186     8.95e-06      0.00123      0.00163     0.000753            0      0.00167     0.000806     0.000982            0      0.00204      0.00101      0.00424     0.000111
     49    60      0.00195      0.00194     9.26e-06      0.00133      0.00166      0.00118            0      0.00146      0.00088      0.00148            0      0.00181       0.0011      0.00425     0.000112
     49    70      0.00166      0.00166     2.54e-06      0.00118      0.00153     0.000896            0      0.00143     0.000774      0.00111            0      0.00184     0.000981      0.00227     5.98e-05
     49    80      0.00115      0.00114     8.44e-06     0.000983      0.00127     0.000739            0       0.0012     0.000647     0.000943            0      0.00151     0.000818      0.00409     0.000108
     49    90     0.000929     0.000919     9.92e-06     0.000916      0.00114     0.000825            0     0.000999     0.000608      0.00102            0      0.00124     0.000754      0.00448     0.000118
     49   100      0.00134      0.00134     6.12e-06      0.00106      0.00138     0.000787            0      0.00131       0.0007        0.001            0      0.00164     0.000882      0.00352     9.25e-05
     49   110     0.000921      0.00092      1.5e-06     0.000884      0.00114     0.000714            0      0.00104     0.000584     0.000927            0      0.00131     0.000744      0.00166     4.37e-05
     49   120        0.019        0.019     8.41e-07      0.00257      0.00519      0.00263            0      0.00252      0.00172      0.00534            0      0.00506      0.00347      0.00112     2.96e-05
     49   130      0.00479      0.00478     6.03e-06      0.00215      0.00261      0.00221            0      0.00209      0.00143       0.0026            0      0.00261      0.00174      0.00308      8.1e-05
     49   140      0.00219      0.00217     1.52e-05      0.00133      0.00176      0.00101            0      0.00161     0.000875       0.0013            0      0.00208      0.00113      0.00553     0.000146
     49   142      0.00238      0.00237     1.41e-05      0.00148      0.00183      0.00161            0      0.00136      0.00099      0.00195            0      0.00172      0.00122      0.00537     0.000141
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     49    10     0.000955     0.000954     4.98e-07     0.000879      0.00116     0.000747            0     0.000997     0.000581     0.000984            0       0.0013     0.000763      0.00094     2.47e-05
     49    20       0.0014       0.0014     3.22e-07      0.00103      0.00141     0.000791            0      0.00125     0.000679     0.000988            0       0.0017     0.000897     0.000647      1.7e-05
     49    30     0.000869     0.000869        3e-07      0.00082      0.00111     0.000679            0     0.000946     0.000542     0.000876            0      0.00128      0.00072     0.000537     1.41e-05
     49    40      0.00118      0.00118     1.62e-07     0.000966      0.00129     0.000772            0      0.00114     0.000638     0.000961            0      0.00153     0.000831       0.0005     1.32e-05
     49    50     0.000736     0.000736      1.5e-07     0.000747      0.00102     0.000612            0     0.000869     0.000494     0.000816            0      0.00118     0.000664     0.000378     9.96e-06
     49    60     0.000783     0.000783     2.34e-07     0.000817      0.00105     0.000697            0     0.000926     0.000541     0.000891            0      0.00118     0.000691     0.000549     1.45e-05
     49    61     0.000937     0.000936     2.69e-07      0.00085      0.00115     0.000639            0      0.00104      0.00056     0.000885            0      0.00135     0.000745     0.000763     2.01e-05
  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              49  469.560    0.005      0.00258     6.55e-06      0.00259      0.00128      0.00191      0.00101            0      0.00153     0.000845      0.00165            0      0.00213      0.00126      0.00295     7.77e-05
! Validation         49  469.560    0.005      0.00135     2.09e-07      0.00135     0.000863      0.00138     0.000732            0     0.000981     0.000571      0.00126            0      0.00148     0.000915     0.000537     1.41e-05
Wall time: 469.5607769479975
! Best model       49    0.001
training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     50    10      0.00139      0.00136     2.76e-05      0.00105      0.00139     0.000729            0      0.00133     0.000687     0.000929            0       0.0017     0.000877       0.0075     0.000197
     50    20      0.00225      0.00225      5.1e-07      0.00138      0.00179     0.000965            0      0.00175     0.000903      0.00123            0      0.00217      0.00113     0.000891     2.35e-05
     50    30      0.00165      0.00165     3.22e-06      0.00121      0.00153      0.00102            0      0.00139     0.000803      0.00124            0      0.00175     0.000998      0.00254     6.68e-05
     50    40      0.00172      0.00172     1.23e-06      0.00124      0.00156      0.00136            0      0.00114     0.000833      0.00166            0      0.00146      0.00104      0.00131     3.44e-05
     50    50      0.00172      0.00171     8.05e-06      0.00121      0.00156     0.000892            0       0.0015     0.000798      0.00113            0      0.00186     0.000997      0.00406     0.000107
     50    60      0.00273      0.00273     2.71e-07      0.00148      0.00197     0.000847            0      0.00204     0.000963       0.0011            0       0.0025       0.0012     0.000647      1.7e-05
     50    70      0.00309      0.00308     1.04e-05      0.00161      0.00209     0.000916            0      0.00223      0.00105      0.00117            0      0.00266      0.00128      0.00439     0.000116
     50    80      0.00199      0.00198     1.02e-05      0.00126      0.00168     0.000766            0      0.00171     0.000825     0.000961            0      0.00212      0.00103      0.00458      0.00012
     50    90      0.00176      0.00175     1.43e-05      0.00121      0.00157     0.000845            0      0.00153     0.000793      0.00104            0      0.00193     0.000991      0.00538     0.000142
     50   100     0.000959     0.000957     2.48e-06     0.000897      0.00117     0.000661            0      0.00111      0.00059     0.000847            0      0.00139     0.000746      0.00223     5.88e-05
     50   110       0.0159       0.0159     2.78e-07      0.00258      0.00476      0.00262            0      0.00254      0.00172      0.00492            0      0.00461      0.00317     0.000623     1.64e-05
     50   120      0.00161      0.00161      1.1e-06      0.00114      0.00151     0.000819            0      0.00142     0.000747      0.00108            0      0.00181     0.000964      0.00134     3.53e-05
     50   130     0.000892     0.000891     1.13e-06     0.000849      0.00112     0.000676            0        0.001      0.00056     0.000848            0      0.00132     0.000724       0.0014     3.69e-05
     50   140      0.00154      0.00154     1.97e-06      0.00114      0.00148     0.000893            0      0.00136     0.000752      0.00113            0      0.00173     0.000953      0.00178     4.69e-05
     50   142       0.0014      0.00139     8.11e-06      0.00109       0.0014     0.000757            0      0.00138     0.000714     0.000948            0      0.00171     0.000888      0.00399     0.000105
validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     50    10     0.000911     0.000911     6.12e-07     0.000869      0.00114     0.000744            0     0.000981     0.000575     0.000977            0      0.00126     0.000747      0.00104     2.73e-05
     50    20      0.00139      0.00139      2.9e-07      0.00102       0.0014     0.000794            0      0.00122     0.000672     0.000995            0      0.00169     0.000894     0.000684      1.8e-05
     50    30     0.000849     0.000849     2.88e-07     0.000812       0.0011     0.000675            0     0.000935     0.000537     0.000871            0      0.00127     0.000713     0.000562     1.48e-05
     50    40      0.00119      0.00119     1.37e-07     0.000962       0.0013     0.000775            0      0.00113     0.000635     0.000967            0      0.00153     0.000834     0.000378     9.96e-06
     50    50     0.000711     0.000711     1.95e-07     0.000731        0.001     0.000607            0     0.000842     0.000483     0.000809            0      0.00115     0.000654     0.000464     1.22e-05
     50    60      0.00079     0.000789     1.88e-07     0.000823      0.00106     0.000705            0      0.00093     0.000545     0.000903            0      0.00118     0.000695       0.0005     1.32e-05
     50    61     0.000897     0.000897     1.97e-07     0.000835      0.00113     0.000636            0      0.00101      0.00055     0.000874            0      0.00131      0.00073     0.000626     1.65e-05
  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      B_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     B_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              50  479.228    0.005      0.00247     6.85e-06      0.00248      0.00127      0.00187      0.00098            0      0.00152     0.000835       0.0016            0      0.00209      0.00123      0.00298     7.84e-05
! Validation         50  479.228    0.005      0.00133      1.9e-07      0.00133     0.000856      0.00137     0.000731            0     0.000969     0.000566      0.00126            0      0.00147     0.000909     0.000497     1.31e-05
Wall time: 479.22844982199604
! Best model       50    0.001
! Stop training: max epochs
Wall time: 479.2787696729938
Cumulative wall time: 479.2787696729938