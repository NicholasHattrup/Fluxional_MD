Torch device: cpu
Processing dataset...
Loaded data: Batch(atomic_numbers=[38456, 1], batch=[38456], cell=[1012, 3, 3], edge_cell_shift=[564990, 3], edge_index=[2, 564990], forces=[38456, 3], pbc=[1012, 3], pos=[38456, 3], ptr=[1013], total_energy=[1012, 1])
Cached processed data to disk
Done!
Successfully loaded the data set of type ASEDataset(1012)...
Replace string dataset_forces_rms to 0.03737002611160278
Replace string dataset_per_atom_total_energy_mean to -20.31889533996582
Atomic outputs are scaled by: [H, C: 0.037370], shifted by [H, C: -20.318895].
Replace string dataset_total_energy_std to tensor([0.0165])
Initially outputs are globally scaled by: tensor([0.0165]), total_energy are globally shifted by None.
Successfully built the network...
Number of weights: 458920
! Starting training ...
validation
# Epoch batch         loss       loss_e      e/N_mae
      0    10       0.0115       0.0115      0.00169
      0    20       0.0119       0.0119      0.00176
      0    30        0.013        0.013      0.00186
      0    40      0.00871      0.00871      0.00154
      0    50       0.0129       0.0129      0.00177
      0    60       0.0101       0.0101       0.0016
      0    61       0.0096       0.0096       0.0016
  Initialization     #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Initial Validation          0    7.944    0.005        0.012        0.012      0.00177
Wall time: 7.9440972080000005
! Best model        0    0.012
training
# Epoch batch         loss       loss_e      e/N_mae
      1    10      0.00251      0.00251     0.000731
      1    20     0.000606     0.000606     0.000381
      1    30      0.00268      0.00268     0.000686
      1    40     0.000644     0.000644     0.000346
      1    48      0.00121      0.00121     0.000506
validation
# Epoch batch         loss       loss_e      e/N_mae
      1    10     0.000909     0.000909     0.000359
      1    20     0.000517     0.000517     0.000287
      1    30     0.000498     0.000498     0.000307
      1    40     0.000157     0.000157      0.00019
      1    50      0.00137      0.00137     0.000587
      1    60     0.000773     0.000773       0.0004
      1    61     0.000302     0.000302     0.000272
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train               1   59.443    0.005      0.00224      0.00224     0.000578
! Validation          1   59.443    0.005     0.000543     0.000543     0.000276
Wall time: 59.443460707999996
! Best model        1    0.001
training
# Epoch batch         loss       loss_e      e/N_mae
      2    10      0.00121      0.00121     0.000406
      2    20        0.001        0.001     0.000422
      2    30      0.00121      0.00121     0.000425
      2    40     0.000638     0.000638     0.000289
      2    48      0.00105      0.00105      0.00038
validation
# Epoch batch         loss       loss_e      e/N_mae
      2    10       0.0009       0.0009     0.000359
      2    20     0.000478     0.000478     0.000273
      2    30     0.000485     0.000485     0.000315
      2    40     0.000226     0.000226     0.000221
      2    50      0.00137      0.00137     0.000571
      2    60     0.000845     0.000845     0.000403
      2    61      0.00042      0.00042     0.000315
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train               2  111.061    0.005     0.000654     0.000654     0.000313
! Validation          2  111.061    0.005      0.00052      0.00052      0.00027
Wall time: 111.061975083
! Best model        2    0.001
training
# Epoch batch         loss       loss_e      e/N_mae
      3    10     0.000398     0.000398     0.000269
      3    20      0.00269      0.00269     0.000694
      3    30     0.000658     0.000658     0.000328
      3    40      0.00156      0.00156     0.000478
      3    48     3.87e-05     3.87e-05     8.83e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
      3    10      0.00086      0.00086      0.00034
      3    20     0.000499     0.000499     0.000314
      3    30     0.000549     0.000549     0.000342
      3    40     0.000181     0.000181     0.000199
      3    50      0.00137      0.00137     0.000568
      3    60     0.000834     0.000834     0.000414
      3    61     0.000477     0.000477     0.000334
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train               3  162.447    0.005     0.000646     0.000646     0.000322
! Validation          3  162.447    0.005     0.000518     0.000518     0.000276
Wall time: 162.447631
! Best model        3    0.001
training
# Epoch batch         loss       loss_e      e/N_mae
      4    10     0.000615     0.000615     0.000358
      4    20     0.000401     0.000401     0.000275
      4    30     0.000727     0.000727     0.000316
      4    40     0.000557     0.000557     0.000346
      4    48     0.000557     0.000557     0.000292
validation
# Epoch batch         loss       loss_e      e/N_mae
      4    10     0.000835     0.000835     0.000335
      4    20     0.000482     0.000482     0.000309
      4    30     0.000532     0.000532     0.000338
      4    40     0.000187     0.000187     0.000199
      4    50      0.00134      0.00134     0.000558
      4    60     0.000811     0.000811     0.000405
      4    61       0.0005       0.0005     0.000342
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train               4  214.084    0.005     0.000626     0.000626     0.000318
! Validation          4  214.084    0.005       0.0005       0.0005     0.000272
Wall time: 214.084960708
! Best model        4    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
      5    10      0.00103      0.00103     0.000358
      5    20     0.000837     0.000837     0.000386
      5    30     0.000571     0.000571     0.000323
      5    40      0.00023      0.00023     0.000209
      5    48      0.00102      0.00102     0.000387
validation
# Epoch batch         loss       loss_e      e/N_mae
      5    10     0.000809     0.000809     0.000332
      5    20     0.000448     0.000448     0.000294
      5    30     0.000513     0.000513     0.000332
      5    40     0.000212     0.000212     0.000206
      5    50      0.00131      0.00131     0.000543
      5    60     0.000787     0.000787     0.000392
      5    61     0.000527     0.000527     0.000352
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train               5  265.685    0.005     0.000692     0.000692      0.00034
! Validation          5  265.685    0.005     0.000479     0.000479     0.000267
Wall time: 265.686317875
! Best model        5    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
      6    10      0.00028      0.00028     0.000192
      6    20     0.000252     0.000252     0.000221
      6    30     0.000175     0.000175     0.000178
      6    40      0.00102      0.00102     0.000465
      6    48     0.000401     0.000401     0.000324
validation
# Epoch batch         loss       loss_e      e/N_mae
      6    10     0.000792     0.000792     0.000337
      6    20     0.000438     0.000438     0.000279
      6    30     0.000471     0.000471     0.000312
      6    40     0.000192     0.000192     0.000199
      6    50      0.00125      0.00125     0.000541
      6    60     0.000732     0.000732      0.00038
      6    61     0.000452     0.000452     0.000327
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train               6  317.187    0.005     0.000629     0.000629     0.000317
! Validation          6  317.187    0.005     0.000466     0.000466     0.000259
Wall time: 317.187524708
! Best model        6    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
      7    10     0.000966     0.000966     0.000383
      7    20     0.000202     0.000202     0.000178
      7    30     0.000461     0.000461     0.000292
      7    40     0.000458     0.000458      0.00028
      7    48      8.5e-05      8.5e-05     0.000151
validation
# Epoch batch         loss       loss_e      e/N_mae
      7    10     0.000708     0.000708     0.000322
      7    20     0.000396     0.000396     0.000267
      7    30     0.000456     0.000456     0.000308
      7    40     0.000182     0.000182     0.000186
      7    50      0.00114      0.00114     0.000512
      7    60     0.000655     0.000655     0.000365
      7    61     0.000479     0.000479     0.000336
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train               7  368.675    0.005     0.000502     0.000502     0.000285
! Validation          7  368.675    0.005     0.000428     0.000428      0.00025
Wall time: 368.676088166
! Best model        7    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
      8    10     0.000312     0.000312     0.000257
      8    20     0.000804     0.000804     0.000429
      8    30     0.000226     0.000226     0.000204
      8    40     0.000503     0.000503     0.000288
      8    48     0.000418     0.000418     0.000337
validation
# Epoch batch         loss       loss_e      e/N_mae
      8    10     0.000513     0.000513     0.000292
      8    20     0.000249     0.000249     0.000211
      8    30     0.000391     0.000391     0.000284
      8    40     0.000208     0.000208     0.000194
      8    50     0.000795     0.000795     0.000404
      8    60     0.000439     0.000439       0.0003
      8    61     0.000597     0.000597     0.000368
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train               8  420.099    0.005     0.000396     0.000396      0.00025
! Validation          8  420.099    0.005     0.000324     0.000324     0.000224
Wall time: 420.100312208
! Best model        8    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
      9    10     0.000384     0.000384     0.000274
      9    20     0.000823     0.000823     0.000413
      9    30     0.000274     0.000274     0.000226
      9    40     0.000257     0.000257     0.000213
      9    48     0.000859     0.000859     0.000436
validation
# Epoch batch         loss       loss_e      e/N_mae
      9    10     0.000375     0.000375     0.000264
      9    20     0.000177     0.000177     0.000181
      9    30     0.000312     0.000312     0.000245
      9    40     0.000185     0.000185     0.000174
      9    50     0.000532     0.000532     0.000341
      9    60     0.000266     0.000266     0.000237
      9    61     0.000571     0.000571     0.000356
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train               9  474.006    0.005     0.000409     0.000409     0.000261
! Validation          9  474.006    0.005      0.00026      0.00026     0.000205
Wall time: 474.007343875
! Best model        9    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     10    10     0.000493     0.000493     0.000285
     10    20     0.000186     0.000186     0.000197
     10    30     0.000412     0.000412     0.000231
     10    40     0.000327     0.000327     0.000262
     10    48     0.000103     0.000103     0.000142
validation
# Epoch batch         loss       loss_e      e/N_mae
     10    10     0.000295     0.000295     0.000236
     10    20     0.000137     0.000137     0.000163
     10    30      0.00026      0.00026     0.000225
     10    40     0.000163     0.000163      0.00016
     10    50     0.000403     0.000403     0.000302
     10    60     0.000198     0.000198     0.000207
     10    61     0.000553     0.000553     0.000354
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              10  528.314    0.005     0.000363     0.000363     0.000247
! Validation         10  528.314    0.005     0.000224     0.000224     0.000192
Wall time: 528.3152065410001
! Best model       10    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     11    10     0.000455     0.000455     0.000307
     11    20     0.000184     0.000184     0.000177
     11    30     0.000156     0.000156     0.000166
     11    40     0.000226     0.000226     0.000202
     11    48     7.88e-05     7.88e-05     0.000139
validation
# Epoch batch         loss       loss_e      e/N_mae
     11    10     0.000209     0.000209     0.000201
     11    20     0.000113     0.000113     0.000151
     11    30     0.000196     0.000196     0.000189
     11    40      0.00014      0.00014     0.000143
     11    50     0.000306     0.000306     0.000265
     11    60     0.000143     0.000143     0.000179
     11    61     0.000507     0.000507     0.000348
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              11  582.837    0.005     0.000235     0.000235     0.000198
! Validation         11  582.837    0.005     0.000189     0.000189     0.000177
Wall time: 582.83784625
! Best model       11    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     12    10     0.000253     0.000253     0.000178
     12    20     0.000187     0.000187     0.000179
     12    30     0.000171     0.000171     0.000166
     12    40     0.000124     0.000124     0.000148
     12    48      0.00016      0.00016     0.000179
validation
# Epoch batch         loss       loss_e      e/N_mae
     12    10      0.00013      0.00013     0.000155
     12    20     8.11e-05     8.11e-05     0.000133
     12    30     0.000105     0.000105     0.000127
     12    40     0.000118     0.000118     0.000127
     12    50     0.000213     0.000213     0.000218
     12    60     9.42e-05     9.42e-05     0.000141
     12    61     0.000439     0.000439     0.000334
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              12  636.504    0.005     0.000165     0.000165     0.000167
! Validation         12  636.504    0.005     0.000152     0.000152     0.000162
Wall time: 636.505141
! Best model       12    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     13    10     0.000157     0.000157     0.000181
     13    20     0.000128     0.000128     0.000141
     13    30      0.00033      0.00033     0.000219
     13    40     0.000287     0.000287     0.000252
     13    48     0.000646     0.000646     0.000381
validation
# Epoch batch         loss       loss_e      e/N_mae
     13    10     0.000121     0.000121     0.000151
     13    20     9.61e-05     9.61e-05     0.000143
     13    30     7.72e-05     7.72e-05     0.000105
     13    40     0.000101     0.000101     0.000122
     13    50     0.000222     0.000222     0.000222
     13    60     9.86e-05     9.86e-05     0.000144
     13    61     0.000376     0.000376     0.000312
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              13  688.636    0.005     0.000274     0.000274     0.000213
! Validation         13  688.636    0.005     0.000141     0.000141     0.000154
Wall time: 688.63818975
! Best model       13    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     14    10     0.000105     0.000105     0.000138
     14    20     0.000192     0.000192     0.000193
     14    30     0.000154     0.000154     0.000169
     14    40     0.000188     0.000188     0.000202
     14    48     1.65e-06     1.65e-06     2.09e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     14    10     8.58e-05     8.58e-05     0.000121
     14    20     8.34e-05     8.34e-05     0.000131
     14    30     4.84e-05     4.84e-05     9.25e-05
     14    40     9.53e-05     9.53e-05     0.000118
     14    50     0.000174     0.000174     0.000193
     14    60     8.11e-05     8.11e-05     0.000133
     14    61     0.000348     0.000348     0.000302
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              14  742.615    0.005     0.000139     0.000139     0.000158
! Validation         14  742.615    0.005     0.000123     0.000123     0.000147
Wall time: 742.6164525
! Best model       14    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     15    10     9.54e-05     9.54e-05     0.000125
     15    20     0.000102     0.000102     0.000146
     15    30     0.000161     0.000161     0.000154
     15    40     0.000127     0.000127      0.00014
     15    48     0.000204     0.000204      0.00023
validation
# Epoch batch         loss       loss_e      e/N_mae
     15    10     6.77e-05     6.77e-05     0.000103
     15    20     7.56e-05     7.56e-05     0.000121
     15    30     3.44e-05     3.44e-05     8.19e-05
     15    40     7.25e-05     7.25e-05     0.000108
     15    50     0.000151     0.000151     0.000178
     15    60     7.28e-05     7.28e-05     0.000124
     15    61     0.000291     0.000291      0.00028
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              15  795.614    0.005     0.000125     0.000125     0.000149
! Validation         15  795.614    0.005     0.000107     0.000107     0.000139
Wall time: 795.614684166
! Best model       15    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     16    10      5.4e-05      5.4e-05     9.87e-05
     16    20     6.31e-05     6.31e-05     0.000109
     16    30     4.66e-05     4.66e-05     8.37e-05
     16    40     5.76e-05     5.76e-05     8.37e-05
     16    48     1.34e-05     1.34e-05     5.38e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     16    10     4.74e-05     4.74e-05      8.1e-05
     16    20     5.74e-05     5.74e-05     0.000105
     16    30     2.95e-05     2.95e-05     8.22e-05
     16    40     5.21e-05     5.21e-05     9.51e-05
     16    50     0.000125     0.000125      0.00016
     16    60     6.36e-05     6.36e-05     0.000117
     16    61     0.000213     0.000213      0.00024
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              16  847.211    0.005     8.06e-05     8.06e-05     0.000119
! Validation         16  847.211    0.005        9e-05        9e-05     0.000129
Wall time: 847.210824
! Best model       16    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     17    10     6.92e-05     6.92e-05     0.000108
     17    20     5.73e-05     5.73e-05     0.000101
     17    30     0.000231     0.000231     0.000222
     17    40     0.000156     0.000156      0.00019
     17    48      1.3e-05      1.3e-05     5.62e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     17    10     3.36e-05     3.36e-05     6.87e-05
     17    20     4.88e-05     4.88e-05     9.64e-05
     17    30     2.89e-05     2.89e-05     7.87e-05
     17    40     3.31e-05     3.31e-05     7.45e-05
     17    50     0.000105     0.000105      0.00015
     17    60     4.73e-05     4.73e-05     9.54e-05
     17    61     0.000169     0.000169     0.000215
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              17  898.926    0.005     0.000101     0.000101     0.000136
! Validation         17  898.926    0.005     7.37e-05     7.37e-05     0.000116
Wall time: 898.926563291
! Best model       17    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     18    10     4.03e-05     4.03e-05     8.36e-05
     18    20     3.09e-05     3.09e-05     7.47e-05
     18    30     4.12e-05     4.12e-05     9.08e-05
     18    40     3.23e-05     3.23e-05     7.71e-05
     18    48     6.17e-05     6.17e-05      9.4e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     18    10     2.37e-05     2.37e-05     5.81e-05
     18    20     4.16e-05     4.16e-05     9.35e-05
     18    30     3.33e-05     3.33e-05     8.22e-05
     18    40     2.16e-05     2.16e-05     6.33e-05
     18    50     9.86e-05     9.86e-05     0.000154
     18    60     3.87e-05     3.87e-05     8.67e-05
     18    61      0.00013      0.00013     0.000187
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              18  951.204    0.005     5.08e-05     5.08e-05     9.29e-05
! Validation         18  951.204    0.005     6.09e-05     6.09e-05     0.000106
Wall time: 951.204165458
! Best model       18    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     19    10     2.68e-05     2.68e-05     6.62e-05
     19    20     6.81e-05     6.81e-05       0.0001
     19    30     6.34e-05     6.34e-05     0.000109
     19    40      4.6e-05      4.6e-05     8.36e-05
     19    48     4.24e-05     4.24e-05     0.000105
validation
# Epoch batch         loss       loss_e      e/N_mae
     19    10     1.28e-05     1.28e-05     4.18e-05
     19    20     3.39e-05     3.39e-05     8.67e-05
     19    30     3.75e-05     3.75e-05     8.35e-05
     19    40     1.35e-05     1.35e-05     5.17e-05
     19    50     9.05e-05     9.05e-05     0.000152
     19    60     3.26e-05     3.26e-05     7.55e-05
     19    61     9.78e-05     9.78e-05     0.000161
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              19 1002.797    0.005     5.19e-05     5.19e-05     9.46e-05
! Validation         19 1002.797    0.005     5.04e-05     5.04e-05     9.57e-05
Wall time: 1002.798206083
! Best model       19    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     20    10     2.98e-05     2.98e-05     7.01e-05
     20    20     2.35e-05     2.35e-05     5.94e-05
     20    30     5.69e-05     5.69e-05     9.77e-05
     20    40     6.82e-05     6.82e-05     0.000121
     20    48     9.69e-05     9.69e-05     0.000124
validation
# Epoch batch         loss       loss_e      e/N_mae
     20    10     9.58e-06     9.58e-06     4.18e-05
     20    20     3.15e-05     3.15e-05      8.1e-05
     20    30     3.83e-05     3.83e-05     8.42e-05
     20    40     8.83e-06     8.83e-06     4.14e-05
     20    50     9.13e-05     9.13e-05     0.000155
     20    60     2.91e-05     2.91e-05     7.13e-05
     20    61     8.46e-05     8.46e-05     0.000149
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              20 1054.764    0.005     5.73e-05     5.73e-05     9.88e-05
! Validation         20 1054.764    0.005     4.34e-05     4.34e-05     8.88e-05
Wall time: 1054.764131625
! Best model       20    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     21    10     2.75e-05     2.75e-05     6.42e-05
     21    20     1.79e-05     1.79e-05     5.71e-05
     21    30      0.00012      0.00012     0.000154
     21    40     6.33e-05     6.33e-05     0.000107
     21    48     1.35e-05     1.35e-05     5.46e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     21    10     7.06e-06     7.06e-06     3.63e-05
     21    20     2.88e-05     2.88e-05     7.65e-05
     21    30     3.92e-05     3.92e-05     8.61e-05
     21    40      7.4e-06      7.4e-06     3.82e-05
     21    50     9.01e-05     9.01e-05     0.000155
     21    60     2.53e-05     2.53e-05     6.46e-05
     21    61     7.21e-05     7.21e-05     0.000136
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              21 1106.665    0.005     5.87e-05     5.87e-05     0.000101
! Validation         21 1106.665    0.005     3.86e-05     3.86e-05     8.35e-05
Wall time: 1106.6655551659999
! Best model       21    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     22    10     3.54e-05     3.54e-05     6.85e-05
     22    20     6.82e-05     6.82e-05     9.77e-05
     22    30     3.74e-05     3.74e-05     8.56e-05
     22    40     2.41e-05     2.41e-05     6.83e-05
     22    48     6.84e-05     6.84e-05     0.000136
validation
# Epoch batch         loss       loss_e      e/N_mae
     22    10     5.41e-06     5.41e-06     3.34e-05
     22    20     2.78e-05     2.78e-05     7.16e-05
     22    30     3.72e-05     3.72e-05     8.26e-05
     22    40     5.64e-06     5.64e-06     3.21e-05
     22    50     8.74e-05     8.74e-05     0.000153
     22    60     2.16e-05     2.16e-05      6.3e-05
     22    61     6.24e-05     6.24e-05     0.000125
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              22 1158.243    0.005     4.59e-05     4.59e-05     9.02e-05
! Validation         22 1158.243    0.005     3.45e-05     3.45e-05     7.86e-05
Wall time: 1158.2427700829999
! Best model       22    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     23    10      8.8e-05      8.8e-05     0.000129
     23    20     2.16e-05     2.16e-05     6.45e-05
     23    30     4.28e-05     4.28e-05     7.91e-05
     23    40     5.72e-05     5.72e-05     0.000102
     23    48     6.72e-05     6.72e-05     0.000112
validation
# Epoch batch         loss       loss_e      e/N_mae
     23    10     3.45e-06     3.45e-06      2.6e-05
     23    20     2.58e-05     2.58e-05     6.65e-05
     23    30      3.4e-05      3.4e-05     7.87e-05
     23    40     4.72e-06     4.72e-06     3.12e-05
     23    50     8.05e-05     8.05e-05     0.000146
     23    60     2.05e-05     2.05e-05     5.81e-05
     23    61     5.36e-05     5.36e-05     0.000115
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              23 1209.897    0.005      3.4e-05      3.4e-05     7.58e-05
! Validation         23 1209.897    0.005     3.09e-05     3.09e-05     7.42e-05
Wall time: 1209.897554291
! Best model       23    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     24    10     2.32e-05     2.32e-05     5.88e-05
     24    20     4.65e-05     4.65e-05     9.06e-05
     24    30     1.69e-05     1.69e-05     4.96e-05
     24    40     3.25e-05     3.25e-05      7.5e-05
     24    48     0.000115     0.000115     0.000177
validation
# Epoch batch         loss       loss_e      e/N_mae
     24    10     2.11e-06     2.11e-06     2.15e-05
     24    20     2.15e-05     2.15e-05      6.1e-05
     24    30     3.36e-05     3.36e-05     7.74e-05
     24    40     5.65e-06     5.65e-06     3.37e-05
     24    50     7.98e-05     7.98e-05     0.000145
     24    60     1.86e-05     1.86e-05     5.53e-05
     24    61     4.54e-05     4.54e-05     0.000103
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              24 1261.337    0.005     3.98e-05     3.98e-05     8.08e-05
! Validation         24 1261.337    0.005     2.78e-05     2.78e-05     7.01e-05
Wall time: 1261.337249041
! Best model       24    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     25    10     7.08e-05     7.08e-05     0.000113
     25    20     3.56e-05     3.56e-05     7.83e-05
     25    30     9.73e-05     9.73e-05     0.000137
     25    40     2.56e-05     2.56e-05     7.04e-05
     25    48     3.72e-05     3.72e-05     8.11e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     25    10     2.35e-06     2.35e-06     2.38e-05
     25    20     2.18e-05     2.18e-05     6.07e-05
     25    30      2.9e-05      2.9e-05      7.1e-05
     25    40     5.36e-06     5.36e-06     3.47e-05
     25    50     6.71e-05     6.71e-05     0.000133
     25    60     2.05e-05     2.05e-05     6.04e-05
     25    61     4.42e-05     4.42e-05      9.9e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              25 1312.834    0.005     6.15e-05     6.15e-05     0.000104
! Validation         25 1312.834    0.005     2.58e-05     2.58e-05     6.71e-05
Wall time: 1312.834285
! Best model       25    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     26    10     1.54e-05     1.54e-05     5.48e-05
     26    20     2.32e-05     2.32e-05     6.97e-05
     26    30      3.3e-05      3.3e-05      7.5e-05
     26    40     2.05e-05     2.05e-05     5.77e-05
     26    48     2.25e-06     2.25e-06     2.49e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     26    10     1.82e-06     1.82e-06     2.02e-05
     26    20     2.06e-05     2.06e-05     6.07e-05
     26    30     2.54e-05     2.54e-05     6.84e-05
     26    40     5.03e-06     5.03e-06     3.24e-05
     26    50     5.97e-05     5.97e-05     0.000126
     26    60     1.59e-05     1.59e-05      5.4e-05
     26    61     4.91e-05     4.91e-05     0.000102
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              26 1364.349    0.005     3.85e-05     3.85e-05     8.24e-05
! Validation         26 1364.349    0.005     2.34e-05     2.34e-05     6.38e-05
Wall time: 1364.3490058329999
! Best model       26    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     27    10     8.21e-05     8.21e-05     0.000118
     27    20     1.89e-05     1.89e-05      5.8e-05
     27    30     4.05e-05     4.05e-05     8.36e-05
     27    40      1.6e-05      1.6e-05     5.53e-05
     27    48     1.05e-05     1.05e-05     5.38e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     27    10     1.18e-06     1.18e-06     1.54e-05
     27    20     2.08e-05     2.08e-05     6.14e-05
     27    30     2.28e-05     2.28e-05     6.39e-05
     27    40     5.52e-06     5.52e-06     3.24e-05
     27    50     5.43e-05     5.43e-05      0.00012
     27    60     1.51e-05     1.51e-05     5.17e-05
     27    61     4.74e-05     4.74e-05      9.9e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              27 1415.940    0.005     2.94e-05     2.94e-05      7.2e-05
! Validation         27 1415.940    0.005      2.1e-05      2.1e-05     6.04e-05
Wall time: 1415.9397187499999
! Best model       27    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     28    10     0.000125     0.000125     0.000156
     28    20     5.73e-05     5.73e-05     8.46e-05
     28    30     1.75e-05     1.75e-05     5.64e-05
     28    40     5.48e-05     5.48e-05     0.000104
     28    48     1.37e-05     1.37e-05     6.18e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     28    10     2.31e-06     2.31e-06     2.41e-05
     28    20     1.88e-05     1.88e-05     5.94e-05
     28    30     1.88e-05     1.88e-05     6.04e-05
     28    40     5.34e-06     5.34e-06     3.28e-05
     28    50     4.88e-05     4.88e-05      0.00011
     28    60     1.56e-05     1.56e-05      5.2e-05
     28    61     4.78e-05     4.78e-05     9.96e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              28 1467.512    0.005     4.45e-05     4.45e-05     8.85e-05
! Validation         28 1467.512    0.005     1.98e-05     1.98e-05     5.87e-05
Wall time: 1467.5118484159998
! Best model       28    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     29    10     3.02e-05     3.02e-05     7.32e-05
     29    20     2.88e-05     2.88e-05     6.27e-05
     29    30     1.84e-05     1.84e-05     5.83e-05
     29    40     1.57e-05     1.57e-05     5.63e-05
     29    48     1.37e-07     1.37e-07     4.82e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
     29    10     1.82e-06     1.82e-06     2.22e-05
     29    20     1.94e-05     1.94e-05     6.14e-05
     29    30     1.78e-05     1.78e-05     5.78e-05
     29    40     6.39e-06     6.39e-06     3.34e-05
     29    50     4.62e-05     4.62e-05     0.000105
     29    60     1.28e-05     1.28e-05     5.01e-05
     29    61     4.47e-05     4.47e-05     9.16e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              29 1518.926    0.005     2.41e-05     2.41e-05     6.28e-05
! Validation         29 1518.926    0.005     1.83e-05     1.83e-05     5.54e-05
Wall time: 1518.9261501659998
! Best model       29    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     30    10     6.04e-06     6.04e-06     3.34e-05
     30    20     1.48e-05     1.48e-05     5.35e-05
     30    30     1.72e-05     1.72e-05     5.79e-05
     30    40     7.82e-06     7.82e-06     3.36e-05
     30    48     1.37e-06     1.37e-06     1.85e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     30    10     1.94e-06     1.94e-06     2.31e-05
     30    20     1.87e-05     1.87e-05     5.94e-05
     30    30     1.57e-05     1.57e-05      5.3e-05
     30    40     6.12e-06     6.12e-06     3.44e-05
     30    50     4.02e-05     4.02e-05     9.67e-05
     30    60      1.4e-05      1.4e-05     5.24e-05
     30    61     4.38e-05     4.38e-05     9.42e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              30 1570.467    0.005     1.91e-05     1.91e-05     5.64e-05
! Validation         30 1570.467    0.005      1.7e-05      1.7e-05     5.29e-05
Wall time: 1570.4679133329998
! Best model       30    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     31    10     8.68e-06     8.68e-06      4.1e-05
     31    20      9.8e-06      9.8e-06     4.63e-05
     31    30     1.24e-05     1.24e-05     4.99e-05
     31    40     1.73e-05     1.73e-05     5.32e-05
     31    48     2.18e-05     2.18e-05     7.63e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     31    10     2.63e-06     2.63e-06     2.54e-05
     31    20     1.74e-05     1.74e-05     5.69e-05
     31    30     1.41e-05     1.41e-05     5.17e-05
     31    40     6.73e-06     6.73e-06     3.34e-05
     31    50     3.77e-05     3.77e-05     9.03e-05
     31    60     1.37e-05     1.37e-05     5.27e-05
     31    61     4.33e-05     4.33e-05     9.42e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              31 1621.986    0.005     2.28e-05     2.28e-05     6.15e-05
! Validation         31 1621.986    0.005     1.61e-05     1.61e-05     5.11e-05
Wall time: 1621.9867072499999
! Best model       31    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     32    10     1.67e-05     1.67e-05     5.61e-05
     32    20     1.41e-05     1.41e-05     5.28e-05
     32    30     1.96e-05     1.96e-05     5.42e-05
     32    40     1.62e-05     1.62e-05      5.7e-05
     32    48     2.71e-05     2.71e-05     7.47e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     32    10     2.63e-06     2.63e-06     2.38e-05
     32    20     1.72e-05     1.72e-05     5.36e-05
     32    30     1.26e-05     1.26e-05     4.82e-05
     32    40     6.42e-06     6.42e-06     3.41e-05
     32    50     3.44e-05     3.44e-05     8.32e-05
     32    60      1.3e-05      1.3e-05     5.24e-05
     32    61     4.47e-05     4.47e-05     9.69e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              32 1673.541    0.005     1.87e-05     1.87e-05     5.53e-05
! Validation         32 1673.541    0.005     1.52e-05     1.52e-05     4.93e-05
Wall time: 1673.541378125
! Best model       32    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     33    10     1.75e-05     1.75e-05     5.58e-05
     33    20     4.99e-05     4.99e-05     8.88e-05
     33    30     2.54e-05     2.54e-05     6.71e-05
     33    40     5.21e-05     5.21e-05     0.000106
     33    48     1.27e-05     1.27e-05     5.14e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     33    10     4.39e-06     4.39e-06     3.08e-05
     33    20     1.53e-05     1.53e-05     5.04e-05
     33    30     1.07e-05     1.07e-05     4.53e-05
     33    40     5.47e-06     5.47e-06     3.15e-05
     33    50     3.09e-05     3.09e-05     7.65e-05
     33    60     1.35e-05     1.35e-05      5.3e-05
     33    61     4.13e-05     4.13e-05     9.32e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              33 1724.874    0.005     2.99e-05     2.99e-05     7.28e-05
! Validation         33 1724.874    0.005     1.43e-05     1.43e-05     4.76e-05
Wall time: 1724.87477025
! Best model       33    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     34    10     3.17e-05     3.17e-05     6.78e-05
     34    20     3.01e-05     3.01e-05     7.36e-05
     34    30     7.68e-05     7.68e-05     0.000138
     34    40     9.69e-06     9.69e-06     4.04e-05
     34    48      2.6e-06      2.6e-06     2.09e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     34    10     4.36e-06     4.36e-06     3.21e-05
     34    20     1.53e-05     1.53e-05      5.2e-05
     34    30     1.06e-05     1.06e-05     4.59e-05
     34    40     5.81e-06     5.81e-06     3.21e-05
     34    50     3.14e-05     3.14e-05     7.81e-05
     34    60     1.19e-05     1.19e-05     4.95e-05
     34    61     4.49e-05     4.49e-05     9.58e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              34 1775.881    0.005     2.59e-05     2.59e-05      6.7e-05
! Validation         34 1775.881    0.005     1.41e-05     1.41e-05     4.72e-05
Wall time: 1775.881700041
! Best model       34    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     35    10     1.19e-05     1.19e-05     4.65e-05
     35    20     7.03e-06     7.03e-06     3.61e-05
     35    30     1.08e-05     1.08e-05     4.25e-05
     35    40     1.74e-05     1.74e-05     5.59e-05
     35    48     9.33e-06     9.33e-06     3.69e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     35    10     5.37e-06     5.37e-06     3.53e-05
     35    20      1.5e-05      1.5e-05     4.98e-05
     35    30     9.26e-06     9.26e-06      4.3e-05
     35    40     5.44e-06     5.44e-06     2.99e-05
     35    50     2.71e-05     2.71e-05      7.1e-05
     35    60     1.09e-05     1.09e-05     4.79e-05
     35    61     4.46e-05     4.46e-05     9.64e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              35 1827.191    0.005      1.8e-05      1.8e-05     5.52e-05
! Validation         35 1827.191    0.005     1.31e-05     1.31e-05     4.52e-05
Wall time: 1827.1917348749998
! Best model       35    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     36    10     2.99e-05     2.99e-05     7.57e-05
     36    20     7.97e-06     7.97e-06      3.9e-05
     36    30     1.44e-05     1.44e-05     5.45e-05
     36    40     3.87e-05     3.87e-05     7.26e-05
     36    48     1.53e-05     1.53e-05     6.34e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     36    10     3.85e-06     3.85e-06     2.89e-05
     36    20     1.41e-05     1.41e-05     4.82e-05
     36    30     1.03e-05     1.03e-05     4.56e-05
     36    40     5.05e-06     5.05e-06     2.99e-05
     36    50     2.59e-05     2.59e-05     6.55e-05
     36    60     1.14e-05     1.14e-05     4.88e-05
     36    61     4.32e-05     4.32e-05     9.53e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              36 1878.365    0.005     1.73e-05     1.73e-05     5.32e-05
! Validation         36 1878.365    0.005     1.26e-05     1.26e-05     4.44e-05
Wall time: 1878.3665893749999
! Best model       36    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     37    10     3.08e-05     3.08e-05     7.98e-05
     37    20     1.37e-05     1.37e-05     4.85e-05
     37    30     2.73e-05     2.73e-05     7.55e-05
     37    40     7.41e-06     7.41e-06     3.73e-05
     37    48     4.83e-06     4.83e-06     3.61e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     37    10     5.26e-06     5.26e-06     3.53e-05
     37    20     1.21e-05     1.21e-05      4.5e-05
     37    30     1.02e-05     1.02e-05     4.56e-05
     37    40     4.82e-06     4.82e-06     2.99e-05
     37    50     2.58e-05     2.58e-05     6.49e-05
     37    60     1.08e-05     1.08e-05     4.88e-05
     37    61     4.29e-05     4.29e-05     9.26e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              37 1929.643    0.005     1.99e-05     1.99e-05     5.89e-05
! Validation         37 1929.643    0.005      1.2e-05      1.2e-05     4.31e-05
Wall time: 1929.6442330829998
! Best model       37    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     38    10      1.6e-05      1.6e-05     5.86e-05
     38    20     1.35e-05     1.35e-05     5.03e-05
     38    30     3.56e-05     3.56e-05     9.31e-05
     38    40      6.2e-06      6.2e-06     3.48e-05
     38    48     4.03e-05     4.03e-05     0.000102
validation
# Epoch batch         loss       loss_e      e/N_mae
     38    10     5.95e-06     5.95e-06     3.82e-05
     38    20     1.14e-05     1.14e-05     4.27e-05
     38    30     1.08e-05     1.08e-05     4.56e-05
     38    40     4.52e-06     4.52e-06      2.7e-05
     38    50     2.45e-05     2.45e-05     6.14e-05
     38    60     1.05e-05     1.05e-05     4.79e-05
     38    61     3.93e-05     3.93e-05     8.94e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              38 1980.885    0.005     1.86e-05     1.86e-05      5.5e-05
! Validation         38 1980.885    0.005     1.13e-05     1.13e-05     4.16e-05
Wall time: 1980.884767541
! Best model       38    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     39    10     2.19e-05     2.19e-05     6.23e-05
     39    20     2.72e-05     2.72e-05     7.75e-05
     39    30      2.8e-05      2.8e-05     7.89e-05
     39    40     1.21e-05     1.21e-05     4.97e-05
     39    48     2.82e-06     2.82e-06     2.41e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     39    10     6.79e-06     6.79e-06     4.05e-05
     39    20      1.1e-05      1.1e-05     4.27e-05
     39    30     8.38e-06     8.38e-06     4.05e-05
     39    40     4.05e-06     4.05e-06     2.76e-05
     39    50     2.34e-05     2.34e-05     5.85e-05
     39    60     1.01e-05     1.01e-05     4.66e-05
     39    61     4.06e-05     4.06e-05     9.05e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              39 2031.863    0.005      2.4e-05      2.4e-05     6.58e-05
! Validation         39 2031.863    0.005     1.11e-05     1.11e-05     4.11e-05
Wall time: 2031.8626761659998
! Best model       39    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     40    10     9.01e-06     9.01e-06     3.68e-05
     40    20     1.04e-05     1.04e-05     4.75e-05
     40    30     6.76e-06     6.76e-06     3.65e-05
     40    40     5.22e-06     5.22e-06     2.87e-05
     40    48     3.39e-06     3.39e-06     2.49e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     40    10     6.91e-06     6.91e-06     4.05e-05
     40    20     1.08e-05     1.08e-05     4.21e-05
     40    30     8.18e-06     8.18e-06     3.89e-05
     40    40     3.83e-06     3.83e-06     2.76e-05
     40    50     2.12e-05     2.12e-05     5.59e-05
     40    60     9.87e-06     9.87e-06     4.75e-05
     40    61     4.21e-05     4.21e-05     9.05e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              40 2083.090    0.005     1.34e-05     1.34e-05     4.67e-05
! Validation         40 2083.090    0.005     1.06e-05     1.06e-05     3.99e-05
Wall time: 2083.0906528329997
! Best model       40    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     41    10     3.34e-05     3.34e-05     7.04e-05
     41    20     8.65e-06     8.65e-06     3.83e-05
     41    30     2.54e-05     2.54e-05     6.83e-05
     41    40     1.21e-05     1.21e-05     4.52e-05
     41    48      8.3e-06      8.3e-06     4.82e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     41    10     5.94e-06     5.94e-06     3.66e-05
     41    20     1.06e-05     1.06e-05     4.18e-05
     41    30     8.15e-06     8.15e-06     3.82e-05
     41    40     3.26e-06     3.26e-06     2.63e-05
     41    50     1.94e-05     1.94e-05     5.24e-05
     41    60     9.05e-06     9.05e-06     4.56e-05
     41    61     4.04e-05     4.04e-05     8.99e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              41 2134.361    0.005     1.54e-05     1.54e-05     5.11e-05
! Validation         41 2134.361    0.005     9.95e-06     9.95e-06     3.86e-05
Wall time: 2134.362306
! Best model       41    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     42    10     7.51e-06     7.51e-06     3.75e-05
     42    20     3.09e-06     3.09e-06     2.51e-05
     42    30     7.65e-06     7.65e-06     3.96e-05
     42    40     2.28e-05     2.28e-05      5.5e-05
     42    48     1.72e-06     1.72e-06     2.17e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     42    10        7e-06        7e-06     4.02e-05
     42    20     9.64e-06     9.64e-06     4.08e-05
     42    30     9.49e-06     9.49e-06     4.21e-05
     42    40     2.83e-06     2.83e-06     2.47e-05
     42    50     1.79e-05     1.79e-05     5.01e-05
     42    60     1.03e-05     1.03e-05     4.69e-05
     42    61     4.02e-05     4.02e-05     8.83e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              42 2185.559    0.005     1.17e-05     1.17e-05     4.34e-05
! Validation         42 2185.559    0.005     9.59e-06     9.59e-06      3.8e-05
Wall time: 2185.5604452499997
! Best model       42    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     43    10     1.71e-05     1.71e-05     5.96e-05
     43    20     1.97e-05     1.97e-05     5.91e-05
     43    30     2.76e-05     2.76e-05     6.18e-05
     43    40      2.6e-06      2.6e-06     2.01e-05
     43    48     6.13e-06     6.13e-06     4.02e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     43    10     7.52e-06     7.52e-06     4.08e-05
     43    20     8.77e-06     8.77e-06     3.79e-05
     43    30     8.44e-06     8.44e-06     3.92e-05
     43    40     2.89e-06     2.89e-06     2.41e-05
     43    50     1.75e-05     1.75e-05     4.95e-05
     43    60     9.72e-06     9.72e-06     4.63e-05
     43    61     3.97e-05     3.97e-05     8.73e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              43 2236.813    0.005      1.4e-05      1.4e-05     4.75e-05
! Validation         43 2236.813    0.005     9.16e-06     9.16e-06     3.68e-05
Wall time: 2236.81371725
! Best model       43    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     44    10     1.56e-05     1.56e-05     4.84e-05
     44    20     3.77e-05     3.77e-05     9.26e-05
     44    30     2.97e-05     2.97e-05     8.34e-05
     44    40     1.39e-05     1.39e-05     4.88e-05
     44    48     2.59e-06     2.59e-06     2.33e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     44    10      6.3e-06      6.3e-06     3.76e-05
     44    20     7.75e-06     7.75e-06     3.85e-05
     44    30     8.21e-06     8.21e-06     3.69e-05
     44    40     2.37e-06     2.37e-06     2.18e-05
     44    50     1.59e-05     1.59e-05     4.59e-05
     44    60     8.77e-06     8.77e-06      4.5e-05
     44    61     3.72e-05     3.72e-05     8.57e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              44 2287.987    0.005     1.77e-05     1.77e-05     5.54e-05
! Validation         44 2287.987    0.005     8.77e-06     8.77e-06      3.6e-05
Wall time: 2287.987924916
! Best model       44    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     45    10     9.73e-06     9.73e-06     4.04e-05
     45    20     5.59e-06     5.59e-06     2.99e-05
     45    30     1.07e-05     1.07e-05     4.14e-05
     45    40     2.31e-05     2.31e-05     4.83e-05
     45    48     3.32e-06     3.32e-06     2.89e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     45    10     5.79e-06     5.79e-06     3.57e-05
     45    20     7.45e-06     7.45e-06      3.5e-05
     45    30     7.22e-06     7.22e-06     3.53e-05
     45    40     2.22e-06     2.22e-06     2.12e-05
     45    50      1.5e-05      1.5e-05      4.3e-05
     45    60     9.18e-06     9.18e-06     4.63e-05
     45    61     3.75e-05     3.75e-05     8.57e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              45 2339.235    0.005     1.21e-05     1.21e-05     4.37e-05
! Validation         45 2339.235    0.005     8.24e-06     8.24e-06     3.48e-05
Wall time: 2339.2360089579997
! Best model       45    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     46    10     1.91e-05     1.91e-05     5.11e-05
     46    20     1.27e-05     1.27e-05     4.52e-05
     46    30     1.59e-05     1.59e-05     4.33e-05
     46    40     5.77e-06     5.77e-06     2.97e-05
     46    48     2.17e-07     2.17e-07     8.03e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
     46    10     5.82e-06     5.82e-06      3.5e-05
     46    20      7.1e-06      7.1e-06     3.34e-05
     46    30     6.44e-06     6.44e-06     3.31e-05
     46    40     2.61e-06     2.61e-06     2.22e-05
     46    50     1.44e-05     1.44e-05     4.14e-05
     46    60     7.28e-06     7.28e-06     4.08e-05
     46    61     3.49e-05     3.49e-05     8.35e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              46 2390.468    0.005     9.88e-06     9.88e-06     4.02e-05
! Validation         46 2390.468    0.005     7.95e-06     7.95e-06     3.43e-05
Wall time: 2390.4686093749997
! Best model       46    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     47    10     5.85e-06     5.85e-06     3.02e-05
     47    20     1.25e-05     1.25e-05     4.13e-05
     47    30      8.7e-06      8.7e-06     4.09e-05
     47    40     8.11e-06     8.11e-06      3.6e-05
     47    48     3.09e-06     3.09e-06     2.65e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     47    10      5.6e-06      5.6e-06     3.44e-05
     47    20     6.29e-06     6.29e-06     3.34e-05
     47    30     6.32e-06     6.32e-06     3.21e-05
     47    40     2.34e-06     2.34e-06     1.93e-05
     47    50     1.36e-05     1.36e-05     4.27e-05
     47    60     6.93e-06     6.93e-06     3.98e-05
     47    61     3.34e-05     3.34e-05     8.25e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              47 2441.678    0.005     9.17e-06     9.17e-06     3.87e-05
! Validation         47 2441.678    0.005      7.5e-06      7.5e-06     3.32e-05
Wall time: 2441.678883833
! Best model       47    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     48    10      2.1e-06      2.1e-06      2.1e-05
     48    20     6.21e-06     6.21e-06     3.33e-05
     48    30     1.49e-05     1.49e-05     5.16e-05
     48    40     1.06e-05     1.06e-05      4.5e-05
     48    48     1.26e-05     1.26e-05     5.94e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     48    10     5.78e-06     5.78e-06     3.47e-05
     48    20     5.76e-06     5.76e-06     3.24e-05
     48    30     6.11e-06     6.11e-06     3.08e-05
     48    40     2.12e-06     2.12e-06     1.73e-05
     48    50     1.29e-05     1.29e-05     4.08e-05
     48    60     6.57e-06     6.57e-06     3.85e-05
     48    61     3.33e-05     3.33e-05     8.19e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              48 2492.861    0.005     1.19e-05     1.19e-05     4.47e-05
! Validation         48 2492.861    0.005     7.23e-06     7.23e-06     3.25e-05
Wall time: 2492.861706916
! Best model       48    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     49    10     4.88e-05     4.88e-05     0.000107
     49    20      1.8e-05      1.8e-05     6.41e-05
     49    30     1.19e-05     1.19e-05     3.72e-05
     49    40     9.82e-06     9.82e-06     4.84e-05
     49    48     6.94e-06     6.94e-06     4.34e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     49    10     6.07e-06     6.07e-06     3.63e-05
     49    20      5.3e-06      5.3e-06     3.15e-05
     49    30     5.79e-06     5.79e-06     3.05e-05
     49    40     2.03e-06     2.03e-06     1.67e-05
     49    50     1.26e-05     1.26e-05     3.89e-05
     49    60     6.26e-06     6.26e-06     3.76e-05
     49    61        3e-05        3e-05     7.76e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              49 2543.893    0.005     1.25e-05     1.25e-05     4.46e-05
! Validation         49 2543.893    0.005     6.83e-06     6.83e-06     3.15e-05
Wall time: 2543.892905625
! Best model       49    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     50    10      1.4e-05      1.4e-05     5.64e-05
     50    20     1.99e-05     1.99e-05      5.3e-05
     50    30     9.46e-06     9.46e-06      4.3e-05
     50    40     6.92e-06     6.92e-06     3.77e-05
     50    48     2.52e-06     2.52e-06     2.33e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     50    10     6.23e-06     6.23e-06     3.66e-05
     50    20     4.98e-06     4.98e-06     3.08e-05
     50    30     5.27e-06     5.27e-06     2.89e-05
     50    40     2.06e-06     2.06e-06     1.77e-05
     50    50     1.14e-05     1.14e-05     4.05e-05
     50    60     5.75e-06     5.75e-06      3.6e-05
     50    61     2.93e-05     2.93e-05     7.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              50 2594.996    0.005     1.23e-05     1.23e-05     4.69e-05
! Validation         50 2594.996    0.005     6.42e-06     6.42e-06     3.03e-05
Wall time: 2594.996658083
! Best model       50    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     51    10     1.29e-05     1.29e-05     5.27e-05
     51    20     1.47e-05     1.47e-05     5.54e-05
     51    30     5.76e-06     5.76e-06     3.28e-05
     51    40     4.06e-06     4.06e-06     2.85e-05
     51    48     4.78e-06     4.78e-06     2.73e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     51    10     6.27e-06     6.27e-06     3.57e-05
     51    20     4.51e-06     4.51e-06     3.02e-05
     51    30        5e-06        5e-06     2.92e-05
     51    40      1.3e-06      1.3e-06     1.45e-05
     51    50      1.2e-05      1.2e-05     4.24e-05
     51    60      5.3e-06      5.3e-06     3.41e-05
     51    61     2.48e-05     2.48e-05     7.12e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              51 2646.230    0.005     1.04e-05     1.04e-05     4.18e-05
! Validation         51 2646.230    0.005     6.28e-06     6.28e-06     3.01e-05
Wall time: 2646.2304544159997
! Best model       51    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     52    10     1.21e-05     1.21e-05     3.61e-05
     52    20     7.72e-06     7.72e-06     3.18e-05
     52    30     6.37e-06     6.37e-06     3.22e-05
     52    40     1.54e-05     1.54e-05     4.06e-05
     52    48     9.23e-05     9.23e-05     0.000137
validation
# Epoch batch         loss       loss_e      e/N_mae
     52    10      5.6e-06      5.6e-06     3.44e-05
     52    20     4.68e-06     4.68e-06     3.12e-05
     52    30     5.02e-06     5.02e-06     2.96e-05
     52    40      1.4e-06      1.4e-06     1.38e-05
     52    50     1.11e-05     1.11e-05     3.98e-05
     52    60     5.36e-06     5.36e-06     3.44e-05
     52    61     2.61e-05     2.61e-05     7.17e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              52 2698.634    0.005     1.36e-05     1.36e-05     4.56e-05
! Validation         52 2698.634    0.005     6.12e-06     6.12e-06     2.96e-05
Wall time: 2698.635284083
! Best model       52    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     53    10     3.99e-05     3.99e-05     9.07e-05
     53    20     1.18e-05     1.18e-05     4.05e-05
     53    30     5.75e-06     5.75e-06     3.37e-05
     53    40     9.78e-06     9.78e-06     3.72e-05
     53    48     1.54e-05     1.54e-05     6.51e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     53    10     5.94e-06     5.94e-06     3.47e-05
     53    20     4.85e-06     4.85e-06     3.05e-05
     53    30     5.77e-06     5.77e-06     3.31e-05
     53    40     1.46e-06     1.46e-06     1.54e-05
     53    50     1.02e-05     1.02e-05     3.76e-05
     53    60     6.32e-06     6.32e-06     3.92e-05
     53    61     1.84e-05     1.84e-05     6.05e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              53 2752.703    0.005     1.96e-05     1.96e-05     5.59e-05
! Validation         53 2752.703    0.005     6.04e-06     6.04e-06     2.99e-05
Wall time: 2752.703898625
! Best model       53    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     54    10     9.89e-06     9.89e-06     4.71e-05
     54    20     1.71e-05     1.71e-05     5.66e-05
     54    30      9.5e-06      9.5e-06     3.84e-05
     54    40     5.13e-06     5.13e-06     3.33e-05
     54    48      1.3e-05      1.3e-05      5.7e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     54    10     5.43e-06     5.43e-06     3.31e-05
     54    20     4.86e-06     4.86e-06     3.02e-05
     54    30     5.96e-06     5.96e-06     3.24e-05
     54    40     1.66e-06     1.66e-06     1.77e-05
     54    50     1.04e-05     1.04e-05     3.98e-05
     54    60     6.42e-06     6.42e-06     3.98e-05
     54    61     1.79e-05     1.79e-05        6e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              54 2806.362    0.005        1e-05        1e-05     4.07e-05
! Validation         54 2806.362    0.005     5.86e-06     5.86e-06     2.95e-05
Wall time: 2806.363189708
! Best model       54    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     55    10     7.83e-06     7.83e-06      3.8e-05
     55    20     2.19e-05     2.19e-05     5.39e-05
     55    30     7.45e-06     7.45e-06     3.49e-05
     55    40     4.45e-06     4.45e-06     2.89e-05
     55    48     4.03e-05     4.03e-05     9.56e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     55    10     5.54e-06     5.54e-06     3.37e-05
     55    20     3.95e-06     3.95e-06     2.73e-05
     55    30     5.09e-06     5.09e-06     3.02e-05
     55    40     1.82e-06     1.82e-06      1.9e-05
     55    50     1.08e-05     1.08e-05     4.24e-05
     55    60     6.21e-06     6.21e-06     3.95e-05
     55    61     1.79e-05     1.79e-05     5.94e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              55 2858.023    0.005     8.14e-06     8.14e-06     3.46e-05
! Validation         55 2858.023    0.005     5.51e-06     5.51e-06     2.85e-05
Wall time: 2858.023845375
! Best model       55    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     56    10     1.72e-05     1.72e-05     6.05e-05
     56    20     1.05e-05     1.05e-05     4.67e-05
     56    30     9.73e-06     9.73e-06     3.52e-05
     56    40     3.14e-06     3.14e-06     2.15e-05
     56    48      1.4e-06      1.4e-06     1.53e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     56    10     6.27e-06     6.27e-06      3.6e-05
     56    20      3.6e-06      3.6e-06     2.76e-05
     56    30     4.86e-06     4.86e-06     3.02e-05
     56    40     1.64e-06     1.64e-06     1.83e-05
     56    50     8.78e-06     8.78e-06     3.89e-05
     56    60     5.74e-06     5.74e-06     3.79e-05
     56    61     1.82e-05     1.82e-05      6.1e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              56 2910.608    0.005     1.22e-05     1.22e-05     4.51e-05
! Validation         56 2910.608    0.005     5.25e-06     5.25e-06     2.82e-05
Wall time: 2910.608675333
! Best model       56    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     57    10     2.52e-05     2.52e-05     7.52e-05
     57    20     1.15e-05     1.15e-05     4.11e-05
     57    30     2.33e-05     2.33e-05     6.75e-05
     57    40     1.51e-05     1.51e-05     5.11e-05
     57    48     4.91e-05     4.91e-05     0.000115
validation
# Epoch batch         loss       loss_e      e/N_mae
     57    10     5.94e-06     5.94e-06     3.37e-05
     57    20     4.11e-06     4.11e-06     2.99e-05
     57    30     4.72e-06     4.72e-06     2.86e-05
     57    40     1.44e-06     1.44e-06     1.73e-05
     57    50     9.99e-06     9.99e-06      4.3e-05
     57    60      4.3e-06      4.3e-06     3.37e-05
     57    61     1.66e-05     1.66e-05     5.73e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              57 2962.357    0.005     1.91e-05     1.91e-05     5.62e-05
! Validation         57 2962.357    0.005     5.17e-06     5.17e-06      2.8e-05
Wall time: 2962.357859666
! Best model       57    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     58    10     1.92e-05     1.92e-05     6.02e-05
     58    20     9.42e-06     9.42e-06     4.06e-05
     58    30     5.48e-06     5.48e-06     3.33e-05
     58    40     1.16e-05     1.16e-05     4.63e-05
     58    48     1.02e-05     1.02e-05      5.3e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     58    10     5.59e-06     5.59e-06     3.34e-05
     58    20     3.47e-06     3.47e-06     2.83e-05
     58    30     5.15e-06     5.15e-06     2.99e-05
     58    40     1.41e-06     1.41e-06     1.61e-05
     58    50     9.81e-06     9.81e-06     3.95e-05
     58    60     4.41e-06     4.41e-06     3.41e-05
     58    61     1.79e-05     1.79e-05     5.94e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              58 3015.382    0.005     1.64e-05     1.64e-05     5.25e-05
! Validation         58 3015.382    0.005     5.35e-06     5.35e-06     2.88e-05
Wall time: 3015.383314791
training
# Epoch batch         loss       loss_e      e/N_mae
     59    10     1.15e-05     1.15e-05     4.94e-05
     59    20     1.21e-05     1.21e-05     4.02e-05
     59    30     3.68e-06     3.68e-06     2.45e-05
     59    40     3.56e-06     3.56e-06     2.37e-05
     59    48     2.88e-06     2.88e-06     2.73e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     59    10     5.01e-06     5.01e-06     3.28e-05
     59    20     4.44e-06     4.44e-06     3.12e-05
     59    30     5.07e-06     5.07e-06     2.89e-05
     59    40     1.45e-06     1.45e-06     1.73e-05
     59    50     8.89e-06     8.89e-06     4.11e-05
     59    60      4.1e-06      4.1e-06     3.24e-05
     59    61     1.86e-05     1.86e-05     6.32e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              59 3067.511    0.005     9.13e-06     9.13e-06     3.91e-05
! Validation         59 3067.511    0.005     5.15e-06     5.15e-06     2.82e-05
Wall time: 3067.512074375
! Best model       59    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     60    10     1.28e-05     1.28e-05     4.49e-05
     60    20     5.25e-06     5.25e-06      3.2e-05
     60    30     4.68e-06     4.68e-06     3.04e-05
     60    40     2.61e-06     2.61e-06     2.35e-05
     60    48     2.99e-06     2.99e-06     2.57e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     60    10     4.97e-06     4.97e-06     3.21e-05
     60    20     4.31e-06     4.31e-06     3.12e-05
     60    30     3.83e-06     3.83e-06      2.7e-05
     60    40     1.28e-06     1.28e-06     1.64e-05
     60    50     7.85e-06     7.85e-06     3.79e-05
     60    60     3.82e-06     3.82e-06     3.08e-05
     60    61      1.8e-05      1.8e-05     6.05e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              60 3119.604    0.005     9.09e-06     9.09e-06     3.91e-05
! Validation         60 3119.604    0.005     4.83e-06     4.83e-06     2.76e-05
Wall time: 3119.6052046249997
! Best model       60    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     61    10      2.6e-05      2.6e-05     7.77e-05
     61    20     4.58e-06     4.58e-06     2.78e-05
     61    30     1.04e-05     1.04e-05     4.56e-05
     61    40     1.27e-05     1.27e-05     5.32e-05
     61    48     3.75e-06     3.75e-06     3.13e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     61    10     5.54e-06     5.54e-06     3.44e-05
     61    20     3.81e-06     3.81e-06     2.92e-05
     61    30     3.66e-06     3.66e-06      2.7e-05
     61    40     8.41e-07     8.41e-07     1.22e-05
     61    50     7.95e-06     7.95e-06     3.79e-05
     61    60     4.19e-06     4.19e-06     3.34e-05
     61    61     1.83e-05     1.83e-05     5.84e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              61 3171.877    0.005     1.31e-05     1.31e-05     4.87e-05
! Validation         61 3171.877    0.005     4.67e-06     4.67e-06     2.67e-05
Wall time: 3171.8782767079997
! Best model       61    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     62    10     8.55e-06     8.55e-06     3.93e-05
     62    20     9.33e-06     9.33e-06      3.9e-05
     62    30     7.59e-06     7.59e-06     3.93e-05
     62    40     9.59e-06     9.59e-06     4.05e-05
     62    48     3.79e-05     3.79e-05     9.88e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     62    10     4.61e-06     4.61e-06     3.02e-05
     62    20     4.13e-06     4.13e-06     3.05e-05
     62    30     3.59e-06     3.59e-06      2.6e-05
     62    40     1.12e-06     1.12e-06     1.41e-05
     62    50     8.53e-06     8.53e-06     3.95e-05
     62    60     4.17e-06     4.17e-06     3.18e-05
     62    61     1.94e-05     1.94e-05      6.1e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              62 3224.209    0.005     1.09e-05     1.09e-05     4.25e-05
! Validation         62 3224.209    0.005     4.54e-06     4.54e-06     2.65e-05
Wall time: 3224.210389125
! Best model       62    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     63    10     1.25e-05     1.25e-05     3.72e-05
     63    20     1.24e-05     1.24e-05     4.71e-05
     63    30     9.64e-06     9.64e-06     4.02e-05
     63    40        1e-05        1e-05     4.59e-05
     63    48     1.02e-05     1.02e-05      4.5e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     63    10     4.41e-06     4.41e-06     3.12e-05
     63    20     3.96e-06     3.96e-06     3.05e-05
     63    30     3.76e-06     3.76e-06      2.6e-05
     63    40     9.05e-07     9.05e-07     1.28e-05
     63    50     7.85e-06     7.85e-06     3.66e-05
     63    60     4.28e-06     4.28e-06     3.37e-05
     63    61     1.98e-05     1.98e-05     6.05e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              63 3277.163    0.005     9.92e-06     9.92e-06     4.04e-05
! Validation         63 3277.163    0.005     4.54e-06     4.54e-06     2.67e-05
Wall time: 3277.164057166
training
# Epoch batch         loss       loss_e      e/N_mae
     64    10     3.48e-06     3.48e-06     2.41e-05
     64    20     8.56e-06     8.56e-06     3.74e-05
     64    30     3.12e-06     3.12e-06     2.46e-05
     64    40     4.37e-06     4.37e-06     2.86e-05
     64    48     2.59e-07     2.59e-07     5.62e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
     64    10     3.93e-06     3.93e-06     2.83e-05
     64    20     3.85e-06     3.85e-06     2.92e-05
     64    30     3.12e-06     3.12e-06     2.44e-05
     64    40     6.81e-07     6.81e-07     1.16e-05
     64    50     6.99e-06     6.99e-06     3.28e-05
     64    60        4e-06        4e-06     3.21e-05
     64    61     1.86e-05     1.86e-05     6.05e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              64 3329.359    0.005     7.03e-06     7.03e-06     3.45e-05
! Validation         64 3329.359    0.005     4.29e-06     4.29e-06     2.59e-05
Wall time: 3329.358920375
! Best model       64    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     65    10     7.46e-06     7.46e-06     3.76e-05
     65    20     5.76e-06     5.76e-06     2.74e-05
     65    30     1.81e-06     1.81e-06     1.83e-05
     65    40     2.57e-06     2.57e-06     2.15e-05
     65    48     7.42e-06     7.42e-06     4.42e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     65    10     4.23e-06     4.23e-06     3.05e-05
     65    20     3.66e-06     3.66e-06     2.86e-05
     65    30     3.39e-06     3.39e-06     2.54e-05
     65    40     6.23e-07     6.23e-07     1.12e-05
     65    50     7.25e-06     7.25e-06     3.34e-05
     65    60      3.5e-06      3.5e-06     2.99e-05
     65    61     1.89e-05     1.89e-05     6.05e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              65 3381.335    0.005     9.98e-06     9.98e-06     4.14e-05
! Validation         65 3381.335    0.005     4.29e-06     4.29e-06     2.58e-05
Wall time: 3381.335557416
! Best model       65    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     66    10     9.92e-06     9.92e-06     4.57e-05
     66    20      1.7e-05      1.7e-05        6e-05
     66    30     3.73e-06     3.73e-06     2.46e-05
     66    40     3.59e-06     3.59e-06     2.39e-05
     66    48     1.55e-06     1.55e-06     1.61e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     66    10     5.17e-06     5.17e-06     3.28e-05
     66    20     3.43e-06     3.43e-06     2.83e-05
     66    30     3.44e-06     3.44e-06     2.51e-05
     66    40     3.25e-07     3.25e-07     8.35e-06
     66    50     6.34e-06     6.34e-06     2.96e-05
     66    60     4.27e-06     4.27e-06     3.41e-05
     66    61     1.84e-05     1.84e-05     5.84e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              66 3433.566    0.005     1.47e-05     1.47e-05     5.05e-05
! Validation         66 3433.566    0.005      4.2e-06      4.2e-06     2.53e-05
Wall time: 3433.5657604999997
! Best model       66    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     67    10      8.2e-06      8.2e-06     4.28e-05
     67    20     4.78e-06     4.78e-06     2.72e-05
     67    30     1.07e-05     1.07e-05     4.86e-05
     67    40     2.96e-06     2.96e-06     2.39e-05
     67    48     5.08e-06     5.08e-06     3.45e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     67    10     4.88e-06     4.88e-06     3.08e-05
     67    20     3.33e-06     3.33e-06     2.73e-05
     67    30     3.43e-06     3.43e-06     2.51e-05
     67    40     4.95e-07     4.95e-07     1.03e-05
     67    50      5.9e-06      5.9e-06     2.89e-05
     67    60     4.17e-06     4.17e-06     3.31e-05
     67    61     1.85e-05     1.85e-05        6e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              67 3485.761    0.005     8.66e-06     8.66e-06     3.87e-05
! Validation         67 3485.761    0.005     3.98e-06     3.98e-06     2.46e-05
Wall time: 3485.7615204159997
! Best model       67    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     68    10      1.2e-05      1.2e-05     4.55e-05
     68    20     4.76e-06     4.76e-06     2.77e-05
     68    30     8.51e-06     8.51e-06     4.25e-05
     68    40     1.38e-05     1.38e-05     4.37e-05
     68    48      6.6e-07      6.6e-07     1.28e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     68    10     4.58e-06     4.58e-06     3.02e-05
     68    20     3.17e-06     3.17e-06     2.73e-05
     68    30     2.97e-06     2.97e-06     2.38e-05
     68    40     3.13e-07     3.13e-07     8.99e-06
     68    50     6.39e-06     6.39e-06     3.31e-05
     68    60     3.29e-06     3.29e-06     2.86e-05
     68    61     1.72e-05     1.72e-05     5.89e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              68 3537.971    0.005      6.6e-06      6.6e-06     3.35e-05
! Validation         68 3537.971    0.005     3.81e-06     3.81e-06     2.42e-05
Wall time: 3537.9708124999997
! Best model       68    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     69    10     9.63e-06     9.63e-06      3.9e-05
     69    20     8.65e-06     8.65e-06     4.08e-05
     69    30     3.48e-06     3.48e-06     2.46e-05
     69    40     1.25e-05     1.25e-05     5.11e-05
     69    48      1.5e-05      1.5e-05     6.34e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     69    10     3.34e-06     3.34e-06     2.57e-05
     69    20     2.56e-06     2.56e-06     2.47e-05
     69    30     2.46e-06     2.46e-06     2.22e-05
     69    40     5.49e-07     5.49e-07     1.16e-05
     69    50     5.33e-06     5.33e-06     3.12e-05
     69    60     2.62e-06     2.62e-06     2.51e-05
     69    61     1.52e-05     1.52e-05     5.51e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              69 3590.140    0.005     6.64e-06     6.64e-06     3.34e-05
! Validation         69 3590.140    0.005     3.56e-06     3.56e-06     2.35e-05
Wall time: 3590.140543833
! Best model       69    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     70    10     3.65e-05     3.65e-05     9.32e-05
     70    20     4.88e-06     4.88e-06     3.13e-05
     70    30     1.28e-05     1.28e-05     5.24e-05
     70    40     1.77e-05     1.77e-05     5.84e-05
     70    48     1.13e-05     1.13e-05     5.14e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     70    10     3.72e-06     3.72e-06     2.57e-05
     70    20     4.13e-06     4.13e-06     2.99e-05
     70    30      3.4e-06      3.4e-06     2.41e-05
     70    40     6.47e-07     6.47e-07     1.32e-05
     70    50     5.93e-06     5.93e-06     3.02e-05
     70    60     2.87e-06     2.87e-06     2.73e-05
     70    61     1.75e-05     1.75e-05      6.1e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              70 3642.116    0.005     1.79e-05     1.79e-05     5.58e-05
! Validation         70 3642.116    0.005     3.77e-06     3.77e-06     2.42e-05
Wall time: 3642.11644325
training
# Epoch batch         loss       loss_e      e/N_mae
     71    10     7.18e-06     7.18e-06     3.56e-05
     71    20     6.34e-06     6.34e-06     3.38e-05
     71    30     8.01e-06     8.01e-06     4.32e-05
     71    40     1.57e-05     1.57e-05     4.59e-05
     71    48     5.33e-06     5.33e-06     3.69e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     71    10     3.76e-06     3.76e-06     2.83e-05
     71    20     3.22e-06     3.22e-06      2.7e-05
     71    30     3.06e-06     3.06e-06     2.44e-05
     71    40     4.88e-07     4.88e-07     1.16e-05
     71    50     6.13e-06     6.13e-06     3.08e-05
     71    60      2.3e-06      2.3e-06     2.38e-05
     71    61     1.48e-05     1.48e-05     5.25e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              71 3695.432    0.005     7.77e-06     7.77e-06     3.58e-05
! Validation         71 3695.432    0.005     3.55e-06     3.55e-06     2.35e-05
Wall time: 3695.432761083
! Best model       71    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     72    10     7.26e-06     7.26e-06     4.04e-05
     72    20     9.25e-06     9.25e-06     3.78e-05
     72    30     4.52e-06     4.52e-06     2.74e-05
     72    40     3.28e-06     3.28e-06     2.51e-05
     72    48      1.8e-06      1.8e-06     2.17e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     72    10     3.61e-06     3.61e-06     2.63e-05
     72    20     2.95e-06     2.95e-06     2.54e-05
     72    30     3.08e-06     3.08e-06     2.35e-05
     72    40      6.4e-07      6.4e-07     1.28e-05
     72    50     5.54e-06     5.54e-06     2.99e-05
     72    60     2.68e-06     2.68e-06     2.57e-05
     72    61     1.56e-05     1.56e-05     5.51e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              72 3747.542    0.005     5.86e-06     5.86e-06     3.17e-05
! Validation         72 3747.542    0.005     3.49e-06     3.49e-06     2.32e-05
Wall time: 3747.5431612909997
! Best model       72    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     73    10     1.99e-06     1.99e-06      1.9e-05
     73    20     3.53e-06     3.53e-06     2.75e-05
     73    30      4.6e-06      4.6e-06     3.09e-05
     73    40     5.85e-06     5.85e-06     3.54e-05
     73    48     6.87e-08     6.87e-08     4.02e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
     73    10     3.56e-06     3.56e-06     2.79e-05
     73    20     2.77e-06     2.77e-06     2.51e-05
     73    30     2.93e-06     2.93e-06     2.38e-05
     73    40     6.51e-07     6.51e-07     1.25e-05
     73    50     5.08e-06     5.08e-06     2.96e-05
     73    60     2.44e-06     2.44e-06     2.44e-05
     73    61     1.46e-05     1.46e-05     5.35e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              73 3799.979    0.005     5.31e-06     5.31e-06     3.01e-05
! Validation         73 3799.979    0.005     3.35e-06     3.35e-06     2.28e-05
Wall time: 3799.979455541
! Best model       73    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     74    10     7.05e-06     7.05e-06      3.8e-05
     74    20     3.41e-06     3.41e-06     2.47e-05
     74    30     1.99e-06     1.99e-06     1.82e-05
     74    40     1.07e-05     1.07e-05     4.21e-05
     74    48     1.95e-06     1.95e-06     1.85e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     74    10     3.95e-06     3.95e-06     2.89e-05
     74    20     2.93e-06     2.93e-06     2.47e-05
     74    30     2.69e-06     2.69e-06     2.22e-05
     74    40     8.81e-07     8.81e-07     1.48e-05
     74    50     4.59e-06     4.59e-06     2.63e-05
     74    60     2.52e-06     2.52e-06     2.51e-05
     74    61     1.51e-05     1.51e-05     5.51e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              74 3852.143    0.005     6.65e-06     6.65e-06     3.36e-05
! Validation         74 3852.143    0.005     3.28e-06     3.28e-06     2.24e-05
Wall time: 3852.144599208
! Best model       74    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     75    10     1.26e-05     1.26e-05     4.74e-05
     75    20     3.71e-06     3.71e-06     2.43e-05
     75    30     4.44e-06     4.44e-06     2.66e-05
     75    40     1.71e-05     1.71e-05     5.76e-05
     75    48     1.53e-07     1.53e-07     6.42e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
     75    10     4.21e-06     4.21e-06     2.99e-05
     75    20     2.59e-06     2.59e-06     2.44e-05
     75    30     2.25e-06     2.25e-06     2.02e-05
     75    40     6.97e-07     6.97e-07     1.38e-05
     75    50     4.81e-06     4.81e-06     2.86e-05
     75    60     2.73e-06     2.73e-06     2.63e-05
     75    61      1.2e-05      1.2e-05     4.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              75 3905.297    0.005     1.04e-05     1.04e-05     4.24e-05
! Validation         75 3905.297    0.005     3.06e-06     3.06e-06     2.18e-05
Wall time: 3905.2981260829997
! Best model       75    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     76    10     8.82e-06     8.82e-06     4.18e-05
     76    20     3.36e-05     3.36e-05     8.61e-05
     76    30     7.47e-06     7.47e-06     3.52e-05
     76    40     1.02e-05     1.02e-05     4.86e-05
     76    48     1.13e-05     1.13e-05     5.54e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     76    10     3.33e-06     3.33e-06     2.51e-05
     76    20     3.23e-06     3.23e-06     2.76e-05
     76    30     2.82e-06     2.82e-06     2.22e-05
     76    40     8.86e-07     8.86e-07     1.51e-05
     76    50      5.2e-06      5.2e-06     2.99e-05
     76    60     2.47e-06     2.47e-06     2.44e-05
     76    61     1.38e-05     1.38e-05     5.41e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              76 3958.269    0.005      1.7e-05      1.7e-05     5.57e-05
! Validation         76 3958.269    0.005     3.13e-06     3.13e-06     2.18e-05
Wall time: 3958.2693624159997
training
# Epoch batch         loss       loss_e      e/N_mae
     77    10     7.03e-06     7.03e-06     3.84e-05
     77    20     4.61e-06     4.61e-06     2.57e-05
     77    30      7.9e-06      7.9e-06     3.99e-05
     77    40     3.36e-06     3.36e-06     2.37e-05
     77    48     3.83e-06     3.83e-06     2.89e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     77    10     2.38e-06     2.38e-06     2.09e-05
     77    20     3.39e-06     3.39e-06     2.89e-05
     77    30     2.65e-06     2.65e-06     2.18e-05
     77    40     9.53e-07     9.53e-07     1.61e-05
     77    50     5.49e-06     5.49e-06     3.21e-05
     77    60      2.2e-06      2.2e-06     2.22e-05
     77    61     1.13e-05     1.13e-05     5.14e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              77 4011.108    0.005     6.88e-06     6.88e-06     3.48e-05
! Validation         77 4011.108    0.005     3.02e-06     3.02e-06     2.19e-05
Wall time: 4011.109066041
! Best model       77    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     78    10     1.11e-05     1.11e-05     4.84e-05
     78    20     2.07e-05     2.07e-05     6.93e-05
     78    30     4.33e-06     4.33e-06     2.69e-05
     78    40     1.28e-05     1.28e-05     5.46e-05
     78    48     4.61e-06     4.61e-06     3.29e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     78    10     2.91e-06     2.91e-06     2.38e-05
     78    20     3.74e-06     3.74e-06     2.89e-05
     78    30     2.85e-06     2.85e-06     2.18e-05
     78    40     5.66e-07     5.66e-07     1.16e-05
     78    50     5.56e-06     5.56e-06     3.12e-05
     78    60     2.06e-06     2.06e-06     2.18e-05
     78    61     1.12e-05     1.12e-05     4.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              78 4064.262    0.005      1.2e-05      1.2e-05     4.61e-05
! Validation         78 4064.262    0.005     3.12e-06     3.12e-06      2.2e-05
Wall time: 4064.2626185
training
# Epoch batch         loss       loss_e      e/N_mae
     79    10     4.68e-05     4.68e-05     9.81e-05
     79    20     2.11e-05     2.11e-05     6.11e-05
     79    30        6e-06        6e-06     3.53e-05
     79    40     3.41e-05     3.41e-05     9.03e-05
     79    48      3.1e-06      3.1e-06     2.89e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     79    10      3.1e-06      3.1e-06     2.54e-05
     79    20     4.63e-06     4.63e-06     3.15e-05
     79    30     3.04e-06     3.04e-06     2.28e-05
     79    40     1.22e-06     1.22e-06     1.64e-05
     79    50     5.82e-06     5.82e-06     3.31e-05
     79    60     2.05e-06     2.05e-06     2.12e-05
     79    61      1.1e-05      1.1e-05     4.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              79 4117.138    0.005     1.88e-05     1.88e-05     5.98e-05
! Validation         79 4117.138    0.005     3.17e-06     3.17e-06     2.22e-05
Wall time: 4117.1388802500005
training
# Epoch batch         loss       loss_e      e/N_mae
     80    10     1.18e-05     1.18e-05     4.38e-05
     80    20     4.02e-06     4.02e-06     2.89e-05
     80    30     3.46e-06     3.46e-06     2.33e-05
     80    40     1.84e-06     1.84e-06      1.8e-05
     80    48      2.9e-06      2.9e-06     2.73e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     80    10     2.41e-06     2.41e-06     2.15e-05
     80    20      4.9e-06      4.9e-06     3.24e-05
     80    30      3.6e-06      3.6e-06     2.44e-05
     80    40     9.45e-07     9.45e-07     1.41e-05
     80    50     6.43e-06     6.43e-06     3.63e-05
     80    60      1.7e-06      1.7e-06     2.06e-05
     80    61     1.12e-05     1.12e-05     4.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              80 4170.853    0.005     5.54e-06     5.54e-06        3e-05
! Validation         80 4170.853    0.005     3.17e-06     3.17e-06     2.24e-05
Wall time: 4170.854193583001
training
# Epoch batch         loss       loss_e      e/N_mae
     81    10     5.79e-06     5.79e-06     3.18e-05
     81    20     1.63e-05     1.63e-05     4.19e-05
     81    30     1.01e-05     1.01e-05     3.99e-05
     81    40     5.28e-06     5.28e-06     3.31e-05
     81    48     1.19e-05     1.19e-05     4.66e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     81    10     2.51e-06     2.51e-06     2.38e-05
     81    20     4.74e-06     4.74e-06     3.18e-05
     81    30     3.56e-06     3.56e-06     2.47e-05
     81    40     1.22e-06     1.22e-06     1.67e-05
     81    50     6.24e-06     6.24e-06     3.41e-05
     81    60        2e-06        2e-06     2.12e-05
     81    61      1.1e-05      1.1e-05     4.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              81 4224.350    0.005     7.58e-06     7.58e-06     3.52e-05
! Validation         81 4224.350    0.005     3.09e-06     3.09e-06     2.21e-05
Wall time: 4224.350960666
training
# Epoch batch         loss       loss_e      e/N_mae
     82    10     4.39e-06     4.39e-06     2.79e-05
     82    20     4.84e-06     4.84e-06     3.03e-05
     82    30     4.94e-06     4.94e-06     2.94e-05
     82    40     3.51e-06     3.51e-06     2.68e-05
     82    48     1.76e-06     1.76e-06     1.77e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     82    10     3.38e-06     3.38e-06      2.7e-05
     82    20      3.7e-06      3.7e-06     2.76e-05
     82    30      3.1e-06      3.1e-06     2.41e-05
     82    40     1.32e-06     1.32e-06      1.8e-05
     82    50     5.55e-06     5.55e-06     3.37e-05
     82    60     2.18e-06     2.18e-06     2.22e-05
     82    61        1e-05        1e-05     4.44e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              82 4277.353    0.005     5.31e-06     5.31e-06     2.94e-05
! Validation         82 4277.353    0.005     2.92e-06     2.92e-06     2.17e-05
Wall time: 4277.353948875
! Best model       82    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     83    10     4.67e-06     4.67e-06     3.11e-05
     83    20     5.79e-06     5.79e-06     3.34e-05
     83    30     1.31e-06     1.31e-06     1.37e-05
     83    40     1.67e-06     1.67e-06     1.67e-05
     83    48     1.37e-06     1.37e-06     1.85e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     83    10     2.75e-06     2.75e-06     2.44e-05
     83    20     3.25e-06     3.25e-06     2.54e-05
     83    30     2.91e-06     2.91e-06     2.35e-05
     83    40     1.19e-06     1.19e-06     1.73e-05
     83    50     4.81e-06     4.81e-06     3.05e-05
     83    60     1.61e-06     1.61e-06      1.8e-05
     83    61      7.6e-06      7.6e-06     3.91e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              83 4330.665    0.005     4.46e-06     4.46e-06     2.77e-05
! Validation         83 4330.665    0.005     2.67e-06     2.67e-06     2.09e-05
Wall time: 4330.665752041
! Best model       83    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     84    10     3.33e-06     3.33e-06     2.35e-05
     84    20     2.92e-06     2.92e-06     2.61e-05
     84    30     2.31e-05     2.31e-05     7.44e-05
     84    40     4.77e-06     4.77e-06     2.69e-05
     84    48      7.3e-06      7.3e-06     4.18e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     84    10     2.42e-06     2.42e-06     2.25e-05
     84    20     3.29e-06     3.29e-06     2.54e-05
     84    30     3.13e-06     3.13e-06     2.47e-05
     84    40     1.32e-06     1.32e-06     1.86e-05
     84    50     4.67e-06     4.67e-06     2.89e-05
     84    60      1.6e-06      1.6e-06      1.9e-05
     84    61     7.13e-06     7.13e-06     3.85e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              84 4383.866    0.005     7.11e-06     7.11e-06     3.54e-05
! Validation         84 4383.866    0.005     2.66e-06     2.66e-06     2.08e-05
Wall time: 4383.866210125
! Best model       84    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     85    10     1.83e-05     1.83e-05     6.47e-05
     85    20     1.81e-05     1.81e-05     6.47e-05
     85    30     7.93e-06     7.93e-06     4.07e-05
     85    40     1.85e-06     1.85e-06     1.87e-05
     85    48     3.09e-06     3.09e-06     2.81e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     85    10     2.65e-06     2.65e-06     2.25e-05
     85    20      2.5e-06      2.5e-06     2.31e-05
     85    30     2.69e-06     2.69e-06     2.18e-05
     85    40     9.26e-07     9.26e-07     1.51e-05
     85    50     3.92e-06     3.92e-06     2.63e-05
     85    60     1.41e-06     1.41e-06     1.57e-05
     85    61     7.42e-06     7.42e-06     3.91e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              85 4437.376    0.005     8.68e-06     8.68e-06     3.97e-05
! Validation         85 4437.376    0.005     2.48e-06     2.48e-06     1.98e-05
Wall time: 4437.376684458
! Best model       85    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     86    10     1.42e-06     1.42e-06     1.49e-05
     86    20     7.36e-06     7.36e-06     3.83e-05
     86    30      2.4e-06      2.4e-06     2.23e-05
     86    40     5.91e-06     5.91e-06     3.21e-05
     86    48     1.02e-06     1.02e-06     1.53e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     86    10     1.96e-06     1.96e-06      1.8e-05
     86    20     2.69e-06     2.69e-06     2.35e-05
     86    30     3.03e-06     3.03e-06     2.38e-05
     86    40     1.08e-06     1.08e-06     1.61e-05
     86    50     3.68e-06     3.68e-06     2.57e-05
     86    60      1.3e-06      1.3e-06     1.48e-05
     86    61     7.12e-06     7.12e-06     3.75e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              86 4493.747    0.005      5.2e-06      5.2e-06        3e-05
! Validation         86 4493.747    0.005     2.42e-06     2.42e-06     1.96e-05
Wall time: 4493.747719833001
! Best model       86    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     87    10     6.44e-05     6.44e-05     0.000114
     87    20     1.65e-05     1.65e-05     5.43e-05
     87    30     1.52e-05     1.52e-05     5.55e-05
     87    40     1.02e-05     1.02e-05     4.21e-05
     87    48     2.87e-06     2.87e-06     2.73e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     87    10     2.74e-06     2.74e-06     2.25e-05
     87    20      2.9e-06      2.9e-06     2.44e-05
     87    30     2.78e-06     2.78e-06     2.12e-05
     87    40     1.07e-06     1.07e-06     1.57e-05
     87    50     3.37e-06     3.37e-06     2.35e-05
     87    60      1.5e-06      1.5e-06     1.57e-05
     87    61     6.98e-06     6.98e-06     3.48e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              87 4547.564    0.005     1.31e-05     1.31e-05     4.73e-05
! Validation         87 4547.564    0.005     2.43e-06     2.43e-06     1.95e-05
Wall time: 4547.564624250001
training
# Epoch batch         loss       loss_e      e/N_mae
     88    10     8.42e-06     8.42e-06     3.69e-05
     88    20        5e-06        5e-06     3.02e-05
     88    30     1.08e-05     1.08e-05     4.77e-05
     88    40     9.47e-06     9.47e-06     4.19e-05
     88    48     4.23e-07     4.23e-07     1.04e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     88    10     2.38e-06     2.38e-06     2.22e-05
     88    20     3.13e-06     3.13e-06      2.6e-05
     88    30     2.62e-06     2.62e-06     2.25e-05
     88    40     8.14e-07     8.14e-07     1.41e-05
     88    50     3.08e-06     3.08e-06     2.25e-05
     88    60     1.39e-06     1.39e-06     1.61e-05
     88    61     7.18e-06     7.18e-06     3.75e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              88 4599.923    0.005     7.13e-06     7.13e-06      3.6e-05
! Validation         88 4599.923    0.005     2.35e-06     2.35e-06     1.92e-05
Wall time: 4599.923695
! Best model       88    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     89    10     2.79e-06     2.79e-06      2.3e-05
     89    20     7.25e-06     7.25e-06     3.43e-05
     89    30     2.79e-06     2.79e-06     2.33e-05
     89    40     4.05e-06     4.05e-06     2.88e-05
     89    48     5.09e-06     5.09e-06     3.21e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     89    10     2.65e-06     2.65e-06     2.35e-05
     89    20     2.94e-06     2.94e-06     2.38e-05
     89    30     2.63e-06     2.63e-06     2.41e-05
     89    40     7.31e-07     7.31e-07     1.25e-05
     89    50     3.55e-06     3.55e-06     2.38e-05
     89    60     1.53e-06     1.53e-06     1.86e-05
     89    61     7.07e-06     7.07e-06     3.59e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              89 4653.666    0.005     4.61e-06     4.61e-06     2.78e-05
! Validation         89 4653.666    0.005     2.42e-06     2.42e-06     1.94e-05
Wall time: 4653.666484583
training
# Epoch batch         loss       loss_e      e/N_mae
     90    10      3.6e-06      3.6e-06     2.44e-05
     90    20     3.17e-06     3.17e-06     2.49e-05
     90    30     6.78e-06     6.78e-06      3.2e-05
     90    40     3.99e-06     3.99e-06      2.9e-05
     90    48      2.8e-07      2.8e-07     7.23e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
     90    10     2.73e-06     2.73e-06     2.31e-05
     90    20     2.77e-06     2.77e-06     2.31e-05
     90    30     2.39e-06     2.39e-06     2.28e-05
     90    40      5.9e-07      5.9e-07     1.22e-05
     90    50     3.38e-06     3.38e-06     2.38e-05
     90    60     1.52e-06     1.52e-06      1.8e-05
     90    61     5.97e-06     5.97e-06     3.37e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              90 4707.793    0.005     5.18e-06     5.18e-06        3e-05
! Validation         90 4707.793    0.005     2.27e-06     2.27e-06      1.9e-05
Wall time: 4707.794257958
! Best model       90    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     91    10     1.47e-06     1.47e-06     1.68e-05
     91    20     4.66e-06     4.66e-06     2.55e-05
     91    30     1.98e-06     1.98e-06     1.88e-05
     91    40     9.18e-06     9.18e-06     4.23e-05
     91    48      8.5e-06      8.5e-06     3.61e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     91    10     2.26e-06     2.26e-06     2.25e-05
     91    20     2.53e-06     2.53e-06     2.18e-05
     91    30     2.53e-06     2.53e-06     2.22e-05
     91    40     7.27e-07     7.27e-07     1.25e-05
     91    50     3.73e-06     3.73e-06      2.6e-05
     91    60     1.41e-06     1.41e-06     1.61e-05
     91    61     5.46e-06     5.46e-06     3.16e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              91 4760.120    0.005     4.72e-06     4.72e-06     2.81e-05
! Validation         91 4760.120    0.005     2.23e-06     2.23e-06     1.88e-05
Wall time: 4760.120937833
! Best model       91    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     92    10     1.39e-05     1.39e-05      5.3e-05
     92    20     3.01e-05     3.01e-05     7.38e-05
     92    30     6.53e-06     6.53e-06     3.72e-05
     92    40     2.92e-06     2.92e-06     2.44e-05
     92    48     3.75e-06     3.75e-06     3.13e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     92    10     2.68e-06     2.68e-06     2.47e-05
     92    20     2.41e-06     2.41e-06     2.12e-05
     92    30     2.24e-06     2.24e-06     2.22e-05
     92    40     6.19e-07     6.19e-07     1.28e-05
     92    50     4.08e-06     4.08e-06     2.89e-05
     92    60     2.04e-06     2.04e-06     2.06e-05
     92    61     6.38e-06     6.38e-06     3.53e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              92 4812.495    0.005     7.14e-06     7.14e-06     3.43e-05
! Validation         92 4812.495    0.005     2.25e-06     2.25e-06     1.89e-05
Wall time: 4812.496137125
training
# Epoch batch         loss       loss_e      e/N_mae
     93    10     4.81e-06     4.81e-06      2.7e-05
     93    20     3.46e-06     3.46e-06     2.62e-05
     93    30     3.55e-06     3.55e-06     2.28e-05
     93    40      6.3e-06      6.3e-06     3.58e-05
     93    48     6.61e-06     6.61e-06     4.26e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     93    10     2.42e-06     2.42e-06     2.25e-05
     93    20     2.52e-06     2.52e-06     2.18e-05
     93    30     2.31e-06     2.31e-06     2.22e-05
     93    40      5.6e-07      5.6e-07     1.22e-05
     93    50     3.69e-06     3.69e-06     2.73e-05
     93    60     1.37e-06     1.37e-06     1.77e-05
     93    61     5.02e-06     5.02e-06     3.11e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              93 4863.862    0.005     4.82e-06     4.82e-06     2.86e-05
! Validation         93 4863.862    0.005     2.18e-06     2.18e-06     1.89e-05
Wall time: 4863.862654083
! Best model       93    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     94    10     6.07e-06     6.07e-06     3.21e-05
     94    20     3.82e-06     3.82e-06     2.72e-05
     94    30     9.11e-06     9.11e-06     3.73e-05
     94    40     1.16e-05     1.16e-05     4.26e-05
     94    48     2.59e-07     2.59e-07     6.42e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
     94    10     2.68e-06     2.68e-06     2.47e-05
     94    20     2.86e-06     2.86e-06     2.41e-05
     94    30     2.61e-06     2.61e-06     2.35e-05
     94    40     9.07e-07     9.07e-07     1.38e-05
     94    50     3.93e-06     3.93e-06     2.54e-05
     94    60     1.75e-06     1.75e-06     2.02e-05
     94    61     4.41e-06     4.41e-06     2.89e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              94 4918.013    0.005     8.94e-06     8.94e-06     3.92e-05
! Validation         94 4918.013    0.005     2.23e-06     2.23e-06     1.91e-05
Wall time: 4918.014388583
training
# Epoch batch         loss       loss_e      e/N_mae
     95    10     9.26e-06     9.26e-06     3.84e-05
     95    20     5.23e-06     5.23e-06     3.04e-05
     95    30     1.21e-05     1.21e-05     5.27e-05
     95    40     1.06e-05     1.06e-05     4.55e-05
     95    48      5.1e-06      5.1e-06     2.81e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     95    10     3.25e-06     3.25e-06     2.54e-05
     95    20     3.54e-06     3.54e-06     2.67e-05
     95    30     3.39e-06     3.39e-06      2.7e-05
     95    40     5.11e-07     5.11e-07     1.19e-05
     95    50     3.74e-06     3.74e-06     2.54e-05
     95    60     1.78e-06     1.78e-06     2.06e-05
     95    61      6.8e-06      6.8e-06     3.75e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              95 4971.114    0.005     1.69e-05     1.69e-05     5.32e-05
! Validation         95 4971.114    0.005     2.42e-06     2.42e-06     1.98e-05
Wall time: 4971.1149214160005
training
# Epoch batch         loss       loss_e      e/N_mae
     96    10     7.42e-06     7.42e-06     3.51e-05
     96    20     8.26e-06     8.26e-06     3.94e-05
     96    30     9.02e-06     9.02e-06     3.87e-05
     96    40     1.36e-05     1.36e-05     5.46e-05
     96    48     7.32e-06     7.32e-06     4.42e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     96    10     3.23e-06     3.23e-06      2.6e-05
     96    20     3.91e-06     3.91e-06     2.73e-05
     96    30     3.18e-06     3.18e-06     2.63e-05
     96    40     9.28e-07     9.28e-07     1.48e-05
     96    50     4.24e-06     4.24e-06      2.7e-05
     96    60     1.55e-06     1.55e-06     1.96e-05
     96    61     5.09e-06     5.09e-06     3.32e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              96 5023.661    0.005     8.37e-06     8.37e-06     3.73e-05
! Validation         96 5023.661    0.005     2.36e-06     2.36e-06     1.97e-05
Wall time: 5023.661835000001
training
# Epoch batch         loss       loss_e      e/N_mae
     97    10     4.62e-06     4.62e-06     2.91e-05
     97    20     4.01e-06     4.01e-06     2.85e-05
     97    30     2.52e-06     2.52e-06     2.11e-05
     97    40     5.03e-06     5.03e-06     2.47e-05
     97    48     1.36e-06     1.36e-06     1.45e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     97    10     2.79e-06     2.79e-06     2.47e-05
     97    20     3.23e-06     3.23e-06     2.51e-05
     97    30     2.33e-06     2.33e-06     2.18e-05
     97    40     1.02e-06     1.02e-06     1.48e-05
     97    50     3.33e-06     3.33e-06     2.51e-05
     97    60     1.59e-06     1.59e-06      1.9e-05
     97    61     4.51e-06     4.51e-06     3.11e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              97 5075.670    0.005     3.63e-06     3.63e-06     2.46e-05
! Validation         97 5075.670    0.005     2.18e-06     2.18e-06      1.9e-05
Wall time: 5075.670753125
training
# Epoch batch         loss       loss_e      e/N_mae
     98    10      2.7e-06      2.7e-06     2.26e-05
     98    20     2.55e-06     2.55e-06     2.27e-05
     98    30     4.15e-06     4.15e-06     2.75e-05
     98    40     2.69e-06     2.69e-06     2.08e-05
     98    48     5.84e-06     5.84e-06     3.13e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     98    10     2.38e-06     2.38e-06     2.22e-05
     98    20     2.43e-06     2.43e-06     2.28e-05
     98    30        2e-06        2e-06     2.02e-05
     98    40     7.57e-07     7.57e-07     1.16e-05
     98    50     3.13e-06     3.13e-06     2.51e-05
     98    60     1.52e-06     1.52e-06     1.83e-05
     98    61     3.71e-06     3.71e-06     2.89e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              98 5127.639    0.005     3.19e-06     3.19e-06     2.28e-05
! Validation         98 5127.639    0.005     2.06e-06     2.06e-06     1.84e-05
Wall time: 5127.640672708
! Best model       98    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
     99    10     5.54e-06     5.54e-06     3.42e-05
     99    20     3.66e-06     3.66e-06     2.54e-05
     99    30     1.44e-06     1.44e-06     1.63e-05
     99    40     7.71e-06     7.71e-06     3.46e-05
     99    48     8.66e-07     8.66e-07     1.45e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
     99    10     2.18e-06     2.18e-06     2.28e-05
     99    20     1.84e-06     1.84e-06     1.96e-05
     99    30     1.54e-06     1.54e-06      1.8e-05
     99    40     8.09e-07     8.09e-07     1.35e-05
     99    50     3.38e-06     3.38e-06      2.7e-05
     99    60     1.37e-06     1.37e-06     1.67e-05
     99    61     3.08e-06     3.08e-06     2.62e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train              99 5179.708    0.005     3.94e-06     3.94e-06     2.56e-05
! Validation         99 5179.708    0.005     1.96e-06     1.96e-06     1.79e-05
Wall time: 5179.707934625
! Best model       99    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    100    10     3.82e-06     3.82e-06     2.71e-05
    100    20     2.47e-06     2.47e-06     2.27e-05
    100    30     2.73e-06     2.73e-06     2.45e-05
    100    40     6.08e-06     6.08e-06     3.66e-05
    100    48     2.25e-06     2.25e-06     2.41e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    100    10     2.22e-06     2.22e-06     2.15e-05
    100    20     1.81e-06     1.81e-06     2.02e-05
    100    30     1.48e-06     1.48e-06      1.7e-05
    100    40     8.39e-07     8.39e-07     1.16e-05
    100    50     2.69e-06     2.69e-06     2.47e-05
    100    60     1.27e-06     1.27e-06     1.67e-05
    100    61     2.64e-06     2.64e-06     2.25e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             100 5232.281    0.005     5.62e-06     5.62e-06     3.14e-05
! Validation        100 5232.281    0.005     1.84e-06     1.84e-06     1.72e-05
Wall time: 5232.281637166
! Best model      100    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    101    10      3.7e-06      3.7e-06     1.95e-05
    101    20     1.74e-06     1.74e-06     1.71e-05
    101    30     9.45e-06     9.45e-06     4.47e-05
    101    40     3.05e-06     3.05e-06     2.37e-05
    101    48     2.34e-06     2.34e-06     2.33e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    101    10     2.06e-06     2.06e-06     2.06e-05
    101    20      1.4e-06      1.4e-06     1.61e-05
    101    30     1.49e-06     1.49e-06      1.8e-05
    101    40     7.02e-07     7.02e-07     1.03e-05
    101    50     2.94e-06     2.94e-06      2.6e-05
    101    60     1.14e-06     1.14e-06     1.45e-05
    101    61     2.75e-06     2.75e-06     2.25e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             101 5284.242    0.005     4.98e-06     4.98e-06     2.92e-05
! Validation        101 5284.242    0.005     1.73e-06     1.73e-06     1.65e-05
Wall time: 5284.243113875001
! Best model      101    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    102    10     1.81e-06     1.81e-06     1.83e-05
    102    20     1.39e-05     1.39e-05     5.53e-05
    102    30     5.38e-06     5.38e-06      3.2e-05
    102    40     2.92e-06     2.92e-06     2.17e-05
    102    48     1.91e-06     1.91e-06     1.69e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    102    10     2.24e-06     2.24e-06     2.15e-05
    102    20     1.82e-06     1.82e-06      1.8e-05
    102    30      1.8e-06      1.8e-06     1.93e-05
    102    40     9.38e-07     9.38e-07     1.35e-05
    102    50     2.66e-06     2.66e-06     2.51e-05
    102    60     1.37e-06     1.37e-06     1.73e-05
    102    61      2.4e-06      2.4e-06     2.14e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             102 5335.896    0.005     4.37e-06     4.37e-06     2.73e-05
! Validation        102 5335.896    0.005     1.78e-06     1.78e-06      1.7e-05
Wall time: 5335.896742875
training
# Epoch batch         loss       loss_e      e/N_mae
    103    10     2.33e-06     2.33e-06     2.18e-05
    103    20     2.86e-06     2.86e-06     2.21e-05
    103    30     3.34e-06     3.34e-06     2.25e-05
    103    40     3.91e-06     3.91e-06     2.71e-05
    103    48     1.32e-07     1.32e-07     5.62e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    103    10     1.85e-06     1.85e-06     1.96e-05
    103    20     2.14e-06     2.14e-06     2.06e-05
    103    30      1.3e-06      1.3e-06     1.54e-05
    103    40     6.32e-07     6.32e-07     1.06e-05
    103    50     2.47e-06     2.47e-06     2.31e-05
    103    60      1.2e-06      1.2e-06     1.61e-05
    103    61      2.9e-06      2.9e-06     2.36e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             103 5387.469    0.005     3.54e-06     3.54e-06     2.49e-05
! Validation        103 5387.469    0.005     1.65e-06     1.65e-06     1.62e-05
Wall time: 5387.470336583
! Best model      103    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    104    10     2.39e-06     2.39e-06     1.78e-05
    104    20     2.68e-06     2.68e-06     2.12e-05
    104    30     4.04e-06     4.04e-06     2.87e-05
    104    40     2.32e-06     2.32e-06     1.86e-05
    104    48     4.23e-06     4.23e-06     2.81e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    104    10     1.72e-06     1.72e-06     1.77e-05
    104    20        2e-06        2e-06     2.06e-05
    104    30     1.18e-06     1.18e-06     1.51e-05
    104    40     4.37e-07     4.37e-07     9.96e-06
    104    50     1.76e-06     1.76e-06     1.96e-05
    104    60     1.11e-06     1.11e-06     1.51e-05
    104    61     2.32e-06     2.32e-06      2.2e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             104 5439.199    0.005     2.72e-06     2.72e-06     2.09e-05
! Validation        104 5439.199    0.005     1.56e-06     1.56e-06      1.6e-05
Wall time: 5439.200172666
! Best model      104    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    105    10     5.34e-06     5.34e-06     2.77e-05
    105    20     1.82e-05     1.82e-05     5.96e-05
    105    30     5.36e-06     5.36e-06     3.32e-05
    105    40     2.66e-06     2.66e-06      2.2e-05
    105    48     6.05e-06     6.05e-06     4.02e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    105    10     2.14e-06     2.14e-06     2.02e-05
    105    20     2.13e-06     2.13e-06     1.99e-05
    105    30     1.08e-06     1.08e-06     1.41e-05
    105    40     6.49e-07     6.49e-07     1.09e-05
    105    50     1.96e-06     1.96e-06     2.25e-05
    105    60     1.07e-06     1.07e-06     1.38e-05
    105    61     2.84e-06     2.84e-06     2.46e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             105 5490.983    0.005      8.8e-06      8.8e-06     3.86e-05
! Validation        105 5490.983    0.005     1.55e-06     1.55e-06     1.59e-05
Wall time: 5490.984366083
! Best model      105    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    106    10     6.84e-06     6.84e-06     3.48e-05
    106    20     7.36e-06     7.36e-06     3.99e-05
    106    30     3.47e-06     3.47e-06     2.37e-05
    106    40     2.52e-06     2.52e-06     2.01e-05
    106    48     5.08e-06     5.08e-06     2.73e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    106    10     1.92e-06     1.92e-06     2.06e-05
    106    20     1.62e-06     1.62e-06     1.77e-05
    106    30     1.39e-06     1.39e-06     1.51e-05
    106    40     1.09e-06     1.09e-06     1.48e-05
    106    50     2.22e-06     2.22e-06     2.31e-05
    106    60     1.08e-06     1.08e-06     1.57e-05
    106    61     2.74e-06     2.74e-06     2.46e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             106 5542.811    0.005     3.82e-06     3.82e-06     2.45e-05
! Validation        106 5542.811    0.005     1.58e-06     1.58e-06     1.61e-05
Wall time: 5542.812540125
training
# Epoch batch         loss       loss_e      e/N_mae
    107    10     1.51e-05     1.51e-05     5.72e-05
    107    20     4.63e-06     4.63e-06     3.05e-05
    107    30     5.65e-06     5.65e-06     2.84e-05
    107    40     2.75e-06     2.75e-06     2.22e-05
    107    48     9.49e-06     9.49e-06     4.58e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    107    10     2.55e-06     2.55e-06     2.25e-05
    107    20     1.97e-06     1.97e-06      1.9e-05
    107    30     1.31e-06     1.31e-06     1.48e-05
    107    40     8.58e-07     8.58e-07     1.19e-05
    107    50      2.6e-06      2.6e-06     2.41e-05
    107    60     9.36e-07     9.36e-07     1.48e-05
    107    61     1.99e-06     1.99e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             107 5595.712    0.005     1.16e-05     1.16e-05     4.49e-05
! Validation        107 5595.712    0.005     1.59e-06     1.59e-06     1.63e-05
Wall time: 5595.713088583
training
# Epoch batch         loss       loss_e      e/N_mae
    108    10     2.83e-06     2.83e-06     1.98e-05
    108    20     8.47e-06     8.47e-06     4.11e-05
    108    30     3.29e-06     3.29e-06     2.62e-05
    108    40     1.28e-05     1.28e-05     5.15e-05
    108    48     6.47e-06     6.47e-06      4.1e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    108    10     2.47e-06     2.47e-06     2.18e-05
    108    20     1.71e-06     1.71e-06     1.83e-05
    108    30     1.14e-06     1.14e-06     1.41e-05
    108    40     6.85e-07     6.85e-07     1.25e-05
    108    50     1.88e-06     1.88e-06     2.12e-05
    108    60     1.02e-06     1.02e-06     1.61e-05
    108    61     2.33e-06     2.33e-06     2.09e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             108 5647.501    0.005     6.41e-06     6.41e-06     3.38e-05
! Validation        108 5647.501    0.005      1.6e-06      1.6e-06     1.65e-05
Wall time: 5647.501363
training
# Epoch batch         loss       loss_e      e/N_mae
    109    10     9.67e-06     9.67e-06     4.32e-05
    109    20      1.8e-06      1.8e-06     1.94e-05
    109    30     4.07e-06     4.07e-06     2.87e-05
    109    40     2.81e-06     2.81e-06     2.24e-05
    109    48     3.75e-06     3.75e-06     3.13e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    109    10        2e-06        2e-06     1.96e-05
    109    20     1.39e-06     1.39e-06      1.8e-05
    109    30     7.95e-07     7.95e-07     1.22e-05
    109    40     4.18e-07     4.18e-07     9.32e-06
    109    50     1.88e-06     1.88e-06     2.02e-05
    109    60     1.32e-06     1.32e-06     1.83e-05
    109    61     2.23e-06     2.23e-06     2.25e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             109 5701.048    0.005     4.74e-06     4.74e-06     2.79e-05
! Validation        109 5701.048    0.005     1.51e-06     1.51e-06      1.6e-05
Wall time: 5701.049340958
! Best model      109    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    110    10     4.93e-06     4.93e-06     2.93e-05
    110    20     3.78e-06     3.78e-06     2.49e-05
    110    30     2.74e-06     2.74e-06     2.33e-05
    110    40     2.13e-06     2.13e-06     1.95e-05
    110    48     1.91e-06     1.91e-06     1.61e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    110    10     1.83e-06     1.83e-06     2.02e-05
    110    20     1.63e-06     1.63e-06     1.93e-05
    110    30     7.99e-07     7.99e-07     1.28e-05
    110    40     4.54e-07     4.54e-07     9.96e-06
    110    50     2.59e-06     2.59e-06     2.47e-05
    110    60     1.33e-06     1.33e-06     1.86e-05
    110    61     2.51e-06     2.51e-06     2.36e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             110 5753.190    0.005     3.95e-06     3.95e-06     2.52e-05
! Validation        110 5753.190    0.005     1.51e-06     1.51e-06      1.6e-05
Wall time: 5753.191025416
training
# Epoch batch         loss       loss_e      e/N_mae
    111    10     1.19e-06     1.19e-06     1.43e-05
    111    20     3.47e-06     3.47e-06     2.32e-05
    111    30     7.51e-06     7.51e-06      3.8e-05
    111    40     1.96e-06     1.96e-06     1.82e-05
    111    48      2.8e-06      2.8e-06     2.01e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    111    10     1.93e-06     1.93e-06     2.02e-05
    111    20     1.42e-06     1.42e-06     1.73e-05
    111    30      1.1e-06      1.1e-06     1.51e-05
    111    40     4.61e-07     4.61e-07     8.99e-06
    111    50     2.15e-06     2.15e-06     2.25e-05
    111    60     1.19e-06     1.19e-06     1.77e-05
    111    61     2.91e-06     2.91e-06     2.52e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             111 5804.594    0.005     3.21e-06     3.21e-06     2.35e-05
! Validation        111 5804.594    0.005     1.46e-06     1.46e-06     1.56e-05
Wall time: 5804.594964125
! Best model      111    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    112    10     9.95e-06     9.95e-06     4.42e-05
    112    20     5.56e-06     5.56e-06     3.12e-05
    112    30     7.78e-06     7.78e-06     3.69e-05
    112    40     1.72e-06     1.72e-06     1.66e-05
    112    48      8.9e-06      8.9e-06     3.77e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    112    10     1.37e-06     1.37e-06     1.73e-05
    112    20      1.3e-06      1.3e-06     1.67e-05
    112    30      7.9e-07      7.9e-07     1.25e-05
    112    40     6.19e-07     6.19e-07     1.12e-05
    112    50     2.09e-06     2.09e-06     2.31e-05
    112    60     1.07e-06     1.07e-06     1.61e-05
    112    61     2.35e-06     2.35e-06     2.36e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             112 5857.602    0.005     5.17e-06     5.17e-06     2.97e-05
! Validation        112 5857.602    0.005     1.43e-06     1.43e-06     1.54e-05
Wall time: 5857.602519291
! Best model      112    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    113    10     2.37e-06     2.37e-06     2.15e-05
    113    20     7.74e-06     7.74e-06     3.94e-05
    113    30     4.87e-06     4.87e-06     2.98e-05
    113    40     5.21e-06     5.21e-06     2.78e-05
    113    48     4.38e-06     4.38e-06     3.13e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    113    10     1.53e-06     1.53e-06     1.83e-05
    113    20     1.36e-06     1.36e-06     1.73e-05
    113    30     8.69e-07     8.69e-07     1.22e-05
    113    40     6.68e-07     6.68e-07     1.03e-05
    113    50     2.63e-06     2.63e-06     2.54e-05
    113    60     1.15e-06     1.15e-06      1.7e-05
    113    61     1.93e-06     1.93e-06     2.09e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             113 5909.519    0.005     6.71e-06     6.71e-06     3.36e-05
! Validation        113 5909.519    0.005      1.4e-06      1.4e-06     1.52e-05
Wall time: 5909.5188074160005
! Best model      113    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    114    10     3.23e-06     3.23e-06     2.53e-05
    114    20     5.36e-06     5.36e-06     3.27e-05
    114    30     5.02e-06     5.02e-06     3.21e-05
    114    40     7.65e-06     7.65e-06     3.67e-05
    114    48     3.14e-05     3.14e-05     6.91e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    114    10      1.5e-06      1.5e-06     1.93e-05
    114    20     1.54e-06     1.54e-06     1.83e-05
    114    30     1.04e-06     1.04e-06     1.38e-05
    114    40     6.09e-07     6.09e-07     9.64e-06
    114    50      2.1e-06      2.1e-06     2.22e-05
    114    60     9.53e-07     9.53e-07     1.54e-05
    114    61     2.29e-06     2.29e-06     2.25e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             114 5962.815    0.005     6.29e-06     6.29e-06     3.14e-05
! Validation        114 5962.815    0.005     1.43e-06     1.43e-06     1.54e-05
Wall time: 5962.815907541
training
# Epoch batch         loss       loss_e      e/N_mae
    115    10     9.05e-06     9.05e-06     4.28e-05
    115    20     2.12e-06     2.12e-06     2.07e-05
    115    30     6.36e-06     6.36e-06     3.67e-05
    115    40     2.64e-06     2.64e-06     2.01e-05
    115    48      1.8e-06      1.8e-06     2.09e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    115    10     1.44e-06     1.44e-06     1.83e-05
    115    20     1.49e-06     1.49e-06      1.8e-05
    115    30     6.15e-07     6.15e-07     1.09e-05
    115    40     5.35e-07     5.35e-07     8.67e-06
    115    50     1.92e-06     1.92e-06     2.22e-05
    115    60     8.26e-07     8.26e-07     1.41e-05
    115    61     5.67e-07     5.67e-07     1.18e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             115 6015.563    0.005     4.02e-06     4.02e-06      2.6e-05
! Validation        115 6015.563    0.005      1.4e-06      1.4e-06     1.51e-05
Wall time: 6015.564250208
training
# Epoch batch         loss       loss_e      e/N_mae
    116    10     6.21e-06     6.21e-06     3.09e-05
    116    20     9.88e-07     9.88e-07     1.25e-05
    116    30     5.17e-06     5.17e-06     3.07e-05
    116    40     9.39e-06     9.39e-06     4.29e-05
    116    48     5.72e-06     5.72e-06     3.61e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    116    10      1.9e-06      1.9e-06     2.09e-05
    116    20     1.72e-06     1.72e-06      1.9e-05
    116    30     8.58e-07     8.58e-07     1.32e-05
    116    40     5.01e-07     5.01e-07     9.32e-06
    116    50      2.2e-06      2.2e-06     2.31e-05
    116    60     1.04e-06     1.04e-06     1.57e-05
    116    61     8.35e-07     8.35e-07     1.39e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             116 6067.257    0.005     4.09e-06     4.09e-06     2.55e-05
! Validation        116 6067.257    0.005     1.37e-06     1.37e-06     1.52e-05
Wall time: 6067.257448416
! Best model      116    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    117    10     6.58e-06     6.58e-06     3.18e-05
    117    20     3.67e-06     3.67e-06     2.36e-05
    117    30     2.13e-05     2.13e-05     6.89e-05
    117    40     1.75e-05     1.75e-05     6.03e-05
    117    48     7.31e-05     7.31e-05     0.000136
validation
# Epoch batch         loss       loss_e      e/N_mae
    117    10     1.78e-06     1.78e-06     2.09e-05
    117    20     1.73e-06     1.73e-06     2.15e-05
    117    30     9.53e-07     9.53e-07     1.41e-05
    117    40     3.83e-07     3.83e-07     8.67e-06
    117    50     1.99e-06     1.99e-06     2.06e-05
    117    60     1.02e-06     1.02e-06     1.45e-05
    117    61     1.11e-06     1.11e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             117 6119.198    0.005     9.31e-06     9.31e-06     3.73e-05
! Validation        117 6119.198    0.005      1.4e-06      1.4e-06     1.54e-05
Wall time: 6119.198189041001
training
# Epoch batch         loss       loss_e      e/N_mae
    118    10     3.38e-06     3.38e-06     2.59e-05
    118    20     4.35e-05     4.35e-05     8.97e-05
    118    30      1.4e-05      1.4e-05     5.16e-05
    118    40     6.82e-06     6.82e-06     3.54e-05
    118    48     7.71e-07     7.71e-07     1.37e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    118    10     2.13e-06     2.13e-06     2.15e-05
    118    20     2.14e-06     2.14e-06     2.18e-05
    118    30     1.51e-06     1.51e-06     1.67e-05
    118    40     8.66e-07     8.66e-07     1.22e-05
    118    50     2.25e-06     2.25e-06     2.31e-05
    118    60     6.87e-07     6.87e-07     1.06e-05
    118    61      1.5e-06      1.5e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             118 6171.388    0.005     1.81e-05     1.81e-05     5.51e-05
! Validation        118 6171.388    0.005     1.59e-06     1.59e-06     1.65e-05
Wall time: 6171.389662833
training
# Epoch batch         loss       loss_e      e/N_mae
    119    10     7.27e-06     7.27e-06     3.68e-05
    119    20     1.89e-05     1.89e-05     5.88e-05
    119    30     1.47e-05     1.47e-05     5.34e-05
    119    40     4.53e-06     4.53e-06     2.94e-05
    119    48     8.98e-06     8.98e-06     4.98e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    119    10     2.58e-06     2.58e-06     2.25e-05
    119    20     2.96e-06     2.96e-06     2.63e-05
    119    30     1.65e-06     1.65e-06      1.9e-05
    119    40     7.38e-07     7.38e-07     1.12e-05
    119    50     1.84e-06     1.84e-06     2.12e-05
    119    60     9.17e-07     9.17e-07     1.28e-05
    119    61     3.13e-06     3.13e-06     2.57e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             119 6223.785    0.005     9.71e-06     9.71e-06     4.11e-05
! Validation        119 6223.785    0.005     1.59e-06     1.59e-06     1.67e-05
Wall time: 6223.7860105830005
training
# Epoch batch         loss       loss_e      e/N_mae
    120    10     1.06e-05     1.06e-05     4.37e-05
    120    20     5.49e-06     5.49e-06      3.3e-05
    120    30     6.61e-06     6.61e-06     3.32e-05
    120    40     1.11e-05     1.11e-05     4.54e-05
    120    48     7.87e-07     7.87e-07     1.45e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    120    10     2.45e-06     2.45e-06     2.22e-05
    120    20      2.1e-06      2.1e-06     2.18e-05
    120    30     1.82e-06     1.82e-06     1.77e-05
    120    40     1.04e-06     1.04e-06     1.25e-05
    120    50     2.08e-06     2.08e-06     2.18e-05
    120    60     1.19e-06     1.19e-06     1.61e-05
    120    61     2.47e-06     2.47e-06      2.2e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             120 6275.901    0.005     7.45e-06     7.45e-06     3.56e-05
! Validation        120 6275.901    0.005     1.57e-06     1.57e-06     1.63e-05
Wall time: 6275.9016197500005
training
# Epoch batch         loss       loss_e      e/N_mae
    121    10     4.75e-06     4.75e-06     2.76e-05
    121    20     5.56e-06     5.56e-06      3.2e-05
    121    30     4.43e-06     4.43e-06     2.73e-05
    121    40     3.43e-06     3.43e-06     2.37e-05
    121    48     8.04e-06     8.04e-06     4.42e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    121    10     2.28e-06     2.28e-06     2.15e-05
    121    20     1.51e-06     1.51e-06     1.86e-05
    121    30     1.41e-06     1.41e-06     1.67e-05
    121    40     8.07e-07     8.07e-07     1.16e-05
    121    50     2.13e-06     2.13e-06     2.25e-05
    121    60     1.11e-06     1.11e-06     1.51e-05
    121    61     2.54e-06     2.54e-06     2.36e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             121 6328.025    0.005     4.35e-06     4.35e-06     2.72e-05
! Validation        121 6328.025    0.005     1.46e-06     1.46e-06     1.57e-05
Wall time: 6328.025812958001
training
# Epoch batch         loss       loss_e      e/N_mae
    122    10     9.11e-06     9.11e-06     3.77e-05
    122    20     3.85e-06     3.85e-06     2.67e-05
    122    30     4.64e-06     4.64e-06     2.58e-05
    122    40     1.78e-06     1.78e-06     1.78e-05
    122    48     1.02e-06     1.02e-06     1.69e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    122    10     2.43e-06     2.43e-06     2.25e-05
    122    20     1.54e-06     1.54e-06     1.83e-05
    122    30     1.17e-06     1.17e-06     1.57e-05
    122    40     9.07e-07     9.07e-07     1.09e-05
    122    50     1.95e-06     1.95e-06     2.12e-05
    122    60     1.22e-06     1.22e-06     1.64e-05
    122    61     2.38e-06     2.38e-06      2.2e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             122 6379.983    0.005     4.56e-06     4.56e-06     2.78e-05
! Validation        122 6379.983    0.005     1.44e-06     1.44e-06     1.58e-05
Wall time: 6379.98284675
training
# Epoch batch         loss       loss_e      e/N_mae
    123    10     2.18e-06     2.18e-06     2.02e-05
    123    20     2.25e-06     2.25e-06     1.91e-05
    123    30     3.43e-06     3.43e-06     2.69e-05
    123    40     4.29e-06     4.29e-06     2.73e-05
    123    48     5.97e-07     5.97e-07     1.37e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    123    10     1.97e-06     1.97e-06     2.02e-05
    123    20     1.38e-06     1.38e-06     1.77e-05
    123    30      1.2e-06      1.2e-06     1.51e-05
    123    40     1.19e-06     1.19e-06     1.19e-05
    123    50     1.62e-06     1.62e-06      1.9e-05
    123    60     1.44e-06     1.44e-06     1.73e-05
    123    61     1.31e-06     1.31e-06     1.55e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             123 6432.302    0.005     3.18e-06     3.18e-06     2.31e-05
! Validation        123 6432.302    0.005     1.38e-06     1.38e-06     1.54e-05
Wall time: 6432.302364416
training
# Epoch batch         loss       loss_e      e/N_mae
    124    10     2.24e-06     2.24e-06     1.93e-05
    124    20     2.23e-06     2.23e-06     2.09e-05
    124    30     1.52e-05     1.52e-05     5.76e-05
    124    40      2.9e-06      2.9e-06     2.35e-05
    124    48     4.48e-06     4.48e-06     3.05e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    124    10     2.02e-06     2.02e-06     1.96e-05
    124    20     1.24e-06     1.24e-06     1.64e-05
    124    30      1.4e-06      1.4e-06     1.57e-05
    124    40        1e-06        1e-06     1.22e-05
    124    50     1.73e-06     1.73e-06     2.02e-05
    124    60     1.19e-06     1.19e-06     1.61e-05
    124    61      1.7e-06      1.7e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             124 6484.687    0.005     5.33e-06     5.33e-06     3.07e-05
! Validation        124 6484.687    0.005     1.34e-06     1.34e-06     1.51e-05
Wall time: 6484.688327916
! Best model      124    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    125    10     2.19e-06     2.19e-06     1.85e-05
    125    20     1.95e-06     1.95e-06     1.71e-05
    125    30     2.27e-06     2.27e-06     1.64e-05
    125    40     4.05e-06     4.05e-06     2.64e-05
    125    48     3.86e-07     3.86e-07     8.83e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    125    10     1.53e-06     1.53e-06      1.7e-05
    125    20     1.29e-06     1.29e-06      1.7e-05
    125    30     8.12e-07     8.12e-07     1.25e-05
    125    40     8.86e-07     8.86e-07     1.16e-05
    125    50     1.55e-06     1.55e-06      1.8e-05
    125    60     1.29e-06     1.29e-06     1.57e-05
    125    61     2.43e-06     2.43e-06      2.2e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             125 6536.679    0.005     2.94e-06     2.94e-06     2.24e-05
! Validation        125 6536.679    0.005     1.29e-06     1.29e-06     1.47e-05
Wall time: 6536.6800395
! Best model      125    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    126    10     2.58e-06     2.58e-06     2.24e-05
    126    20     2.52e-06     2.52e-06     2.26e-05
    126    30     2.04e-06     2.04e-06     1.72e-05
    126    40     1.43e-06     1.43e-06     1.62e-05
    126    48     6.87e-08     6.87e-08     4.02e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    126    10     1.48e-06     1.48e-06     1.77e-05
    126    20     1.63e-06     1.63e-06     1.83e-05
    126    30     8.16e-07     8.16e-07     1.12e-05
    126    40     7.38e-07     7.38e-07     1.06e-05
    126    50     1.66e-06     1.66e-06     1.99e-05
    126    60      9.7e-07      9.7e-07     1.35e-05
    126    61      1.7e-06      1.7e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             126 6589.645    0.005     2.15e-06     2.15e-06      1.9e-05
! Validation        126 6589.645    0.005     1.23e-06     1.23e-06     1.45e-05
Wall time: 6589.645879250001
! Best model      126    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    127    10     9.21e-07     9.21e-07     1.23e-05
    127    20      1.3e-06      1.3e-06     1.36e-05
    127    30     5.39e-06     5.39e-06      2.7e-05
    127    40     4.78e-07     4.78e-07     9.32e-06
    127    48      6.6e-07      6.6e-07      1.2e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    127    10     1.34e-06     1.34e-06     1.67e-05
    127    20     9.45e-07     9.45e-07     1.45e-05
    127    30     9.66e-07     9.66e-07     1.28e-05
    127    40     9.51e-07     9.51e-07     1.25e-05
    127    50     1.71e-06     1.71e-06     2.02e-05
    127    60     1.06e-06     1.06e-06     1.48e-05
    127    61     1.43e-06     1.43e-06     1.87e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             127 6642.371    0.005     1.88e-06     1.88e-06     1.78e-05
! Validation        127 6642.371    0.005      1.2e-06      1.2e-06     1.45e-05
Wall time: 6642.371764
! Best model      127    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    128    10     2.71e-06     2.71e-06     2.44e-05
    128    20     5.29e-06     5.29e-06     3.29e-05
    128    30     2.65e-06     2.65e-06     2.21e-05
    128    40     2.06e-06     2.06e-06     1.73e-05
    128    48     1.24e-05     1.24e-05     5.78e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    128    10     1.34e-06     1.34e-06      1.7e-05
    128    20     1.21e-06     1.21e-06     1.67e-05
    128    30     7.44e-07     7.44e-07     1.19e-05
    128    40     8.75e-07     8.75e-07     1.12e-05
    128    50     1.39e-06     1.39e-06     1.77e-05
    128    60     8.66e-07     8.66e-07     1.22e-05
    128    61     1.32e-06     1.32e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             128 6695.902    0.005     2.82e-06     2.82e-06     2.13e-05
! Validation        128 6695.902    0.005     1.18e-06     1.18e-06     1.43e-05
Wall time: 6695.903384541
! Best model      128    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    129    10     1.12e-06     1.12e-06     1.46e-05
    129    20     4.06e-06     4.06e-06     2.42e-05
    129    30     6.08e-06     6.08e-06     3.44e-05
    129    40     3.66e-06     3.66e-06     2.85e-05
    129    48     5.16e-06     5.16e-06     2.97e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    129    10     1.22e-06     1.22e-06     1.54e-05
    129    20     1.46e-06     1.46e-06     1.86e-05
    129    30     7.63e-07     7.63e-07     1.25e-05
    129    40     7.14e-07     7.14e-07     1.03e-05
    129    50     1.39e-06     1.39e-06     1.77e-05
    129    60     8.43e-07     8.43e-07     1.32e-05
    129    61     1.34e-06     1.34e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             129 6748.574    0.005     4.42e-06     4.42e-06     2.79e-05
! Validation        129 6748.574    0.005     1.15e-06     1.15e-06     1.41e-05
Wall time: 6748.574743708
! Best model      129    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    130    10     1.95e-06     1.95e-06     1.79e-05
    130    20     1.25e-06     1.25e-06      1.3e-05
    130    30     5.66e-06     5.66e-06     3.48e-05
    130    40     2.02e-06     2.02e-06      1.8e-05
    130    48      7.7e-06      7.7e-06      4.5e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    130    10     1.26e-06     1.26e-06     1.64e-05
    130    20     1.67e-06     1.67e-06     2.02e-05
    130    30      8.5e-07      8.5e-07     1.32e-05
    130    40     7.02e-07     7.02e-07     1.03e-05
    130    50     1.33e-06     1.33e-06     1.77e-05
    130    60        1e-06        1e-06     1.45e-05
    130    61     1.39e-06     1.39e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             130 6803.721    0.005     3.05e-06     3.05e-06     2.26e-05
! Validation        130 6803.721    0.005     1.17e-06     1.17e-06     1.42e-05
Wall time: 6803.722822625
training
# Epoch batch         loss       loss_e      e/N_mae
    131    10     2.69e-06     2.69e-06     2.24e-05
    131    20     8.36e-06     8.36e-06     3.97e-05
    131    30     1.45e-05     1.45e-05      5.5e-05
    131    40     2.19e-05     2.19e-05     6.94e-05
    131    48     7.24e-07     7.24e-07     1.28e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    131    10     1.69e-06     1.69e-06      1.8e-05
    131    20     2.02e-06     2.02e-06     2.22e-05
    131    30     7.52e-07     7.52e-07     1.19e-05
    131    40      5.6e-07      5.6e-07     8.67e-06
    131    50     1.15e-06     1.15e-06     1.64e-05
    131    60     9.53e-07     9.53e-07     1.54e-05
    131    61     1.92e-06     1.92e-06     2.14e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             131 6858.009    0.005     1.06e-05     1.06e-05     4.31e-05
! Validation        131 6858.009    0.005     1.23e-06     1.23e-06     1.42e-05
Wall time: 6858.009525958
training
# Epoch batch         loss       loss_e      e/N_mae
    132    10     3.74e-05     3.74e-05     9.07e-05
    132    20     1.21e-05     1.21e-05        4e-05
    132    30     2.32e-06     2.32e-06     2.08e-05
    132    40     3.67e-06     3.67e-06     2.52e-05
    132    48     2.12e-06     2.12e-06     1.77e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    132    10     1.42e-06     1.42e-06     1.67e-05
    132    20     1.38e-06     1.38e-06      1.9e-05
    132    30     8.98e-07     8.98e-07     1.35e-05
    132    40     5.03e-07     5.03e-07     8.99e-06
    132    50     1.27e-06     1.27e-06     1.67e-05
    132    60     7.29e-07     7.29e-07     1.28e-05
    132    61     2.19e-06     2.19e-06     2.09e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             132 6913.425    0.005     9.35e-06     9.35e-06        4e-05
! Validation        132 6913.425    0.005     1.15e-06     1.15e-06     1.38e-05
Wall time: 6913.425416541
! Best model      132    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    133    10     4.05e-06     4.05e-06     2.73e-05
    133    20     4.94e-06     4.94e-06     2.96e-05
    133    30     7.75e-06     7.75e-06     4.09e-05
    133    40     4.15e-06     4.15e-06     2.99e-05
    133    48     6.87e-07     6.87e-07     1.12e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    133    10     1.09e-06     1.09e-06     1.45e-05
    133    20     1.61e-06     1.61e-06     1.99e-05
    133    30     1.11e-06     1.11e-06     1.45e-05
    133    40     6.81e-07     6.81e-07     1.03e-05
    133    50     1.13e-06     1.13e-06     1.57e-05
    133    60     8.39e-07     8.39e-07     1.35e-05
    133    61     1.98e-06     1.98e-06     2.09e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             133 6966.716    0.005     5.02e-06     5.02e-06     2.98e-05
! Validation        133 6966.716    0.005     1.19e-06     1.19e-06     1.42e-05
Wall time: 6966.717281541
training
# Epoch batch         loss       loss_e      e/N_mae
    134    10     2.34e-06     2.34e-06     1.79e-05
    134    20     2.13e-06     2.13e-06     1.85e-05
    134    30     3.08e-06     3.08e-06     2.24e-05
    134    40     6.23e-06     6.23e-06     3.69e-05
    134    48     5.84e-06     5.84e-06     4.02e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    134    10     1.27e-06     1.27e-06      1.7e-05
    134    20     1.22e-06     1.22e-06     1.73e-05
    134    30        7e-07        7e-07     1.19e-05
    134    40     4.48e-07     4.48e-07     8.99e-06
    134    50     1.04e-06     1.04e-06     1.48e-05
    134    60     1.04e-06     1.04e-06     1.51e-05
    134    61     1.62e-06     1.62e-06     1.87e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             134 7021.720    0.005     3.28e-06     3.28e-06     2.33e-05
! Validation        134 7021.720    0.005     1.12e-06     1.12e-06     1.39e-05
Wall time: 7021.720001916
! Best model      134    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    135    10     1.23e-05     1.23e-05     5.43e-05
    135    20     2.55e-06     2.55e-06     2.15e-05
    135    30     6.39e-06     6.39e-06     2.84e-05
    135    40     3.14e-06     3.14e-06     2.18e-05
    135    48     6.66e-06     6.66e-06     3.53e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    135    10     8.77e-07     8.77e-07     1.35e-05
    135    20     1.12e-06     1.12e-06     1.57e-05
    135    30     6.59e-07     6.59e-07     1.22e-05
    135    40     4.02e-07     4.02e-07     8.35e-06
    135    50     1.15e-06     1.15e-06     1.51e-05
    135    60     1.14e-06     1.14e-06     1.64e-05
    135    61     1.32e-06     1.32e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             135 7075.479    0.005     4.29e-06     4.29e-06      2.7e-05
! Validation        135 7075.479    0.005     1.13e-06     1.13e-06      1.4e-05
Wall time: 7075.479933791001
training
# Epoch batch         loss       loss_e      e/N_mae
    136    10     2.85e-06     2.85e-06     2.09e-05
    136    20     9.42e-06     9.42e-06      3.9e-05
    136    30     4.92e-05     4.92e-05     0.000102
    136    40     4.15e-05     4.15e-05     9.66e-05
    136    48      1.3e-05      1.3e-05     5.94e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    136    10     1.37e-06     1.37e-06      1.7e-05
    136    20     1.37e-06     1.37e-06     1.64e-05
    136    30      9.3e-07      9.3e-07     1.48e-05
    136    40     1.17e-06     1.17e-06     1.28e-05
    136    50     9.26e-07     9.26e-07     1.45e-05
    136    60     1.35e-06     1.35e-06      1.8e-05
    136    61     1.42e-06     1.42e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             136 7133.194    0.005     1.41e-05     1.41e-05        5e-05
! Validation        136 7133.194    0.005     1.25e-06     1.25e-06     1.46e-05
Wall time: 7133.195137083
training
# Epoch batch         loss       loss_e      e/N_mae
    137    10     5.22e-06     5.22e-06     2.78e-05
    137    20     2.05e-06     2.05e-06     1.99e-05
    137    30     7.01e-06     7.01e-06     3.92e-05
    137    40     3.16e-06     3.16e-06     2.41e-05
    137    48     3.58e-06     3.58e-06     2.33e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    137    10      1.3e-06      1.3e-06      1.7e-05
    137    20     9.05e-07     9.05e-07     1.38e-05
    137    30     6.81e-07     6.81e-07     1.22e-05
    137    40     1.43e-06     1.43e-06     1.28e-05
    137    50     1.08e-06     1.08e-06     1.51e-05
    137    60     1.18e-06     1.18e-06     1.77e-05
    137    61     8.91e-07     8.91e-07     1.39e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             137 7189.911    0.005     5.28e-06     5.28e-06     2.97e-05
! Validation        137 7189.911    0.005     1.22e-06     1.22e-06     1.46e-05
Wall time: 7189.912448041
training
# Epoch batch         loss       loss_e      e/N_mae
    138    10      6.7e-06      6.7e-06     3.79e-05
    138    20     3.23e-06     3.23e-06     2.25e-05
    138    30     2.51e-06     2.51e-06     2.03e-05
    138    40     2.59e-06     2.59e-06     2.35e-05
    138    48      1.1e-06      1.1e-06     1.77e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    138    10     1.68e-06     1.68e-06     1.73e-05
    138    20      1.1e-06      1.1e-06     1.51e-05
    138    30     4.56e-07     4.56e-07     1.03e-05
    138    40     1.11e-06     1.11e-06     1.12e-05
    138    50      1.1e-06      1.1e-06     1.67e-05
    138    60     1.23e-06     1.23e-06      1.7e-05
    138    61     1.16e-06     1.16e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             138 7246.654    0.005     4.05e-06     4.05e-06     2.53e-05
! Validation        138 7246.654    0.005     1.17e-06     1.17e-06     1.42e-05
Wall time: 7246.655424416001
training
# Epoch batch         loss       loss_e      e/N_mae
    139    10     4.34e-06     4.34e-06     2.97e-05
    139    20     2.23e-06     2.23e-06     2.22e-05
    139    30     1.83e-06     1.83e-06     1.84e-05
    139    40      3.4e-06      3.4e-06     2.77e-05
    139    48     4.53e-06     4.53e-06     2.73e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    139    10     1.28e-06     1.28e-06     1.51e-05
    139    20     8.28e-07     8.28e-07     1.22e-05
    139    30        6e-07        6e-07     1.16e-05
    139    40     7.99e-07     7.99e-07     9.96e-06
    139    50     9.57e-07     9.57e-07     1.35e-05
    139    60     1.15e-06     1.15e-06     1.67e-05
    139    61     1.51e-06     1.51e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             139 7303.190    0.005     2.55e-06     2.55e-06     2.04e-05
! Validation        139 7303.190    0.005      1.1e-06      1.1e-06     1.35e-05
Wall time: 7303.191434958
! Best model      139    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    140    10     1.99e-06     1.99e-06     1.98e-05
    140    20     4.59e-06     4.59e-06     2.78e-05
    140    30     1.38e-06     1.38e-06      1.5e-05
    140    40     1.36e-06     1.36e-06     1.68e-05
    140    48     8.93e-07     8.93e-07     1.37e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    140    10     1.25e-06     1.25e-06     1.57e-05
    140    20     7.57e-07     7.57e-07     1.25e-05
    140    30     4.37e-07     4.37e-07     9.32e-06
    140    40     6.36e-07     6.36e-07     9.32e-06
    140    50     9.28e-07     9.28e-07     1.28e-05
    140    60     8.83e-07     8.83e-07     1.45e-05
    140    61     1.25e-06     1.25e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             140 7359.513    0.005     2.38e-06     2.38e-06     2.05e-05
! Validation        140 7359.513    0.005     1.04e-06     1.04e-06     1.33e-05
Wall time: 7359.513033416
! Best model      140    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    141    10     1.79e-06     1.79e-06     1.95e-05
    141    20     2.53e-06     2.53e-06      2.1e-05
    141    30     2.59e-06     2.59e-06     2.38e-05
    141    40     2.35e-06     2.35e-06     1.95e-05
    141    48     9.77e-07     9.77e-07     1.45e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    141    10     1.28e-06     1.28e-06     1.54e-05
    141    20     8.47e-07     8.47e-07     1.28e-05
    141    30     4.14e-07     4.14e-07     9.64e-06
    141    40     5.47e-07     5.47e-07     8.67e-06
    141    50     1.08e-06     1.08e-06     1.48e-05
    141    60      9.3e-07      9.3e-07     1.45e-05
    141    61     1.02e-06     1.02e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             141 7416.780    0.005     1.84e-06     1.84e-06     1.81e-05
! Validation        141 7416.780    0.005     9.93e-07     9.93e-07     1.31e-05
Wall time: 7416.781450500001
! Best model      141    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    142    10     1.04e-05     1.04e-05     3.87e-05
    142    20     7.13e-06     7.13e-06     3.89e-05
    142    30     2.03e-06     2.03e-06     1.71e-05
    142    40     1.85e-06     1.85e-06     1.81e-05
    142    48     3.98e-06     3.98e-06     3.21e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    142    10     1.01e-06     1.01e-06     1.41e-05
    142    20     8.96e-07     8.96e-07     1.32e-05
    142    30     6.45e-07     6.45e-07     1.19e-05
    142    40      4.1e-07      4.1e-07     8.35e-06
    142    50     1.07e-06     1.07e-06     1.45e-05
    142    60     7.25e-07     7.25e-07     1.22e-05
    142    61     1.06e-06     1.06e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             142 7472.757    0.005      3.5e-06      3.5e-06     2.43e-05
! Validation        142 7472.757    0.005     9.55e-07     9.55e-07      1.3e-05
Wall time: 7472.7582595
! Best model      142    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    143    10     1.36e-05     1.36e-05     5.75e-05
    143    20     4.25e-06     4.25e-06     3.06e-05
    143    30     2.89e-06     2.89e-06     2.18e-05
    143    40     1.13e-05     1.13e-05     4.74e-05
    143    48      2.8e-06      2.8e-06     2.73e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    143    10     1.25e-06     1.25e-06     1.67e-05
    143    20     1.06e-06     1.06e-06     1.54e-05
    143    30     8.56e-07     8.56e-07     1.38e-05
    143    40     3.93e-07     3.93e-07     8.35e-06
    143    50     9.57e-07     9.57e-07     1.28e-05
    143    60     1.07e-06     1.07e-06     1.54e-05
    143    61     1.34e-06     1.34e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             143 7528.988    0.005     6.84e-06     6.84e-06     3.55e-05
! Validation        143 7528.988    0.005     1.01e-06     1.01e-06     1.33e-05
Wall time: 7528.989136
training
# Epoch batch         loss       loss_e      e/N_mae
    144    10     7.35e-06     7.35e-06     3.53e-05
    144    20     6.84e-06     6.84e-06     3.14e-05
    144    30     3.49e-06     3.49e-06     2.14e-05
    144    40     5.64e-06     5.64e-06     3.43e-05
    144    48     2.23e-05     2.23e-05     7.15e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    144    10     8.24e-07     8.24e-07     1.41e-05
    144    20     9.21e-07     9.21e-07     1.28e-05
    144    30     7.78e-07     7.78e-07     1.35e-05
    144    40     2.13e-07     2.13e-07     6.42e-06
    144    50     8.52e-07     8.52e-07     1.28e-05
    144    60     8.92e-07     8.92e-07     1.51e-05
    144    61     6.34e-07     6.34e-07     1.23e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             144 7585.173    0.005      7.4e-06      7.4e-06     3.42e-05
! Validation        144 7585.173    0.005     1.01e-06     1.01e-06     1.34e-05
Wall time: 7585.173907916001
training
# Epoch batch         loss       loss_e      e/N_mae
    145    10      1.2e-05      1.2e-05     4.82e-05
    145    20     1.22e-05     1.22e-05     5.14e-05
    145    30     1.46e-05     1.46e-05     4.97e-05
    145    40     4.41e-06     4.41e-06     2.72e-05
    145    48      3.8e-06      3.8e-06     3.05e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    145    10     1.82e-06     1.82e-06     2.12e-05
    145    20     1.47e-06     1.47e-06     1.86e-05
    145    30     1.05e-06     1.05e-06     1.51e-05
    145    40     1.01e-07     1.01e-07      4.5e-06
    145    50     9.02e-07     9.02e-07     1.32e-05
    145    60      1.1e-06      1.1e-06     1.64e-05
    145    61     2.68e-06     2.68e-06     2.25e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             145 7641.530    0.005     1.39e-05     1.39e-05     4.85e-05
! Validation        145 7641.530    0.005     1.22e-06     1.22e-06     1.43e-05
Wall time: 7641.531363791
training
# Epoch batch         loss       loss_e      e/N_mae
    146    10     7.88e-06     7.88e-06     3.75e-05
    146    20     4.34e-06     4.34e-06     2.93e-05
    146    30     3.86e-06     3.86e-06     2.69e-05
    146    40     2.72e-06     2.72e-06     2.39e-05
    146    48     8.56e-07     8.56e-07     1.45e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    146    10     1.34e-06     1.34e-06     1.83e-05
    146    20     1.05e-06     1.05e-06     1.54e-05
    146    30     7.08e-07     7.08e-07     1.19e-05
    146    40     2.85e-07     2.85e-07      6.1e-06
    146    50     8.94e-07     8.94e-07     1.25e-05
    146    60     1.01e-06     1.01e-06     1.48e-05
    146    61     3.31e-06     3.31e-06     2.89e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             146 7698.407    0.005     4.88e-06     4.88e-06     2.83e-05
! Validation        146 7698.407    0.005     1.19e-06     1.19e-06      1.4e-05
Wall time: 7698.407841958
training
# Epoch batch         loss       loss_e      e/N_mae
    147    10     1.49e-06     1.49e-06     1.47e-05
    147    20     4.42e-06     4.42e-06     2.53e-05
    147    30     1.42e-06     1.42e-06     1.46e-05
    147    40     1.72e-06     1.72e-06     1.76e-05
    147    48     3.94e-06     3.94e-06     2.65e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    147    10     1.03e-06     1.03e-06     1.64e-05
    147    20     9.34e-07     9.34e-07     1.45e-05
    147    30     5.94e-07     5.94e-07     1.06e-05
    147    40     3.06e-07     3.06e-07     7.39e-06
    147    50     1.06e-06     1.06e-06     1.54e-05
    147    60     8.09e-07     8.09e-07     1.41e-05
    147    61      2.3e-06      2.3e-06     2.46e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             147 7754.269    0.005     2.68e-06     2.68e-06     2.11e-05
! Validation        147 7754.269    0.005     1.06e-06     1.06e-06     1.33e-05
Wall time: 7754.270151000001
training
# Epoch batch         loss       loss_e      e/N_mae
    148    10     5.67e-06     5.67e-06     3.29e-05
    148    20     1.89e-06     1.89e-06      1.8e-05
    148    30     3.21e-06     3.21e-06     2.52e-05
    148    40     2.28e-06     2.28e-06     1.97e-05
    148    48        4e-06        4e-06     2.89e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    148    10     1.19e-06     1.19e-06      1.7e-05
    148    20     9.91e-07     9.91e-07     1.41e-05
    148    30     9.02e-07     9.02e-07     1.38e-05
    148    40     3.32e-07     3.32e-07     8.67e-06
    148    50     9.68e-07     9.68e-07     1.48e-05
    148    60     8.43e-07     8.43e-07     1.35e-05
    148    61     2.49e-06     2.49e-06     2.57e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             148 7810.102    0.005     2.62e-06     2.62e-06     2.07e-05
! Validation        148 7810.102    0.005     1.02e-06     1.02e-06     1.31e-05
Wall time: 7810.103209541
training
# Epoch batch         loss       loss_e      e/N_mae
    149    10     2.82e-06     2.82e-06     2.17e-05
    149    20     2.97e-06     2.97e-06     2.29e-05
    149    30     5.75e-06     5.75e-06     3.17e-05
    149    40     2.84e-06     2.84e-06     2.14e-05
    149    48     1.17e-06     1.17e-06     1.61e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    149    10     1.16e-06     1.16e-06      1.7e-05
    149    20     9.62e-07     9.62e-07     1.41e-05
    149    30     6.15e-07     6.15e-07     1.19e-05
    149    40      2.6e-07      2.6e-07     6.75e-06
    149    50     9.15e-07     9.15e-07     1.38e-05
    149    60     6.32e-07     6.32e-07     1.22e-05
    149    61     1.71e-06     1.71e-06     2.14e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             149 7866.024    0.005     3.05e-06     3.05e-06      2.3e-05
! Validation        149 7866.024    0.005     9.38e-07     9.38e-07     1.27e-05
Wall time: 7866.024623833
! Best model      149    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    150    10     2.38e-06     2.38e-06     2.03e-05
    150    20     2.28e-06     2.28e-06     2.08e-05
    150    30     2.94e-06     2.94e-06     2.03e-05
    150    40     3.26e-06     3.26e-06     2.42e-05
    150    48     4.76e-06     4.76e-06     3.53e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    150    10     1.07e-06     1.07e-06     1.54e-05
    150    20     9.64e-07     9.64e-07     1.48e-05
    150    30      7.5e-07      7.5e-07     1.19e-05
    150    40     2.13e-07     2.13e-07     6.75e-06
    150    50     7.59e-07     7.59e-07     1.25e-05
    150    60     8.01e-07     8.01e-07     1.25e-05
    150    61     1.71e-06     1.71e-06     2.09e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             150 7922.065    0.005      3.5e-06      3.5e-06     2.43e-05
! Validation        150 7922.065    0.005     9.48e-07     9.48e-07     1.28e-05
Wall time: 7922.066028708
training
# Epoch batch         loss       loss_e      e/N_mae
    151    10      5.3e-06      5.3e-06     3.41e-05
    151    20     6.61e-06     6.61e-06     3.52e-05
    151    30     8.31e-06     8.31e-06     4.03e-05
    151    40     3.33e-06     3.33e-06     2.75e-05
    151    48     1.87e-06     1.87e-06     2.17e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    151    10     9.57e-07     9.57e-07     1.41e-05
    151    20     7.16e-07     7.16e-07     1.19e-05
    151    30     8.56e-07     8.56e-07     1.32e-05
    151    40     2.98e-07     2.98e-07     6.42e-06
    151    50     9.53e-07     9.53e-07     1.38e-05
    151    60     7.74e-07     7.74e-07     1.32e-05
    151    61     1.22e-06     1.22e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             151 7977.962    0.005     5.48e-06     5.48e-06     3.14e-05
! Validation        151 7977.962    0.005     9.35e-07     9.35e-07     1.28e-05
Wall time: 7977.96269025
! Best model      151    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    152    10     2.51e-06     2.51e-06      2.3e-05
    152    20     2.97e-06     2.97e-06     2.32e-05
    152    30     5.51e-06     5.51e-06      3.5e-05
    152    40     6.52e-06     6.52e-06     3.48e-05
    152    48     3.31e-06     3.31e-06     2.17e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    152    10     1.07e-06     1.07e-06     1.48e-05
    152    20     9.07e-07     9.07e-07     1.38e-05
    152    30     3.66e-07     3.66e-07     8.67e-06
    152    40     3.59e-07     3.59e-07     7.39e-06
    152    50     8.12e-07     8.12e-07     1.28e-05
    152    60      7.1e-07      7.1e-07     1.22e-05
    152    61     1.64e-06     1.64e-06     1.87e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             152 8033.693    0.005     5.25e-06     5.25e-06     3.04e-05
! Validation        152 8033.693    0.005     9.43e-07     9.43e-07     1.27e-05
Wall time: 8033.693442416
training
# Epoch batch         loss       loss_e      e/N_mae
    153    10     2.79e-05     2.79e-05     7.67e-05
    153    20      8.9e-06      8.9e-06     3.97e-05
    153    30      6.6e-06      6.6e-06      3.3e-05
    153    40     5.67e-06     5.67e-06     3.23e-05
    153    48     4.46e-06     4.46e-06     2.65e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    153    10     1.64e-06     1.64e-06     1.77e-05
    153    20        9e-07        9e-07     1.48e-05
    153    30     3.21e-07     3.21e-07     7.71e-06
    153    40     4.21e-07     4.21e-07     8.99e-06
    153    50     1.03e-06     1.03e-06     1.32e-05
    153    60     8.43e-07     8.43e-07     1.41e-05
    153    61     1.76e-06     1.76e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             153 8089.627    0.005     7.51e-06     7.51e-06     3.66e-05
! Validation        153 8089.627    0.005     1.02e-06     1.02e-06     1.36e-05
Wall time: 8089.6280480000005
training
# Epoch batch         loss       loss_e      e/N_mae
    154    10     3.79e-06     3.79e-06     2.39e-05
    154    20     2.06e-06     2.06e-06     1.76e-05
    154    30     1.95e-06     1.95e-06     2.02e-05
    154    40     4.83e-06     4.83e-06     2.98e-05
    154    48     2.64e-08     2.64e-08     2.41e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    154    10     1.21e-06     1.21e-06     1.57e-05
    154    20     8.98e-07     8.98e-07     1.35e-05
    154    30     3.13e-07     3.13e-07     8.35e-06
    154    40     3.85e-07     3.85e-07     8.03e-06
    154    50     1.03e-06     1.03e-06     1.32e-05
    154    60     1.01e-06     1.01e-06     1.48e-05
    154    61        2e-06        2e-06     2.14e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             154 8145.543    0.005     4.74e-06     4.74e-06     2.82e-05
! Validation        154 8145.543    0.005     9.68e-07     9.68e-07      1.3e-05
Wall time: 8145.5438917500005
training
# Epoch batch         loss       loss_e      e/N_mae
    155    10     1.34e-06     1.34e-06     1.41e-05
    155    20     2.87e-06     2.87e-06      2.2e-05
    155    30     3.25e-06     3.25e-06     2.03e-05
    155    40        3e-06        3e-06     2.33e-05
    155    48     1.37e-06     1.37e-06     1.53e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    155    10      1.3e-06      1.3e-06     1.77e-05
    155    20     9.53e-07     9.53e-07     1.45e-05
    155    30     2.54e-07     2.54e-07     7.07e-06
    155    40     4.71e-07     4.71e-07     9.96e-06
    155    50     1.23e-06     1.23e-06     1.45e-05
    155    60     1.07e-06     1.07e-06     1.45e-05
    155    61     1.55e-06     1.55e-06     1.87e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             155 8201.374    0.005     2.73e-06     2.73e-06     2.09e-05
! Validation        155 8201.374    0.005     9.12e-07     9.12e-07     1.26e-05
Wall time: 8201.375202000001
! Best model      155    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    156    10     1.28e-06     1.28e-06     1.43e-05
    156    20     2.77e-06     2.77e-06     2.06e-05
    156    30     1.33e-06     1.33e-06     1.61e-05
    156    40      1.7e-06      1.7e-06     1.87e-05
    156    48      1.8e-06      1.8e-06     1.85e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    156    10     1.06e-06     1.06e-06     1.51e-05
    156    20     8.88e-07     8.88e-07     1.41e-05
    156    30     2.66e-07     2.66e-07     7.71e-06
    156    40     4.08e-07     4.08e-07     9.96e-06
    156    50     1.29e-06     1.29e-06     1.38e-05
    156    60     8.64e-07     8.64e-07     1.35e-05
    156    61     1.89e-06     1.89e-06     2.09e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             156 8257.086    0.005      1.9e-06      1.9e-06     1.78e-05
! Validation        156 8257.086    0.005     8.84e-07     8.84e-07     1.25e-05
Wall time: 8257.0874765
! Best model      156    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    157    10     1.47e-06     1.47e-06     1.64e-05
    157    20     1.94e-06     1.94e-06     1.98e-05
    157    30     3.32e-06     3.32e-06     2.42e-05
    157    40     4.45e-06     4.45e-06     2.91e-05
    157    48     1.36e-06     1.36e-06     1.45e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    157    10      1.2e-06      1.2e-06     1.51e-05
    157    20     9.02e-07     9.02e-07     1.38e-05
    157    30      2.6e-07      2.6e-07     7.39e-06
    157    40     3.36e-07     3.36e-07     8.67e-06
    157    50     9.45e-07     9.45e-07     1.22e-05
    157    60     8.09e-07     8.09e-07     1.28e-05
    157    61     1.18e-06     1.18e-06     1.55e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             157 8312.695    0.005     2.44e-06     2.44e-06     2.06e-05
! Validation        157 8312.695    0.005     8.58e-07     8.58e-07     1.24e-05
Wall time: 8312.695238
! Best model      157    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    158    10     4.39e-06     4.39e-06      2.6e-05
    158    20     4.95e-06     4.95e-06     2.85e-05
    158    30     2.05e-06     2.05e-06     2.17e-05
    158    40     1.06e-06     1.06e-06     1.49e-05
    158    48     2.34e-06     2.34e-06     2.33e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    158    10     1.07e-06     1.07e-06     1.64e-05
    158    20     8.05e-07     8.05e-07     1.38e-05
    158    30     4.12e-07     4.12e-07     9.96e-06
    158    40     3.02e-07     3.02e-07     8.03e-06
    158    50     1.08e-06     1.08e-06     1.48e-05
    158    60     7.76e-07     7.76e-07     1.28e-05
    158    61      1.6e-06      1.6e-06     1.87e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             158 8368.011    0.005     2.38e-06     2.38e-06     1.98e-05
! Validation        158 8368.011    0.005     8.56e-07     8.56e-07     1.23e-05
Wall time: 8368.011539708
! Best model      158    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    159    10     4.98e-06     4.98e-06     3.18e-05
    159    20     3.49e-06     3.49e-06     2.82e-05
    159    30     3.49e-06     3.49e-06     2.63e-05
    159    40     3.66e-06     3.66e-06     2.38e-05
    159    48     1.27e-05     1.27e-05     4.42e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    159    10     5.28e-07     5.28e-07     1.09e-05
    159    20      1.1e-06      1.1e-06     1.51e-05
    159    30     5.05e-07     5.05e-07     1.06e-05
    159    40     2.66e-07     2.66e-07     6.42e-06
    159    50     9.43e-07     9.43e-07     1.45e-05
    159    60     6.21e-07     6.21e-07     1.12e-05
    159    61     1.69e-06     1.69e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             159 8423.119    0.005     4.73e-06     4.73e-06     2.83e-05
! Validation        159 8423.119    0.005     8.46e-07     8.46e-07      1.2e-05
Wall time: 8423.120417083
! Best model      159    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    160    10     3.64e-06     3.64e-06     2.43e-05
    160    20     1.46e-06     1.46e-06     1.76e-05
    160    30     1.73e-06     1.73e-06     1.85e-05
    160    40     1.48e-06     1.48e-06     1.61e-05
    160    48     2.13e-06     2.13e-06     1.85e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    160    10      5.9e-07      5.9e-07     1.03e-05
    160    20     1.14e-06     1.14e-06     1.54e-05
    160    30     3.09e-07     3.09e-07     7.71e-06
    160    40     4.12e-07     4.12e-07     8.67e-06
    160    50     9.43e-07     9.43e-07     1.35e-05
    160    60     6.19e-07     6.19e-07     1.12e-05
    160    61     1.63e-06     1.63e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             160 8478.248    0.005     3.51e-06     3.51e-06     2.47e-05
! Validation        160 8478.248    0.005     8.64e-07     8.64e-07     1.21e-05
Wall time: 8478.248853041001
training
# Epoch batch         loss       loss_e      e/N_mae
    161    10      2.3e-06      2.3e-06     2.09e-05
    161    20     3.62e-06     3.62e-06     2.62e-05
    161    30     2.86e-06     2.86e-06      2.4e-05
    161    40     1.69e-06     1.69e-06     1.62e-05
    161    48     3.38e-07     3.38e-07     7.23e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    161    10     5.45e-07     5.45e-07     9.64e-06
    161    20     1.01e-06     1.01e-06     1.54e-05
    161    30     4.37e-07     4.37e-07     9.96e-06
    161    40     2.92e-07     2.92e-07      6.1e-06
    161    50     1.13e-06     1.13e-06     1.57e-05
    161    60     6.02e-07     6.02e-07     1.09e-05
    161    61     9.93e-07     9.93e-07     1.23e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             161 8533.271    0.005     2.72e-06     2.72e-06     2.19e-05
! Validation        161 8533.271    0.005     8.52e-07     8.52e-07     1.21e-05
Wall time: 8533.2719155
training
# Epoch batch         loss       loss_e      e/N_mae
    162    10     2.84e-06     2.84e-06     2.35e-05
    162    20      9.8e-06      9.8e-06     4.09e-05
    162    30     1.98e-06     1.98e-06     1.87e-05
    162    40     4.61e-06     4.61e-06        3e-05
    162    48      5.6e-07      5.6e-07      1.2e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    162    10     5.11e-07     5.11e-07     9.96e-06
    162    20     1.34e-06     1.34e-06     1.77e-05
    162    30     4.78e-07     4.78e-07     1.03e-05
    162    40     3.36e-07     3.36e-07     6.42e-06
    162    50     8.66e-07     8.66e-07     1.38e-05
    162    60     5.71e-07     5.71e-07     1.12e-05
    162    61      1.2e-06      1.2e-06     1.45e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             162 8588.267    0.005     4.75e-06     4.75e-06     2.86e-05
! Validation        162 8588.267    0.005     8.37e-07     8.37e-07     1.21e-05
Wall time: 8588.267436125001
! Best model      162    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    163    10     3.32e-06     3.32e-06     2.47e-05
    163    20     1.62e-06     1.62e-06     1.53e-05
    163    30        2e-06        2e-06     1.87e-05
    163    40     6.36e-06     6.36e-06     3.57e-05
    163    48     4.61e-06     4.61e-06     3.21e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    163    10     5.56e-07     5.56e-07     1.09e-05
    163    20     1.22e-06     1.22e-06     1.64e-05
    163    30     4.86e-07     4.86e-07     1.03e-05
    163    40     2.92e-07     2.92e-07     6.75e-06
    163    50     8.98e-07     8.98e-07     1.48e-05
    163    60     6.47e-07     6.47e-07     9.96e-06
    163    61      1.4e-06      1.4e-06     1.45e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             163 8643.180    0.005     3.66e-06     3.66e-06      2.4e-05
! Validation        163 8643.180    0.005     8.23e-07     8.23e-07     1.19e-05
Wall time: 8643.181425708
! Best model      163    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    164    10     1.22e-05     1.22e-05     4.97e-05
    164    20     1.32e-05     1.32e-05     4.75e-05
    164    30        8e-06        8e-06     4.18e-05
    164    40     4.72e-06     4.72e-06     3.24e-05
    164    48     6.56e-05     6.56e-05     0.000133
validation
# Epoch batch         loss       loss_e      e/N_mae
    164    10     6.55e-07     6.55e-07     1.25e-05
    164    20     1.41e-06     1.41e-06     1.77e-05
    164    30     5.14e-07     5.14e-07     9.96e-06
    164    40     1.18e-07     1.18e-07     4.18e-06
    164    50     1.23e-06     1.23e-06     1.54e-05
    164    60     7.82e-07     7.82e-07     1.22e-05
    164    61     1.51e-06     1.51e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             164 8698.239    0.005     1.38e-05     1.38e-05     4.72e-05
! Validation        164 8698.239    0.005     9.01e-07     9.01e-07     1.26e-05
Wall time: 8698.239037625
training
# Epoch batch         loss       loss_e      e/N_mae
    165    10     1.31e-05     1.31e-05      5.3e-05
    165    20     1.54e-05     1.54e-05     5.39e-05
    165    30      1.2e-05      1.2e-05     4.75e-05
    165    40      2.2e-05      2.2e-05     6.09e-05
    165    48      1.8e-07      1.8e-07     6.42e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    165    10     7.31e-07     7.31e-07     1.22e-05
    165    20      1.7e-06      1.7e-06      1.9e-05
    165    30     4.82e-07     4.82e-07     8.99e-06
    165    40     4.61e-07     4.61e-07     9.64e-06
    165    50     6.42e-07     6.42e-07     9.64e-06
    165    60     1.08e-06     1.08e-06     1.57e-05
    165    61     2.71e-06     2.71e-06     2.36e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             165 8753.481    0.005     2.96e-05     2.96e-05     7.05e-05
! Validation        165 8753.481    0.005     1.51e-06     1.51e-06     1.59e-05
Wall time: 8753.480927291
training
# Epoch batch         loss       loss_e      e/N_mae
    166    10     4.24e-06     4.24e-06     2.26e-05
    166    20        4e-06        4e-06     2.81e-05
    166    30     1.93e-05     1.93e-05     6.82e-05
    166    40     2.28e-06     2.28e-06      2.1e-05
    166    48     5.13e-06     5.13e-06     3.69e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    166    10     6.13e-07     6.13e-07     1.22e-05
    166    20     1.42e-06     1.42e-06     1.77e-05
    166    30      7.4e-07      7.4e-07     9.32e-06
    166    40     6.72e-07     6.72e-07     1.22e-05
    166    50     4.02e-07     4.02e-07     7.71e-06
    166    60     9.43e-07     9.43e-07     1.38e-05
    166    61      1.6e-06      1.6e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             166 8808.537    0.005     1.07e-05     1.07e-05     4.21e-05
! Validation        166 8808.537    0.005     1.37e-06     1.37e-06     1.51e-05
Wall time: 8808.538470333
training
# Epoch batch         loss       loss_e      e/N_mae
    167    10     8.18e-06     8.18e-06     3.96e-05
    167    20     2.82e-06     2.82e-06     2.18e-05
    167    30     2.79e-06     2.79e-06     2.02e-05
    167    40     6.47e-07     6.47e-07     1.04e-05
    167    48     4.15e-06     4.15e-06     2.41e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    167    10     5.47e-07     5.47e-07     1.03e-05
    167    20     1.72e-06     1.72e-06     1.99e-05
    167    30     7.74e-07     7.74e-07     1.09e-05
    167    40     4.48e-07     4.48e-07     9.64e-06
    167    50     4.16e-07     4.16e-07     8.67e-06
    167    60      8.2e-07      8.2e-07     1.32e-05
    167    61     1.87e-06     1.87e-06      2.2e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             167 8863.663    0.005     3.34e-06     3.34e-06     2.33e-05
! Validation        167 8863.663    0.005     1.18e-06     1.18e-06     1.38e-05
Wall time: 8863.663744583
training
# Epoch batch         loss       loss_e      e/N_mae
    168    10      4.4e-06      4.4e-06     3.22e-05
    168    20     2.82e-06     2.82e-06     2.49e-05
    168    30     6.42e-06     6.42e-06     3.61e-05
    168    40     1.81e-06     1.81e-06     1.87e-05
    168    48     4.67e-06     4.67e-06     3.29e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    168    10     8.01e-07     8.01e-07     1.28e-05
    168    20      1.5e-06      1.5e-06      1.9e-05
    168    30     7.31e-07     7.31e-07     1.09e-05
    168    40     5.98e-07     5.98e-07     9.32e-06
    168    50     3.78e-07     3.78e-07     8.03e-06
    168    60     7.69e-07     7.69e-07     1.25e-05
    168    61     1.78e-06     1.78e-06     2.03e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             168 8918.593    0.005     5.14e-06     5.14e-06     2.94e-05
! Validation        168 8918.593    0.005     1.08e-06     1.08e-06     1.32e-05
Wall time: 8918.593584875
training
# Epoch batch         loss       loss_e      e/N_mae
    169    10     5.88e-07     5.88e-07     1.03e-05
    169    20     1.86e-06     1.86e-06     1.91e-05
    169    30     2.78e-06     2.78e-06     2.35e-05
    169    40     4.07e-06     4.07e-06     2.89e-05
    169    48     3.43e-06     3.43e-06     3.05e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    169    10     7.04e-07     7.04e-07     1.22e-05
    169    20     1.24e-06     1.24e-06     1.67e-05
    169    30     4.61e-07     4.61e-07     9.64e-06
    169    40     4.27e-07     4.27e-07     8.99e-06
    169    50     7.08e-07     7.08e-07     1.16e-05
    169    60     6.38e-07     6.38e-07     1.09e-05
    169    61     1.84e-06     1.84e-06     2.03e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             169 8973.677    0.005     3.13e-06     3.13e-06     2.33e-05
! Validation        169 8973.677    0.005     1.04e-06     1.04e-06     1.31e-05
Wall time: 8973.677997458
training
# Epoch batch         loss       loss_e      e/N_mae
    170    10     2.33e-06     2.33e-06     1.91e-05
    170    20     4.27e-06     4.27e-06     2.84e-05
    170    30     2.97e-06     2.97e-06     2.28e-05
    170    40     2.51e-06     2.51e-06     2.01e-05
    170    48     5.34e-07     5.34e-07     1.04e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    170    10     5.18e-07     5.18e-07     1.16e-05
    170    20     1.59e-06     1.59e-06      1.8e-05
    170    30     7.35e-07     7.35e-07     1.19e-05
    170    40     3.36e-07     3.36e-07     8.67e-06
    170    50     7.33e-07     7.33e-07     1.22e-05
    170    60     6.21e-07     6.21e-07     1.09e-05
    170    61     1.92e-06     1.92e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             170 9028.834    0.005     2.72e-06     2.72e-06     2.19e-05
! Validation        170 9028.834    0.005     9.73e-07     9.73e-07     1.27e-05
Wall time: 9028.835524583
training
# Epoch batch         loss       loss_e      e/N_mae
    171    10     1.18e-06     1.18e-06     1.41e-05
    171    20     3.22e-06     3.22e-06     2.66e-05
    171    30     3.56e-06     3.56e-06     2.31e-05
    171    40     1.12e-06     1.12e-06     1.51e-05
    171    48     2.08e-06     2.08e-06     2.41e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    171    10     6.57e-07     6.57e-07     1.22e-05
    171    20     1.18e-06     1.18e-06     1.51e-05
    171    30     8.16e-07     8.16e-07     1.16e-05
    171    40     2.16e-07     2.16e-07     6.75e-06
    171    50     8.18e-07     8.18e-07     1.32e-05
    171    60     6.81e-07     6.81e-07     1.16e-05
    171    61     1.43e-06     1.43e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             171 9083.898    0.005     2.93e-06     2.93e-06     2.26e-05
! Validation        171 9083.898    0.005     9.37e-07     9.37e-07     1.25e-05
Wall time: 9083.899433
training
# Epoch batch         loss       loss_e      e/N_mae
    172    10      5.9e-06      5.9e-06     3.33e-05
    172    20     2.82e-06     2.82e-06     2.05e-05
    172    30     1.46e-06     1.46e-06     1.51e-05
    172    40     1.01e-06     1.01e-06     1.33e-05
    172    48     4.23e-08     4.23e-08     3.21e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    172    10     4.44e-07     4.44e-07     9.96e-06
    172    20     1.31e-06     1.31e-06     1.67e-05
    172    30     5.64e-07     5.64e-07     9.96e-06
    172    40     3.21e-07     3.21e-07     8.99e-06
    172    50     8.62e-07     8.62e-07     1.19e-05
    172    60     6.49e-07     6.49e-07     1.06e-05
    172    61     1.56e-06     1.56e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             172 9139.111    0.005      2.6e-06      2.6e-06     2.03e-05
! Validation        172 9139.111    0.005     8.28e-07     8.28e-07     1.18e-05
Wall time: 9139.111860791001
training
# Epoch batch         loss       loss_e      e/N_mae
    173    10     1.86e-06     1.86e-06     1.63e-05
    173    20     4.33e-06     4.33e-06     2.89e-05
    173    30     7.33e-06     7.33e-06     3.67e-05
    173    40      3.6e-06      3.6e-06     2.69e-05
    173    48     1.62e-06     1.62e-06     2.09e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    173    10     5.62e-07     5.62e-07     1.06e-05
    173    20     1.27e-06     1.27e-06     1.67e-05
    173    30     6.68e-07     6.68e-07     1.03e-05
    173    40     3.19e-07     3.19e-07     8.35e-06
    173    50     7.65e-07     7.65e-07     1.19e-05
    173    60     6.59e-07     6.59e-07     1.25e-05
    173    61      1.3e-06      1.3e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             173 9194.143    0.005     2.38e-06     2.38e-06     2.01e-05
! Validation        173 9194.143    0.005      8.3e-07      8.3e-07     1.19e-05
Wall time: 9194.143582625
training
# Epoch batch         loss       loss_e      e/N_mae
    174    10     2.15e-06     2.15e-06     1.86e-05
    174    20     1.29e-06     1.29e-06     1.66e-05
    174    30     5.76e-07     5.76e-07     9.42e-06
    174    40     9.38e-07     9.38e-07     1.31e-05
    174    48     7.99e-06     7.99e-06     4.58e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    174    10     3.44e-07     3.44e-07     8.99e-06
    174    20     1.22e-06     1.22e-06     1.67e-05
    174    30     8.71e-07     8.71e-07     1.19e-05
    174    40     4.14e-07     4.14e-07     8.67e-06
    174    50     7.84e-07     7.84e-07     1.32e-05
    174    60     7.14e-07     7.14e-07     1.22e-05
    174    61     8.63e-07     8.63e-07     1.28e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             174 9249.391    0.005     2.11e-06     2.11e-06     1.82e-05
! Validation        174 9249.391    0.005     7.77e-07     7.77e-07     1.15e-05
Wall time: 9249.392293416
! Best model      174    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    175    10     1.78e-06     1.78e-06     1.67e-05
    175    20     4.15e-06     4.15e-06     2.86e-05
    175    30      2.5e-06      2.5e-06     2.26e-05
    175    40     1.93e-06     1.93e-06     1.94e-05
    175    48     1.32e-06     1.32e-06     1.93e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    175    10     5.26e-07     5.26e-07     1.16e-05
    175    20     1.14e-06     1.14e-06     1.51e-05
    175    30     6.76e-07     6.76e-07     1.12e-05
    175    40     3.11e-07     3.11e-07     7.71e-06
    175    50     7.59e-07     7.59e-07     1.25e-05
    175    60     5.11e-07     5.11e-07     1.12e-05
    175    61     1.05e-06     1.05e-06     1.55e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             175 9304.529    0.005     2.71e-06     2.71e-06     2.18e-05
! Validation        175 9304.529    0.005     7.41e-07     7.41e-07     1.13e-05
Wall time: 9304.528950375001
! Best model      175    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    176    10     2.96e-06     2.96e-06     2.25e-05
    176    20     1.18e-05     1.18e-05     4.89e-05
    176    30     6.37e-06     6.37e-06     3.84e-05
    176    40      5.7e-06      5.7e-06     3.44e-05
    176    48     3.38e-07     3.38e-07     6.42e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    176    10     7.31e-07     7.31e-07     1.19e-05
    176    20     1.02e-06     1.02e-06     1.38e-05
    176    30     4.56e-07     4.56e-07     8.99e-06
    176    40     3.59e-07     3.59e-07     8.67e-06
    176    50     6.02e-07     6.02e-07     1.06e-05
    176    60     6.09e-07     6.09e-07     1.19e-05
    176    61     2.82e-07     2.82e-07     6.96e-06
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             176 9359.612    0.005     7.74e-06     7.74e-06     3.72e-05
! Validation        176 9359.612    0.005     7.96e-07     7.96e-07     1.16e-05
Wall time: 9359.613316333
training
# Epoch batch         loss       loss_e      e/N_mae
    177    10     1.27e-05     1.27e-05     5.27e-05
    177    20     7.56e-06     7.56e-06     3.98e-05
    177    30     2.03e-06     2.03e-06     2.03e-05
    177    40     4.87e-06     4.87e-06     3.05e-05
    177    48     2.45e-06     2.45e-06     2.33e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    177    10     9.28e-07     9.28e-07     1.22e-05
    177    20     7.04e-07     7.04e-07     1.16e-05
    177    30     4.71e-07     4.71e-07     9.64e-06
    177    40     3.85e-07     3.85e-07     9.64e-06
    177    50      8.2e-07      8.2e-07     1.22e-05
    177    60     7.48e-07     7.48e-07     1.32e-05
    177    61     9.48e-07     9.48e-07     1.55e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             177 9414.671    0.005      7.7e-06      7.7e-06     3.61e-05
! Validation        177 9414.671    0.005     9.08e-07     9.08e-07     1.23e-05
Wall time: 9414.672032625
training
# Epoch batch         loss       loss_e      e/N_mae
    178    10      7.6e-06      7.6e-06     4.15e-05
    178    20     3.18e-06     3.18e-06     2.35e-05
    178    30     1.16e-06     1.16e-06     1.61e-05
    178    40     1.15e-06     1.15e-06     1.47e-05
    178    48     6.75e-06     6.75e-06     3.85e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    178    10     7.23e-07     7.23e-07     1.06e-05
    178    20     4.78e-07     4.78e-07     9.32e-06
    178    30     3.17e-07     3.17e-07     7.71e-06
    178    40     3.85e-07     3.85e-07     9.32e-06
    178    50     1.06e-06     1.06e-06     1.19e-05
    178    60     8.22e-07     8.22e-07     1.25e-05
    178    61     6.69e-07     6.69e-07     1.28e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             178 9469.412    0.005     3.94e-06     3.94e-06     2.61e-05
! Validation        178 9469.412    0.005     8.67e-07     8.67e-07     1.19e-05
Wall time: 9469.413133458
training
# Epoch batch         loss       loss_e      e/N_mae
    179    10     5.89e-06     5.89e-06     3.13e-05
    179    20     3.82e-06     3.82e-06     2.82e-05
    179    30     3.14e-06     3.14e-06     2.46e-05
    179    40     8.81e-07     8.81e-07     1.14e-05
    179    48      9.4e-07      9.4e-07     1.45e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    179    10     6.74e-07     6.74e-07     9.64e-06
    179    20     3.87e-07     3.87e-07     8.99e-06
    179    30     2.81e-07     2.81e-07     7.39e-06
    179    40     1.23e-07     1.23e-07     4.82e-06
    179    50      8.9e-07      8.9e-07     1.19e-05
    179    60     8.07e-07     8.07e-07     1.38e-05
    179    61     6.83e-07     6.83e-07     1.34e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             179 9524.736    0.005     3.95e-06     3.95e-06     2.54e-05
! Validation        179 9524.736    0.005     8.33e-07     8.33e-07     1.19e-05
Wall time: 9524.736842583
training
# Epoch batch         loss       loss_e      e/N_mae
    180    10     3.73e-06     3.73e-06     2.42e-05
    180    20     5.47e-06     5.47e-06     3.66e-05
    180    30     2.85e-06     2.85e-06     2.58e-05
    180    40     2.29e-06     2.29e-06     1.96e-05
    180    48     2.46e-06     2.46e-06     2.17e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    180    10     4.67e-07     4.67e-07     1.12e-05
    180    20     4.37e-07     4.37e-07     8.67e-06
    180    30     3.97e-07     3.97e-07     8.35e-06
    180    40     2.94e-07     2.94e-07     8.35e-06
    180    50     1.01e-06     1.01e-06     1.35e-05
    180    60     9.95e-07     9.95e-07     1.61e-05
    180    61     8.74e-07     8.74e-07     1.45e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             180 9579.736    0.005      2.5e-06      2.5e-06      2.1e-05
! Validation        180 9579.736    0.005     8.43e-07     8.43e-07      1.2e-05
Wall time: 9579.737463166
training
# Epoch batch         loss       loss_e      e/N_mae
    181    10     2.51e-06     2.51e-06     2.31e-05
    181    20     1.43e-06     1.43e-06     1.45e-05
    181    30     1.32e-06     1.32e-06      1.6e-05
    181    40     3.75e-06     3.75e-06     2.66e-05
    181    48     1.17e-06     1.17e-06     1.77e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    181    10     4.14e-07     4.14e-07     1.03e-05
    181    20     5.47e-07     5.47e-07     9.32e-06
    181    30     3.68e-07     3.68e-07     8.35e-06
    181    40      2.6e-07      2.6e-07     7.07e-06
    181    50        9e-07        9e-07     1.35e-05
    181    60     7.74e-07     7.74e-07     1.35e-05
    181    61     7.26e-07     7.26e-07     1.28e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             181 9635.002    0.005     2.59e-06     2.59e-06     2.13e-05
! Validation        181 9635.002    0.005     7.63e-07     7.63e-07     1.13e-05
Wall time: 9635.00293075
training
# Epoch batch         loss       loss_e      e/N_mae
    182    10     2.49e-06     2.49e-06     2.01e-05
    182    20     2.16e-06     2.16e-06     1.87e-05
    182    30      3.5e-06      3.5e-06     2.49e-05
    182    40        2e-06        2e-06     2.02e-05
    182    48     1.35e-05     1.35e-05      4.9e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    182    10     5.37e-07     5.37e-07     1.06e-05
    182    20     5.64e-07     5.64e-07     1.06e-05
    182    30      5.3e-07      5.3e-07     1.06e-05
    182    40     2.51e-07     2.51e-07     6.42e-06
    182    50     5.64e-07     5.64e-07     9.64e-06
    182    60     5.28e-07     5.28e-07     1.09e-05
    182    61     1.19e-06     1.19e-06      1.5e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             182 9690.087    0.005     3.48e-06     3.48e-06     2.36e-05
! Validation        182 9690.087    0.005      7.9e-07      7.9e-07     1.13e-05
Wall time: 9690.087262166
training
# Epoch batch         loss       loss_e      e/N_mae
    183    10     1.54e-05     1.54e-05     5.95e-05
    183    20     3.09e-06     3.09e-06     2.59e-05
    183    30     2.86e-06     2.86e-06     2.27e-05
    183    40     3.66e-06     3.66e-06      2.6e-05
    183    48      4.7e-06      4.7e-06     2.97e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    183    10     6.74e-07     6.74e-07     1.16e-05
    183    20     1.01e-06     1.01e-06     1.51e-05
    183    30     3.85e-07     3.85e-07     7.71e-06
    183    40      7.1e-07      7.1e-07     1.09e-05
    183    50     8.75e-07     8.75e-07     1.25e-05
    183    60     4.97e-07     4.97e-07     1.03e-05
    183    61      1.5e-06      1.5e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             183 9744.927    0.005     5.33e-06     5.33e-06     2.97e-05
! Validation        183 9744.927    0.005     8.69e-07     8.69e-07     1.23e-05
Wall time: 9744.927251250001
training
# Epoch batch         loss       loss_e      e/N_mae
    184    10     2.93e-06     2.93e-06     2.55e-05
    184    20     8.88e-06     8.88e-06     4.48e-05
    184    30     4.31e-06     4.31e-06     2.82e-05
    184    40     2.38e-06     2.38e-06      2.1e-05
    184    48      2.9e-06      2.9e-06     2.81e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    184    10     7.14e-07     7.14e-07     1.25e-05
    184    20      9.4e-07      9.4e-07     1.38e-05
    184    30     4.88e-07     4.88e-07     9.32e-06
    184    40     5.24e-07     5.24e-07     9.64e-06
    184    50     9.47e-07     9.47e-07     1.28e-05
    184    60        6e-07        6e-07     1.22e-05
    184    61     1.29e-06     1.29e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             184 9800.084    0.005     3.99e-06     3.99e-06     2.61e-05
! Validation        184 9800.084    0.005     8.54e-07     8.54e-07     1.24e-05
Wall time: 9800.084846916001
training
# Epoch batch         loss       loss_e      e/N_mae
    185    10     3.34e-06     3.34e-06     2.48e-05
    185    20     2.18e-06     2.18e-06     1.87e-05
    185    30     2.24e-06     2.24e-06      1.8e-05
    185    40     4.29e-06     4.29e-06     2.78e-05
    185    48      3.7e-06      3.7e-06     2.73e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    185    10     6.38e-07     6.38e-07     1.35e-05
    185    20        1e-06        1e-06     1.35e-05
    185    30     7.04e-07     7.04e-07     1.19e-05
    185    40      1.2e-07      1.2e-07      4.5e-06
    185    50     8.58e-07     8.58e-07     1.41e-05
    185    60     7.27e-07     7.27e-07     1.22e-05
    185    61     6.41e-07     6.41e-07     1.12e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             185 9855.183    0.005     2.98e-06     2.98e-06     2.21e-05
! Validation        185 9855.183    0.005     7.59e-07     7.59e-07     1.14e-05
Wall time: 9855.183572708
training
# Epoch batch         loss       loss_e      e/N_mae
    186    10     4.79e-06     4.79e-06     2.82e-05
    186    20      2.4e-06      2.4e-06     1.85e-05
    186    30     5.24e-06     5.24e-06     3.06e-05
    186    40     5.39e-06     5.39e-06     3.26e-05
    186    48     2.71e-06     2.71e-06     2.73e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    186    10     7.63e-07     7.63e-07     1.45e-05
    186    20     1.15e-06     1.15e-06     1.45e-05
    186    30     5.96e-07     5.96e-07     1.09e-05
    186    40     2.96e-07     2.96e-07      6.1e-06
    186    50     7.69e-07     7.69e-07     1.38e-05
    186    60     4.56e-07     4.56e-07     1.12e-05
    186    61      1.3e-06      1.3e-06     1.55e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             186 9910.235    0.005     6.79e-06     6.79e-06     3.37e-05
! Validation        186 9910.235    0.005      8.4e-07      8.4e-07     1.22e-05
Wall time: 9910.235831166001
training
# Epoch batch         loss       loss_e      e/N_mae
    187    10     3.03e-06     3.03e-06     2.61e-05
    187    20     2.25e-06     2.25e-06     2.09e-05
    187    30     3.51e-06     3.51e-06     2.38e-05
    187    40     1.71e-06     1.71e-06     1.68e-05
    187    48     1.69e-06     1.69e-06     2.01e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    187    10     6.66e-07     6.66e-07     1.32e-05
    187    20     1.04e-06     1.04e-06     1.51e-05
    187    30     4.71e-07     4.71e-07     1.03e-05
    187    40     2.58e-07     2.58e-07      6.1e-06
    187    50     7.04e-07     7.04e-07     1.12e-05
    187    60     5.54e-07     5.54e-07     1.19e-05
    187    61     1.59e-06     1.59e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             187 9965.284    0.005     4.07e-06     4.07e-06     2.54e-05
! Validation        187 9965.284    0.005     8.19e-07     8.19e-07      1.2e-05
Wall time: 9965.284267791001
training
# Epoch batch         loss       loss_e      e/N_mae
    188    10     2.64e-06     2.64e-06     2.09e-05
    188    20     5.47e-07     5.47e-07     1.01e-05
    188    30     6.87e-07     6.87e-07     1.15e-05
    188    40     2.04e-06     2.04e-06     1.96e-05
    188    48     2.11e-06     2.11e-06     2.41e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    188    10     5.41e-07     5.41e-07     9.96e-06
    188    20      9.4e-07      9.4e-07     1.45e-05
    188    30      2.6e-07      2.6e-07     7.39e-06
    188    40     1.82e-07     1.82e-07     5.46e-06
    188    50     6.97e-07     6.97e-07     1.16e-05
    188    60     6.95e-07     6.95e-07     1.32e-05
    188    61     2.07e-06     2.07e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             188 10020.100    0.005     2.06e-06     2.06e-06     1.86e-05
! Validation        188 10020.100    0.005     7.51e-07     7.51e-07     1.13e-05
Wall time: 10020.100524041
training
# Epoch batch         loss       loss_e      e/N_mae
    189    10      2.7e-06      2.7e-06     2.22e-05
    189    20     1.51e-06     1.51e-06     1.61e-05
    189    30     2.14e-06     2.14e-06     1.94e-05
    189    40     5.22e-06     5.22e-06     2.93e-05
    189    48      3.1e-06      3.1e-06     2.81e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    189    10     5.54e-07     5.54e-07     9.96e-06
    189    20      6.4e-07      6.4e-07     1.25e-05
    189    30     3.17e-07     3.17e-07     8.35e-06
    189    40     2.68e-07     2.68e-07     7.07e-06
    189    50        1e-06        1e-06     1.48e-05
    189    60     3.44e-07     3.44e-07     8.67e-06
    189    61      2.2e-06      2.2e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             189 10075.080    0.005     3.02e-06     3.02e-06     2.22e-05
! Validation        189 10075.080    0.005     7.21e-07     7.21e-07      1.1e-05
Wall time: 10075.08104275
! Best model      189    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    190    10     7.85e-06     7.85e-06     4.04e-05
    190    20     5.96e-06     5.96e-06     3.35e-05
    190    30     9.24e-06     9.24e-06     4.22e-05
    190    40     5.36e-06     5.36e-06     3.11e-05
    190    48     1.04e-05     1.04e-05     5.06e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    190    10     7.08e-07     7.08e-07     1.16e-05
    190    20     1.06e-06     1.06e-06     1.61e-05
    190    30      4.1e-07      4.1e-07     8.99e-06
    190    40     6.04e-07     6.04e-07     9.96e-06
    190    50     1.36e-06     1.36e-06     1.64e-05
    190    60     6.64e-07     6.64e-07     1.25e-05
    190    61     2.08e-06     2.08e-06     2.09e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             190 10130.126    0.005     7.24e-06     7.24e-06     3.51e-05
! Validation        190 10130.126    0.005     8.18e-07     8.18e-07      1.2e-05
Wall time: 10130.127644041
training
# Epoch batch         loss       loss_e      e/N_mae
    191    10     2.76e-06     2.76e-06     2.22e-05
    191    20      3.4e-06      3.4e-06     2.49e-05
    191    30     6.06e-06     6.06e-06      3.6e-05
    191    40     3.25e-06     3.25e-06     2.52e-05
    191    48     4.89e-06     4.89e-06     3.37e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    191    10        7e-07        7e-07     1.25e-05
    191    20     9.95e-07     9.95e-07     1.45e-05
    191    30     3.87e-07     3.87e-07     8.99e-06
    191    40     6.07e-07     6.07e-07     1.03e-05
    191    50     1.81e-06     1.81e-06     1.77e-05
    191    60     9.21e-07     9.21e-07     1.35e-05
    191    61      1.6e-06      1.6e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             191 10185.282    0.005     7.92e-06     7.92e-06     3.66e-05
! Validation        191 10185.282    0.005     8.43e-07     8.43e-07     1.22e-05
Wall time: 10185.283226375
training
# Epoch batch         loss       loss_e      e/N_mae
    192    10     1.03e-05     1.03e-05     4.36e-05
    192    20     1.82e-05     1.82e-05     5.14e-05
    192    30     1.23e-05     1.23e-05     3.99e-05
    192    40     8.51e-06     8.51e-06     3.98e-05
    192    48     6.77e-06     6.77e-06     4.26e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    192    10     8.69e-07     8.69e-07     1.45e-05
    192    20     1.98e-06     1.98e-06     2.06e-05
    192    30     3.91e-07     3.91e-07     8.03e-06
    192    40     6.36e-07     6.36e-07     1.06e-05
    192    50     1.28e-06     1.28e-06     1.64e-05
    192    60     2.06e-06     2.06e-06     2.02e-05
    192    61     3.57e-06     3.57e-06     2.57e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             192 10240.360    0.005      1.1e-05      1.1e-05     4.34e-05
! Validation        192 10240.360    0.005     1.01e-06     1.01e-06     1.32e-05
Wall time: 10240.361095916
training
# Epoch batch         loss       loss_e      e/N_mae
    193    10     2.51e-05     2.51e-05     7.21e-05
    193    20     4.01e-06     4.01e-06      2.4e-05
    193    30     4.76e-06     4.76e-06     2.83e-05
    193    40     6.08e-06     6.08e-06     3.16e-05
    193    48     1.79e-06     1.79e-06     2.09e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    193    10     1.26e-06     1.26e-06      1.7e-05
    193    20     1.98e-06     1.98e-06     2.18e-05
    193    30     4.88e-07     4.88e-07     9.64e-06
    193    40     5.58e-07     5.58e-07     9.32e-06
    193    50     1.44e-06     1.44e-06     1.61e-05
    193    60     1.76e-06     1.76e-06     2.06e-05
    193    61     4.67e-06     4.67e-06     2.94e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             193 10295.360    0.005     8.18e-06     8.18e-06     3.66e-05
! Validation        193 10295.360    0.005     1.05e-06     1.05e-06     1.37e-05
Wall time: 10295.360086416
training
# Epoch batch         loss       loss_e      e/N_mae
    194    10      2.2e-06      2.2e-06     2.09e-05
    194    20     2.86e-06     2.86e-06     2.53e-05
    194    30     3.14e-06     3.14e-06     2.45e-05
    194    40     2.14e-06     2.14e-06     1.87e-05
    194    48     5.18e-06     5.18e-06     3.29e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    194    10     1.06e-06     1.06e-06     1.51e-05
    194    20     1.12e-06     1.12e-06     1.64e-05
    194    30     4.97e-07     4.97e-07     9.64e-06
    194    40      3.3e-07      3.3e-07     7.39e-06
    194    50     1.18e-06     1.18e-06     1.38e-05
    194    60     1.23e-06     1.23e-06     1.67e-05
    194    61     3.22e-06     3.22e-06     2.41e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             194 10350.656    0.005     2.58e-06     2.58e-06     2.08e-05
! Validation        194 10350.656    0.005     9.02e-07     9.02e-07     1.25e-05
Wall time: 10350.657334666
training
# Epoch batch         loss       loss_e      e/N_mae
    195    10     3.81e-06     3.81e-06     2.87e-05
    195    20     3.28e-06     3.28e-06     2.27e-05
    195    30     8.61e-06     8.61e-06     3.64e-05
    195    40     1.05e-05     1.05e-05     4.72e-05
    195    48     9.32e-06     9.32e-06     3.53e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    195    10     8.83e-07     8.83e-07     1.35e-05
    195    20     9.64e-07     9.64e-07     1.51e-05
    195    30     3.44e-07     3.44e-07     8.03e-06
    195    40      3.7e-07      3.7e-07     7.71e-06
    195    50     9.64e-07     9.64e-07     1.35e-05
    195    60     6.19e-07     6.19e-07     1.28e-05
    195    61     3.19e-06     3.19e-06     2.41e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             195 10405.701    0.005     7.55e-06     7.55e-06     3.44e-05
! Validation        195 10405.701    0.005     8.48e-07     8.48e-07     1.22e-05
Wall time: 10405.702064541001
training
# Epoch batch         loss       loss_e      e/N_mae
    196    10     1.84e-05     1.84e-05     6.03e-05
    196    20     4.69e-06     4.69e-06     2.82e-05
    196    30     5.83e-06     5.83e-06     3.14e-05
    196    40     5.35e-06     5.35e-06     3.04e-05
    196    48     2.37e-05     2.37e-05     6.59e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    196    10     1.04e-06     1.04e-06     1.51e-05
    196    20     1.19e-06     1.19e-06     1.61e-05
    196    30     5.35e-07     5.35e-07     1.06e-05
    196    40     4.86e-07     4.86e-07     9.32e-06
    196    50      9.4e-07      9.4e-07     1.22e-05
    196    60      5.9e-07      5.9e-07     1.22e-05
    196    61     3.65e-06     3.65e-06     2.68e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             196 10460.956    0.005     1.04e-05     1.04e-05     4.15e-05
! Validation        196 10460.956    0.005     9.99e-07     9.99e-07     1.33e-05
Wall time: 10460.957064291
training
# Epoch batch         loss       loss_e      e/N_mae
    197    10     2.35e-06     2.35e-06     2.21e-05
    197    20     8.01e-06     8.01e-06     3.43e-05
    197    30     3.12e-06     3.12e-06     2.21e-05
    197    40     3.73e-06     3.73e-06     2.53e-05
    197    48     2.64e-08     2.64e-08     2.41e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    197    10     1.31e-06     1.31e-06     1.64e-05
    197    20     1.07e-06     1.07e-06     1.54e-05
    197    30     6.55e-07     6.55e-07     1.19e-05
    197    40     4.29e-07     4.29e-07     9.32e-06
    197    50     1.82e-06     1.82e-06     1.77e-05
    197    60     7.42e-07     7.42e-07     1.35e-05
    197    61     3.61e-06     3.61e-06     2.68e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             197 10516.168    0.005     5.96e-06     5.96e-06     3.12e-05
! Validation        197 10516.168    0.005      1.1e-06      1.1e-06      1.4e-05
Wall time: 10516.169177708
training
# Epoch batch         loss       loss_e      e/N_mae
    198    10     8.56e-06     8.56e-06     3.23e-05
    198    20     1.92e-06     1.92e-06     1.94e-05
    198    30     1.93e-06     1.93e-06     1.94e-05
    198    40     2.55e-06     2.55e-06     2.21e-05
    198    48     1.72e-06     1.72e-06     1.93e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    198    10     6.83e-07     6.83e-07     1.16e-05
    198    20     1.17e-06     1.17e-06     1.54e-05
    198    30     3.61e-07     3.61e-07     8.67e-06
    198    40      5.2e-07      5.2e-07     1.03e-05
    198    50     1.45e-06     1.45e-06     1.64e-05
    198    60     5.66e-07     5.66e-07     1.22e-05
    198    61     2.78e-06     2.78e-06     2.41e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             198 10570.944    0.005     3.19e-06     3.19e-06     2.31e-05
! Validation        198 10570.944    0.005     9.31e-07     9.31e-07      1.3e-05
Wall time: 10570.945322083
training
# Epoch batch         loss       loss_e      e/N_mae
    199    10     2.18e-06     2.18e-06     1.97e-05
    199    20      1.5e-06      1.5e-06     1.61e-05
    199    30     1.85e-06     1.85e-06     1.99e-05
    199    40     2.19e-06     2.19e-06     2.08e-05
    199    48     6.13e-07     6.13e-07     1.12e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    199    10     6.47e-07     6.47e-07     1.06e-05
    199    20     9.15e-07     9.15e-07     1.38e-05
    199    30      3.7e-07      3.7e-07     9.32e-06
    199    40     1.69e-07     1.69e-07      6.1e-06
    199    50     1.04e-06     1.04e-06     1.41e-05
    199    60     5.26e-07     5.26e-07     1.19e-05
    199    61     2.63e-06     2.63e-06     2.36e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             199 10626.044    0.005     1.82e-06     1.82e-06     1.72e-05
! Validation        199 10626.044    0.005      8.8e-07      8.8e-07     1.24e-05
Wall time: 10626.045109833
training
# Epoch batch         loss       loss_e      e/N_mae
    200    10     1.82e-06     1.82e-06      1.9e-05
    200    20     2.01e-06     2.01e-06     1.98e-05
    200    30     1.12e-06     1.12e-06     1.37e-05
    200    40     8.45e-07     8.45e-07     1.12e-05
    200    48     6.87e-07     6.87e-07      1.2e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    200    10     6.59e-07     6.59e-07     1.16e-05
    200    20     6.74e-07     6.74e-07     1.22e-05
    200    30     3.11e-07     3.11e-07     8.03e-06
    200    40     1.94e-07     1.94e-07      6.1e-06
    200    50     1.19e-06     1.19e-06     1.45e-05
    200    60     6.34e-07     6.34e-07     1.32e-05
    200    61     1.93e-06     1.93e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             200 10681.258    0.005     1.66e-06     1.66e-06     1.72e-05
! Validation        200 10681.258    0.005     8.01e-07     8.01e-07     1.17e-05
Wall time: 10681.259500041
training
# Epoch batch         loss       loss_e      e/N_mae
    201    10     9.02e-07     9.02e-07     1.31e-05
    201    20     1.55e-06     1.55e-06     1.76e-05
    201    30     1.43e-06     1.43e-06     1.56e-05
    201    40     1.54e-06     1.54e-06     1.54e-05
    201    48     1.24e-06     1.24e-06     1.53e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    201    10     6.85e-07     6.85e-07     1.16e-05
    201    20     6.81e-07     6.81e-07     1.22e-05
    201    30     2.77e-07     2.77e-07     7.39e-06
    201    40     1.31e-07     1.31e-07     5.46e-06
    201    50     1.15e-06     1.15e-06     1.51e-05
    201    60     4.12e-07     4.12e-07     1.06e-05
    201    61     1.51e-06     1.51e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             201 10736.355    0.005     1.34e-06     1.34e-06     1.52e-05
! Validation        201 10736.355    0.005     7.15e-07     7.15e-07     1.11e-05
Wall time: 10736.355494041
! Best model      201    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    202    10     1.48e-06     1.48e-06      1.7e-05
    202    20     5.15e-07     5.15e-07     1.01e-05
    202    30     8.59e-07     8.59e-07     1.16e-05
    202    40     2.55e-06     2.55e-06      2.3e-05
    202    48     4.08e-06     4.08e-06     3.13e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    202    10     5.83e-07     5.83e-07     1.16e-05
    202    20     6.97e-07     6.97e-07     1.19e-05
    202    30     3.95e-07     3.95e-07     9.32e-06
    202    40     2.51e-07     2.51e-07     7.71e-06
    202    50     8.26e-07     8.26e-07     1.32e-05
    202    60     5.37e-07     5.37e-07     1.16e-05
    202    61     1.55e-06     1.55e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             202 10791.420    0.005     1.39e-06     1.39e-06     1.49e-05
! Validation        202 10791.420    0.005     6.58e-07     6.58e-07     1.07e-05
Wall time: 10791.420526666001
! Best model      202    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    203    10     1.14e-06     1.14e-06     1.33e-05
    203    20     2.17e-06     2.17e-06     1.87e-05
    203    30     5.48e-07     5.48e-07     1.06e-05
    203    40     1.82e-06     1.82e-06     1.81e-05
    203    48     1.32e-06     1.32e-06     1.61e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    203    10      5.9e-07      5.9e-07     1.12e-05
    203    20     7.82e-07     7.82e-07     1.35e-05
    203    30     2.85e-07     2.85e-07     7.39e-06
    203    40     1.56e-07     1.56e-07      6.1e-06
    203    50     7.97e-07     7.97e-07     1.25e-05
    203    60     4.56e-07     4.56e-07     1.03e-05
    203    61     1.37e-06     1.37e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             203 10846.617    0.005     2.07e-06     2.07e-06     1.83e-05
! Validation        203 10846.617    0.005     6.65e-07     6.65e-07     1.08e-05
Wall time: 10846.618154458
training
# Epoch batch         loss       loss_e      e/N_mae
    204    10     4.41e-06     4.41e-06     2.87e-05
    204    20     3.12e-06     3.12e-06     2.03e-05
    204    30     4.47e-07     4.47e-07     8.46e-06
    204    40     3.92e-06     3.92e-06     2.75e-05
    204    48     5.18e-06     5.18e-06     3.53e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    204    10     6.55e-07     6.55e-07     1.12e-05
    204    20     4.99e-07     4.99e-07     1.09e-05
    204    30     4.21e-07     4.21e-07     8.67e-06
    204    40     5.71e-08     5.71e-08     3.85e-06
    204    50        9e-07        9e-07     1.28e-05
    204    60     3.44e-07     3.44e-07     9.32e-06
    204    61     1.53e-06     1.53e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             204 10901.494    0.005     2.46e-06     2.46e-06     2.03e-05
! Validation        204 10901.494    0.005     6.23e-07     6.23e-07     1.04e-05
Wall time: 10901.493897958
! Best model      204    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    205    10     6.38e-06     6.38e-06     3.37e-05
    205    20     2.19e-06     2.19e-06     1.85e-05
    205    30     3.69e-06     3.69e-06     2.75e-05
    205    40     9.53e-06     9.53e-06     4.33e-05
    205    48     1.95e-06     1.95e-06     1.93e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    205    10     5.85e-07     5.85e-07     1.09e-05
    205    20     5.01e-07     5.01e-07     9.32e-06
    205    30     2.43e-07     2.43e-07     5.46e-06
    205    40     1.65e-07     1.65e-07     5.46e-06
    205    50     1.45e-06     1.45e-06     1.73e-05
    205    60     3.76e-07     3.76e-07     8.67e-06
    205    61     1.63e-06     1.63e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             205 10956.591    0.005     4.78e-06     4.78e-06     2.81e-05
! Validation        205 10956.591    0.005     6.37e-07     6.37e-07     1.04e-05
Wall time: 10956.590841416
training
# Epoch batch         loss       loss_e      e/N_mae
    206    10     7.06e-06     7.06e-06     3.75e-05
    206    20     6.35e-06     6.35e-06     2.99e-05
    206    30     5.05e-06     5.05e-06     3.09e-05
    206    40     5.47e-06     5.47e-06     3.14e-05
    206    48      2.9e-06      2.9e-06     2.81e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    206    10     5.33e-07     5.33e-07     9.96e-06
    206    20     7.25e-07     7.25e-07     1.06e-05
    206    30     2.96e-07     2.96e-07     7.39e-06
    206    40     3.11e-07     3.11e-07     6.75e-06
    206    50      1.4e-06      1.4e-06     1.45e-05
    206    60     3.02e-07     3.02e-07     7.39e-06
    206    61     2.25e-06     2.25e-06     2.03e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             206 11011.823    0.005     7.34e-06     7.34e-06     3.44e-05
! Validation        206 11011.823    0.005     6.68e-07     6.68e-07     1.07e-05
Wall time: 11011.823869958
training
# Epoch batch         loss       loss_e      e/N_mae
    207    10      3.6e-06      3.6e-06     2.68e-05
    207    20     6.81e-06     6.81e-06     3.21e-05
    207    30     9.56e-07     9.56e-07     1.32e-05
    207    40     2.75e-06     2.75e-06     2.18e-05
    207    48      2.8e-07      2.8e-07     7.23e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    207    10     5.01e-07     5.01e-07     1.03e-05
    207    20     6.13e-07     6.13e-07     1.12e-05
    207    30     1.88e-07     1.88e-07     5.46e-06
    207    40      1.2e-07      1.2e-07      4.5e-06
    207    50     1.43e-06     1.43e-06     1.41e-05
    207    60     4.16e-07     4.16e-07     8.35e-06
    207    61      3.4e-06      3.4e-06     2.41e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             207 11066.859    0.005     2.62e-06     2.62e-06     2.08e-05
! Validation        207 11066.859    0.005     6.81e-07     6.81e-07     1.06e-05
Wall time: 11066.859501500001
training
# Epoch batch         loss       loss_e      e/N_mae
    208    10     1.26e-06     1.26e-06      1.7e-05
    208    20     1.71e-06     1.71e-06     1.94e-05
    208    30     4.35e-06     4.35e-06     2.93e-05
    208    40     2.93e-06     2.93e-06     2.06e-05
    208    48     1.44e-06     1.44e-06     1.61e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    208    10     3.72e-07     3.72e-07     9.32e-06
    208    20     5.52e-07     5.52e-07     1.06e-05
    208    30     3.02e-07     3.02e-07     8.03e-06
    208    40     1.42e-07     1.42e-07     5.14e-06
    208    50     1.27e-06     1.27e-06     1.41e-05
    208    60     4.61e-07     4.61e-07     8.99e-06
    208    61     2.13e-06     2.13e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             208 11121.920    0.005      1.9e-06      1.9e-06      1.8e-05
! Validation        208 11121.920    0.005     6.47e-07     6.47e-07     1.05e-05
Wall time: 11121.921216416
training
# Epoch batch         loss       loss_e      e/N_mae
    209    10     2.41e-06     2.41e-06     1.97e-05
    209    20     6.28e-07     6.28e-07     1.12e-05
    209    30     6.14e-07     6.14e-07      9.1e-06
    209    40     1.79e-06     1.79e-06      1.9e-05
    209    48     1.67e-06     1.67e-06     2.09e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    209    10     3.42e-07     3.42e-07     9.32e-06
    209    20      5.2e-07      5.2e-07     1.06e-05
    209    30     4.14e-07     4.14e-07     9.64e-06
    209    40     1.69e-07     1.69e-07     5.46e-06
    209    50     1.19e-06     1.19e-06     1.48e-05
    209    60     2.45e-07     2.45e-07     7.39e-06
    209    61     2.06e-06     2.06e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             209 11176.842    0.005     1.47e-06     1.47e-06     1.59e-05
! Validation        209 11176.842    0.005     6.23e-07     6.23e-07     1.03e-05
Wall time: 11176.842458333
training
# Epoch batch         loss       loss_e      e/N_mae
    210    10     7.29e-07     7.29e-07     1.16e-05
    210    20     1.31e-06     1.31e-06     1.48e-05
    210    30        3e-06        3e-06     2.36e-05
    210    40     4.88e-06     4.88e-06     2.58e-05
    210    48     1.62e-06     1.62e-06     2.09e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    210    10     2.41e-07     2.41e-07     7.39e-06
    210    20     7.74e-07     7.74e-07     1.32e-05
    210    30     2.66e-07     2.66e-07     7.07e-06
    210    40     2.66e-07     2.66e-07     6.75e-06
    210    50     1.19e-06     1.19e-06     1.45e-05
    210    60     3.09e-07     3.09e-07     8.35e-06
    210    61     2.02e-06     2.02e-06     2.14e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             210 11232.069    0.005     2.93e-06     2.93e-06     2.18e-05
! Validation        210 11232.069    0.005     5.97e-07     5.97e-07        1e-05
Wall time: 11232.069792916
! Best model      210    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    211    10     1.82e-06     1.82e-06     1.99e-05
    211    20     6.92e-06     6.92e-06     3.37e-05
    211    30     7.61e-06     7.61e-06     3.83e-05
    211    40     6.46e-06     6.46e-06     3.52e-05
    211    48     3.85e-06     3.85e-06     2.33e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    211    10     4.71e-07     4.71e-07     9.64e-06
    211    20     4.84e-07     4.84e-07     1.03e-05
    211    30     2.01e-07     2.01e-07     5.46e-06
    211    40     4.52e-07     4.52e-07     9.32e-06
    211    50     1.05e-06     1.05e-06     1.19e-05
    211    60     2.92e-07     2.92e-07     7.71e-06
    211    61     1.74e-06     1.74e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             211 11287.287    0.005      6.2e-06      6.2e-06     3.25e-05
! Validation        211 11287.287    0.005     5.86e-07     5.86e-07     9.84e-06
Wall time: 11287.287529583
! Best model      211    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    212    10      5.3e-06      5.3e-06     2.84e-05
    212    20     1.87e-06     1.87e-06     1.76e-05
    212    30     2.22e-06     2.22e-06     1.94e-05
    212    40     5.98e-07     5.98e-07     8.99e-06
    212    48     5.28e-09     5.28e-09     8.03e-07
validation
# Epoch batch         loss       loss_e      e/N_mae
    212    10     4.18e-07     4.18e-07     9.96e-06
    212    20     5.11e-07     5.11e-07     1.06e-05
    212    30     3.19e-07     3.19e-07     7.71e-06
    212    40      2.6e-07      2.6e-07     6.42e-06
    212    50     1.23e-06     1.23e-06     1.41e-05
    212    60     5.24e-07     5.24e-07     9.64e-06
    212    61     1.56e-06     1.56e-06     1.87e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             212 11342.307    0.005     2.86e-06     2.86e-06     2.15e-05
! Validation        212 11342.307    0.005     6.14e-07     6.14e-07     1.02e-05
Wall time: 11342.307603291001
training
# Epoch batch         loss       loss_e      e/N_mae
    213    10     7.28e-07     7.28e-07      1.1e-05
    213    20     3.05e-06     3.05e-06     2.44e-05
    213    30     2.34e-06     2.34e-06      2.1e-05
    213    40     9.24e-07     9.24e-07     1.34e-05
    213    48     1.23e-06     1.23e-06     1.85e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    213    10     4.61e-07     4.61e-07     1.06e-05
    213    20      3.7e-07      3.7e-07     8.67e-06
    213    30     3.68e-07     3.68e-07     8.35e-06
    213    40     1.44e-07     1.44e-07     5.46e-06
    213    50     9.45e-07     9.45e-07     1.22e-05
    213    60     3.11e-07     3.11e-07     8.67e-06
    213    61     1.36e-06     1.36e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             213 11397.361    0.005     1.78e-06     1.78e-06     1.75e-05
! Validation        213 11397.361    0.005     5.75e-07     5.75e-07     9.96e-06
Wall time: 11397.361474791
! Best model      213    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    214    10     2.99e-06     2.99e-06     2.29e-05
    214    20     3.94e-06     3.94e-06     2.37e-05
    214    30     4.15e-06     4.15e-06     2.79e-05
    214    40      8.3e-06      8.3e-06     3.97e-05
    214    48      5.1e-06      5.1e-06     3.69e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    214    10     3.78e-07     3.78e-07     9.64e-06
    214    20        7e-07        7e-07     1.25e-05
    214    30     5.85e-07     5.85e-07     1.06e-05
    214    40     1.67e-07     1.67e-07     6.42e-06
    214    50     8.12e-07     8.12e-07     1.28e-05
    214    60     3.15e-07     3.15e-07     9.32e-06
    214    61     1.64e-06     1.64e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             214 11452.166    0.005     3.28e-06     3.28e-06     2.38e-05
! Validation        214 11452.166    0.005     5.54e-07     5.54e-07     9.94e-06
Wall time: 11452.166019958
! Best model      214    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    215    10     1.26e-06     1.26e-06     1.49e-05
    215    20     1.44e-06     1.44e-06      1.6e-05
    215    30     3.98e-06     3.98e-06     2.33e-05
    215    40     3.26e-06     3.26e-06     2.51e-05
    215    48     3.38e-06     3.38e-06     2.73e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    215    10     2.64e-07     2.64e-07     8.35e-06
    215    20     5.75e-07     5.75e-07     1.12e-05
    215    30     6.13e-07     6.13e-07     1.03e-05
    215    40     1.08e-07     1.08e-07     4.82e-06
    215    50     9.07e-07     9.07e-07     1.38e-05
    215    60     8.58e-07     8.58e-07     1.38e-05
    215    61     1.25e-06     1.25e-06      1.5e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             215 11507.299    0.005     2.76e-06     2.76e-06     2.11e-05
! Validation        215 11507.299    0.005     5.68e-07     5.68e-07     9.88e-06
Wall time: 11507.299844875
training
# Epoch batch         loss       loss_e      e/N_mae
    216    10     5.98e-06     5.98e-06     3.76e-05
    216    20     3.91e-06     3.91e-06     2.58e-05
    216    30     3.93e-06     3.93e-06     2.86e-05
    216    40     3.15e-06     3.15e-06      2.3e-05
    216    48     1.79e-06     1.79e-06     2.09e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    216    10     4.63e-07     4.63e-07     8.99e-06
    216    20     7.52e-07     7.52e-07     1.19e-05
    216    30     9.26e-07     9.26e-07     1.25e-05
    216    40     4.86e-08     4.86e-08     2.89e-06
    216    50      5.9e-07      5.9e-07     1.19e-05
    216    60     7.19e-07     7.19e-07     1.28e-05
    216    61     9.37e-07     9.37e-07     1.55e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             216 11562.348    0.005     5.38e-06     5.38e-06      3.1e-05
! Validation        216 11562.348    0.005     5.96e-07     5.96e-07     1.02e-05
Wall time: 11562.348662125
training
# Epoch batch         loss       loss_e      e/N_mae
    217    10     1.04e-05     1.04e-05     4.36e-05
    217    20     2.83e-05     2.83e-05     6.48e-05
    217    30     2.26e-05     2.26e-05     6.94e-05
    217    40     2.23e-05     2.23e-05      6.4e-05
    217    48     1.34e-05     1.34e-05     4.74e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    217    10     6.09e-07     6.09e-07     1.12e-05
    217    20     9.62e-07     9.62e-07     1.45e-05
    217    30     6.85e-07     6.85e-07     1.12e-05
    217    40     2.01e-07     2.01e-07     6.42e-06
    217    50     1.12e-06     1.12e-06     1.64e-05
    217    60     5.03e-07     5.03e-07     1.16e-05
    217    61     1.96e-06     1.96e-06     2.14e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             217 11617.343    0.005     9.84e-06     9.84e-06     4.11e-05
! Validation        217 11617.343    0.005     7.22e-07     7.22e-07     1.14e-05
Wall time: 11617.342999666
training
# Epoch batch         loss       loss_e      e/N_mae
    218    10      5.9e-06      5.9e-06     2.96e-05
    218    20     2.87e-06     2.87e-06      2.3e-05
    218    30     9.82e-06     9.82e-06     3.96e-05
    218    40     4.42e-06     4.42e-06     2.62e-05
    218    48     1.61e-06     1.61e-06     1.77e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    218    10     6.61e-07     6.61e-07     1.03e-05
    218    20     1.01e-06     1.01e-06     1.48e-05
    218    30     8.35e-07     8.35e-07     1.12e-05
    218    40     4.44e-07     4.44e-07     8.67e-06
    218    50     9.26e-07     9.26e-07     1.38e-05
    218    60     4.78e-07     4.78e-07     9.96e-06
    218    61     2.55e-06     2.55e-06     2.46e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             218 11672.447    0.005     4.62e-06     4.62e-06     2.69e-05
! Validation        218 11672.447    0.005      7.5e-07      7.5e-07     1.14e-05
Wall time: 11672.44753325
training
# Epoch batch         loss       loss_e      e/N_mae
    219    10     7.19e-07     7.19e-07     1.16e-05
    219    20     2.76e-06     2.76e-06     2.15e-05
    219    30      1.7e-06      1.7e-06     1.93e-05
    219    40     6.79e-06     6.79e-06     3.33e-05
    219    48     2.35e-06     2.35e-06     1.93e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    219    10     5.05e-07     5.05e-07     1.03e-05
    219    20     8.12e-07     8.12e-07     1.35e-05
    219    30     6.87e-07     6.87e-07     1.12e-05
    219    40     4.25e-07     4.25e-07     8.99e-06
    219    50     7.74e-07     7.74e-07     1.25e-05
    219    60      6.4e-07      6.4e-07     1.12e-05
    219    61     1.75e-06     1.75e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             219 11727.295    0.005     3.73e-06     3.73e-06     2.55e-05
! Validation        219 11727.295    0.005      6.7e-07      6.7e-07      1.1e-05
Wall time: 11727.296499666001
training
# Epoch batch         loss       loss_e      e/N_mae
    220    10      3.6e-06      3.6e-06     2.33e-05
    220    20     3.64e-06     3.64e-06     2.59e-05
    220    30     1.82e-06     1.82e-06     1.62e-05
    220    40     1.21e-06     1.21e-06     1.62e-05
    220    48     1.72e-06     1.72e-06     1.61e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    220    10      3.8e-07      3.8e-07     9.32e-06
    220    20     5.85e-07     5.85e-07     1.06e-05
    220    30     7.74e-07     7.74e-07     1.16e-05
    220    40     2.35e-07     2.35e-07     7.07e-06
    220    50      9.7e-07      9.7e-07     1.51e-05
    220    60      4.5e-07      4.5e-07     1.03e-05
    220    61     1.51e-06     1.51e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             220 11782.421    0.005     2.54e-06     2.54e-06     2.11e-05
! Validation        220 11782.421    0.005     6.21e-07     6.21e-07     1.04e-05
Wall time: 11782.422170958
training
# Epoch batch         loss       loss_e      e/N_mae
    221    10     2.59e-06     2.59e-06     2.07e-05
    221    20     1.11e-06     1.11e-06     1.42e-05
    221    30     5.11e-06     5.11e-06     3.13e-05
    221    40     7.99e-07     7.99e-07     1.26e-05
    221    48     3.86e-07     3.86e-07     8.83e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    221    10     3.42e-07     3.42e-07     7.39e-06
    221    20     5.64e-07     5.64e-07     1.22e-05
    221    30     5.11e-07     5.11e-07     9.96e-06
    221    40      3.3e-07      3.3e-07     7.39e-06
    221    50     1.05e-06     1.05e-06     1.54e-05
    221    60     4.29e-07     4.29e-07     8.03e-06
    221    61     1.84e-06     1.84e-06     1.87e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             221 11837.541    0.005     3.18e-06     3.18e-06     2.31e-05
! Validation        221 11837.541    0.005     6.11e-07     6.11e-07     1.01e-05
Wall time: 11837.541526166
training
# Epoch batch         loss       loss_e      e/N_mae
    222    10     2.52e-06     2.52e-06     2.27e-05
    222    20     1.36e-06     1.36e-06     1.55e-05
    222    30     2.15e-06     2.15e-06     2.07e-05
    222    40      8.5e-07      8.5e-07     1.32e-05
    222    48     1.03e-06     1.03e-06     1.53e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    222    10      4.8e-07      4.8e-07     9.64e-06
    222    20     4.59e-07     4.59e-07     1.03e-05
    222    30     5.64e-07     5.64e-07     1.09e-05
    222    40     1.92e-07     1.92e-07     5.78e-06
    222    50     9.68e-07     9.68e-07     1.32e-05
    222    60     5.05e-07     5.05e-07     9.32e-06
    222    61      1.3e-06      1.3e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             222 11892.428    0.005     1.23e-06     1.23e-06     1.42e-05
! Validation        222 11892.428    0.005     5.71e-07     5.71e-07     9.91e-06
Wall time: 11892.429091875001
training
# Epoch batch         loss       loss_e      e/N_mae
    223    10     9.71e-07     9.71e-07     1.23e-05
    223    20     2.36e-06     2.36e-06     2.02e-05
    223    30     2.85e-06     2.85e-06     2.41e-05
    223    40     2.91e-06     2.91e-06     2.33e-05
    223    48     3.49e-06     3.49e-06     2.73e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    223    10     3.23e-07     3.23e-07     6.75e-06
    223    20     4.73e-07     4.73e-07     1.06e-05
    223    30     4.31e-07     4.31e-07     8.35e-06
    223    40     9.72e-08     9.72e-08     4.18e-06
    223    50     1.07e-06     1.07e-06     1.28e-05
    223    60     5.01e-07     5.01e-07     8.67e-06
    223    61     1.13e-06     1.13e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             223 11947.534    0.005     2.64e-06     2.64e-06     2.16e-05
! Validation        223 11947.534    0.005     5.32e-07     5.32e-07     9.32e-06
Wall time: 11947.5355095
! Best model      223    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    224    10     3.33e-06     3.33e-06     2.49e-05
    224    20     3.47e-06     3.47e-06     2.64e-05
    224    30     5.04e-06     5.04e-06     3.42e-05
    224    40     6.33e-06     6.33e-06     3.46e-05
    224    48     2.38e-05     2.38e-05     7.87e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    224    10     4.35e-07     4.35e-07     8.67e-06
    224    20     7.25e-07     7.25e-07     1.19e-05
    224    30      5.6e-07      5.6e-07     9.32e-06
    224    40     6.55e-08     6.55e-08     2.89e-06
    224    50     6.93e-07     6.93e-07     1.16e-05
    224    60     4.14e-07     4.14e-07     8.03e-06
    224    61     1.12e-06     1.12e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             224 12002.617    0.005     4.04e-06     4.04e-06     2.52e-05
! Validation        224 12002.617    0.005     5.27e-07     5.27e-07     9.52e-06
Wall time: 12002.618105458001
! Best model      224    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    225    10     3.79e-05     3.79e-05     8.98e-05
    225    20     0.000216     0.000216     0.000227
    225    30     3.29e-05     3.29e-05     8.05e-05
    225    40     2.16e-05     2.16e-05     7.22e-05
    225    48     6.65e-06     6.65e-06     4.26e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    225    10     3.58e-06     3.58e-06      2.6e-05
    225    20      5.6e-06      5.6e-06     3.66e-05
    225    30     4.81e-06     4.81e-06     3.31e-05
    225    40     2.11e-06     2.11e-06     2.25e-05
    225    50     4.89e-06     4.89e-06     2.92e-05
    225    60     3.39e-06     3.39e-06      2.6e-05
    225    61     5.55e-06     5.55e-06     3.27e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             225 12057.568    0.005      4.1e-05      4.1e-05     8.14e-05
! Validation        225 12057.568    0.005     5.62e-06     5.62e-06     3.53e-05
Wall time: 12057.569378875
training
# Epoch batch         loss       loss_e      e/N_mae
    226    10     1.19e-05     1.19e-05     4.21e-05
    226    20     6.18e-06     6.18e-06     3.43e-05
    226    30     5.12e-06     5.12e-06     3.17e-05
    226    40     1.96e-06     1.96e-06     1.87e-05
    226    48     4.11e-06     4.11e-06     2.89e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    226    10     3.08e-06     3.08e-06     2.57e-05
    226    20     6.31e-06     6.31e-06     3.63e-05
    226    30     5.27e-06     5.27e-06     3.69e-05
    226    40     1.99e-06     1.99e-06     2.15e-05
    226    50     4.19e-06     4.19e-06     2.89e-05
    226    60     3.19e-06     3.19e-06      2.7e-05
    226    61     6.99e-06     6.99e-06     3.32e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             226 12112.848    0.005     5.26e-06     5.26e-06     3.02e-05
! Validation        226 12112.848    0.005     5.84e-06     5.84e-06     3.65e-05
Wall time: 12112.849017208
training
# Epoch batch         loss       loss_e      e/N_mae
    227    10     2.56e-06     2.56e-06     2.37e-05
    227    20     1.62e-06     1.62e-06     1.62e-05
    227    30     9.86e-07     9.86e-07     1.25e-05
    227    40     2.31e-06     2.31e-06     1.93e-05
    227    48     3.43e-07     3.43e-07     8.83e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    227    10     1.23e-06     1.23e-06     1.51e-05
    227    20     2.85e-06     2.85e-06     2.31e-05
    227    30     2.59e-06     2.59e-06     2.54e-05
    227    40     1.14e-06     1.14e-06     1.48e-05
    227    50     2.33e-06     2.33e-06     2.22e-05
    227    60     1.03e-06     1.03e-06     1.38e-05
    227    61     4.04e-06     4.04e-06     2.41e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             227 12168.108    0.005     2.02e-06     2.02e-06     1.86e-05
! Validation        227 12168.108    0.005     2.89e-06     2.89e-06     2.46e-05
Wall time: 12168.108575791
training
# Epoch batch         loss       loss_e      e/N_mae
    228    10     1.52e-06     1.52e-06     1.69e-05
    228    20     2.32e-06     2.32e-06     1.98e-05
    228    30     1.86e-06     1.86e-06     1.83e-05
    228    40     3.35e-06     3.35e-06     2.61e-05
    228    48     8.08e-07     8.08e-07     1.37e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    228    10      5.9e-07      5.9e-07     1.03e-05
    228    20     1.71e-06     1.71e-06     1.67e-05
    228    30     1.02e-06     1.02e-06     1.41e-05
    228    40     6.04e-07     6.04e-07     8.67e-06
    228    50     1.53e-06     1.53e-06      1.7e-05
    228    60     2.98e-07     2.98e-07     7.71e-06
    228    61     3.36e-06     3.36e-06     2.57e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             228 12223.076    0.005     1.81e-06     1.81e-06     1.78e-05
! Validation        228 12223.076    0.005      1.6e-06      1.6e-06     1.73e-05
Wall time: 12223.077645833
training
# Epoch batch         loss       loss_e      e/N_mae
    229    10     3.85e-06     3.85e-06     2.53e-05
    229    20     6.53e-07     6.53e-07     1.15e-05
    229    30     2.57e-06     2.57e-06     2.21e-05
    229    40     1.84e-06     1.84e-06     1.65e-05
    229    48      6.6e-07      6.6e-07     1.28e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    229    10     4.04e-07     4.04e-07     1.03e-05
    229    20     1.34e-06     1.34e-06     1.54e-05
    229    30     6.49e-07     6.49e-07     9.96e-06
    229    40     2.41e-07     2.41e-07     5.46e-06
    229    50     1.41e-06     1.41e-06     1.61e-05
    229    60     1.75e-07     1.75e-07     7.07e-06
    229    61     2.64e-06     2.64e-06     2.41e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             229 12278.090    0.005      2.1e-06      2.1e-06     1.91e-05
! Validation        229 12278.090    0.005        1e-06        1e-06     1.31e-05
Wall time: 12278.090229208
training
# Epoch batch         loss       loss_e      e/N_mae
    230    10      6.3e-06      6.3e-06     3.42e-05
    230    20     3.36e-06     3.36e-06     2.47e-05
    230    30     8.16e-06     8.16e-06     3.87e-05
    230    40     9.84e-06     9.84e-06     4.55e-05
    230    48     8.18e-06     8.18e-06      4.5e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    230    10     3.95e-07     3.95e-07     8.67e-06
    230    20     1.88e-06     1.88e-06      1.9e-05
    230    30     8.45e-07     8.45e-07     1.16e-05
    230    40     5.73e-07     5.73e-07     1.03e-05
    230    50     1.14e-06     1.14e-06     1.48e-05
    230    60     2.54e-07     2.54e-07     7.71e-06
    230    61     2.85e-06     2.85e-06     2.52e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             230 12333.060    0.005     6.55e-06     6.55e-06     3.47e-05
! Validation        230 12333.060    0.005     1.16e-06     1.16e-06     1.43e-05
Wall time: 12333.06168275
training
# Epoch batch         loss       loss_e      e/N_mae
    231    10     2.61e-06     2.61e-06      2.2e-05
    231    20     2.21e-06     2.21e-06     2.02e-05
    231    30     1.37e-06     1.37e-06     1.65e-05
    231    40     7.31e-07     7.31e-07     1.19e-05
    231    48     4.33e-07     4.33e-07     8.03e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    231    10     4.99e-07     4.99e-07     8.99e-06
    231    20        2e-06        2e-06     1.83e-05
    231    30     8.54e-07     8.54e-07     1.16e-05
    231    40     6.83e-07     6.83e-07     1.22e-05
    231    50     1.36e-06     1.36e-06     1.35e-05
    231    60      1.1e-07      1.1e-07      4.5e-06
    231    61     3.25e-06     3.25e-06     2.57e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             231 12388.027    0.005     3.74e-06     3.74e-06     2.51e-05
! Validation        231 12388.027    0.005      1.3e-06      1.3e-06     1.54e-05
Wall time: 12388.02718475
training
# Epoch batch         loss       loss_e      e/N_mae
    232    10     1.52e-06     1.52e-06     1.56e-05
    232    20     1.36e-06     1.36e-06     1.38e-05
    232    30     1.08e-06     1.08e-06     1.47e-05
    232    40     5.81e-07     5.81e-07      1.1e-05
    232    48     7.66e-07     7.66e-07     1.45e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    232    10      3.7e-07      3.7e-07     8.67e-06
    232    20     1.46e-06     1.46e-06     1.67e-05
    232    30     6.57e-07     6.57e-07     1.09e-05
    232    40     5.22e-07     5.22e-07     9.64e-06
    232    50     1.45e-06     1.45e-06     1.48e-05
    232    60     2.35e-07     2.35e-07     7.71e-06
    232    61     3.23e-06     3.23e-06     2.62e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             232 12443.088    0.005     1.13e-06     1.13e-06     1.35e-05
! Validation        232 12443.088    0.005     9.78e-07     9.78e-07     1.33e-05
Wall time: 12443.089885458001
training
# Epoch batch         loss       loss_e      e/N_mae
    233    10      1.1e-06      1.1e-06     1.39e-05
    233    20     4.07e-07     4.07e-07     9.53e-06
    233    30      6.4e-07      6.4e-07     1.08e-05
    233    40     3.77e-06     3.77e-06     2.73e-05
    233    48     1.84e-06     1.84e-06     1.93e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    233    10     5.05e-07     5.05e-07     9.32e-06
    233    20     1.38e-06     1.38e-06     1.77e-05
    233    30     7.29e-07     7.29e-07     1.19e-05
    233    40     2.41e-07     2.41e-07     6.75e-06
    233    50     1.23e-06     1.23e-06     1.48e-05
    233    60     1.99e-07     1.99e-07     6.42e-06
    233    61     1.84e-06     1.84e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             233 12498.266    0.005     1.32e-06     1.32e-06     1.47e-05
! Validation        233 12498.266    0.005     7.34e-07     7.34e-07     1.13e-05
Wall time: 12498.266577083
training
# Epoch batch         loss       loss_e      e/N_mae
    234    10     1.02e-06     1.02e-06     1.38e-05
    234    20     1.39e-06     1.39e-06     1.38e-05
    234    30     6.69e-07     6.69e-07     1.12e-05
    234    40     1.31e-06     1.31e-06     1.56e-05
    234    48     4.63e-06     4.63e-06     2.97e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    234    10     2.66e-07     2.66e-07     7.39e-06
    234    20     1.12e-06     1.12e-06     1.61e-05
    234    30     4.86e-07     4.86e-07     1.06e-05
    234    40     2.32e-07     2.32e-07     7.39e-06
    234    50     1.43e-06     1.43e-06     1.64e-05
    234    60     3.36e-07     3.36e-07     8.35e-06
    234    61     2.05e-06     2.05e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             234 12553.198    0.005     1.45e-06     1.45e-06     1.52e-05
! Validation        234 12553.198    0.005     6.38e-07     6.38e-07     1.05e-05
Wall time: 12553.197926291
training
# Epoch batch         loss       loss_e      e/N_mae
    235    10     3.39e-06     3.39e-06     2.77e-05
    235    20     6.38e-06     6.38e-06     3.37e-05
    235    30     3.13e-06     3.13e-06     2.41e-05
    235    40     4.35e-06     4.35e-06     2.97e-05
    235    48     1.91e-06     1.91e-06     1.69e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    235    10     3.17e-07     3.17e-07     8.03e-06
    235    20     1.09e-06     1.09e-06     1.51e-05
    235    30     5.07e-07     5.07e-07     9.64e-06
    235    40     1.63e-07     1.63e-07     5.14e-06
    235    50     1.41e-06     1.41e-06     1.48e-05
    235    60     3.11e-07     3.11e-07     8.67e-06
    235    61     2.26e-06     2.26e-06     2.14e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             235 12608.237    0.005     3.53e-06     3.53e-06     2.45e-05
! Validation        235 12608.237    0.005     6.31e-07     6.31e-07     1.03e-05
Wall time: 12608.237887250001
training
# Epoch batch         loss       loss_e      e/N_mae
    236    10     2.71e-06     2.71e-06     2.13e-05
    236    20     9.06e-07     9.06e-07     1.24e-05
    236    30     1.12e-06     1.12e-06      1.5e-05
    236    40     1.49e-06     1.49e-06     1.64e-05
    236    48     3.22e-07     3.22e-07     9.64e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    236    10     2.45e-07     2.45e-07     7.07e-06
    236    20     8.35e-07     8.35e-07     1.22e-05
    236    30     4.06e-07     4.06e-07     8.99e-06
    236    40     2.81e-07     2.81e-07     7.71e-06
    236    50     8.86e-07     8.86e-07     1.28e-05
    236    60     4.48e-07     4.48e-07     1.09e-05
    236    61     2.66e-06     2.66e-06      2.3e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             236 12663.394    0.005     1.28e-06     1.28e-06     1.48e-05
! Validation        236 12663.394    0.005     5.64e-07     5.64e-07     9.77e-06
Wall time: 12663.395146166
training
# Epoch batch         loss       loss_e      e/N_mae
    237    10     1.26e-06     1.26e-06      1.6e-05
    237    20     1.29e-06     1.29e-06     1.54e-05
    237    30     2.01e-06     2.01e-06     1.84e-05
    237    40     1.32e-06     1.32e-06     1.61e-05
    237    48     4.27e-06     4.27e-06     2.73e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    237    10      1.9e-07      1.9e-07      6.1e-06
    237    20     9.34e-07     9.34e-07     1.41e-05
    237    30     6.47e-07     6.47e-07     1.25e-05
    237    40     1.59e-07     1.59e-07     4.82e-06
    237    50     7.12e-07     7.12e-07     1.09e-05
    237    60     3.57e-07     3.57e-07     8.35e-06
    237    61     1.94e-06     1.94e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             237 12718.390    0.005     1.63e-06     1.63e-06     1.63e-05
! Validation        237 12718.390    0.005     5.21e-07     5.21e-07     9.45e-06
Wall time: 12718.391010333
! Best model      237    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    238    10     1.65e-06     1.65e-06     1.84e-05
    238    20     1.52e-06     1.52e-06     1.71e-05
    238    30     7.19e-07     7.19e-07     1.05e-05
    238    40     7.34e-07     7.34e-07     1.11e-05
    238    48     6.45e-07     6.45e-07     9.64e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    238    10     1.25e-07     1.25e-07     4.82e-06
    238    20     9.76e-07     9.76e-07     1.32e-05
    238    30     3.21e-07     3.21e-07     8.35e-06
    238    40     1.67e-07     1.67e-07     5.46e-06
    238    50     1.15e-06     1.15e-06     1.32e-05
    238    60     3.89e-07     3.89e-07     8.99e-06
    238    61     2.04e-06     2.04e-06     2.09e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             238 12775.874    0.005     1.63e-06     1.63e-06     1.65e-05
! Validation        238 12775.874    0.005     4.98e-07     4.98e-07     9.04e-06
Wall time: 12775.874641666
! Best model      238    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    239    10     1.32e-06     1.32e-06     1.58e-05
    239    20     2.81e-07     2.81e-07     5.78e-06
    239    30     6.71e-07     6.71e-07     9.53e-06
    239    40     4.88e-07     4.88e-07      9.1e-06
    239    48      4.7e-07      4.7e-07     1.04e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    239    10     1.18e-07     1.18e-07     3.85e-06
    239    20     7.31e-07     7.31e-07     1.12e-05
    239    30     4.37e-07     4.37e-07     9.32e-06
    239    40     2.32e-07     2.32e-07     7.07e-06
    239    50     1.12e-06     1.12e-06     1.28e-05
    239    60     3.57e-07     3.57e-07     7.07e-06
    239    61     1.94e-06     1.94e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             239 12832.980    0.005     9.36e-07     9.36e-07     1.25e-05
! Validation        239 12832.980    0.005     4.91e-07     4.91e-07     8.89e-06
Wall time: 12832.981247875001
! Best model      239    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    240    10     7.26e-07     7.26e-07     1.12e-05
    240    20     1.62e-06     1.62e-06     1.75e-05
    240    30     2.55e-06     2.55e-06     2.26e-05
    240    40     2.55e-06     2.55e-06     2.23e-05
    240    48      6.6e-07      6.6e-07     1.28e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    240    10     1.65e-07     1.65e-07     5.46e-06
    240    20     5.98e-07     5.98e-07     1.03e-05
    240    30     2.71e-07     2.71e-07     7.07e-06
    240    40     1.88e-07     1.88e-07     5.46e-06
    240    50     1.26e-06     1.26e-06     1.51e-05
    240    60     3.36e-07     3.36e-07     7.39e-06
    240    61     1.43e-06     1.43e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             240 12889.516    0.005     9.22e-07     9.22e-07     1.23e-05
! Validation        240 12889.516    0.005     4.71e-07     4.71e-07     8.75e-06
Wall time: 12889.517226666001
! Best model      240    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    241    10     8.35e-07     8.35e-07     1.19e-05
    241    20      1.9e-06      1.9e-06     1.65e-05
    241    30     7.16e-07     7.16e-07     1.12e-05
    241    40     9.17e-07     9.17e-07     1.28e-05
    241    48      1.9e-06      1.9e-06     2.09e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    241    10     2.71e-07     2.71e-07     7.71e-06
    241    20     5.92e-07     5.92e-07     9.32e-06
    241    30     2.51e-07     2.51e-07     6.75e-06
    241    40      2.6e-07      2.6e-07     6.75e-06
    241    50     1.43e-06     1.43e-06     1.51e-05
    241    60     2.92e-07     2.92e-07     7.39e-06
    241    61     1.26e-06     1.26e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             241 12945.529    0.005     1.02e-06     1.02e-06     1.32e-05
! Validation        241 12945.529    0.005     4.73e-07     4.73e-07     8.83e-06
Wall time: 12945.530009875
training
# Epoch batch         loss       loss_e      e/N_mae
    242    10     1.86e-06     1.86e-06     1.57e-05
    242    20     2.62e-06     2.62e-06     2.07e-05
    242    30     9.51e-07     9.51e-07     1.19e-05
    242    40     1.87e-06     1.87e-06     1.88e-05
    242    48     3.83e-06     3.83e-06     2.73e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    242    10     8.24e-08     8.24e-08     3.85e-06
    242    20     5.88e-07     5.88e-07     1.03e-05
    242    30     3.23e-07     3.23e-07     7.39e-06
    242    40     1.23e-07     1.23e-07     4.82e-06
    242    50     1.14e-06     1.14e-06     1.35e-05
    242    60     3.19e-07     3.19e-07     8.35e-06
    242    61      8.1e-07      8.1e-07     1.34e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             242 13002.069    0.005     1.81e-06     1.81e-06     1.71e-05
! Validation        242 13002.069    0.005     4.51e-07     4.51e-07     8.65e-06
Wall time: 13002.069496333
! Best model      242    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    243    10      4.1e-06      4.1e-06     2.64e-05
    243    20     1.07e-06     1.07e-06     1.55e-05
    243    30     1.63e-06     1.63e-06     1.85e-05
    243    40      6.3e-07      6.3e-07     1.07e-05
    243    48     1.04e-06     1.04e-06      1.2e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    243    10     3.36e-07     3.36e-07     8.67e-06
    243    20     4.33e-07     4.33e-07     9.64e-06
    243    30     2.64e-07     2.64e-07     6.75e-06
    243    40     1.08e-07     1.08e-07     4.82e-06
    243    50     1.21e-06     1.21e-06     1.41e-05
    243    60     3.25e-07     3.25e-07     9.32e-06
    243    61     1.11e-06     1.11e-06     1.55e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             243 13058.344    0.005     1.85e-06     1.85e-06     1.76e-05
! Validation        243 13058.344    0.005     4.52e-07     4.52e-07     8.91e-06
Wall time: 13058.345234791
training
# Epoch batch         loss       loss_e      e/N_mae
    244    10     2.46e-06     2.46e-06     2.18e-05
    244    20     3.11e-06     3.11e-06     2.57e-05
    244    30     4.59e-06     4.59e-06     2.49e-05
    244    40     8.03e-07     8.03e-07     1.16e-05
    244    48     1.37e-06     1.37e-06     1.85e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    244    10     3.66e-07     3.66e-07     8.67e-06
    244    20      5.2e-07      5.2e-07     9.96e-06
    244    30     4.02e-07     4.02e-07     8.35e-06
    244    40     1.69e-07     1.69e-07     5.78e-06
    244    50     1.24e-06     1.24e-06     1.41e-05
    244    60     3.11e-07     3.11e-07     8.35e-06
    244    61     1.28e-06     1.28e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             244 13114.583    0.005     1.58e-06     1.58e-06     1.59e-05
! Validation        244 13114.583    0.005     4.53e-07     4.53e-07     8.85e-06
Wall time: 13114.584390708
training
# Epoch batch         loss       loss_e      e/N_mae
    245    10     2.05e-06     2.05e-06     1.78e-05
    245    20     1.31e-06     1.31e-06      1.7e-05
    245    30     1.47e-06     1.47e-06     1.57e-05
    245    40      4.7e-07      4.7e-07     1.02e-05
    245    48     1.29e-06     1.29e-06     1.69e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    245    10     3.68e-07     3.68e-07     9.64e-06
    245    20     4.35e-07     4.35e-07     8.99e-06
    245    30     4.18e-07     4.18e-07     8.35e-06
    245    40     2.66e-07     2.66e-07     7.07e-06
    245    50     9.72e-07     9.72e-07     1.22e-05
    245    60     2.26e-07     2.26e-07     7.71e-06
    245    61     1.29e-06     1.29e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             245 13173.226    0.005     1.12e-06     1.12e-06     1.36e-05
! Validation        245 13173.226    0.005     4.45e-07     4.45e-07     8.94e-06
Wall time: 13173.227061375
! Best model      245    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    246    10     1.22e-06     1.22e-06     1.67e-05
    246    20     8.29e-07     8.29e-07     1.24e-05
    246    30     1.21e-06     1.21e-06     1.26e-05
    246    40     2.32e-06     2.32e-06     1.86e-05
    246    48     2.04e-06     2.04e-06     2.01e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    246    10     3.09e-07     3.09e-07     8.99e-06
    246    20      4.1e-07      4.1e-07     8.35e-06
    246    30     3.17e-07     3.17e-07     7.07e-06
    246    40     3.02e-07     3.02e-07     7.39e-06
    246    50     1.35e-06     1.35e-06     1.51e-05
    246    60     3.25e-07     3.25e-07     8.67e-06
    246    61     1.08e-06     1.08e-06     1.55e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             246 13229.668    0.005     1.46e-06     1.46e-06     1.57e-05
! Validation        246 13229.668    0.005     4.32e-07     4.32e-07     8.57e-06
Wall time: 13229.669414291
! Best model      246    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    247    10     1.89e-06     1.89e-06     1.84e-05
    247    20     1.37e-06     1.37e-06     1.66e-05
    247    30     7.94e-07     7.94e-07     9.96e-06
    247    40     1.92e-07     1.92e-07     6.21e-06
    247    48     9.14e-07     9.14e-07     1.28e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    247    10     2.58e-07     2.58e-07     7.07e-06
    247    20     4.63e-07     4.63e-07     9.32e-06
    247    30     3.44e-07     3.44e-07     7.39e-06
    247    40     3.42e-07     3.42e-07     7.71e-06
    247    50     1.24e-06     1.24e-06     1.51e-05
    247    60     3.61e-07     3.61e-07     8.35e-06
    247    61     1.42e-06     1.42e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             247 13299.929    0.005      1.3e-06      1.3e-06     1.46e-05
! Validation        247 13299.929    0.005     4.36e-07     4.36e-07     8.58e-06
Wall time: 13299.930733625
training
# Epoch batch         loss       loss_e      e/N_mae
    248    10     5.05e-07     5.05e-07     1.11e-05
    248    20     8.23e-07     8.23e-07     1.22e-05
    248    30      3.3e-07      3.3e-07     8.25e-06
    248    40     7.46e-07     7.46e-07     9.85e-06
    248    48     3.22e-07     3.22e-07     8.83e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    248    10     2.71e-07     2.71e-07     6.75e-06
    248    20     5.49e-07     5.49e-07     9.64e-06
    248    30     2.94e-07     2.94e-07     7.07e-06
    248    40     2.26e-07     2.26e-07     6.75e-06
    248    50     1.31e-06     1.31e-06     1.57e-05
    248    60     2.87e-07     2.87e-07     7.07e-06
    248    61     1.09e-06     1.09e-06     1.39e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             248 13370.193    0.005     7.48e-07     7.48e-07     1.13e-05
! Validation        248 13370.193    0.005     4.43e-07     4.43e-07     8.69e-06
Wall time: 13370.1950235
training
# Epoch batch         loss       loss_e      e/N_mae
    249    10     5.97e-07     5.97e-07      1.1e-05
    249    20     8.86e-07     8.86e-07     1.25e-05
    249    30      7.3e-07      7.3e-07     1.16e-05
    249    40     9.57e-07     9.57e-07     1.48e-05
    249    48     1.37e-07     1.37e-07     5.62e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    249    10     2.98e-07     2.98e-07     7.71e-06
    249    20     5.16e-07     5.16e-07     9.32e-06
    249    30     3.76e-07     3.76e-07     8.67e-06
    249    40     2.54e-07     2.54e-07     7.07e-06
    249    50     1.01e-06     1.01e-06     1.28e-05
    249    60        3e-07        3e-07     7.07e-06
    249    61     1.11e-06     1.11e-06     1.28e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             249 13440.482    0.005     9.83e-07     9.83e-07     1.31e-05
! Validation        249 13440.482    0.005     4.19e-07     4.19e-07     8.42e-06
Wall time: 13440.483586166001
! Best model      249    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    250    10     1.33e-06     1.33e-06     1.67e-05
    250    20     5.26e-07     5.26e-07     8.67e-06
    250    30     6.35e-07     6.35e-07     1.03e-05
    250    40     6.88e-07     6.88e-07     9.42e-06
    250    48     1.37e-06     1.37e-06     1.53e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    250    10     2.58e-07     2.58e-07     7.39e-06
    250    20     5.14e-07     5.14e-07     1.06e-05
    250    30     3.78e-07     3.78e-07     8.03e-06
    250    40     1.25e-07     1.25e-07     4.82e-06
    250    50     1.01e-06     1.01e-06     1.32e-05
    250    60     2.94e-07     2.94e-07     7.39e-06
    250    61     1.22e-06     1.22e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             250 13510.472    0.005     1.14e-06     1.14e-06     1.38e-05
! Validation        250 13510.472    0.005     4.16e-07     4.16e-07     8.38e-06
Wall time: 13510.473411041
! Best model      250    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    251    10     1.48e-06     1.48e-06     1.54e-05
    251    20     6.63e-06     6.63e-06     3.51e-05
    251    30     2.92e-06     2.92e-06     2.56e-05
    251    40     4.49e-06     4.49e-06     2.67e-05
    251    48     8.38e-06     8.38e-06     4.58e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    251    10     3.38e-07     3.38e-07     9.64e-06
    251    20      3.7e-07      3.7e-07     8.35e-06
    251    30     5.05e-07     5.05e-07     1.03e-05
    251    40      4.1e-07      4.1e-07     9.96e-06
    251    50        1e-06        1e-06     1.45e-05
    251    60     3.95e-07     3.95e-07     8.03e-06
    251    61     1.39e-06     1.39e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             251 13580.605    0.005     4.19e-06     4.19e-06     2.56e-05
! Validation        251 13580.605    0.005     4.61e-07     4.61e-07     8.89e-06
Wall time: 13580.606747375
training
# Epoch batch         loss       loss_e      e/N_mae
    252    10     4.45e-06     4.45e-06     2.57e-05
    252    20     1.29e-06     1.29e-06     1.64e-05
    252    30     2.38e-06     2.38e-06     2.11e-05
    252    40      1.6e-06      1.6e-06      1.5e-05
    252    48     8.98e-08     8.98e-08     4.02e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    252    10        3e-07        3e-07     8.03e-06
    252    20        6e-07        6e-07     1.19e-05
    252    30     4.67e-07     4.67e-07     9.64e-06
    252    40     4.06e-07     4.06e-07     9.32e-06
    252    50     1.48e-06     1.48e-06     1.64e-05
    252    60      4.1e-07      4.1e-07     9.96e-06
    252    61     1.93e-06     1.93e-06     2.14e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             252 13652.881    0.005     3.79e-06     3.79e-06     2.48e-05
! Validation        252 13652.881    0.005     5.16e-07     5.16e-07      9.4e-06
Wall time: 13652.88235125
training
# Epoch batch         loss       loss_e      e/N_mae
    253    10     1.27e-06     1.27e-06     1.53e-05
    253    20     2.21e-06     2.21e-06     2.12e-05
    253    30     4.28e-07     4.28e-07     8.89e-06
    253    40     1.45e-06     1.45e-06     1.55e-05
    253    48     2.86e-06     2.86e-06     2.57e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    253    10     2.66e-07     2.66e-07     7.39e-06
    253    20     5.43e-07     5.43e-07     1.16e-05
    253    30     3.87e-07     3.87e-07     8.35e-06
    253    40     1.16e-07     1.16e-07     4.82e-06
    253    50     1.05e-06     1.05e-06     1.48e-05
    253    60     3.04e-07     3.04e-07     8.35e-06
    253    61     1.64e-06     1.64e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             253 13720.706    0.005     1.53e-06     1.53e-06      1.6e-05
! Validation        253 13720.706    0.005     4.89e-07     4.89e-07     8.94e-06
Wall time: 13720.706822708
training
# Epoch batch         loss       loss_e      e/N_mae
    254    10     1.28e-06     1.28e-06     1.57e-05
    254    20     1.62e-06     1.62e-06     1.49e-05
    254    30     7.38e-07     7.38e-07     1.17e-05
    254    40      1.4e-06      1.4e-06     1.61e-05
    254    48     3.05e-06     3.05e-06     2.57e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    254    10     3.17e-07     3.17e-07     8.03e-06
    254    20     8.86e-07     8.86e-07     1.32e-05
    254    30     6.49e-07     6.49e-07     1.09e-05
    254    40     4.23e-08     4.23e-08     2.57e-06
    254    50     9.19e-07     9.19e-07     1.38e-05
    254    60     4.37e-07     4.37e-07     7.39e-06
    254    61     2.08e-06     2.08e-06     2.09e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             254 13777.409    0.005     1.26e-06     1.26e-06      1.4e-05
! Validation        254 13777.409    0.005     4.77e-07     4.77e-07     8.95e-06
Wall time: 13777.409349916
training
# Epoch batch         loss       loss_e      e/N_mae
    255    10      1.6e-06      1.6e-06     1.66e-05
    255    20     1.85e-06     1.85e-06     1.26e-05
    255    30     1.54e-06     1.54e-06     1.72e-05
    255    40     1.07e-06     1.07e-06     1.39e-05
    255    48     3.06e-07     3.06e-07     8.03e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    255    10     3.95e-07     3.95e-07     9.64e-06
    255    20     9.19e-07     9.19e-07     1.45e-05
    255    30     5.45e-07     5.45e-07     1.06e-05
    255    40     2.96e-08     2.96e-08     2.57e-06
    255    50     6.91e-07     6.91e-07     1.19e-05
    255    60     3.91e-07     3.91e-07     7.39e-06
    255    61     2.04e-06     2.04e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             255 13832.930    0.005     2.18e-06     2.18e-06      1.9e-05
! Validation        255 13832.930    0.005     4.55e-07     4.55e-07     8.84e-06
Wall time: 13832.930627333
training
# Epoch batch         loss       loss_e      e/N_mae
    256    10     1.42e-06     1.42e-06     1.77e-05
    256    20     7.64e-07     7.64e-07     1.16e-05
    256    30     1.34e-06     1.34e-06      1.5e-05
    256    40     1.26e-06     1.26e-06     1.38e-05
    256    48     3.01e-06     3.01e-06     2.73e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    256    10     4.52e-07     4.52e-07     1.09e-05
    256    20     6.83e-07     6.83e-07     1.25e-05
    256    30     3.99e-07     3.99e-07     9.64e-06
    256    40     1.52e-07     1.52e-07     5.14e-06
    256    50        1e-06        1e-06     1.45e-05
    256    60     2.81e-07     2.81e-07     8.67e-06
    256    61     1.84e-06     1.84e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             256 13889.130    0.005     1.64e-06     1.64e-06     1.64e-05
! Validation        256 13889.130    0.005     4.41e-07     4.41e-07      8.6e-06
Wall time: 13889.13135025
training
# Epoch batch         loss       loss_e      e/N_mae
    257    10     1.67e-06     1.67e-06     1.81e-05
    257    20     1.94e-06     1.94e-06     1.85e-05
    257    30     4.96e-06     4.96e-06     3.07e-05
    257    40     5.93e-06     5.93e-06     3.75e-05
    257    48     2.39e-06     2.39e-06     2.57e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    257    10     2.56e-07     2.56e-07     8.03e-06
    257    20     5.28e-07     5.28e-07     1.09e-05
    257    30     2.32e-07     2.32e-07      6.1e-06
    257    40      1.1e-07      1.1e-07      4.5e-06
    257    50     1.34e-06     1.34e-06     1.67e-05
    257    60     3.04e-07     3.04e-07     8.03e-06
    257    61     2.49e-06     2.49e-06     2.25e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             257 13945.641    0.005      3.3e-06      3.3e-06     2.38e-05
! Validation        257 13945.641    0.005      4.5e-07      4.5e-07     8.75e-06
Wall time: 13945.642586166001
training
# Epoch batch         loss       loss_e      e/N_mae
    258    10     6.46e-06     6.46e-06     3.56e-05
    258    20     7.47e-06     7.47e-06        4e-05
    258    30     7.09e-06     7.09e-06     3.79e-05
    258    40     5.42e-06     5.42e-06     2.97e-05
    258    48     2.82e-06     2.82e-06     2.09e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    258    10     2.87e-07     2.87e-07     6.42e-06
    258    20      9.7e-07      9.7e-07     1.51e-05
    258    30     4.21e-07     4.21e-07     8.67e-06
    258    40     7.78e-07     7.78e-07     1.25e-05
    258    50     9.51e-07     9.51e-07     1.35e-05
    258    60     3.68e-07     3.68e-07     7.39e-06
    258    61     2.04e-06     2.04e-06      2.3e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             258 14002.038    0.005      9.7e-06      9.7e-06     3.97e-05
! Validation        258 14002.038    0.005     6.05e-07     6.05e-07     1.02e-05
Wall time: 14002.039111541
training
# Epoch batch         loss       loss_e      e/N_mae
    259    10     2.72e-06     2.72e-06     2.22e-05
    259    20     2.83e-06     2.83e-06     2.36e-05
    259    30     6.58e-07     6.58e-07     1.15e-05
    259    40     1.67e-06     1.67e-06     1.87e-05
    259    48     2.58e-06     2.58e-06     2.09e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    259    10     3.13e-07     3.13e-07     6.75e-06
    259    20      9.7e-07      9.7e-07     1.48e-05
    259    30     5.64e-07     5.64e-07     1.03e-05
    259    40     3.28e-07     3.28e-07     8.35e-06
    259    50      7.1e-07      7.1e-07     1.16e-05
    259    60     2.92e-07     2.92e-07     6.42e-06
    259    61     1.63e-06     1.63e-06     1.87e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             259 14058.331    0.005     2.21e-06     2.21e-06      1.9e-05
! Validation        259 14058.331    0.005     5.38e-07     5.38e-07     9.54e-06
Wall time: 14058.332171083
training
# Epoch batch         loss       loss_e      e/N_mae
    260    10     2.73e-06     2.73e-06     2.17e-05
    260    20     2.13e-06     2.13e-06     2.09e-05
    260    30      2.8e-06      2.8e-06     2.26e-05
    260    40     1.21e-06     1.21e-06     1.48e-05
    260    48      5.6e-07      5.6e-07      1.2e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    260    10     2.49e-07     2.49e-07      6.1e-06
    260    20     5.66e-07     5.66e-07     1.09e-05
    260    30     5.05e-07     5.05e-07     8.67e-06
    260    40     2.49e-07     2.49e-07     7.71e-06
    260    50     9.28e-07     9.28e-07     1.25e-05
    260    60     3.09e-07     3.09e-07     7.07e-06
    260    61     1.95e-06     1.95e-06     2.14e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             260 14114.412    0.005     1.63e-06     1.63e-06     1.72e-05
! Validation        260 14114.412    0.005     5.01e-07     5.01e-07     9.02e-06
Wall time: 14114.412429625001
training
# Epoch batch         loss       loss_e      e/N_mae
    261    10     2.28e-06     2.28e-06     1.99e-05
    261    20     1.85e-06     1.85e-06     1.76e-05
    261    30     1.08e-06     1.08e-06     1.21e-05
    261    40     6.18e-06     6.18e-06     3.58e-05
    261    48     1.08e-06     1.08e-06     1.69e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    261    10     1.84e-07     1.84e-07     6.75e-06
    261    20     6.83e-07     6.83e-07     1.19e-05
    261    30     4.35e-07     4.35e-07     7.71e-06
    261    40        3e-07        3e-07     7.71e-06
    261    50     9.53e-07     9.53e-07     1.32e-05
    261    60     2.64e-07     2.64e-07     7.07e-06
    261    61     1.99e-06     1.99e-06     2.09e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             261 14171.247    0.005     2.53e-06     2.53e-06     2.06e-05
! Validation        261 14171.247    0.005     4.98e-07     4.98e-07      9.1e-06
Wall time: 14171.247860166
training
# Epoch batch         loss       loss_e      e/N_mae
    262    10     3.44e-06     3.44e-06     2.68e-05
    262    20     7.16e-06     7.16e-06     3.58e-05
    262    30     4.52e-06     4.52e-06      2.9e-05
    262    40     7.05e-06     7.05e-06     3.53e-05
    262    48     2.67e-06     2.67e-06     2.41e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    262    10     1.23e-07     1.23e-07     4.18e-06
    262    20     4.52e-07     4.52e-07     1.06e-05
    262    30     3.97e-07     3.97e-07     9.32e-06
    262    40     2.87e-07     2.87e-07     7.71e-06
    262    50     9.68e-07     9.68e-07     1.28e-05
    262    60     3.06e-07     3.06e-07      4.5e-06
    262    61     1.96e-06     1.96e-06     2.03e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             262 14228.432    0.005     4.68e-06     4.68e-06     2.82e-05
! Validation        262 14228.432    0.005     4.74e-07     4.74e-07     8.76e-06
Wall time: 14228.433601333001
training
# Epoch batch         loss       loss_e      e/N_mae
    263    10     1.94e-06     1.94e-06      1.8e-05
    263    20     1.74e-05     1.74e-05        5e-05
    263    30      2.2e-05      2.2e-05     7.16e-05
    263    40     1.68e-05     1.68e-05     5.59e-05
    263    48     8.46e-06     8.46e-06     3.53e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    263    10      6.3e-07      6.3e-07     1.16e-05
    263    20     1.41e-06     1.41e-06      1.7e-05
    263    30     8.26e-07     8.26e-07     1.16e-05
    263    40     3.59e-07     3.59e-07     8.35e-06
    263    50     2.03e-06     2.03e-06     2.06e-05
    263    60     1.05e-06     1.05e-06     1.51e-05
    263    61     3.22e-06     3.22e-06     2.36e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             263 14284.834    0.005     1.71e-05     1.71e-05     5.36e-05
! Validation        263 14284.834    0.005     7.96e-07     7.96e-07     1.15e-05
Wall time: 14284.835400416001
training
# Epoch batch         loss       loss_e      e/N_mae
    264    10     2.55e-05     2.55e-05     7.61e-05
    264    20     7.92e-06     7.92e-06     3.97e-05
    264    30     1.19e-05     1.19e-05     4.96e-05
    264    40      2.2e-05      2.2e-05     6.32e-05
    264    48     1.64e-05     1.64e-05     5.38e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    264    10     2.38e-06     2.38e-06     1.96e-05
    264    20     2.04e-06     2.04e-06     2.28e-05
    264    30     1.01e-06     1.01e-06     1.41e-05
    264    40     3.02e-07     3.02e-07     6.75e-06
    264    50     3.17e-06     3.17e-06     2.35e-05
    264    60     1.95e-06     1.95e-06     1.93e-05
    264    61     3.01e-06     3.01e-06     2.41e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             264 14341.149    0.005     2.12e-05     2.12e-05     5.89e-05
! Validation        264 14341.149    0.005     1.33e-06     1.33e-06     1.42e-05
Wall time: 14341.150344166
training
# Epoch batch         loss       loss_e      e/N_mae
    265    10     6.95e-05     6.95e-05     0.000116
    265    20     4.13e-05     4.13e-05     0.000102
    265    30     5.25e-05     5.25e-05     0.000112
    265    40     6.51e-06     6.51e-06     3.72e-05
    265    48     2.95e-05     2.95e-05     8.35e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    265    10     2.14e-06     2.14e-06     2.15e-05
    265    20     1.44e-06     1.44e-06     1.64e-05
    265    30     2.27e-06     2.27e-06     2.28e-05
    265    40     4.02e-07     4.02e-07     8.99e-06
    265    50     4.53e-06     4.53e-06     2.76e-05
    265    60        9e-07        9e-07     1.38e-05
    265    61     3.17e-06     3.17e-06     2.78e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             265 14397.562    0.005     3.76e-05     3.76e-05     8.11e-05
! Validation        265 14397.562    0.005     1.95e-06     1.95e-06      1.7e-05
Wall time: 14397.562985416
training
# Epoch batch         loss       loss_e      e/N_mae
    266    10     2.89e-05     2.89e-05     6.98e-05
    266    20     4.77e-06     4.77e-06     3.03e-05
    266    30     4.19e-06     4.19e-06     2.35e-05
    266    40     1.41e-06     1.41e-06     1.77e-05
    266    48     1.04e-06     1.04e-06      1.2e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    266    10     1.12e-06     1.12e-06     1.57e-05
    266    20     1.65e-06     1.65e-06     1.77e-05
    266    30     1.53e-06     1.53e-06     1.93e-05
    266    40     4.46e-07     4.46e-07     8.67e-06
    266    50     3.94e-06     3.94e-06     2.51e-05
    266    60     5.75e-07     5.75e-07     1.09e-05
    266    61      4.4e-06      4.4e-06     3.16e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             266 14455.187    0.005     7.42e-06     7.42e-06     3.42e-05
! Validation        266 14455.187    0.005     1.63e-06     1.63e-06     1.62e-05
Wall time: 14455.188104125
training
# Epoch batch         loss       loss_e      e/N_mae
    267    10     1.08e-06     1.08e-06     1.41e-05
    267    20     1.89e-06     1.89e-06     1.51e-05
    267    30     7.15e-07     7.15e-07     1.09e-05
    267    40     4.99e-07     4.99e-07     9.32e-06
    267    48     2.11e-07     2.11e-07     6.42e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    267    10     5.98e-07     5.98e-07     1.19e-05
    267    20     1.21e-06     1.21e-06     1.64e-05
    267    30     8.54e-07     8.54e-07     1.38e-05
    267    40     4.61e-07     4.61e-07     8.99e-06
    267    50     2.19e-06     2.19e-06     1.99e-05
    267    60     3.23e-07     3.23e-07     8.99e-06
    267    61     3.79e-06     3.79e-06     2.68e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             267 14512.848    0.005     1.43e-06     1.43e-06     1.58e-05
! Validation        267 14512.848    0.005     1.15e-06     1.15e-06     1.36e-05
Wall time: 14512.849014041
training
# Epoch batch         loss       loss_e      e/N_mae
    268    10     1.42e-06     1.42e-06      1.5e-05
    268    20     6.54e-07     6.54e-07     1.02e-05
    268    30     1.22e-06     1.22e-06     1.48e-05
    268    40     1.12e-06     1.12e-06      1.3e-05
    268    48     1.46e-06     1.46e-06     1.93e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    268    10     2.45e-07     2.45e-07     7.07e-06
    268    20     1.14e-06     1.14e-06     1.51e-05
    268    30     8.62e-07     8.62e-07     1.28e-05
    268    40      4.9e-07      4.9e-07     1.03e-05
    268    50     1.75e-06     1.75e-06      1.8e-05
    268    60     3.68e-07     3.68e-07     9.32e-06
    268    61     3.36e-06     3.36e-06     2.41e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             268 14569.097    0.005     1.49e-06     1.49e-06     1.57e-05
! Validation        268 14569.097    0.005     8.49e-07     8.49e-07     1.18e-05
Wall time: 14569.097657083
training
# Epoch batch         loss       loss_e      e/N_mae
    269    10     1.73e-06     1.73e-06     1.79e-05
    269    20     1.05e-06     1.05e-06     1.41e-05
    269    30     1.49e-06     1.49e-06     1.83e-05
    269    40     9.43e-07     9.43e-07     1.36e-05
    269    48     6.76e-07     6.76e-07     1.28e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    269    10     9.72e-08     9.72e-08      4.5e-06
    269    20     1.02e-06     1.02e-06     1.45e-05
    269    30     6.02e-07     6.02e-07     1.06e-05
    269    40     3.74e-07     3.74e-07     9.32e-06
    269    50      1.7e-06      1.7e-06     1.83e-05
    269    60     3.02e-07     3.02e-07     6.75e-06
    269    61     3.67e-06     3.67e-06     2.57e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             269 14625.980    0.005     1.31e-06     1.31e-06     1.52e-05
! Validation        269 14625.980    0.005      7.2e-07      7.2e-07     1.06e-05
Wall time: 14625.980707666
training
# Epoch batch         loss       loss_e      e/N_mae
    270    10     4.92e-07     4.92e-07     9.64e-06
    270    20     5.59e-07     5.59e-07      9.1e-06
    270    30     5.28e-07     5.28e-07     9.53e-06
    270    40        5e-07        5e-07     9.32e-06
    270    48     4.23e-07     4.23e-07     9.64e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    270    10     6.34e-08     6.34e-08     3.85e-06
    270    20     9.34e-07     9.34e-07     1.35e-05
    270    30     6.93e-07     6.93e-07     1.25e-05
    270    40     3.53e-07     3.53e-07     8.67e-06
    270    50     1.36e-06     1.36e-06      1.7e-05
    270    60     3.78e-07     3.78e-07     7.71e-06
    270    61     3.67e-06     3.67e-06     2.57e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             270 14682.976    0.005     7.47e-07     7.47e-07     1.14e-05
! Validation        270 14682.976    0.005     6.21e-07     6.21e-07     1.02e-05
Wall time: 14682.977333125
training
# Epoch batch         loss       loss_e      e/N_mae
    271    10     4.22e-07     4.22e-07     8.35e-06
    271    20     7.39e-07     7.39e-07     1.02e-05
    271    30     6.84e-07     6.84e-07     1.12e-05
    271    40     1.16e-06     1.16e-06     1.51e-05
    271    48      6.6e-07      6.6e-07     1.28e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    271    10      7.4e-08      7.4e-08     3.85e-06
    271    20     7.74e-07     7.74e-07     1.25e-05
    271    30      4.9e-07      4.9e-07     9.32e-06
    271    40     1.92e-07     1.92e-07     6.42e-06
    271    50     1.26e-06     1.26e-06     1.64e-05
    271    60     2.87e-07     2.87e-07     8.03e-06
    271    61     3.12e-06     3.12e-06     2.25e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             271 14739.605    0.005     7.87e-07     7.87e-07     1.12e-05
! Validation        271 14739.605    0.005     5.41e-07     5.41e-07     9.45e-06
Wall time: 14739.606014291001
training
# Epoch batch         loss       loss_e      e/N_mae
    272    10     1.43e-06     1.43e-06     1.76e-05
    272    20     4.26e-07     4.26e-07      9.1e-06
    272    30     7.52e-07     7.52e-07     1.15e-05
    272    40     1.02e-06     1.02e-06     1.47e-05
    272    48     7.71e-07     7.71e-07     1.28e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    272    10     1.33e-07     1.33e-07     5.14e-06
    272    20     8.58e-07     8.58e-07     1.35e-05
    272    30     5.18e-07     5.18e-07     1.03e-05
    272    40     1.42e-07     1.42e-07     5.78e-06
    272    50     1.39e-06     1.39e-06     1.64e-05
    272    60     3.17e-07     3.17e-07     8.03e-06
    272    61     3.22e-06     3.22e-06     2.46e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             272 14795.886    0.005     1.02e-06     1.02e-06     1.32e-05
! Validation        272 14795.886    0.005     5.18e-07     5.18e-07     9.21e-06
Wall time: 14795.887044375
training
# Epoch batch         loss       loss_e      e/N_mae
    273    10      7.8e-07      7.8e-07     1.26e-05
    273    20     4.95e-07     4.95e-07      9.1e-06
    273    30     1.79e-06     1.79e-06     1.65e-05
    273    40     4.95e-07     4.95e-07     9.32e-06
    273    48     1.99e-06     1.99e-06     1.93e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    273    10     1.35e-07     1.35e-07     5.46e-06
    273    20     6.68e-07     6.68e-07     1.09e-05
    273    30     4.02e-07     4.02e-07     9.32e-06
    273    40     1.69e-07     1.69e-07     5.14e-06
    273    50     1.59e-06     1.59e-06      1.7e-05
    273    60      3.7e-07      3.7e-07     8.35e-06
    273    61     2.87e-06     2.87e-06      2.2e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             273 14852.388    0.005     1.06e-06     1.06e-06     1.31e-05
! Validation        273 14852.388    0.005     4.77e-07     4.77e-07     8.87e-06
Wall time: 14852.389344625
training
# Epoch batch         loss       loss_e      e/N_mae
    274    10     4.66e-07     4.66e-07     9.64e-06
    274    20     2.43e-06     2.43e-06     1.76e-05
    274    30     1.97e-06     1.97e-06     1.93e-05
    274    40     1.52e-06     1.52e-06     1.51e-05
    274    48     1.97e-06     1.97e-06     2.17e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    274    10     1.27e-07     1.27e-07     4.82e-06
    274    20     6.34e-07     6.34e-07     1.16e-05
    274    30     5.71e-07     5.71e-07     1.22e-05
    274    40     1.29e-07     1.29e-07     5.14e-06
    274    50     1.16e-06     1.16e-06     1.35e-05
    274    60     1.65e-07     1.65e-07     5.78e-06
    274    61     2.61e-06     2.61e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             274 14908.461    0.005     2.08e-06     2.08e-06     1.79e-05
! Validation        274 14908.461    0.005     4.63e-07     4.63e-07     8.76e-06
Wall time: 14908.461798375
training
# Epoch batch         loss       loss_e      e/N_mae
    275    10      1.9e-06      1.9e-06     1.87e-05
    275    20     5.58e-06     5.58e-06     2.72e-05
    275    30     3.01e-06     3.01e-06     1.93e-05
    275    40     2.04e-06     2.04e-06     1.93e-05
    275    48     9.51e-08     9.51e-08     5.62e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    275    10     1.52e-07     1.52e-07     5.46e-06
    275    20     4.71e-07     4.71e-07     9.96e-06
    275    30      5.2e-07      5.2e-07     1.09e-05
    275    40     1.25e-07     1.25e-07     4.82e-06
    275    50     1.24e-06     1.24e-06     1.48e-05
    275    60     2.64e-07     2.64e-07     7.07e-06
    275    61     2.61e-06     2.61e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             275 14964.140    0.005     2.23e-06     2.23e-06     1.86e-05
! Validation        275 14964.140    0.005     4.39e-07     4.39e-07     8.57e-06
Wall time: 14964.14123375
training
# Epoch batch         loss       loss_e      e/N_mae
    276    10     5.69e-07     5.69e-07     1.03e-05
    276    20     6.82e-07     6.82e-07     1.17e-05
    276    30     2.82e-07     2.82e-07      7.6e-06
    276    40     1.89e-06     1.89e-06     1.84e-05
    276    48            0            0            0
validation
# Epoch batch         loss       loss_e      e/N_mae
    276    10     1.67e-07     1.67e-07     5.78e-06
    276    20     7.12e-07     7.12e-07     1.28e-05
    276    30     5.88e-07     5.88e-07     1.22e-05
    276    40      1.2e-07      1.2e-07      4.5e-06
    276    50     1.33e-06     1.33e-06     1.51e-05
    276    60     3.64e-07     3.64e-07     8.67e-06
    276    61     2.79e-06     2.79e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             276 15019.920    0.005     1.24e-06     1.24e-06     1.46e-05
! Validation        276 15019.920    0.005     4.85e-07     4.85e-07     8.91e-06
Wall time: 15019.921829958
training
# Epoch batch         loss       loss_e      e/N_mae
    277    10     3.35e-07     3.35e-07     8.57e-06
    277    20     7.79e-07     7.79e-07     1.11e-05
    277    30     7.33e-07     7.33e-07     1.06e-05
    277    40      6.5e-07      6.5e-07     1.05e-05
    277    48     4.76e-07     4.76e-07     9.64e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    277    10     1.75e-07     1.75e-07     6.42e-06
    277    20     5.45e-07     5.45e-07     1.06e-05
    277    30     3.11e-07     3.11e-07     8.35e-06
    277    40     2.01e-07     2.01e-07      6.1e-06
    277    50     1.12e-06     1.12e-06     1.45e-05
    277    60     3.04e-07     3.04e-07     7.07e-06
    277    61     2.22e-06     2.22e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             277 15075.909    0.005     5.43e-07     5.43e-07     9.55e-06
! Validation        277 15075.909    0.005     4.35e-07     4.35e-07     8.56e-06
Wall time: 15075.910261
training
# Epoch batch         loss       loss_e      e/N_mae
    278    10     5.26e-07     5.26e-07     9.85e-06
    278    20     2.96e-07     2.96e-07     7.28e-06
    278    30     6.08e-07     6.08e-07     1.12e-05
    278    40     1.14e-06     1.14e-06     1.36e-05
    278    48     2.17e-07     2.17e-07     7.23e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    278    10     1.67e-07     1.67e-07     5.78e-06
    278    20     4.21e-07     4.21e-07     8.67e-06
    278    30     3.25e-07     3.25e-07     8.03e-06
    278    40     1.25e-07     1.25e-07     4.82e-06
    278    50     1.18e-06     1.18e-06     1.41e-05
    278    60     2.22e-07     2.22e-07      4.5e-06
    278    61     1.91e-06     1.91e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             278 15134.168    0.005     4.43e-07     4.43e-07     8.62e-06
! Validation        278 15134.168    0.005     4.04e-07     4.04e-07     8.11e-06
Wall time: 15134.16819675
! Best model      278    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    279    10     3.22e-07     3.22e-07     6.64e-06
    279    20     1.47e-06     1.47e-06      1.6e-05
    279    30     1.15e-06     1.15e-06     1.28e-05
    279    40     9.21e-07     9.21e-07      1.3e-05
    279    48     1.04e-05     1.04e-05     4.18e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    279    10     1.04e-07     1.04e-07      4.5e-06
    279    20     4.54e-07     4.54e-07     8.67e-06
    279    30     3.74e-07     3.74e-07     8.99e-06
    279    40     9.09e-08     9.09e-08     4.18e-06
    279    50     1.08e-06     1.08e-06     1.41e-05
    279    60     2.01e-07     2.01e-07     5.46e-06
    279    61     2.06e-06     2.06e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             279 15190.610    0.005     1.57e-06     1.57e-06     1.55e-05
! Validation        279 15190.610    0.005     3.86e-07     3.86e-07     7.88e-06
Wall time: 15190.611476833
! Best model      279    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    280    10     1.62e-05     1.62e-05     4.95e-05
    280    20     7.16e-06     7.16e-06     3.76e-05
    280    30     1.65e-05     1.65e-05     5.42e-05
    280    40     5.14e-06     5.14e-06     2.74e-05
    280    48      2.2e-06      2.2e-06     2.01e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    280    10     2.66e-07     2.66e-07     7.39e-06
    280    20     5.85e-07     5.85e-07     1.03e-05
    280    30     2.66e-07     2.66e-07     7.07e-06
    280    40      1.9e-07      1.9e-07     7.07e-06
    280    50     1.49e-06     1.49e-06     1.61e-05
    280    60     2.43e-07     2.43e-07     7.71e-06
    280    61     2.83e-06     2.83e-06     2.25e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             280 15246.754    0.005     1.81e-05     1.81e-05     5.46e-05
! Validation        280 15246.754    0.005     6.51e-07     6.51e-07     1.03e-05
Wall time: 15246.75510975
training
# Epoch batch         loss       loss_e      e/N_mae
    281    10     1.39e-05     1.39e-05      5.2e-05
    281    20     1.07e-05     1.07e-05     4.06e-05
    281    30     2.62e-06     2.62e-06     1.94e-05
    281    40     2.76e-06     2.76e-06     2.22e-05
    281    48     1.06e-06     1.06e-06     1.37e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    281    10     4.29e-07     4.29e-07     7.71e-06
    281    20     6.57e-07     6.57e-07     1.09e-05
    281    30     3.28e-07     3.28e-07     8.03e-06
    281    40     1.16e-07     1.16e-07     5.14e-06
    281    50      1.1e-06      1.1e-06     1.48e-05
    281    60     4.69e-07     4.69e-07     1.16e-05
    281    61     3.12e-06     3.12e-06     2.25e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             281 15302.681    0.005     8.59e-06     8.59e-06     3.58e-05
! Validation        281 15302.681    0.005     7.22e-07     7.22e-07     1.09e-05
Wall time: 15302.68238675
training
# Epoch batch         loss       loss_e      e/N_mae
    282    10     1.65e-06     1.65e-06      1.8e-05
    282    20     1.28e-06     1.28e-06     1.75e-05
    282    30     2.87e-06     2.87e-06     2.25e-05
    282    40     1.02e-06     1.02e-06     1.02e-05
    282    48     5.76e-07     5.76e-07     1.12e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    282    10     3.44e-07     3.44e-07     7.71e-06
    282    20     7.14e-07     7.14e-07     1.25e-05
    282    30     2.32e-07     2.32e-07     6.42e-06
    282    40     1.69e-07     1.69e-07      6.1e-06
    282    50     1.08e-06     1.08e-06     1.45e-05
    282    60     6.13e-07     6.13e-07     1.32e-05
    282    61     2.88e-06     2.88e-06     2.25e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             282 15358.933    0.005     1.73e-06     1.73e-06     1.75e-05
! Validation        282 15358.933    0.005     6.38e-07     6.38e-07     1.02e-05
Wall time: 15358.934623416
training
# Epoch batch         loss       loss_e      e/N_mae
    283    10     2.19e-06     2.19e-06     2.14e-05
    283    20     2.81e-06     2.81e-06     2.05e-05
    283    30     4.93e-06     4.93e-06     2.63e-05
    283    40     4.44e-06     4.44e-06     3.05e-05
    283    48     5.18e-07     5.18e-07      1.2e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    283    10     3.99e-07     3.99e-07     7.71e-06
    283    20     5.39e-07     5.39e-07     1.09e-05
    283    30     2.56e-07     2.56e-07      6.1e-06
    283    40     3.36e-07     3.36e-07     8.35e-06
    283    50     1.39e-06     1.39e-06     1.73e-05
    283    60     3.42e-07     3.42e-07     9.96e-06
    283    61     2.59e-06     2.59e-06      2.2e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             283 15414.663    0.005        2e-06        2e-06     1.83e-05
! Validation        283 15414.663    0.005     5.85e-07     5.85e-07     9.87e-06
Wall time: 15414.66411825
training
# Epoch batch         loss       loss_e      e/N_mae
    284    10     9.55e-07     9.55e-07     1.18e-05
    284    20     9.78e-07     9.78e-07     1.37e-05
    284    30     7.19e-07     7.19e-07     1.12e-05
    284    40     8.52e-07     8.52e-07     1.33e-05
    284    48     2.11e-07     2.11e-07     6.42e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    284    10     2.32e-07     2.32e-07     6.75e-06
    284    20     6.09e-07     6.09e-07     1.12e-05
    284    30     2.09e-07     2.09e-07     4.82e-06
    284    40     3.42e-07     3.42e-07     9.32e-06
    284    50     1.16e-06     1.16e-06     1.57e-05
    284    60     2.87e-07     2.87e-07     8.35e-06
    284    61     2.84e-06     2.84e-06      2.3e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             284 15470.427    0.005     9.09e-07     9.09e-07     1.25e-05
! Validation        284 15470.427    0.005     5.21e-07     5.21e-07     9.27e-06
Wall time: 15470.427608666001
training
# Epoch batch         loss       loss_e      e/N_mae
    285    10     1.71e-06     1.71e-06     1.86e-05
    285    20     7.31e-07     7.31e-07      1.1e-05
    285    30     1.67e-06     1.67e-06     1.61e-05
    285    40     5.38e-07     5.38e-07     1.06e-05
    285    48     4.49e-07     4.49e-07     9.64e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    285    10      3.7e-07      3.7e-07     8.99e-06
    285    20     5.26e-07     5.26e-07     9.64e-06
    285    30     3.49e-07     3.49e-07     8.03e-06
    285    40     2.64e-07     2.64e-07     7.39e-06
    285    50     1.06e-06     1.06e-06     1.38e-05
    285    60     2.94e-07     2.94e-07     8.03e-06
    285    61     2.54e-06     2.54e-06      2.3e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             285 15526.447    0.005     1.03e-06     1.03e-06      1.3e-05
! Validation        285 15526.447    0.005     4.87e-07     4.87e-07     8.96e-06
Wall time: 15526.447537708
training
# Epoch batch         loss       loss_e      e/N_mae
    286    10     2.51e-06     2.51e-06     2.08e-05
    286    20     7.06e-07     7.06e-07     1.09e-05
    286    30     2.58e-06     2.58e-06     2.26e-05
    286    40     2.64e-06     2.64e-06     2.36e-05
    286    48     3.64e-06     3.64e-06     2.73e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    286    10     3.78e-07     3.78e-07     9.64e-06
    286    20     6.51e-07     6.51e-07     1.12e-05
    286    30     4.04e-07     4.04e-07     8.99e-06
    286    40     2.83e-07     2.83e-07     7.71e-06
    286    50     9.49e-07     9.49e-07     1.19e-05
    286    60     2.01e-07     2.01e-07     7.71e-06
    286    61     2.64e-06     2.64e-06      2.3e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             286 15582.673    0.005     1.48e-06     1.48e-06     1.55e-05
! Validation        286 15582.673    0.005     4.56e-07     4.56e-07     8.53e-06
Wall time: 15582.674131708
training
# Epoch batch         loss       loss_e      e/N_mae
    287    10     1.94e-06     1.94e-06     1.93e-05
    287    20     1.03e-06     1.03e-06     1.42e-05
    287    30     6.02e-07     6.02e-07     1.02e-05
    287    40     2.12e-07     2.12e-07     5.89e-06
    287    48     2.64e-07     2.64e-07     6.42e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    287    10     3.53e-07     3.53e-07     8.35e-06
    287    20     5.22e-07     5.22e-07     1.03e-05
    287    30     4.12e-07     4.12e-07     8.35e-06
    287    40     2.13e-07     2.13e-07     6.75e-06
    287    50     8.66e-07     8.66e-07     1.16e-05
    287    60     2.05e-07     2.05e-07     7.07e-06
    287    61     2.34e-06     2.34e-06     2.14e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             287 15639.949    0.005     9.03e-07     9.03e-07     1.24e-05
! Validation        287 15639.949    0.005     4.26e-07     4.26e-07     8.36e-06
Wall time: 15639.950264708
training
# Epoch batch         loss       loss_e      e/N_mae
    288    10      9.6e-07      9.6e-07     1.34e-05
    288    20     5.71e-07     5.71e-07     9.64e-06
    288    30     1.59e-07     1.59e-07     5.14e-06
    288    40     1.42e-06     1.42e-06      1.6e-05
    288    48     6.76e-07     6.76e-07     1.37e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    288    10     5.03e-07     5.03e-07     1.06e-05
    288    20     5.79e-07     5.79e-07     1.06e-05
    288    30     3.68e-07     3.68e-07     8.67e-06
    288    40     2.68e-07     2.68e-07     6.75e-06
    288    50     8.14e-07     8.14e-07     1.12e-05
    288    60     2.13e-07     2.13e-07     6.75e-06
    288    61      2.1e-06      2.1e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             288 15696.082    0.005     6.13e-07     6.13e-07     1.02e-05
! Validation        288 15696.082    0.005     4.07e-07     4.07e-07     8.11e-06
Wall time: 15696.083363541
training
# Epoch batch         loss       loss_e      e/N_mae
    289    10     4.21e-07     4.21e-07     8.67e-06
    289    20     1.39e-06     1.39e-06     1.58e-05
    289    30     7.61e-07     7.61e-07      1.2e-05
    289    40     1.83e-06     1.83e-06     1.77e-05
    289    48     6.18e-07     6.18e-07      1.2e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    289    10      2.9e-07      2.9e-07     8.03e-06
    289    20     6.15e-07     6.15e-07     1.16e-05
    289    30      2.6e-07      2.6e-07      6.1e-06
    289    40     2.75e-07     2.75e-07     7.07e-06
    289    50     1.05e-06     1.05e-06     1.38e-05
    289    60     2.49e-07     2.49e-07     6.75e-06
    289    61     1.83e-06     1.83e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             289 15752.940    0.005     9.95e-07     9.95e-07     1.32e-05
! Validation        289 15752.940    0.005     4.03e-07     4.03e-07     8.18e-06
Wall time: 15752.941055958001
training
# Epoch batch         loss       loss_e      e/N_mae
    290    10     3.06e-06     3.06e-06     2.47e-05
    290    20     1.48e-06     1.48e-06     1.73e-05
    290    30     1.88e-06     1.88e-06      1.7e-05
    290    40     9.45e-07     9.45e-07     1.33e-05
    290    48     9.14e-07     9.14e-07      1.2e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    290    10     1.94e-07     1.94e-07     6.75e-06
    290    20     5.81e-07     5.81e-07     1.03e-05
    290    30     3.42e-07     3.42e-07     7.39e-06
    290    40     3.25e-07     3.25e-07     8.35e-06
    290    50     1.13e-06     1.13e-06     1.51e-05
    290    60     2.92e-07     2.92e-07      6.1e-06
    290    61     1.67e-06     1.67e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             290 15809.073    0.005     1.69e-06     1.69e-06     1.72e-05
! Validation        290 15809.073    0.005     4.15e-07     4.15e-07     8.21e-06
Wall time: 15809.0744215
training
# Epoch batch         loss       loss_e      e/N_mae
    291    10     2.11e-06     2.11e-06     1.91e-05
    291    20     8.78e-07     8.78e-07     1.26e-05
    291    30     9.76e-07     9.76e-07     1.23e-05
    291    40     1.05e-06     1.05e-06     1.46e-05
    291    48     5.08e-06     5.08e-06     2.65e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    291    10     2.41e-07     2.41e-07     6.75e-06
    291    20     4.21e-07     4.21e-07     8.67e-06
    291    30      5.3e-07      5.3e-07     9.64e-06
    291    40     4.52e-07     4.52e-07     9.64e-06
    291    50     1.01e-06     1.01e-06     1.25e-05
    291    60     2.64e-07     2.64e-07     7.07e-06
    291    61     1.29e-06     1.29e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             291 15866.361    0.005     2.18e-06     2.18e-06     1.89e-05
! Validation        291 15866.361    0.005     4.08e-07     4.08e-07     8.26e-06
Wall time: 15866.3623005
training
# Epoch batch         loss       loss_e      e/N_mae
    292    10     3.21e-06     3.21e-06     2.07e-05
    292    20     1.85e-06     1.85e-06     1.94e-05
    292    30     1.77e-06     1.77e-06     1.33e-05
    292    40     1.89e-06     1.89e-06     1.72e-05
    292    48     1.07e-05     1.07e-05     4.02e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    292    10     3.21e-07     3.21e-07     8.99e-06
    292    20      5.3e-07      5.3e-07     1.06e-05
    292    30     5.01e-07     5.01e-07     7.39e-06
    292    40     2.49e-07     2.49e-07     7.07e-06
    292    50     6.49e-07     6.49e-07     1.19e-05
    292    60     5.07e-07     5.07e-07     8.35e-06
    292    61     1.45e-06     1.45e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             292 15922.897    0.005     2.99e-06     2.99e-06     2.16e-05
! Validation        292 15922.897    0.005      4.2e-07      4.2e-07     8.27e-06
Wall time: 15922.898152375
training
# Epoch batch         loss       loss_e      e/N_mae
    293    10     3.83e-06     3.83e-06      2.6e-05
    293    20     6.18e-06     6.18e-06     3.09e-05
    293    30     9.07e-07     9.07e-07     1.34e-05
    293    40        1e-06        1e-06     1.25e-05
    293    48     2.25e-06     2.25e-06     2.09e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    293    10      4.1e-07      4.1e-07     1.06e-05
    293    20     6.89e-07     6.89e-07     1.12e-05
    293    30      4.1e-07      4.1e-07     5.78e-06
    293    40     2.96e-07     2.96e-07     7.71e-06
    293    50     9.91e-07     9.91e-07     1.38e-05
    293    60     5.05e-07     5.05e-07     1.03e-05
    293    61     1.91e-06     1.91e-06     2.03e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             293 15978.907    0.005     3.83e-06     3.83e-06     2.54e-05
! Validation        293 15978.907    0.005     4.73e-07     4.73e-07     9.04e-06
Wall time: 15978.907934125
training
# Epoch batch         loss       loss_e      e/N_mae
    294    10     2.13e-06     2.13e-06     2.07e-05
    294    20     9.43e-07     9.43e-07     1.36e-05
    294    30     5.92e-07     5.92e-07     9.96e-06
    294    40     1.47e-06     1.47e-06     1.41e-05
    294    48     9.51e-08     9.51e-08     5.62e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    294    10     3.25e-07     3.25e-07     9.32e-06
    294    20     5.54e-07     5.54e-07     1.06e-05
    294    30     3.49e-07     3.49e-07     7.71e-06
    294    40     1.73e-07     1.73e-07     5.78e-06
    294    50     5.96e-07     5.96e-07     1.09e-05
    294    60     6.66e-07     6.66e-07     1.03e-05
    294    61     2.31e-06     2.31e-06     2.09e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             294 16035.104    0.005      1.5e-06      1.5e-06     1.63e-05
! Validation        294 16035.104    0.005     4.53e-07     4.53e-07     8.69e-06
Wall time: 16035.105116666
training
# Epoch batch         loss       loss_e      e/N_mae
    295    10     7.97e-07     7.97e-07     1.18e-05
    295    20     7.22e-07     7.22e-07     1.06e-05
    295    30     1.63e-06     1.63e-06     1.76e-05
    295    40     1.33e-06     1.33e-06     1.67e-05
    295    48     1.07e-06     1.07e-06     1.69e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    295    10     2.09e-07     2.09e-07     7.07e-06
    295    20     5.14e-07     5.14e-07     1.09e-05
    295    30     4.63e-07     4.63e-07     8.99e-06
    295    40     2.09e-07     2.09e-07      6.1e-06
    295    50     6.64e-07     6.64e-07     1.09e-05
    295    60     4.16e-07     4.16e-07     8.35e-06
    295    61     2.46e-06     2.46e-06     2.09e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             295 16091.147    0.005     1.55e-06     1.55e-06     1.61e-05
! Validation        295 16091.147    0.005     4.35e-07     4.35e-07     8.47e-06
Wall time: 16091.147953
training
# Epoch batch         loss       loss_e      e/N_mae
    296    10     1.56e-06     1.56e-06     1.82e-05
    296    20      1.3e-06      1.3e-06     1.71e-05
    296    30     3.61e-07     3.61e-07     8.78e-06
    296    40     3.94e-07     3.94e-07     8.46e-06
    296    48     7.24e-07     7.24e-07     1.28e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    296    10     2.22e-07     2.22e-07     7.07e-06
    296    20     4.27e-07     4.27e-07     8.99e-06
    296    30     4.35e-07     4.35e-07     9.32e-06
    296    40     1.46e-07     1.46e-07     4.82e-06
    296    50     6.04e-07     6.04e-07     1.03e-05
    296    60     4.29e-07     4.29e-07     8.67e-06
    296    61     2.08e-06     2.08e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             296 16147.374    0.005     9.22e-07     9.22e-07     1.25e-05
! Validation        296 16147.374    0.005     3.94e-07     3.94e-07     8.11e-06
Wall time: 16147.37495075
training
# Epoch batch         loss       loss_e      e/N_mae
    297    10     4.27e-07     4.27e-07     8.03e-06
    297    20        9e-07        9e-07     1.17e-05
    297    30     3.12e-06     3.12e-06     1.68e-05
    297    40     6.81e-06     6.81e-06     3.29e-05
    297    48     3.62e-06     3.62e-06     2.49e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    297    10     2.11e-07     2.11e-07     6.75e-06
    297    20     5.73e-07     5.73e-07     1.06e-05
    297    30     3.59e-07     3.59e-07     8.67e-06
    297    40     2.09e-07     2.09e-07     6.75e-06
    297    50     6.57e-07     6.57e-07     1.12e-05
    297    60     3.72e-07     3.72e-07     7.07e-06
    297    61     1.74e-06     1.74e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             297 16203.699    0.005      1.6e-06      1.6e-06      1.5e-05
! Validation        297 16203.699    0.005     3.84e-07     3.84e-07     8.05e-06
Wall time: 16203.699802833
! Best model      297    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    298    10     5.26e-06     5.26e-06     3.02e-05
    298    20     7.16e-06     7.16e-06     3.39e-05
    298    30     5.17e-06     5.17e-06     3.33e-05
    298    40     2.95e-06     2.95e-06     2.13e-05
    298    48     2.25e-06     2.25e-06     2.49e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    298    10     1.54e-07     1.54e-07     5.78e-06
    298    20     7.23e-07     7.23e-07     1.32e-05
    298    30     3.25e-07     3.25e-07     7.39e-06
    298    40      2.2e-07      2.2e-07     6.42e-06
    298    50     6.15e-07     6.15e-07     1.19e-05
    298    60     3.28e-07     3.28e-07      6.1e-06
    298    61     1.81e-06     1.81e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             298 16260.552    0.005     5.19e-06     5.19e-06     2.91e-05
! Validation        298 16260.552    0.005     4.01e-07     4.01e-07     8.26e-06
Wall time: 16260.553096
training
# Epoch batch         loss       loss_e      e/N_mae
    299    10     1.02e-06     1.02e-06     1.28e-05
    299    20     1.54e-06     1.54e-06     1.62e-05
    299    30     6.63e-07     6.63e-07     1.12e-05
    299    40     8.04e-07     8.04e-07     1.24e-05
    299    48     3.59e-07     3.59e-07     8.03e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    299    10     1.48e-07     1.48e-07      4.5e-06
    299    20     6.21e-07     6.21e-07     1.25e-05
    299    30     2.98e-07     2.98e-07     7.07e-06
    299    40     2.28e-07     2.28e-07     6.42e-06
    299    50     7.82e-07     7.82e-07     1.32e-05
    299    60     4.44e-07     4.44e-07     6.75e-06
    299    61     2.24e-06     2.24e-06     2.03e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             299 16316.880    0.005     1.77e-06     1.77e-06     1.68e-05
! Validation        299 16316.880    0.005     4.19e-07     4.19e-07     8.29e-06
Wall time: 16316.880918
training
# Epoch batch         loss       loss_e      e/N_mae
    300    10     1.13e-06     1.13e-06     1.67e-05
    300    20     1.08e-06     1.08e-06     1.48e-05
    300    30     2.44e-07     2.44e-07      7.6e-06
    300    40     5.85e-07     5.85e-07     1.03e-05
    300    48     1.95e-07     1.95e-07     5.62e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    300    10     9.09e-08     9.09e-08      4.5e-06
    300    20     5.22e-07     5.22e-07     9.96e-06
    300    30     2.32e-07     2.32e-07     5.78e-06
    300    40     3.34e-07     3.34e-07     8.67e-06
    300    50      7.5e-07      7.5e-07     1.19e-05
    300    60     3.66e-07     3.66e-07     7.07e-06
    300    61     2.35e-06     2.35e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             300 16372.653    0.005     8.94e-07     8.94e-07     1.24e-05
! Validation        300 16372.653    0.005     3.87e-07     3.87e-07     8.03e-06
Wall time: 16372.65384675
training
# Epoch batch         loss       loss_e      e/N_mae
    301    10     3.55e-07     3.55e-07      7.5e-06
    301    20     4.73e-07     4.73e-07      9.1e-06
    301    30     5.77e-07     5.77e-07     1.11e-05
    301    40     5.84e-07     5.84e-07     1.09e-05
    301    48     2.64e-07     2.64e-07     7.23e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    301    10     1.18e-07     1.18e-07      4.5e-06
    301    20     3.72e-07     3.72e-07     8.35e-06
    301    30      2.6e-07      2.6e-07     7.07e-06
    301    40     2.26e-07     2.26e-07     6.75e-06
    301    50     8.33e-07     8.33e-07     1.28e-05
    301    60     2.64e-07     2.64e-07     5.46e-06
    301    61     2.25e-06     2.25e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             301 16428.669    0.005      5.8e-07      5.8e-07     9.85e-06
! Validation        301 16428.669    0.005     3.62e-07     3.62e-07     7.64e-06
Wall time: 16428.6701515
! Best model      301    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    302    10     8.67e-07     8.67e-07      1.3e-05
    302    20     1.29e-06     1.29e-06     1.39e-05
    302    30     8.52e-07     8.52e-07     1.04e-05
    302    40     1.26e-06     1.26e-06     1.37e-05
    302    48     6.13e-07     6.13e-07      1.2e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    302    10     1.92e-07     1.92e-07      6.1e-06
    302    20     4.56e-07     4.56e-07     8.99e-06
    302    30     2.37e-07     2.37e-07     6.75e-06
    302    40     2.28e-07     2.28e-07     5.78e-06
    302    50     7.38e-07     7.38e-07     1.19e-05
    302    60     2.62e-07     2.62e-07     5.14e-06
    302    61     1.64e-06     1.64e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             302 16484.296    0.005     1.04e-06     1.04e-06     1.33e-05
! Validation        302 16484.296    0.005     3.43e-07     3.43e-07     7.64e-06
Wall time: 16484.296255375
! Best model      302    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    303    10     8.38e-07     8.38e-07     1.32e-05
    303    20     6.71e-07     6.71e-07     9.85e-06
    303    30     6.97e-07     6.97e-07     1.07e-05
    303    40     5.25e-07     5.25e-07     9.21e-06
    303    48      9.4e-07      9.4e-07     1.37e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    303    10     1.23e-07     1.23e-07      4.5e-06
    303    20     4.48e-07     4.48e-07     8.67e-06
    303    30     2.94e-07     2.94e-07     6.42e-06
    303    40     2.09e-07     2.09e-07      6.1e-06
    303    50     7.14e-07     7.14e-07     1.16e-05
    303    60     3.23e-07     3.23e-07     5.78e-06
    303    61     1.98e-06     1.98e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             303 16540.467    0.005     7.26e-07     7.26e-07      1.1e-05
! Validation        303 16540.467    0.005     3.42e-07     3.42e-07     7.54e-06
Wall time: 16540.468209625
! Best model      303    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    304    10      3.9e-07      3.9e-07     8.46e-06
    304    20     1.38e-06     1.38e-06     1.64e-05
    304    30      1.2e-07      1.2e-07      4.6e-06
    304    40     6.02e-07     6.02e-07      1.1e-05
    304    48     2.14e-06     2.14e-06     2.25e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    304    10      1.5e-07      1.5e-07     4.82e-06
    304    20     3.23e-07     3.23e-07     7.39e-06
    304    30     1.86e-07     1.86e-07     5.46e-06
    304    40     1.92e-07     1.92e-07     5.46e-06
    304    50     5.49e-07     5.49e-07     1.03e-05
    304    60     2.81e-07     2.81e-07     7.07e-06
    304    61     1.92e-06     1.92e-06     1.55e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             304 16596.546    0.005     9.18e-07     9.18e-07     1.23e-05
! Validation        304 16596.546    0.005     3.39e-07     3.39e-07     7.52e-06
Wall time: 16596.547052208
! Best model      304    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    305    10     4.22e-07     4.22e-07     9.53e-06
    305    20     2.47e-06     2.47e-06     2.32e-05
    305    30     2.59e-06     2.59e-06     1.96e-05
    305    40     1.63e-06     1.63e-06     1.48e-05
    305    48     1.42e-06     1.42e-06     1.93e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    305    10     3.19e-07     3.19e-07     6.75e-06
    305    20      4.5e-07      4.5e-07     8.67e-06
    305    30     4.04e-07     4.04e-07     8.35e-06
    305    40     2.05e-07     2.05e-07      6.1e-06
    305    50      3.7e-07      3.7e-07     8.35e-06
    305    60     2.66e-07     2.66e-07     6.75e-06
    305    61     1.62e-06     1.62e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             305 16652.705    0.005     2.55e-06     2.55e-06     1.95e-05
! Validation        305 16652.705    0.005     3.46e-07     3.46e-07     7.54e-06
Wall time: 16652.705595665997
training
# Epoch batch         loss       loss_e      e/N_mae
    306    10      4.8e-06      4.8e-06     3.08e-05
    306    20     1.88e-06     1.88e-06     1.83e-05
    306    30     3.28e-06     3.28e-06     2.67e-05
    306    40     2.05e-06     2.05e-06     1.76e-05
    306    48     1.04e-06     1.04e-06     1.28e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    306    10     2.32e-07     2.32e-07     6.75e-06
    306    20     4.12e-07     4.12e-07     8.35e-06
    306    30     1.54e-07     1.54e-07     5.78e-06
    306    40     3.19e-07     3.19e-07     8.03e-06
    306    50     1.03e-06     1.03e-06     1.54e-05
    306    60     4.02e-07     4.02e-07     8.67e-06
    306    61     1.62e-06     1.62e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             306 16709.415    0.005     3.74e-06     3.74e-06     2.54e-05
! Validation        306 16709.415    0.005     4.14e-07     4.14e-07     8.47e-06
Wall time: 16709.41604475
training
# Epoch batch         loss       loss_e      e/N_mae
    307    10     6.35e-06     6.35e-06     3.73e-05
    307    20     4.25e-06     4.25e-06     3.14e-05
    307    30     1.37e-06     1.37e-06      1.6e-05
    307    40        3e-06        3e-06     2.53e-05
    307    48     1.61e-06     1.61e-06     1.93e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    307    10     3.09e-07     3.09e-07     8.35e-06
    307    20     4.71e-07     4.71e-07     9.96e-06
    307    30     1.97e-07     1.97e-07     4.82e-06
    307    40     2.07e-07     2.07e-07     5.78e-06
    307    50     9.74e-07     9.74e-07     1.48e-05
    307    60     3.53e-07     3.53e-07     8.99e-06
    307    61     1.64e-06     1.64e-06     1.55e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             307 16766.800    0.005     4.02e-06     4.02e-06     2.69e-05
! Validation        307 16766.800    0.005     4.31e-07     4.31e-07     8.44e-06
Wall time: 16766.801213374998
training
# Epoch batch         loss       loss_e      e/N_mae
    308    10     1.92e-06     1.92e-06     1.63e-05
    308    20     2.39e-06     2.39e-06     2.14e-05
    308    30     1.08e-06     1.08e-06     1.27e-05
    308    40     2.93e-06     2.93e-06     2.47e-05
    308    48     1.72e-06     1.72e-06     1.61e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    308    10     2.09e-07     2.09e-07     6.75e-06
    308    20     4.92e-07     4.92e-07     9.96e-06
    308    30     2.66e-07     2.66e-07     6.42e-06
    308    40     1.37e-07     1.37e-07     3.53e-06
    308    50     9.47e-07     9.47e-07     1.35e-05
    308    60     2.66e-07     2.66e-07     6.75e-06
    308    61     1.68e-06     1.68e-06     1.55e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             308 16822.904    0.005     2.21e-06     2.21e-06     1.94e-05
! Validation        308 16822.904    0.005     4.12e-07     4.12e-07     8.34e-06
Wall time: 16822.905402916
training
# Epoch batch         loss       loss_e      e/N_mae
    309    10     9.25e-07     9.25e-07     1.18e-05
    309    20     1.36e-06     1.36e-06     1.54e-05
    309    30     5.15e-06     5.15e-06      3.2e-05
    309    40     2.21e-06     2.21e-06     1.81e-05
    309    48     6.76e-07     6.76e-07     1.45e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    309    10     3.87e-07     3.87e-07     9.32e-06
    309    20     5.22e-07     5.22e-07     1.12e-05
    309    30     2.94e-07     2.94e-07     7.39e-06
    309    40     1.42e-07     1.42e-07     5.46e-06
    309    50      8.5e-07      8.5e-07     1.25e-05
    309    60     3.51e-07     3.51e-07     8.03e-06
    309    61      1.7e-06      1.7e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             309 16879.256    0.005     3.34e-06     3.34e-06     2.32e-05
! Validation        309 16879.256    0.005     3.99e-07     3.99e-07     8.03e-06
Wall time: 16879.256668625
training
# Epoch batch         loss       loss_e      e/N_mae
    310    10     3.27e-06     3.27e-06     2.42e-05
    310    20     1.26e-06     1.26e-06      1.6e-05
    310    30     9.07e-07     9.07e-07     1.24e-05
    310    40     9.25e-07     9.25e-07     1.33e-05
    310    48     1.32e-07     1.32e-07     5.62e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    310    10     1.99e-07     1.99e-07     6.42e-06
    310    20     5.85e-07     5.85e-07     1.16e-05
    310    30      3.4e-07      3.4e-07     7.39e-06
    310    40     1.73e-07     1.73e-07     5.14e-06
    310    50     6.19e-07     6.19e-07     1.09e-05
    310    60     3.11e-07     3.11e-07     8.03e-06
    310    61     2.27e-06     2.27e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             310 16935.503    0.005     1.97e-06     1.97e-06     1.77e-05
! Validation        310 16935.503    0.005     4.17e-07     4.17e-07     8.21e-06
Wall time: 16935.503821041
training
# Epoch batch         loss       loss_e      e/N_mae
    311    10     4.78e-07     4.78e-07     9.42e-06
    311    20     4.11e-07     4.11e-07     8.89e-06
    311    30      3.2e-07      3.2e-07     8.46e-06
    311    40     1.48e-06     1.48e-06     1.45e-05
    311    48     2.59e-06     2.59e-06     2.41e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    311    10      2.3e-07      2.3e-07     6.75e-06
    311    20     4.71e-07     4.71e-07     9.64e-06
    311    30      4.1e-07      4.1e-07     7.71e-06
    311    40      2.6e-07      2.6e-07     6.75e-06
    311    50     6.19e-07     6.19e-07     1.03e-05
    311    60     1.65e-07     1.65e-07     4.82e-06
    311    61     2.06e-06     2.06e-06     1.87e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             311 16991.889    0.005     9.18e-07     9.18e-07     1.21e-05
! Validation        311 16991.889    0.005     3.85e-07     3.85e-07     7.84e-06
Wall time: 16991.889741
training
# Epoch batch         loss       loss_e      e/N_mae
    312    10     7.39e-07     7.39e-07      1.3e-05
    312    20      3.7e-06      3.7e-06      2.7e-05
    312    30     6.99e-07     6.99e-07     1.04e-05
    312    40     7.12e-07     7.12e-07     1.23e-05
    312    48     1.15e-06     1.15e-06     1.69e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    312    10     1.33e-07     1.33e-07     5.46e-06
    312    20     4.78e-07     4.78e-07     1.06e-05
    312    30     3.55e-07     3.55e-07     7.71e-06
    312    40     2.03e-07     2.03e-07     5.14e-06
    312    50     5.05e-07     5.05e-07     8.99e-06
    312    60     1.67e-07     1.67e-07     6.42e-06
    312    61     2.15e-06     2.15e-06     1.87e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             312 17048.050    0.005     1.27e-06     1.27e-06     1.47e-05
! Validation        312 17048.050    0.005     3.79e-07     3.79e-07     7.79e-06
Wall time: 17048.051498416
training
# Epoch batch         loss       loss_e      e/N_mae
    313    10     9.94e-07     9.94e-07     1.36e-05
    313    20     3.26e-06     3.26e-06     2.51e-05
    313    30      2.3e-06      2.3e-06     2.15e-05
    313    40     1.17e-06     1.17e-06     1.19e-05
    313    48     6.87e-07     6.87e-07     1.12e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    313    10     1.52e-07     1.52e-07     5.78e-06
    313    20      5.3e-07      5.3e-07     1.03e-05
    313    30     3.93e-07     3.93e-07     8.35e-06
    313    40     3.04e-07     3.04e-07     6.42e-06
    313    50     4.63e-07     4.63e-07     8.99e-06
    313    60     1.82e-07     1.82e-07     5.78e-06
    313    61     2.57e-06     2.57e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             313 17104.397    0.005     2.71e-06     2.71e-06      2.1e-05
! Validation        313 17104.397    0.005     4.11e-07     4.11e-07     8.08e-06
Wall time: 17104.397695833
training
# Epoch batch         loss       loss_e      e/N_mae
    314    10      1.7e-06      1.7e-06     1.69e-05
    314    20     1.95e-06     1.95e-06     1.71e-05
    314    30     1.06e-06     1.06e-06      1.3e-05
    314    40      1.1e-06      1.1e-06     1.51e-05
    314    48     5.28e-08     5.28e-08     3.21e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    314    10     1.42e-07     1.42e-07     5.14e-06
    314    20     6.07e-07     6.07e-07     1.16e-05
    314    30     3.36e-07     3.36e-07      6.1e-06
    314    40     2.22e-07     2.22e-07     5.46e-06
    314    50     4.71e-07     4.71e-07     7.71e-06
    314    60     1.67e-07     1.67e-07      6.1e-06
    314    61      2.5e-06      2.5e-06     2.09e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             314 17160.650    0.005      1.2e-06      1.2e-06     1.45e-05
! Validation        314 17160.650    0.005     3.97e-07     3.97e-07     7.86e-06
Wall time: 17160.650371333
training
# Epoch batch         loss       loss_e      e/N_mae
    315    10     7.93e-07     7.93e-07     1.12e-05
    315    20     5.95e-07     5.95e-07     1.07e-05
    315    30     2.57e-06     2.57e-06     2.46e-05
    315    40     1.12e-06     1.12e-06     1.45e-05
    315    48     2.97e-06     2.97e-06     2.73e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    315    10     1.48e-07     1.48e-07      6.1e-06
    315    20     4.21e-07     4.21e-07     9.64e-06
    315    30     2.83e-07     2.83e-07     6.75e-06
    315    40     1.42e-07     1.42e-07     4.18e-06
    315    50     5.62e-07     5.62e-07     8.03e-06
    315    60     2.03e-07     2.03e-07      6.1e-06
    315    61     3.02e-06     3.02e-06      2.3e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             315 17216.832    0.005     1.24e-06     1.24e-06     1.41e-05
! Validation        315 17216.832    0.005     3.95e-07     3.95e-07     7.88e-06
Wall time: 17216.832497416
training
# Epoch batch         loss       loss_e      e/N_mae
    316    10     2.59e-06     2.59e-06      2.3e-05
    316    20     4.66e-06     4.66e-06     2.92e-05
    316    30     4.07e-07     4.07e-07     8.57e-06
    316    40     4.53e-07     4.53e-07     9.21e-06
    316    48     3.43e-07     3.43e-07     9.64e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    316    10     1.08e-07     1.08e-07      4.5e-06
    316    20      4.1e-07      4.1e-07     8.67e-06
    316    30     4.35e-07     4.35e-07     8.03e-06
    316    40     2.28e-07     2.28e-07     5.78e-06
    316    50     5.16e-07     5.16e-07     8.67e-06
    316    60     2.45e-07     2.45e-07     8.03e-06
    316    61     2.48e-06     2.48e-06     2.14e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             316 17272.937    0.005     1.43e-06     1.43e-06     1.53e-05
! Validation        316 17272.937    0.005     3.58e-07     3.58e-07     7.56e-06
Wall time: 17272.937219290998
training
# Epoch batch         loss       loss_e      e/N_mae
    317    10     8.14e-07     8.14e-07     1.33e-05
    317    20     1.17e-06     1.17e-06     1.54e-05
    317    30     1.72e-06     1.72e-06     1.81e-05
    317    40     5.28e-06     5.28e-06     3.09e-05
    317    48     5.08e-06     5.08e-06     2.65e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    317    10      1.5e-07      1.5e-07     5.14e-06
    317    20     4.44e-07     4.44e-07     9.96e-06
    317    30        3e-07        3e-07     7.07e-06
    317    40     1.14e-07     1.14e-07     3.85e-06
    317    50     5.14e-07     5.14e-07     8.35e-06
    317    60     2.11e-07     2.11e-07     6.42e-06
    317    61     2.34e-06     2.34e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             317 17328.924    0.005     1.39e-06     1.39e-06     1.46e-05
! Validation        317 17328.924    0.005     3.48e-07     3.48e-07     7.49e-06
Wall time: 17328.924812166
training
# Epoch batch         loss       loss_e      e/N_mae
    318    10     1.86e-06     1.86e-06     1.78e-05
    318    20     2.25e-06     2.25e-06     2.01e-05
    318    30     1.96e-06     1.96e-06     1.92e-05
    318    40     2.36e-06     2.36e-06      2.1e-05
    318    48     2.64e-08     2.64e-08     2.41e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    318    10     6.97e-08     6.97e-08     3.21e-06
    318    20     4.16e-07     4.16e-07     9.64e-06
    318    30     2.05e-07     2.05e-07     5.46e-06
    318    40     1.54e-07     1.54e-07     5.46e-06
    318    50     4.44e-07     4.44e-07     8.03e-06
    318    60     3.49e-07     3.49e-07     8.03e-06
    318    61     2.63e-06     2.63e-06     2.03e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             318 17385.990    0.005     2.66e-06     2.66e-06     2.13e-05
! Validation        318 17385.990    0.005     3.85e-07     3.85e-07     7.79e-06
Wall time: 17385.990735583
training
# Epoch batch         loss       loss_e      e/N_mae
    319    10     4.55e-07     4.55e-07     8.46e-06
    319    20     1.11e-06     1.11e-06     1.28e-05
    319    30     1.22e-06     1.22e-06      1.5e-05
    319    40     4.35e-07     4.35e-07     9.21e-06
    319    48     8.45e-07     8.45e-07     1.28e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    319    10     1.06e-07     1.06e-07     4.18e-06
    319    20     4.44e-07     4.44e-07     9.32e-06
    319    30     1.27e-07     1.27e-07      4.5e-06
    319    40     1.61e-07     1.61e-07     5.14e-06
    319    50     5.98e-07     5.98e-07     1.03e-05
    319    60      2.9e-07      2.9e-07     7.39e-06
    319    61     3.03e-06     3.03e-06      2.3e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             319 17441.933    0.005     1.42e-06     1.42e-06     1.53e-05
! Validation        319 17441.933    0.005     3.55e-07     3.55e-07     7.33e-06
Wall time: 17441.933679708
training
# Epoch batch         loss       loss_e      e/N_mae
    320    10     6.85e-07     6.85e-07     1.11e-05
    320    20     4.44e-06     4.44e-06     2.47e-05
    320    30     2.53e-06     2.53e-06     1.91e-05
    320    40     2.91e-05     2.91e-05     7.11e-05
    320    48     5.76e-06     5.76e-06     2.89e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    320    10     2.41e-07     2.41e-07     7.07e-06
    320    20      4.4e-07      4.4e-07     9.64e-06
    320    30     5.03e-07     5.03e-07     1.16e-05
    320    40     1.75e-07     1.75e-07      6.1e-06
    320    50     6.57e-07     6.57e-07     1.12e-05
    320    60      2.2e-07      2.2e-07     7.07e-06
    320    61     2.88e-06     2.88e-06     2.25e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             320 17497.687    0.005     7.83e-06     7.83e-06      3.2e-05
! Validation        320 17497.687    0.005     4.53e-07     4.53e-07     8.58e-06
Wall time: 17497.688162832997
training
# Epoch batch         loss       loss_e      e/N_mae
    321    10     9.99e-06     9.99e-06     3.99e-05
    321    20     6.16e-06     6.16e-06     3.34e-05
    321    30     1.83e-06     1.83e-06     1.61e-05
    321    40     4.45e-06     4.45e-06     2.93e-05
    321    48     1.69e-07     1.69e-07     7.23e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    321    10     4.29e-07     4.29e-07     9.96e-06
    321    20     6.66e-07     6.66e-07     1.03e-05
    321    30     6.17e-07     6.17e-07     1.06e-05
    321    40     1.37e-07     1.37e-07     4.82e-06
    321    50     7.88e-07     7.88e-07     1.12e-05
    321    60      2.3e-07      2.3e-07      6.1e-06
    321    61     3.47e-06     3.47e-06     2.46e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             321 17553.870    0.005     4.03e-06     4.03e-06     2.52e-05
! Validation        321 17553.870    0.005     5.37e-07     5.37e-07     9.14e-06
Wall time: 17553.871210957997
training
# Epoch batch         loss       loss_e      e/N_mae
    322    10     1.72e-06     1.72e-06     1.88e-05
    322    20     1.22e-06     1.22e-06     1.65e-05
    322    30     1.67e-06     1.67e-06     1.62e-05
    322    40     8.26e-07     8.26e-07     1.17e-05
    322    48      2.1e-06      2.1e-06     2.09e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    322    10     2.09e-07     2.09e-07     6.42e-06
    322    20     7.86e-07     7.86e-07     1.25e-05
    322    30     4.65e-07     4.65e-07     9.64e-06
    322    40     4.86e-08     4.86e-08     2.89e-06
    322    50     5.73e-07     5.73e-07     9.96e-06
    322    60     2.09e-07     2.09e-07     7.39e-06
    322    61     3.66e-06     3.66e-06     2.52e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             322 17609.592    0.005     1.84e-06     1.84e-06     1.75e-05
! Validation        322 17609.592    0.005     4.83e-07     4.83e-07     8.71e-06
Wall time: 17609.593340916
training
# Epoch batch         loss       loss_e      e/N_mae
    323    10     8.96e-06     8.96e-06     4.24e-05
    323    20     1.44e-06     1.44e-06     1.67e-05
    323    30        6e-06        6e-06      3.5e-05
    323    40     3.34e-06     3.34e-06     2.45e-05
    323    48      1.4e-06      1.4e-06     1.93e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    323    10     3.64e-07     3.64e-07     9.32e-06
    323    20     5.24e-07     5.24e-07     1.03e-05
    323    30     1.97e-07     1.97e-07     5.78e-06
    323    40     1.27e-07     1.27e-07     5.14e-06
    323    50     8.07e-07     8.07e-07     1.19e-05
    323    60     2.41e-07     2.41e-07     8.35e-06
    323    61     2.62e-06     2.62e-06     2.09e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             323 17666.869    0.005      3.9e-06      3.9e-06     2.58e-05
! Validation        323 17666.869    0.005     4.43e-07     4.43e-07     8.61e-06
Wall time: 17666.86952525
training
# Epoch batch         loss       loss_e      e/N_mae
    324    10     9.55e-07     9.55e-07     1.37e-05
    324    20     1.93e-06     1.93e-06     1.83e-05
    324    30     7.03e-07     7.03e-07     1.17e-05
    324    40     9.57e-07     9.57e-07     1.15e-05
    324    48     5.28e-07     5.28e-07     8.03e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    324    10     3.89e-07     3.89e-07     9.32e-06
    324    20     4.54e-07     4.54e-07     9.96e-06
    324    30     1.71e-07     1.71e-07     5.78e-06
    324    40     1.86e-07     1.86e-07      6.1e-06
    324    50     9.26e-07     9.26e-07     1.32e-05
    324    60      2.9e-07      2.9e-07     8.67e-06
    324    61     2.63e-06     2.63e-06     2.09e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             324 17725.139    0.005     1.48e-06     1.48e-06     1.56e-05
! Validation        324 17725.139    0.005     4.35e-07     4.35e-07     8.43e-06
Wall time: 17725.140074749997
training
# Epoch batch         loss       loss_e      e/N_mae
    325    10      1.4e-06      1.4e-06     1.48e-05
    325    20     1.03e-06     1.03e-06     1.26e-05
    325    30     8.98e-07     8.98e-07     1.34e-05
    325    40     3.41e-06     3.41e-06     2.58e-05
    325    48     1.32e-07     1.32e-07     6.42e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    325    10     1.61e-07     1.61e-07     5.46e-06
    325    20     3.19e-07     3.19e-07     8.35e-06
    325    30      9.3e-08      9.3e-08     4.18e-06
    325    40      1.9e-07      1.9e-07     7.07e-06
    325    50     6.76e-07     6.76e-07     1.06e-05
    325    60      3.8e-07      3.8e-07     8.03e-06
    325    61     2.04e-06     2.04e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             325 17781.746    0.005     1.93e-06     1.93e-06     1.82e-05
! Validation        325 17781.746    0.005     3.57e-07     3.57e-07     7.43e-06
Wall time: 17781.747160707997
training
# Epoch batch         loss       loss_e      e/N_mae
    326    10      3.2e-06      3.2e-06     2.66e-05
    326    20     2.58e-06     2.58e-06     2.36e-05
    326    30     6.11e-06     6.11e-06     2.87e-05
    326    40     3.25e-06     3.25e-06     2.28e-05
    326    48     7.24e-06     7.24e-06     4.42e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    326    10      3.4e-07      3.4e-07     8.99e-06
    326    20     1.84e-07     1.84e-07     6.75e-06
    326    30     2.92e-07     2.92e-07     7.71e-06
    326    40     2.35e-07     2.35e-07     7.07e-06
    326    50     4.54e-07     4.54e-07     9.64e-06
    326    60     5.77e-07     5.77e-07     1.19e-05
    326    61     3.02e-06     3.02e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             326 17837.356    0.005     4.26e-06     4.26e-06     2.69e-05
! Validation        326 17837.356    0.005     4.16e-07     4.16e-07     8.18e-06
Wall time: 17837.357083666
training
# Epoch batch         loss       loss_e      e/N_mae
    327    10     9.86e-06     9.86e-06     4.45e-05
    327    20     4.81e-06     4.81e-06     2.84e-05
    327    30     6.14e-06     6.14e-06     3.34e-05
    327    40     8.47e-07     8.47e-07     1.21e-05
    327    48     4.78e-06     4.78e-06     3.21e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    327    10     4.48e-07     4.48e-07     9.32e-06
    327    20     4.56e-07     4.56e-07     9.64e-06
    327    30     2.94e-07     2.94e-07     8.35e-06
    327    40     1.82e-07     1.82e-07     6.75e-06
    327    50     3.42e-07     3.42e-07     7.39e-06
    327    60     2.75e-07     2.75e-07     8.03e-06
    327    61     3.53e-06     3.53e-06      2.3e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             327 17896.234    0.005     4.95e-06     4.95e-06     2.94e-05
! Validation        327 17896.234    0.005     4.39e-07     4.39e-07      8.4e-06
Wall time: 17896.235481875
training
# Epoch batch         loss       loss_e      e/N_mae
    328    10      7.1e-06      7.1e-06     3.98e-05
    328    20     4.05e-06     4.05e-06     2.56e-05
    328    30     4.03e-06     4.03e-06        3e-05
    328    40     5.35e-05     5.35e-05     8.86e-05
    328    48     4.49e-06     4.49e-06     2.65e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    328    10     1.99e-07     1.99e-07     6.75e-06
    328    20     6.49e-07     6.49e-07     1.12e-05
    328    30     3.55e-07     3.55e-07     8.67e-06
    328    40     1.12e-07     1.12e-07     4.82e-06
    328    50     4.08e-07     4.08e-07     7.71e-06
    328    60     2.85e-07     2.85e-07     8.03e-06
    328    61     4.05e-06     4.05e-06     2.62e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             328 17952.753    0.005     9.74e-06     9.74e-06     3.81e-05
! Validation        328 17952.753    0.005     5.43e-07     5.43e-07     9.17e-06
Wall time: 17952.753843915998
training
# Epoch batch         loss       loss_e      e/N_mae
    329    10     1.29e-05     1.29e-05     4.05e-05
    329    20     4.68e-05     4.68e-05     8.93e-05
    329    30     1.76e-05     1.76e-05     4.86e-05
    329    40     4.15e-05     4.15e-05     9.51e-05
    329    48     2.39e-05     2.39e-05     7.79e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    329    10     5.64e-07     5.64e-07     1.09e-05
    329    20     5.94e-07     5.94e-07     8.67e-06
    329    30     1.04e-06     1.04e-06     1.48e-05
    329    40     2.58e-07     2.58e-07      6.1e-06
    329    50     8.58e-07     8.58e-07     1.32e-05
    329    60     7.76e-07     7.76e-07     1.41e-05
    329    61     4.26e-06     4.26e-06     2.52e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             329 18008.731    0.005     2.14e-05     2.14e-05     5.84e-05
! Validation        329 18008.731    0.005     7.99e-07     7.99e-07     1.12e-05
Wall time: 18008.732298083
training
# Epoch batch         loss       loss_e      e/N_mae
    330    10      2.2e-05      2.2e-05      5.9e-05
    330    20     6.54e-06     6.54e-06     3.54e-05
    330    30     4.51e-06     4.51e-06     3.07e-05
    330    40     6.07e-06     6.07e-06     3.53e-05
    330    48     3.05e-06     3.05e-06     2.49e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    330    10     1.78e-06     1.78e-06     1.96e-05
    330    20     5.77e-07     5.77e-07     1.06e-05
    330    30     9.53e-07     9.53e-07     1.51e-05
    330    40     9.47e-07     9.47e-07     1.54e-05
    330    50     1.42e-06     1.42e-06     1.73e-05
    330    60     9.76e-07     9.76e-07     1.51e-05
    330    61     5.23e-06     5.23e-06        3e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             330 18065.083    0.005     1.05e-05     1.05e-05     3.85e-05
! Validation        330 18065.083    0.005     9.13e-07     9.13e-07     1.24e-05
Wall time: 18065.083855040997
training
# Epoch batch         loss       loss_e      e/N_mae
    331    10     3.82e-06     3.82e-06     2.52e-05
    331    20     1.26e-06     1.26e-06      1.5e-05
    331    30     4.33e-07     4.33e-07     8.46e-06
    331    40     8.14e-07     8.14e-07     1.24e-05
    331    48     7.24e-07     7.24e-07     1.28e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    331    10     1.17e-06     1.17e-06     1.61e-05
    331    20      6.4e-07      6.4e-07     1.19e-05
    331    30     7.02e-07     7.02e-07     1.12e-05
    331    40     5.03e-07     5.03e-07     1.09e-05
    331    50     1.24e-06     1.24e-06     1.64e-05
    331    60     6.66e-07     6.66e-07     1.16e-05
    331    61     4.61e-06     4.61e-06     2.84e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             331 18121.806    0.005     1.74e-06     1.74e-06      1.7e-05
! Validation        331 18121.806    0.005     7.38e-07     7.38e-07      1.1e-05
Wall time: 18121.807579708
training
# Epoch batch         loss       loss_e      e/N_mae
    332    10      1.1e-06      1.1e-06     1.43e-05
    332    20     1.15e-06     1.15e-06     1.41e-05
    332    30     1.56e-06     1.56e-06     1.72e-05
    332    40     7.71e-07     7.71e-07     1.24e-05
    332    48     1.07e-06     1.07e-06     1.69e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    332    10     6.04e-07     6.04e-07     1.09e-05
    332    20     5.69e-07     5.69e-07     1.12e-05
    332    30     4.95e-07     4.95e-07     9.96e-06
    332    40     5.01e-07     5.01e-07     1.19e-05
    332    50     8.58e-07     8.58e-07     1.54e-05
    332    60     4.65e-07     4.65e-07     8.99e-06
    332    61     4.43e-06     4.43e-06     2.57e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             332 18177.828    0.005     1.35e-06     1.35e-06     1.52e-05
! Validation        332 18177.828    0.005     5.81e-07     5.81e-07     9.79e-06
Wall time: 18177.828754041
training
# Epoch batch         loss       loss_e      e/N_mae
    333    10     1.22e-06     1.22e-06     1.38e-05
    333    20     5.22e-07     5.22e-07     9.85e-06
    333    30     8.74e-07     8.74e-07     1.31e-05
    333    40     1.58e-06     1.58e-06     1.75e-05
    333    48      1.8e-07      1.8e-07     6.42e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    333    10     2.92e-07     2.92e-07     7.07e-06
    333    20     4.27e-07     4.27e-07     9.64e-06
    333    30     3.68e-07     3.68e-07     9.32e-06
    333    40     3.32e-07     3.32e-07     8.35e-06
    333    50     7.23e-07     7.23e-07     1.35e-05
    333    60     2.32e-07     2.32e-07     5.78e-06
    333    61      3.6e-06      3.6e-06     2.41e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             333 18234.021    0.005     9.53e-07     9.53e-07     1.28e-05
! Validation        333 18234.021    0.005     4.59e-07     4.59e-07     8.74e-06
Wall time: 18234.02233325
training
# Epoch batch         loss       loss_e      e/N_mae
    334    10     1.26e-06     1.26e-06     1.55e-05
    334    20     8.02e-07     8.02e-07     1.22e-05
    334    30     3.77e-07     3.77e-07      7.6e-06
    334    40     4.12e-07     4.12e-07     8.14e-06
    334    48     3.86e-07     3.86e-07     8.83e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    334    10     2.77e-07     2.77e-07     8.03e-06
    334    20     2.11e-07     2.11e-07     7.39e-06
    334    30     3.55e-07     3.55e-07     9.32e-06
    334    40     2.05e-07     2.05e-07     6.75e-06
    334    50     6.74e-07     6.74e-07     1.25e-05
    334    60     3.68e-07     3.68e-07     5.46e-06
    334    61     3.27e-06     3.27e-06     2.36e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             334 18289.949    0.005     8.98e-07     8.98e-07     1.22e-05
! Validation        334 18289.949    0.005     4.25e-07     4.25e-07     8.41e-06
Wall time: 18289.949870791
training
# Epoch batch         loss       loss_e      e/N_mae
    335    10     7.77e-07     7.77e-07     1.14e-05
    335    20     1.28e-06     1.28e-06     1.46e-05
    335    30     5.71e-07     5.71e-07     9.96e-06
    335    40     5.53e-07     5.53e-07     9.21e-06
    335    48      4.7e-07      4.7e-07     1.04e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    335    10     2.77e-07     2.77e-07     7.39e-06
    335    20     2.66e-07     2.66e-07     7.71e-06
    335    30      2.9e-07      2.9e-07     8.35e-06
    335    40     2.16e-07     2.16e-07     6.42e-06
    335    50      6.4e-07      6.4e-07     1.19e-05
    335    60      3.7e-07      3.7e-07     5.78e-06
    335    61        3e-06        3e-06      2.2e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             335 18345.936    0.005     4.81e-07     4.81e-07     9.11e-06
! Validation        335 18345.936    0.005     4.03e-07     4.03e-07     8.01e-06
Wall time: 18345.936692332998
training
# Epoch batch         loss       loss_e      e/N_mae
    336    10     3.07e-07     3.07e-07        6e-06
    336    20     2.16e-07     2.16e-07     6.96e-06
    336    30     2.88e-07     2.88e-07     7.82e-06
    336    40     2.11e-07     2.11e-07     6.85e-06
    336    48     1.95e-07     1.95e-07     5.62e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    336    10     3.15e-07     3.15e-07     8.67e-06
    336    20     3.38e-07     3.38e-07     9.32e-06
    336    30        3e-07        3e-07     8.67e-06
    336    40     1.42e-07     1.42e-07     5.46e-06
    336    50     7.61e-07     7.61e-07     1.16e-05
    336    60     3.66e-07     3.66e-07      6.1e-06
    336    61      3.1e-06      3.1e-06     2.36e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             336 18401.646    0.005        4e-07        4e-07     8.15e-06
! Validation        336 18401.646    0.005     3.87e-07     3.87e-07     7.89e-06
Wall time: 18401.646512583
training
# Epoch batch         loss       loss_e      e/N_mae
    337    10     2.97e-07     2.97e-07      7.5e-06
    337    20     1.88e-06     1.88e-06      1.8e-05
    337    30     8.76e-07     8.76e-07     1.25e-05
    337    40     1.82e-06     1.82e-06     1.82e-05
    337    48     8.52e-06     8.52e-06     4.34e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    337    10     3.28e-07     3.28e-07     8.03e-06
    337    20     1.82e-07     1.82e-07     6.75e-06
    337    30        3e-07        3e-07     8.03e-06
    337    40     2.71e-07     2.71e-07     7.71e-06
    337    50     8.01e-07     8.01e-07     1.19e-05
    337    60     4.23e-07     4.23e-07     6.42e-06
    337    61     3.19e-06     3.19e-06     2.14e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             337 18458.860    0.005     1.78e-06     1.78e-06     1.62e-05
! Validation        337 18458.860    0.005     3.91e-07     3.91e-07     7.74e-06
Wall time: 18458.8608745
training
# Epoch batch         loss       loss_e      e/N_mae
    338    10     1.16e-05     1.16e-05     5.16e-05
    338    20      1.1e-05      1.1e-05     4.41e-05
    338    30     4.76e-06     4.76e-06     3.09e-05
    338    40      1.4e-05      1.4e-05     5.09e-05
    338    48     1.74e-05     1.74e-05     6.83e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    338    10     3.91e-07     3.91e-07     7.07e-06
    338    20     4.08e-07     4.08e-07     1.03e-05
    338    30     4.97e-07     4.97e-07     1.03e-05
    338    40     3.78e-07     3.78e-07     8.35e-06
    338    50     8.66e-07     8.66e-07     1.41e-05
    338    60     2.49e-07     2.49e-07     6.75e-06
    338    61     3.27e-06     3.27e-06     2.36e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             338 18515.939    0.005     7.57e-06     7.57e-06      3.6e-05
! Validation        338 18515.939    0.005     4.51e-07     4.51e-07     8.57e-06
Wall time: 18515.939997833
training
# Epoch batch         loss       loss_e      e/N_mae
    339    10     6.94e-06     6.94e-06     3.42e-05
    339    20     1.51e-05     1.51e-05     5.89e-05
    339    30     7.07e-06     7.07e-06     3.92e-05
    339    40     2.48e-06     2.48e-06     2.08e-05
    339    48      2.9e-06      2.9e-06     2.81e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    339    10     5.54e-07     5.54e-07     6.75e-06
    339    20     3.25e-07     3.25e-07     8.99e-06
    339    30      4.1e-07      4.1e-07     8.67e-06
    339    40      4.1e-07      4.1e-07     7.39e-06
    339    50     4.97e-07     4.97e-07     1.12e-05
    339    60     1.94e-07     1.94e-07     7.71e-06
    339    61      3.4e-06      3.4e-06     2.52e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             339 18572.371    0.005     7.99e-06     7.99e-06     3.74e-05
! Validation        339 18572.371    0.005     4.95e-07     4.95e-07     8.94e-06
Wall time: 18572.371746040997
training
# Epoch batch         loss       loss_e      e/N_mae
    340    10     1.83e-06     1.83e-06      1.7e-05
    340    20     4.83e-06     4.83e-06     2.81e-05
    340    30     2.28e-06     2.28e-06     1.78e-05
    340    40     1.14e-06     1.14e-06     1.46e-05
    340    48     1.06e-08     1.06e-08     1.61e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    340    10     3.25e-07     3.25e-07      6.1e-06
    340    20     2.09e-07     2.09e-07     7.39e-06
    340    30      4.1e-07      4.1e-07     1.03e-05
    340    40     2.09e-07     2.09e-07     5.46e-06
    340    50     6.34e-07     6.34e-07     1.19e-05
    340    60     1.86e-07     1.86e-07     6.42e-06
    340    61     3.51e-06     3.51e-06     2.46e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             340 18630.332    0.005     1.75e-06     1.75e-06     1.71e-05
! Validation        340 18630.332    0.005     5.12e-07     5.12e-07        9e-06
Wall time: 18630.332973040997
training
# Epoch batch         loss       loss_e      e/N_mae
    341    10     6.92e-07     6.92e-07     1.17e-05
    341    20     1.64e-06     1.64e-06     1.79e-05
    341    30     6.58e-07     6.58e-07     1.17e-05
    341    40     7.65e-07     7.65e-07      1.2e-05
    341    48     2.99e-06     2.99e-06     2.41e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    341    10     3.51e-07     3.51e-07     6.75e-06
    341    20     2.43e-07     2.43e-07     8.03e-06
    341    30      2.6e-07      2.6e-07     7.71e-06
    341    40     1.01e-07     1.01e-07      4.5e-06
    341    50     6.04e-07     6.04e-07     9.96e-06
    341    60     1.06e-07     1.06e-07      4.5e-06
    341    61     3.92e-06     3.92e-06     2.52e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             341 18686.793    0.005     8.79e-07     8.79e-07     1.21e-05
! Validation        341 18686.793    0.005     4.89e-07     4.89e-07     8.56e-06
Wall time: 18686.794292125
training
# Epoch batch         loss       loss_e      e/N_mae
    342    10     3.89e-06     3.89e-06     2.53e-05
    342    20     4.07e-06     4.07e-06     2.66e-05
    342    30      1.3e-06      1.3e-06     1.45e-05
    342    40     2.74e-06     2.74e-06     2.06e-05
    342    48     2.97e-06     2.97e-06     2.81e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    342    10     4.21e-07     4.21e-07     7.07e-06
    342    20     4.27e-07     4.27e-07     8.99e-06
    342    30     2.75e-07     2.75e-07     8.03e-06
    342    40     7.61e-08     7.61e-08     3.21e-06
    342    50     6.81e-07     6.81e-07     9.96e-06
    342    60     1.54e-07     1.54e-07     5.78e-06
    342    61     3.67e-06     3.67e-06     2.46e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             342 18742.830    0.005     3.17e-06     3.17e-06     2.13e-05
! Validation        342 18742.830    0.005     4.63e-07     4.63e-07     8.25e-06
Wall time: 18742.831330833
training
# Epoch batch         loss       loss_e      e/N_mae
    343    10     1.61e-06     1.61e-06     1.57e-05
    343    20     1.83e-06     1.83e-06     2.03e-05
    343    30     2.63e-06     2.63e-06     2.26e-05
    343    40     4.74e-07     4.74e-07     8.99e-06
    343    48      1.4e-06      1.4e-06     1.93e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    343    10     4.73e-07     4.73e-07     8.03e-06
    343    20     4.52e-07     4.52e-07     1.03e-05
    343    30     2.28e-07     2.28e-07     7.39e-06
    343    40     1.52e-07     1.52e-07     5.14e-06
    343    50     1.05e-06     1.05e-06     1.38e-05
    343    60      2.6e-07      2.6e-07     6.75e-06
    343    61     4.28e-06     4.28e-06     2.57e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             343 18798.922    0.005     1.98e-06     1.98e-06     1.81e-05
! Validation        343 18798.922    0.005     4.99e-07     4.99e-07     8.53e-06
Wall time: 18798.922501666
training
# Epoch batch         loss       loss_e      e/N_mae
    344    10     6.26e-07     6.26e-07     1.09e-05
    344    20     1.08e-06     1.08e-06     1.36e-05
    344    30     1.52e-06     1.52e-06     1.77e-05
    344    40     1.37e-06     1.37e-06     1.48e-05
    344    48     2.17e-07     2.17e-07     7.23e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    344    10     2.66e-07     2.66e-07     7.71e-06
    344    20     3.15e-07     3.15e-07     8.67e-06
    344    30      2.3e-07      2.3e-07     6.42e-06
    344    40      2.3e-07      2.3e-07     7.07e-06
    344    50     1.26e-06     1.26e-06     1.48e-05
    344    60      3.3e-07      3.3e-07     7.07e-06
    344    61     3.98e-06     3.98e-06     2.46e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             344 18857.297    0.005     1.27e-06     1.27e-06     1.47e-05
! Validation        344 18857.297    0.005     4.71e-07     4.71e-07     8.39e-06
Wall time: 18857.297969707997
training
# Epoch batch         loss       loss_e      e/N_mae
    345    10     1.84e-07     1.84e-07     5.03e-06
    345    20     1.36e-06     1.36e-06     1.57e-05
    345    30     1.33e-06     1.33e-06     1.42e-05
    345    40     9.81e-07     9.81e-07     1.32e-05
    345    48     1.17e-06     1.17e-06     1.61e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    345    10     2.66e-07     2.66e-07     7.71e-06
    345    20      1.8e-07      1.8e-07     6.75e-06
    345    30     2.37e-07     2.37e-07     7.39e-06
    345    40     2.62e-07     2.62e-07     7.39e-06
    345    50     1.03e-06     1.03e-06     1.25e-05
    345    60     1.35e-07     1.35e-07     4.82e-06
    345    61     3.48e-06     3.48e-06     2.14e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             345 18913.848    0.005     9.28e-07     9.28e-07     1.24e-05
! Validation        345 18913.848    0.005     4.45e-07     4.45e-07     8.17e-06
Wall time: 18913.849276499997
training
# Epoch batch         loss       loss_e      e/N_mae
    346    10     1.04e-06     1.04e-06      1.4e-05
    346    20     2.37e-06     2.37e-06     1.93e-05
    346    30     8.01e-06     8.01e-06     3.54e-05
    346    40     4.88e-06     4.88e-06     3.11e-05
    346    48     1.27e-06     1.27e-06     1.53e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    346    10     1.16e-07     1.16e-07      4.5e-06
    346    20     3.36e-07     3.36e-07     8.99e-06
    346    30        3e-07        3e-07     8.67e-06
    346    40     2.62e-07     2.62e-07     6.75e-06
    346    50     9.93e-07     9.93e-07     1.41e-05
    346    60     7.61e-08     7.61e-08     3.85e-06
    346    61     3.46e-06     3.46e-06     2.25e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             346 18969.582    0.005     5.84e-06     5.84e-06     2.86e-05
! Validation        346 18969.582    0.005     5.34e-07     5.34e-07     8.84e-06
Wall time: 18969.582989415998
training
# Epoch batch         loss       loss_e      e/N_mae
    347    10      2.1e-06      2.1e-06      1.8e-05
    347    20     7.07e-06     7.07e-06     3.41e-05
    347    30     1.77e-06     1.77e-06     1.53e-05
    347    40     1.71e-06     1.71e-06     1.71e-05
    347    48      1.1e-06      1.1e-06     1.77e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    347    10     1.12e-07     1.12e-07     3.85e-06
    347    20     5.33e-07     5.33e-07     1.06e-05
    347    30     3.55e-07     3.55e-07     8.67e-06
    347    40     1.94e-07     1.94e-07     5.78e-06
    347    50     9.05e-07     9.05e-07     1.16e-05
    347    60     1.65e-07     1.65e-07     4.82e-06
    347    61     3.81e-06     3.81e-06     2.46e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             347 19025.513    0.005     3.23e-06     3.23e-06     2.32e-05
! Validation        347 19025.513    0.005     5.78e-07     5.78e-07     9.19e-06
Wall time: 19025.513941208
training
# Epoch batch         loss       loss_e      e/N_mae
    348    10     1.15e-06     1.15e-06     1.43e-05
    348    20     1.44e-06     1.44e-06     1.51e-05
    348    30     8.14e-07     8.14e-07     1.28e-05
    348    40     1.12e-06     1.12e-06     1.58e-05
    348    48     2.64e-08     2.64e-08     2.41e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    348    10     2.01e-07     2.01e-07     6.75e-06
    348    20     3.51e-07     3.51e-07     9.32e-06
    348    30     2.94e-07     2.94e-07     7.71e-06
    348    40      2.2e-07      2.2e-07     6.75e-06
    348    50     5.45e-07     5.45e-07     8.67e-06
    348    60     2.79e-07     2.79e-07     5.46e-06
    348    61     2.48e-06     2.48e-06     2.09e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             348 19082.470    0.005     1.39e-06     1.39e-06     1.55e-05
! Validation        348 19082.470    0.005        5e-07        5e-07     8.74e-06
Wall time: 19082.470265665997
training
# Epoch batch         loss       loss_e      e/N_mae
    349    10     6.52e-07     6.52e-07     1.16e-05
    349    20        9e-07        9e-07     1.27e-05
    349    30     4.61e-07     4.61e-07     1.02e-05
    349    40     4.81e-07     4.81e-07     8.78e-06
    349    48     6.87e-07     6.87e-07     1.37e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    349    10     1.92e-07     1.92e-07     5.14e-06
    349    20     3.44e-07     3.44e-07     8.99e-06
    349    30     2.39e-07     2.39e-07     6.42e-06
    349    40     1.31e-07     1.31e-07      4.5e-06
    349    50     5.54e-07     5.54e-07     8.03e-06
    349    60     2.68e-07     2.68e-07     5.78e-06
    349    61     3.16e-06     3.16e-06     2.46e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             349 19138.452    0.005     6.25e-07     6.25e-07     1.03e-05
! Validation        349 19138.452    0.005     4.43e-07     4.43e-07     8.06e-06
Wall time: 19138.452337290997
training
# Epoch batch         loss       loss_e      e/N_mae
    350    10     5.49e-07     5.49e-07     1.03e-05
    350    20     2.39e-07     2.39e-07     6.53e-06
    350    30     5.11e-07     5.11e-07     9.42e-06
    350    40     1.45e-06     1.45e-06     1.63e-05
    350    48     6.87e-07     6.87e-07     1.37e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    350    10     3.61e-07     3.61e-07     7.39e-06
    350    20      1.8e-07      1.8e-07     6.42e-06
    350    30     1.08e-07     1.08e-07      4.5e-06
    350    40     1.48e-07     1.48e-07     5.14e-06
    350    50     5.81e-07     5.81e-07     9.64e-06
    350    60     3.15e-07     3.15e-07     6.42e-06
    350    61     3.17e-06     3.17e-06     2.46e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             350 19195.939    0.005     6.61e-07     6.61e-07     1.03e-05
! Validation        350 19195.939    0.005      3.9e-07      3.9e-07     7.62e-06
Wall time: 19195.939576499997
training
# Epoch batch         loss       loss_e      e/N_mae
    351    10     2.02e-06     2.02e-06     2.02e-05
    351    20     1.06e-06     1.06e-06     1.38e-05
    351    30     9.86e-07     9.86e-07     1.35e-05
    351    40     1.12e-06     1.12e-06     1.33e-05
    351    48      2.2e-06      2.2e-06     2.09e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    351    10     2.77e-07     2.77e-07     7.39e-06
    351    20     2.01e-07     2.01e-07     7.07e-06
    351    30      2.3e-07      2.3e-07     6.42e-06
    351    40     2.47e-07     2.47e-07      6.1e-06
    351    50     8.28e-07     8.28e-07     1.19e-05
    351    60     2.09e-07     2.09e-07     5.14e-06
    351    61     3.86e-06     3.86e-06     2.46e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             351 19251.768    0.005     1.13e-06     1.13e-06     1.36e-05
! Validation        351 19251.768    0.005     3.69e-07     3.69e-07     7.19e-06
Wall time: 19251.768391291
training
# Epoch batch         loss       loss_e      e/N_mae
    352    10     9.33e-07     9.33e-07     1.41e-05
    352    20     5.32e-07     5.32e-07     1.02e-05
    352    30     7.66e-07     7.66e-07     1.09e-05
    352    40     6.96e-07     6.96e-07     1.07e-05
    352    48      4.7e-07      4.7e-07     1.04e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    352    10      1.9e-07      1.9e-07     5.46e-06
    352    20     1.46e-07     1.46e-07     5.14e-06
    352    30     2.24e-07     2.24e-07     6.75e-06
    352    40     2.32e-07     2.32e-07     5.78e-06
    352    50     7.21e-07     7.21e-07     1.12e-05
    352    60     2.18e-07     2.18e-07     5.78e-06
    352    61     3.37e-06     3.37e-06      2.3e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             352 19311.426    0.005     8.18e-07     8.18e-07     1.19e-05
! Validation        352 19311.426    0.005     3.66e-07     3.66e-07     7.19e-06
Wall time: 19311.427888541
training
# Epoch batch         loss       loss_e      e/N_mae
    353    10     9.19e-07     9.19e-07     1.22e-05
    353    20     7.33e-07     7.33e-07     1.12e-05
    353    30     7.47e-07     7.47e-07     1.23e-05
    353    40      3.8e-07      3.8e-07     8.35e-06
    353    48     1.06e-08     1.06e-08     1.61e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    353    10     2.94e-07     2.94e-07     6.42e-06
    353    20     9.93e-08     9.93e-08      4.5e-06
    353    30     1.08e-07     1.08e-07      4.5e-06
    353    40     2.94e-07     2.94e-07     6.75e-06
    353    50      7.5e-07      7.5e-07     1.03e-05
    353    60     2.98e-07     2.98e-07     6.42e-06
    353    61     2.69e-06     2.69e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             353 19368.563    0.005     5.09e-07     5.09e-07     9.42e-06
! Validation        353 19368.563    0.005     3.35e-07     3.35e-07     6.91e-06
Wall time: 19368.564176083
! Best model      353    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    354    10     7.29e-07     7.29e-07     1.32e-05
    354    20     7.76e-07     7.76e-07      1.3e-05
    354    30     3.66e-07     3.66e-07     8.03e-06
    354    40     2.28e-07     2.28e-07     6.64e-06
    354    48     1.12e-06     1.12e-06     1.53e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    354    10     3.78e-07     3.78e-07     5.78e-06
    354    20     1.52e-07     1.52e-07      6.1e-06
    354    30     1.33e-07     1.33e-07     5.78e-06
    354    40     3.53e-07     3.53e-07     7.39e-06
    354    50     8.09e-07     8.09e-07     1.19e-05
    354    60     1.52e-07     1.52e-07     5.46e-06
    354    61      2.5e-06      2.5e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             354 19425.090    0.005     4.58e-07     4.58e-07     8.84e-06
! Validation        354 19425.090    0.005     3.41e-07     3.41e-07     7.15e-06
Wall time: 19425.091103458
training
# Epoch batch         loss       loss_e      e/N_mae
    355    10     4.64e-07     4.64e-07     8.57e-06
    355    20     3.15e-07     3.15e-07     7.71e-06
    355    30     4.25e-07     4.25e-07     8.89e-06
    355    40     4.06e-07     4.06e-07     9.21e-06
    355    48     2.64e-08     2.64e-08     2.41e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    355    10     3.25e-07     3.25e-07     5.78e-06
    355    20     1.42e-07     1.42e-07     5.14e-06
    355    30     4.48e-07     4.48e-07     9.32e-06
    355    40     3.42e-07     3.42e-07     6.42e-06
    355    50     8.33e-07     8.33e-07     1.22e-05
    355    60     2.18e-07     2.18e-07     5.78e-06
    355    61     2.24e-06     2.24e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             355 19481.629    0.005      5.4e-07      5.4e-07     9.65e-06
! Validation        355 19481.629    0.005     3.35e-07     3.35e-07     7.02e-06
Wall time: 19481.629604166
training
# Epoch batch         loss       loss_e      e/N_mae
    356    10      3.9e-07      3.9e-07     7.17e-06
    356    20      4.7e-07      4.7e-07     6.53e-06
    356    30     2.45e-07     2.45e-07     6.75e-06
    356    40     5.06e-07     5.06e-07      9.1e-06
    356    48     3.43e-07     3.43e-07     9.64e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    356    10     3.59e-07     3.59e-07     6.75e-06
    356    20     1.78e-07     1.78e-07     5.14e-06
    356    30     3.68e-07     3.68e-07     8.03e-06
    356    40     1.39e-07     1.39e-07      4.5e-06
    356    50     7.57e-07     7.57e-07     1.16e-05
    356    60     1.04e-07     1.04e-07      4.5e-06
    356    61     2.41e-06     2.41e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             356 19538.290    0.005     4.35e-07     4.35e-07     8.52e-06
! Validation        356 19538.290    0.005     3.24e-07     3.24e-07     6.94e-06
Wall time: 19538.290711374997
! Best model      356    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    357    10     5.39e-07     5.39e-07      9.1e-06
    357    20     5.71e-07     5.71e-07     1.09e-05
    357    30     4.01e-07     4.01e-07     7.92e-06
    357    40     5.06e-07     5.06e-07     9.96e-06
    357    48     8.98e-08     8.98e-08     4.02e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    357    10     3.83e-07     3.83e-07     6.42e-06
    357    20     2.18e-07     2.18e-07     6.42e-06
    357    30     2.85e-07     2.85e-07     7.71e-06
    357    40     1.16e-07     1.16e-07     3.53e-06
    357    50     7.19e-07     7.19e-07     1.09e-05
    357    60     1.16e-07     1.16e-07     3.85e-06
    357    61      2.6e-06      2.6e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             357 19594.560    0.005     4.31e-07     4.31e-07      8.6e-06
! Validation        357 19594.560    0.005     3.26e-07     3.26e-07     6.85e-06
Wall time: 19594.561681458
training
# Epoch batch         loss       loss_e      e/N_mae
    358    10      2.3e-07      2.3e-07      6.1e-06
    358    20     3.49e-07     3.49e-07     8.03e-06
    358    30      6.5e-07      6.5e-07      1.1e-05
    358    40     3.54e-07     3.54e-07     8.14e-06
    358    48     2.64e-07     2.64e-07     6.42e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    358    10     3.68e-07     3.68e-07     5.14e-06
    358    20     1.54e-07     1.54e-07     5.78e-06
    358    30     3.25e-07     3.25e-07     8.99e-06
    358    40     1.42e-07     1.42e-07     4.82e-06
    358    50     6.13e-07     6.13e-07     8.67e-06
    358    60     1.73e-07     1.73e-07     4.82e-06
    358    61     2.42e-06     2.42e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             358 19651.226    0.005     4.26e-07     4.26e-07     8.64e-06
! Validation        358 19651.226    0.005     3.02e-07     3.02e-07     6.55e-06
Wall time: 19651.227533457997
! Best model      358    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    359    10     1.66e-07     1.66e-07     5.03e-06
    359    20     1.97e-07     1.97e-07     6.21e-06
    359    30     4.09e-07     4.09e-07     8.99e-06
    359    40     3.95e-07     3.95e-07      9.1e-06
    359    48     4.28e-07     4.28e-07     8.03e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    359    10     2.22e-07     2.22e-07     4.18e-06
    359    20     1.14e-07     1.14e-07     4.82e-06
    359    30     3.49e-07     3.49e-07     8.35e-06
    359    40     6.34e-08     6.34e-08     3.21e-06
    359    50     6.19e-07     6.19e-07     1.06e-05
    359    60     2.62e-07     2.62e-07     6.75e-06
    359    61     2.77e-06     2.77e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             359 19707.204    0.005     4.05e-07     4.05e-07     8.19e-06
! Validation        359 19707.204    0.005     2.95e-07     2.95e-07     6.29e-06
Wall time: 19707.204604332997
! Best model      359    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    360    10     5.83e-07     5.83e-07     7.71e-06
    360    20     8.29e-07     8.29e-07     1.33e-05
    360    30     5.94e-07     5.94e-07     1.05e-05
    360    40     2.99e-07     2.99e-07      7.5e-06
    360    48     5.49e-07     5.49e-07     1.04e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    360    10     3.34e-07     3.34e-07     5.78e-06
    360    20     6.55e-08     6.55e-08     4.18e-06
    360    30     1.71e-07     1.71e-07     5.78e-06
    360    40     2.62e-07     2.62e-07     6.42e-06
    360    50     6.49e-07     6.49e-07     1.06e-05
    360    60      2.9e-07      2.9e-07     6.75e-06
    360    61     3.23e-06     3.23e-06     2.14e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             360 19764.036    0.005     5.28e-07     5.28e-07      9.3e-06
! Validation        360 19764.036    0.005     3.03e-07     3.03e-07     6.39e-06
Wall time: 19764.036885540998
training
# Epoch batch         loss       loss_e      e/N_mae
    361    10        3e-07        3e-07     6.53e-06
    361    20     9.31e-07     9.31e-07     8.67e-06
    361    30     1.55e-06     1.55e-06     1.69e-05
    361    40     1.15e-06     1.15e-06     1.48e-05
    361    48     1.65e-05     1.65e-05     6.51e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    361    10     3.47e-07     3.47e-07     6.42e-06
    361    20      9.3e-08      9.3e-08     5.14e-06
    361    30     2.39e-07     2.39e-07     6.42e-06
    361    40     3.57e-07     3.57e-07     7.07e-06
    361    50     5.79e-07     5.79e-07     1.03e-05
    361    60     2.85e-07     2.85e-07     5.78e-06
    361    61     2.44e-06     2.44e-06     1.87e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             361 19820.229    0.005     1.62e-06     1.62e-06     1.43e-05
! Validation        361 19820.229    0.005     3.05e-07     3.05e-07     6.54e-06
Wall time: 19820.230459583
training
# Epoch batch         loss       loss_e      e/N_mae
    362    10     1.51e-05     1.51e-05     5.02e-05
    362    20     1.84e-05     1.84e-05     5.86e-05
    362    30     3.28e-05     3.28e-05     7.92e-05
    362    40     5.28e-05     5.28e-05      0.00011
    362    48     1.69e-05     1.69e-05     5.38e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    362    10     2.35e-07     2.35e-07     6.75e-06
    362    20      7.9e-07      7.9e-07     1.19e-05
    362    30     6.19e-07     6.19e-07     1.25e-05
    362    40     3.78e-07     3.78e-07     8.03e-06
    362    50     4.52e-07     4.52e-07     9.96e-06
    362    60     2.09e-07     2.09e-07     7.39e-06
    362    61     3.09e-06     3.09e-06     2.73e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             362 19876.753    0.005     3.87e-05     3.87e-05     8.01e-05
! Validation        362 19876.753    0.005     8.83e-07     8.83e-07      1.2e-05
Wall time: 19876.754682249997
training
# Epoch batch         loss       loss_e      e/N_mae
    363    10     6.09e-05     6.09e-05     9.57e-05
    363    20      2.3e-05      2.3e-05     6.19e-05
    363    30     1.48e-05     1.48e-05     5.78e-05
    363    40     2.35e-05     2.35e-05     6.23e-05
    363    48     3.22e-06     3.22e-06     2.89e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    363    10     7.33e-07     7.33e-07     1.19e-05
    363    20      1.4e-06      1.4e-06     1.57e-05
    363    30     3.02e-07     3.02e-07     8.03e-06
    363    40     1.39e-06     1.39e-06      1.8e-05
    363    50     5.16e-07     5.16e-07     1.09e-05
    363    60     9.34e-07     9.34e-07     1.51e-05
    363    61     6.35e-06     6.35e-06     3.43e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             363 19933.304    0.005     2.59e-05     2.59e-05      6.3e-05
! Validation        363 19933.304    0.005     1.48e-06     1.48e-06      1.6e-05
Wall time: 19933.305097999997
training
# Epoch batch         loss       loss_e      e/N_mae
    364    10     4.31e-06     4.31e-06     3.13e-05
    364    20     3.64e-06     3.64e-06     2.48e-05
    364    30      6.7e-06      6.7e-06     3.24e-05
    364    40     7.22e-06     7.22e-06      4.1e-05
    364    48     2.56e-06     2.56e-06     2.65e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    364    10      7.9e-07      7.9e-07     1.28e-05
    364    20     8.01e-07     8.01e-07     1.12e-05
    364    30     2.47e-07     2.47e-07     6.42e-06
    364    40     8.26e-07     8.26e-07     1.28e-05
    364    50     5.18e-07     5.18e-07     1.09e-05
    364    60     1.87e-06     1.87e-06     2.09e-05
    364    61     6.01e-06     6.01e-06     3.37e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             364 19989.731    0.005     5.19e-06     5.19e-06        3e-05
! Validation        364 19989.731    0.005      1.2e-06      1.2e-06     1.42e-05
Wall time: 19989.7315025
training
# Epoch batch         loss       loss_e      e/N_mae
    365    10     2.77e-06     2.77e-06     2.01e-05
    365    20      2.2e-06      2.2e-06     2.02e-05
    365    30     1.72e-06     1.72e-06      1.7e-05
    365    40     5.47e-07     5.47e-07     1.11e-05
    365    48     1.53e-06     1.53e-06     2.01e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    365    10     5.69e-07     5.69e-07     1.03e-05
    365    20     5.03e-07     5.03e-07     9.32e-06
    365    30     1.94e-07     1.94e-07      6.1e-06
    365    40     4.44e-07     4.44e-07     8.67e-06
    365    50     3.59e-07     3.59e-07     8.67e-06
    365    60     1.35e-06     1.35e-06      1.8e-05
    365    61     6.01e-06     6.01e-06     3.53e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             365 20046.384    0.005      2.7e-06      2.7e-06     1.98e-05
! Validation        365 20046.384    0.005     8.68e-07     8.68e-07     1.18e-05
Wall time: 20046.38497525
training
# Epoch batch         loss       loss_e      e/N_mae
    366    10     2.85e-06     2.85e-06     2.23e-05
    366    20      7.5e-07      7.5e-07     1.12e-05
    366    30     2.56e-06     2.56e-06     1.91e-05
    366    40     7.28e-07     7.28e-07     1.18e-05
    366    48      4.7e-07      4.7e-07      1.2e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    366    10     3.89e-07     3.89e-07     7.39e-06
    366    20     3.23e-07     3.23e-07     7.39e-06
    366    30     3.23e-07     3.23e-07     7.07e-06
    366    40     2.62e-07     2.62e-07     6.75e-06
    366    50     6.57e-07     6.57e-07     1.12e-05
    366    60     1.06e-06     1.06e-06     1.64e-05
    366    61     5.09e-06     5.09e-06     3.21e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             366 20101.913    0.005     1.38e-06     1.38e-06      1.5e-05
! Validation        366 20101.913    0.005     6.83e-07     6.83e-07     1.03e-05
Wall time: 20101.914668457997
training
# Epoch batch         loss       loss_e      e/N_mae
    367    10     1.74e-06     1.74e-06     1.86e-05
    367    20     4.61e-07     4.61e-07      9.1e-06
    367    30     5.29e-07     5.29e-07     1.02e-05
    367    40     6.88e-07     6.88e-07     1.21e-05
    367    48     1.32e-07     1.32e-07     4.82e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    367    10     3.78e-07     3.78e-07     6.42e-06
    367    20     3.11e-07     3.11e-07     8.35e-06
    367    30     4.97e-07     4.97e-07     8.99e-06
    367    40      2.2e-07      2.2e-07     6.75e-06
    367    50     8.35e-07     8.35e-07     1.19e-05
    367    60      5.9e-07      5.9e-07     1.19e-05
    367    61     4.76e-06     4.76e-06     2.94e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             367 20158.598    0.005     1.07e-06     1.07e-06     1.35e-05
! Validation        367 20158.598    0.005      5.7e-07      5.7e-07     9.45e-06
Wall time: 20158.598587791
training
# Epoch batch         loss       loss_e      e/N_mae
    368    10     8.57e-07     8.57e-07      1.3e-05
    368    20     7.66e-07     7.66e-07     1.24e-05
    368    30     6.73e-07     6.73e-07     8.67e-06
    368    40      4.2e-07      4.2e-07     8.25e-06
    368    48     7.71e-07     7.71e-07     1.37e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    368    10      1.8e-07      1.8e-07     5.14e-06
    368    20     1.23e-07     1.23e-07     5.46e-06
    368    30     3.76e-07     3.76e-07     8.03e-06
    368    40     2.11e-07     2.11e-07     6.42e-06
    368    50     1.11e-06     1.11e-06     1.41e-05
    368    60     3.91e-07     3.91e-07     9.32e-06
    368    61     3.67e-06     3.67e-06     2.46e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             368 20214.811    0.005     6.71e-07     6.71e-07     1.05e-05
! Validation        368 20214.811    0.005     4.94e-07     4.94e-07     8.86e-06
Wall time: 20214.812621833
training
# Epoch batch         loss       loss_e      e/N_mae
    369    10     9.71e-07     9.71e-07     1.27e-05
    369    20     1.08e-06     1.08e-06     1.48e-05
    369    30     4.97e-07     4.97e-07     9.21e-06
    369    40     2.52e-07     2.52e-07     6.85e-06
    369    48     5.28e-08     5.28e-08     3.21e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    369    10     1.29e-07     1.29e-07      6.1e-06
    369    20     1.56e-07     1.56e-07      6.1e-06
    369    30     4.95e-07     4.95e-07     9.32e-06
    369    40     3.51e-07     3.51e-07     8.67e-06
    369    50     1.01e-06     1.01e-06     1.38e-05
    369    60      3.7e-07      3.7e-07     7.39e-06
    369    61     3.28e-06     3.28e-06     2.36e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             369 20270.919    0.005     6.72e-07     6.72e-07     1.06e-05
! Validation        369 20270.919    0.005     4.45e-07     4.45e-07     8.52e-06
Wall time: 20270.920449708
training
# Epoch batch         loss       loss_e      e/N_mae
    370    10      2.6e-07      2.6e-07     6.75e-06
    370    20     3.61e-07     3.61e-07      7.5e-06
    370    30     5.82e-07     5.82e-07     1.09e-05
    370    40     2.42e-07     2.42e-07     6.21e-06
    370    48     3.59e-07     3.59e-07     8.83e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    370    10     8.66e-08     8.66e-08      4.5e-06
    370    20     1.67e-07     1.67e-07     6.42e-06
    370    30     4.88e-07     4.88e-07     8.35e-06
    370    40     1.97e-07     1.97e-07     6.75e-06
    370    50     1.01e-06     1.01e-06     1.35e-05
    370    60     1.88e-07     1.88e-07      4.5e-06
    370    61     3.35e-06     3.35e-06      2.2e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             370 20327.353    0.005     4.04e-07     4.04e-07     8.19e-06
! Validation        370 20327.353    0.005      4.1e-07      4.1e-07     7.91e-06
Wall time: 20327.353195790998
training
# Epoch batch         loss       loss_e      e/N_mae
    371    10     4.53e-07     4.53e-07     9.32e-06
    371    20     3.48e-07     3.48e-07     8.35e-06
    371    30     2.89e-07     2.89e-07     7.71e-06
    371    40     3.04e-07     3.04e-07     7.28e-06
    371    48     5.97e-07     5.97e-07      1.2e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    371    10     1.14e-07     1.14e-07      4.5e-06
    371    20     2.09e-07     2.09e-07     7.39e-06
    371    30     3.66e-07     3.66e-07     7.71e-06
    371    40     1.84e-07     1.84e-07      6.1e-06
    371    50     9.53e-07     9.53e-07     1.32e-05
    371    60     2.54e-07     2.54e-07      6.1e-06
    371    61     2.99e-06     2.99e-06     2.14e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             371 20384.556    0.005     4.36e-07     4.36e-07     8.48e-06
! Validation        371 20384.556    0.005     3.93e-07     3.93e-07     7.86e-06
Wall time: 20384.55803075
training
# Epoch batch         loss       loss_e      e/N_mae
    372    10      8.6e-07      8.6e-07     1.34e-05
    372    20     8.94e-07     8.94e-07     1.35e-05
    372    30     5.12e-07     5.12e-07     9.42e-06
    372    40     8.82e-07     8.82e-07     1.25e-05
    372    48     1.32e-07     1.32e-07     5.62e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    372    10     1.63e-07     1.63e-07      4.5e-06
    372    20      1.9e-07      1.9e-07     6.75e-06
    372    30     3.64e-07     3.64e-07     8.03e-06
    372    40     2.43e-07     2.43e-07     6.75e-06
    372    50     9.34e-07     9.34e-07     1.22e-05
    372    60     2.51e-07     2.51e-07     5.78e-06
    372    61      2.7e-06      2.7e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             372 20440.963    0.005     7.91e-07     7.91e-07     1.17e-05
! Validation        372 20440.963    0.005     3.88e-07     3.88e-07     7.75e-06
Wall time: 20440.963489915997
training
# Epoch batch         loss       loss_e      e/N_mae
    373    10        3e-07        3e-07     7.28e-06
    373    20     6.57e-07     6.57e-07     1.04e-05
    373    30     3.71e-07     3.71e-07      7.6e-06
    373    40     1.84e-06     1.84e-06     1.88e-05
    373    48     1.06e-07     1.06e-07     4.82e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    373    10      2.2e-07      2.2e-07     6.42e-06
    373    20     1.37e-07     1.37e-07      6.1e-06
    373    30     3.32e-07     3.32e-07     7.71e-06
    373    40     1.94e-07     1.94e-07     5.78e-06
    373    50     8.81e-07     8.81e-07     1.32e-05
    373    60      1.9e-07      1.9e-07     5.46e-06
    373    61     2.23e-06     2.23e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             373 20497.485    0.005     7.82e-07     7.82e-07     1.15e-05
! Validation        373 20497.485    0.005     3.61e-07     3.61e-07     7.53e-06
Wall time: 20497.486591457997
training
# Epoch batch         loss       loss_e      e/N_mae
    374    10     8.14e-07     8.14e-07     1.33e-05
    374    20     6.52e-07     6.52e-07     1.17e-05
    374    30     7.21e-07     7.21e-07     1.05e-05
    374    40     5.07e-07     5.07e-07     1.06e-05
    374    48     5.34e-07     5.34e-07     9.64e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    374    10     2.16e-07     2.16e-07     5.46e-06
    374    20     1.63e-07     1.63e-07     6.42e-06
    374    30     1.71e-07     1.71e-07     5.78e-06
    374    40     1.48e-07     1.48e-07     3.85e-06
    374    50     9.38e-07     9.38e-07     1.35e-05
    374    60     2.49e-07     2.49e-07     6.75e-06
    374    61     2.09e-06     2.09e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             374 20553.815    0.005     6.73e-07     6.73e-07     1.03e-05
! Validation        374 20553.815    0.005     3.44e-07     3.44e-07     7.37e-06
Wall time: 20553.816413875
training
# Epoch batch         loss       loss_e      e/N_mae
    375    10     5.34e-07     5.34e-07     1.02e-05
    375    20     3.76e-07     3.76e-07     8.25e-06
    375    30     2.97e-07     2.97e-07      7.6e-06
    375    40     2.66e-07     2.66e-07     7.71e-06
    375    48      4.7e-07      4.7e-07     1.12e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    375    10     1.67e-07     1.67e-07      6.1e-06
    375    20      9.3e-08      9.3e-08     5.14e-06
    375    30     2.09e-07     2.09e-07     6.42e-06
    375    40     1.29e-07     1.29e-07     4.18e-06
    375    50     8.92e-07     8.92e-07     1.28e-05
    375    60      2.3e-07      2.3e-07     6.42e-06
    375    61     2.09e-06     2.09e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             375 20609.823    0.005     4.19e-07     4.19e-07     8.34e-06
! Validation        375 20609.823    0.005     3.38e-07     3.38e-07     7.19e-06
Wall time: 20609.824013625
training
# Epoch batch         loss       loss_e      e/N_mae
    376    10     5.93e-07     5.93e-07     1.02e-05
    376    20     4.32e-07     4.32e-07     8.57e-06
    376    30     4.96e-07     4.96e-07     9.42e-06
    376    40      3.1e-07      3.1e-07     7.28e-06
    376    48     3.22e-07     3.22e-07     9.64e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    376    10     1.99e-07     1.99e-07     6.42e-06
    376    20     9.51e-08     9.51e-08     4.82e-06
    376    30     3.06e-07     3.06e-07     7.71e-06
    376    40     2.85e-07     2.85e-07     7.07e-06
    376    50     8.94e-07     8.94e-07     1.32e-05
    376    60     1.78e-07     1.78e-07     5.78e-06
    376    61     2.29e-06     2.29e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             376 20665.776    0.005     5.93e-07     5.93e-07     1.01e-05
! Validation        376 20665.776    0.005     3.42e-07     3.42e-07      7.3e-06
Wall time: 20665.77673225
training
# Epoch batch         loss       loss_e      e/N_mae
    377    10     4.01e-07     4.01e-07     8.25e-06
    377    20     3.85e-07     3.85e-07     8.46e-06
    377    30     9.53e-07     9.53e-07     1.26e-05
    377    40     4.73e-07     4.73e-07     9.42e-06
    377    48     6.87e-08     6.87e-08     4.02e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    377    10     2.94e-07     2.94e-07     8.03e-06
    377    20     3.17e-08     3.17e-08     2.57e-06
    377    30     2.47e-07     2.47e-07     6.42e-06
    377    40     2.75e-07     2.75e-07     6.75e-06
    377    50     8.86e-07     8.86e-07     1.25e-05
    377    60     2.35e-07     2.35e-07     6.42e-06
    377    61     2.12e-06     2.12e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             377 20721.760    0.005     5.86e-07     5.86e-07     9.91e-06
! Validation        377 20721.760    0.005     3.45e-07     3.45e-07      7.3e-06
Wall time: 20721.760889791
training
# Epoch batch         loss       loss_e      e/N_mae
    378    10     5.07e-07     5.07e-07     1.03e-05
    378    20     1.68e-07     1.68e-07     5.57e-06
    378    30     2.62e-07     2.62e-07     6.75e-06
    378    40      1.5e-06      1.5e-06     1.47e-05
    378    48     1.29e-06     1.29e-06     1.93e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    378    10     4.29e-07     4.29e-07     9.32e-06
    378    20     1.23e-07     1.23e-07     5.46e-06
    378    30     1.56e-07     1.56e-07      6.1e-06
    378    40     3.76e-07     3.76e-07     8.35e-06
    378    50     9.07e-07     9.07e-07     1.38e-05
    378    60      4.1e-07      4.1e-07     8.67e-06
    378    61     2.27e-06     2.27e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             378 20777.775    0.005     6.04e-07     6.04e-07     9.67e-06
! Validation        378 20777.775    0.005      3.4e-07      3.4e-07     7.36e-06
Wall time: 20777.775691125
training
# Epoch batch         loss       loss_e      e/N_mae
    379    10     6.55e-07     6.55e-07     1.06e-05
    379    20     7.62e-07     7.62e-07     1.18e-05
    379    30     6.81e-07     6.81e-07     1.16e-05
    379    40     4.14e-07     4.14e-07     9.42e-06
    379    48     1.06e-08     1.06e-08     1.61e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    379    10     4.95e-07     4.95e-07     9.64e-06
    379    20     1.25e-07     1.25e-07     5.14e-06
    379    30     2.49e-07     2.49e-07     7.39e-06
    379    40     2.09e-07     2.09e-07     5.46e-06
    379    50     8.52e-07     8.52e-07     1.32e-05
    379    60     2.83e-07     2.83e-07     7.39e-06
    379    61     2.29e-06     2.29e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             379 20834.835    0.005     6.15e-07     6.15e-07     1.02e-05
! Validation        379 20834.835    0.005     3.44e-07     3.44e-07     7.25e-06
Wall time: 20834.834958041
training
# Epoch batch         loss       loss_e      e/N_mae
    380    10     4.12e-07     4.12e-07     9.53e-06
    380    20     4.23e-07     4.23e-07     8.67e-06
    380    30     6.11e-07     6.11e-07     1.02e-05
    380    40     4.56e-07     4.56e-07      9.1e-06
    380    48     1.19e-06     1.19e-06     1.85e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    380    10     4.54e-07     4.54e-07     8.67e-06
    380    20      1.8e-07      1.8e-07     6.42e-06
    380    30     1.75e-07     1.75e-07     5.78e-06
    380    40      1.9e-07      1.9e-07     5.46e-06
    380    50     7.59e-07     7.59e-07     1.25e-05
    380    60     3.09e-07     3.09e-07     8.03e-06
    380    61     2.26e-06     2.26e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             380 20890.901    0.005     3.76e-07     3.76e-07     7.78e-06
! Validation        380 20890.901    0.005     3.23e-07     3.23e-07     7.09e-06
Wall time: 20890.901470582998
training
# Epoch batch         loss       loss_e      e/N_mae
    381    10      2.9e-07      2.9e-07     7.28e-06
    381    20     6.19e-07     6.19e-07     1.09e-05
    381    30     6.28e-07     6.28e-07     1.17e-05
    381    40     7.25e-07     7.25e-07     1.21e-05
    381    48     2.75e-07     2.75e-07     8.03e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    381    10     4.56e-07     4.56e-07     8.99e-06
    381    20     1.25e-07     1.25e-07     5.46e-06
    381    30     1.67e-07     1.67e-07     5.78e-06
    381    40     1.56e-07     1.56e-07     5.46e-06
    381    50     9.32e-07     9.32e-07     1.22e-05
    381    60     2.49e-07     2.49e-07      6.1e-06
    381    61      2.4e-06      2.4e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             381 20946.697    0.005     1.09e-06     1.09e-06     1.31e-05
! Validation        381 20946.697    0.005     3.33e-07     3.33e-07     7.08e-06
Wall time: 20946.698292499997
training
# Epoch batch         loss       loss_e      e/N_mae
    382    10     1.01e-06     1.01e-06     1.48e-05
    382    20     2.98e-07     2.98e-07     7.92e-06
    382    30     8.19e-07     8.19e-07     1.25e-05
    382    40     6.04e-07     6.04e-07     1.02e-05
    382    48     3.43e-07     3.43e-07     8.83e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    382    10     3.02e-07     3.02e-07     7.71e-06
    382    20     1.42e-07     1.42e-07     5.46e-06
    382    30      1.5e-07      1.5e-07     5.14e-06
    382    40     2.81e-07     2.81e-07     7.07e-06
    382    50     6.85e-07     6.85e-07     1.12e-05
    382    60     3.13e-07     3.13e-07     7.39e-06
    382    61     2.63e-06     2.63e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             382 21002.534    0.005     7.33e-07     7.33e-07     1.11e-05
! Validation        382 21002.534    0.005     3.35e-07     3.35e-07     7.16e-06
Wall time: 21002.535390540997
training
# Epoch batch         loss       loss_e      e/N_mae
    383    10     7.38e-07     7.38e-07     1.18e-05
    383    20     3.32e-07     3.32e-07     8.46e-06
    383    30     6.85e-07     6.85e-07      1.1e-05
    383    40     3.97e-07     3.97e-07     8.35e-06
    383    48     1.95e-07     1.95e-07     5.62e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    383    10     3.61e-07     3.61e-07     8.67e-06
    383    20     1.01e-07     1.01e-07     5.14e-06
    383    30     1.39e-07     1.39e-07     5.46e-06
    383    40     2.26e-07     2.26e-07     7.07e-06
    383    50     6.49e-07     6.49e-07     1.03e-05
    383    60     2.51e-07     2.51e-07     6.42e-06
    383    61      2.6e-06      2.6e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             383 21058.523    0.005     1.07e-06     1.07e-06     1.28e-05
! Validation        383 21058.523    0.005     3.34e-07     3.34e-07     7.07e-06
Wall time: 21058.524567082997
training
# Epoch batch         loss       loss_e      e/N_mae
    384    10     3.17e-07     3.17e-07     7.07e-06
    384    20     4.46e-07     4.46e-07     9.64e-06
    384    30     8.44e-07     8.44e-07     1.32e-05
    384    40     1.04e-06     1.04e-06     1.56e-05
    384    48     3.06e-07     3.06e-07     8.83e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    384    10     1.88e-07     1.88e-07     6.75e-06
    384    20     1.39e-07     1.39e-07     5.78e-06
    384    30     2.28e-07     2.28e-07      6.1e-06
    384    40      2.6e-07      2.6e-07      6.1e-06
    384    50     5.92e-07     5.92e-07     9.32e-06
    384    60     1.82e-07     1.82e-07     5.46e-06
    384    61     2.61e-06     2.61e-06     1.87e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             384 21113.854    0.005     5.35e-07     5.35e-07     9.47e-06
! Validation        384 21113.854    0.005      3.1e-07      3.1e-07     6.74e-06
Wall time: 21113.855483583
training
# Epoch batch         loss       loss_e      e/N_mae
    385    10     3.75e-07     3.75e-07     8.57e-06
    385    20     3.49e-07     3.49e-07     8.14e-06
    385    30     1.84e-07     1.84e-07     5.46e-06
    385    40     2.43e-07     2.43e-07     5.78e-06
    385    48     2.11e-08     2.11e-08     1.61e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    385    10     2.66e-07     2.66e-07      4.5e-06
    385    20     1.16e-07     1.16e-07      4.5e-06
    385    30     1.67e-07     1.67e-07     5.14e-06
    385    40     1.06e-07     1.06e-07     3.85e-06
    385    50      5.2e-07      5.2e-07     9.32e-06
    385    60     1.99e-07     1.99e-07      6.1e-06
    385    61     2.47e-06     2.47e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             385 21169.678    0.005     3.61e-07     3.61e-07     7.87e-06
! Validation        385 21169.678    0.005     2.98e-07     2.98e-07     6.49e-06
Wall time: 21169.678181665997
training
# Epoch batch         loss       loss_e      e/N_mae
    386    10     2.23e-07     2.23e-07     7.28e-06
    386    20     2.02e-07     2.02e-07     5.57e-06
    386    30     4.02e-07     4.02e-07      9.1e-06
    386    40     1.12e-06     1.12e-06     1.47e-05
    386    48      1.4e-06      1.4e-06     1.61e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    386    10     2.43e-07     2.43e-07     5.78e-06
    386    20     1.06e-07     1.06e-07     4.82e-06
    386    30     1.99e-07     1.99e-07      6.1e-06
    386    40     1.33e-07     1.33e-07     5.14e-06
    386    50     5.73e-07     5.73e-07     9.64e-06
    386    60     1.48e-07     1.48e-07     4.18e-06
    386    61     2.48e-06     2.48e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             386 21226.197    0.005     4.24e-07     4.24e-07     8.02e-06
! Validation        386 21226.197    0.005     2.94e-07     2.94e-07      6.6e-06
Wall time: 21226.1974705
! Best model      386    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    387    10     8.26e-07     8.26e-07      1.2e-05
    387    20     5.23e-07     5.23e-07     1.02e-05
    387    30     6.38e-07     6.38e-07     9.21e-06
    387    40     4.23e-07     4.23e-07     8.57e-06
    387    48     1.72e-06     1.72e-06     2.17e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    387    10     2.41e-07     2.41e-07     7.07e-06
    387    20     1.84e-07     1.84e-07      6.1e-06
    387    30     2.18e-07     2.18e-07     7.07e-06
    387    40     2.16e-07     2.16e-07     5.78e-06
    387    50      4.8e-07      4.8e-07     8.99e-06
    387    60      1.8e-07      1.8e-07     5.78e-06
    387    61     1.92e-06     1.92e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             387 21286.363    0.005     6.33e-07     6.33e-07     1.01e-05
! Validation        387 21286.363    0.005      2.9e-07      2.9e-07     6.72e-06
Wall time: 21286.364372
! Best model      387    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    388    10     3.95e-07     3.95e-07     8.78e-06
    388    20     4.08e-07     4.08e-07     8.25e-06
    388    30     8.26e-07     8.26e-07     1.28e-05
    388    40     1.08e-06     1.08e-06     1.57e-05
    388    48     1.79e-06     1.79e-06     2.25e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    388    10     3.15e-07     3.15e-07     7.39e-06
    388    20     1.12e-07     1.12e-07     5.14e-06
    388    30     2.18e-07     2.18e-07     6.42e-06
    388    40     1.37e-07     1.37e-07     4.82e-06
    388    50     6.32e-07     6.32e-07     1.06e-05
    388    60     2.07e-07     2.07e-07      6.1e-06
    388    61     2.33e-06     2.33e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             388 21343.419    0.005     9.72e-07     9.72e-07     1.24e-05
! Validation        388 21343.419    0.005     2.77e-07     2.77e-07     6.32e-06
Wall time: 21343.419957125
! Best model      388    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    389    10     1.18e-06     1.18e-06     1.49e-05
    389    20     6.68e-06     6.68e-06     3.94e-05
    389    30     1.32e-06     1.32e-06     1.61e-05
    389    40     3.21e-06     3.21e-06     2.15e-05
    389    48     4.49e-07     4.49e-07     1.04e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    389    10      2.6e-07      2.6e-07     8.03e-06
    389    20     3.04e-07     3.04e-07     8.35e-06
    389    30     3.15e-07     3.15e-07     5.14e-06
    389    40     1.54e-07     1.54e-07     5.14e-06
    389    50     5.37e-07     5.37e-07     9.32e-06
    389    60     5.24e-07     5.24e-07     1.12e-05
    389    61     2.29e-06     2.29e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             389 21401.603    0.005     3.25e-06     3.25e-06     2.26e-05
! Validation        389 21401.603    0.005     3.28e-07     3.28e-07     7.17e-06
Wall time: 21401.604501374997
training
# Epoch batch         loss       loss_e      e/N_mae
    390    10     3.46e-06     3.46e-06     2.49e-05
    390    20     7.93e-06     7.93e-06      3.5e-05
    390    30     7.26e-06     7.26e-06     4.09e-05
    390    40      2.6e-06      2.6e-06     2.18e-05
    390    48     1.88e-06     1.88e-06     2.25e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    390    10     3.32e-07     3.32e-07     7.39e-06
    390    20     3.72e-07     3.72e-07     9.32e-06
    390    30     2.75e-07     2.75e-07     6.75e-06
    390    40     1.61e-07     1.61e-07      4.5e-06
    390    50      4.1e-07      4.1e-07     6.75e-06
    390    60     4.78e-07     4.78e-07     9.96e-06
    390    61     2.75e-06     2.75e-06     2.03e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             390 21458.110    0.005     4.61e-06     4.61e-06     2.78e-05
! Validation        390 21458.110    0.005     3.54e-07     3.54e-07     7.15e-06
Wall time: 21458.110849082997
training
# Epoch batch         loss       loss_e      e/N_mae
    391    10     3.64e-06     3.64e-06     2.48e-05
    391    20     1.06e-06     1.06e-06     1.47e-05
    391    30     1.76e-06     1.76e-06     1.85e-05
    391    40     7.59e-07     7.59e-07     1.12e-05
    391    48     2.11e-08     2.11e-08     1.61e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    391    10     8.66e-08     8.66e-08     3.21e-06
    391    20     2.85e-07     2.85e-07     8.99e-06
    391    30     2.05e-07     2.05e-07      4.5e-06
    391    40      1.5e-07      1.5e-07     4.18e-06
    391    50     5.03e-07     5.03e-07     9.32e-06
    391    60     1.94e-07     1.94e-07     5.46e-06
    391    61     2.52e-06     2.52e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             391 21514.682    0.005     1.43e-06     1.43e-06     1.57e-05
! Validation        391 21514.682    0.005     3.06e-07     3.06e-07     6.74e-06
Wall time: 21514.683403290997
training
# Epoch batch         loss       loss_e      e/N_mae
    392    10     4.09e-07     4.09e-07     8.25e-06
    392    20     5.81e-07     5.81e-07     1.09e-05
    392    30     5.92e-07     5.92e-07     9.85e-06
    392    40     6.13e-07     6.13e-07     9.74e-06
    392    48     2.11e-08     2.11e-08     1.61e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    392    10     1.59e-07     1.59e-07      6.1e-06
    392    20     3.59e-07     3.59e-07     8.99e-06
    392    30     3.34e-07     3.34e-07      6.1e-06
    392    40     1.42e-07     1.42e-07     5.78e-06
    392    50     5.14e-07     5.14e-07     1.03e-05
    392    60     1.33e-07     1.33e-07     4.82e-06
    392    61     2.67e-06     2.67e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             392 21571.274    0.005     1.14e-06     1.14e-06     1.37e-05
! Validation        392 21571.274    0.005     2.99e-07     2.99e-07     6.75e-06
Wall time: 21571.275002083
training
# Epoch batch         loss       loss_e      e/N_mae
    393    10     5.97e-07     5.97e-07     9.74e-06
    393    20     2.93e-07     2.93e-07     6.75e-06
    393    30      4.8e-07      4.8e-07     9.42e-06
    393    40     4.79e-07     4.79e-07     9.32e-06
    393    48     1.37e-06     1.37e-06     1.93e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    393    10     1.73e-07     1.73e-07     5.46e-06
    393    20     3.13e-07     3.13e-07     7.07e-06
    393    30        3e-07        3e-07     6.75e-06
    393    40     1.33e-07     1.33e-07      4.5e-06
    393    50     4.48e-07     4.48e-07     9.64e-06
    393    60     1.23e-07     1.23e-07     4.18e-06
    393    61     2.12e-06     2.12e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             393 21627.898    0.005     6.83e-07     6.83e-07     1.06e-05
! Validation        393 21627.898    0.005     2.89e-07     2.89e-07     6.67e-06
Wall time: 21627.898361
training
# Epoch batch         loss       loss_e      e/N_mae
    394    10     5.69e-07     5.69e-07     1.02e-05
    394    20     5.77e-07     5.77e-07      1.1e-05
    394    30     4.33e-07     4.33e-07     8.57e-06
    394    40     5.47e-07     5.47e-07     8.25e-06
    394    48     2.17e-07     2.17e-07     7.23e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    394    10     1.56e-07     1.56e-07     5.46e-06
    394    20     1.94e-07     1.94e-07      6.1e-06
    394    30     2.98e-07     2.98e-07     7.07e-06
    394    40     1.42e-07     1.42e-07      4.5e-06
    394    50     5.49e-07     5.49e-07     9.96e-06
    394    60     1.04e-07     1.04e-07     3.85e-06
    394    61     2.29e-06     2.29e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             394 21684.120    0.005     6.98e-07     6.98e-07     1.04e-05
! Validation        394 21684.120    0.005     2.77e-07     2.77e-07      6.5e-06
Wall time: 21684.120572416
training
# Epoch batch         loss       loss_e      e/N_mae
    395    10     2.75e-07     2.75e-07     7.28e-06
    395    20     3.59e-07     3.59e-07     8.67e-06
    395    30     1.43e-06     1.43e-06     1.71e-05
    395    40     9.64e-07     9.64e-07     1.43e-05
    395    48     1.53e-07     1.53e-07     5.62e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    395    10     1.35e-07     1.35e-07     4.82e-06
    395    20     1.82e-07     1.82e-07     5.78e-06
    395    30     3.95e-07     3.95e-07     7.71e-06
    395    40     2.26e-07     2.26e-07     5.14e-06
    395    50     6.89e-07     6.89e-07     1.09e-05
    395    60      1.1e-07      1.1e-07     4.82e-06
    395    61     2.51e-06     2.51e-06     1.87e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             395 21741.593    0.005     5.84e-07     5.84e-07        1e-05
! Validation        395 21741.593    0.005     3.06e-07     3.06e-07     6.82e-06
Wall time: 21741.594934208
training
# Epoch batch         loss       loss_e      e/N_mae
    396    10     6.85e-07     6.85e-07     1.16e-05
    396    20     5.61e-07     5.61e-07     1.03e-05
    396    30        2e-07        2e-07     6.32e-06
    396    40     3.53e-07     3.53e-07     7.82e-06
    396    48     5.18e-07     5.18e-07      1.2e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    396    10     1.88e-07     1.88e-07     5.46e-06
    396    20     2.47e-07     2.47e-07     6.75e-06
    396    30     3.17e-07     3.17e-07     7.39e-06
    396    40     2.07e-07     2.07e-07      6.1e-06
    396    50     4.52e-07     4.52e-07     9.32e-06
    396    60     1.94e-07     1.94e-07     5.46e-06
    396    61     2.19e-06     2.19e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             396 21797.418    0.005     5.71e-07     5.71e-07     9.85e-06
! Validation        396 21797.418    0.005     2.84e-07     2.84e-07     6.79e-06
Wall time: 21797.418887958
training
# Epoch batch         loss       loss_e      e/N_mae
    397    10     1.31e-06     1.31e-06     1.75e-05
    397    20     1.18e-06     1.18e-06     1.45e-05
    397    30     3.28e-07     3.28e-07     6.85e-06
    397    40     1.03e-06     1.03e-06     1.28e-05
    397    48     8.98e-08     8.98e-08     4.02e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    397    10     1.84e-07     1.84e-07     4.18e-06
    397    20     2.45e-07     2.45e-07     6.42e-06
    397    30     3.34e-07     3.34e-07      6.1e-06
    397    40     1.97e-07     1.97e-07     5.46e-06
    397    50     4.06e-07     4.06e-07     8.03e-06
    397    60     1.39e-07     1.39e-07     4.82e-06
    397    61     1.79e-06     1.79e-06     1.55e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             397 21853.017    0.005     7.69e-07     7.69e-07     1.16e-05
! Validation        397 21853.017    0.005     2.95e-07     2.95e-07     6.66e-06
Wall time: 21853.017485375
training
# Epoch batch         loss       loss_e      e/N_mae
    398    10     9.95e-07     9.95e-07      1.3e-05
    398    20     3.35e-07     3.35e-07      7.6e-06
    398    30     5.26e-07     5.26e-07     1.04e-05
    398    40     2.87e-07     2.87e-07     8.14e-06
    398    48     8.98e-08     8.98e-08     4.82e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    398    10     1.14e-07     1.14e-07     3.21e-06
    398    20     1.97e-07     1.97e-07     6.42e-06
    398    30      4.1e-07      4.1e-07     8.03e-06
    398    40     1.59e-07     1.59e-07     5.46e-06
    398    50     4.54e-07     4.54e-07     8.35e-06
    398    60      1.5e-07      1.5e-07     5.14e-06
    398    61     1.92e-06     1.92e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             398 21908.212    0.005     6.61e-07     6.61e-07     1.08e-05
! Validation        398 21908.212    0.005     2.75e-07     2.75e-07     6.39e-06
Wall time: 21908.212607374997
! Best model      398    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    399    10     9.86e-07     9.86e-07     1.07e-05
    399    20      2.3e-07      2.3e-07     6.42e-06
    399    30     4.59e-07     4.59e-07     9.21e-06
    399    40     1.53e-06     1.53e-06     1.61e-05
    399    48     1.17e-06     1.17e-06     1.61e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    399    10     1.88e-07     1.88e-07     5.78e-06
    399    20     1.59e-07     1.59e-07      6.1e-06
    399    30     3.66e-07     3.66e-07     8.35e-06
    399    40     1.56e-07     1.56e-07     5.14e-06
    399    50     6.83e-07     6.83e-07     9.64e-06
    399    60     6.97e-08     6.97e-08     3.85e-06
    399    61     2.02e-06     2.02e-06     1.87e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             399 21963.319    0.005     7.53e-07     7.53e-07     1.09e-05
! Validation        399 21963.319    0.005     2.91e-07     2.91e-07     6.62e-06
Wall time: 21963.319798375
training
# Epoch batch         loss       loss_e      e/N_mae
    400    10     1.55e-06     1.55e-06      1.8e-05
    400    20     1.66e-06     1.66e-06      1.7e-05
    400    30     2.32e-06     2.32e-06     1.84e-05
    400    40     1.01e-05     1.01e-05     4.09e-05
    400    48     1.17e-05     1.17e-05     5.46e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    400    10      2.6e-07      2.6e-07     7.07e-06
    400    20     1.42e-07     1.42e-07     5.78e-06
    400    30     2.68e-07     2.68e-07     7.07e-06
    400    40      1.5e-07      1.5e-07     5.14e-06
    400    50     5.96e-07     5.96e-07     8.67e-06
    400    60     7.61e-08     7.61e-08     3.53e-06
    400    61     1.56e-06     1.56e-06     1.34e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             400 22018.241    0.005      2.8e-06      2.8e-06     1.94e-05
! Validation        400 22018.241    0.005     2.81e-07     2.81e-07     6.75e-06
Wall time: 22018.241107040998
training
# Epoch batch         loss       loss_e      e/N_mae
    401    10     3.42e-06     3.42e-06      2.4e-05
    401    20      6.2e-06      6.2e-06     3.93e-05
    401    30     5.64e-06     5.64e-06     2.86e-05
    401    40     8.06e-07     8.06e-07     1.25e-05
    401    48     9.51e-08     9.51e-08     4.82e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    401    10     1.67e-07     1.67e-07     5.78e-06
    401    20     1.94e-07     1.94e-07     5.78e-06
    401    30     2.92e-07     2.92e-07      6.1e-06
    401    40      2.2e-07      2.2e-07     6.75e-06
    401    50      3.8e-07      3.8e-07     7.39e-06
    401    60     5.71e-08     5.71e-08     3.21e-06
    401    61     2.32e-06     2.32e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             401 22073.495    0.005     4.88e-06     4.88e-06     2.84e-05
! Validation        401 22073.495    0.005     3.35e-07     3.35e-07     7.26e-06
Wall time: 22073.496383583
training
# Epoch batch         loss       loss_e      e/N_mae
    402    10     1.29e-06     1.29e-06     1.61e-05
    402    20     8.13e-07     8.13e-07     1.33e-05
    402    30     7.41e-07     7.41e-07     1.15e-05
    402    40     1.42e-06     1.42e-06     1.55e-05
    402    48     6.51e-06     6.51e-06     3.77e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    402    10     3.74e-07     3.74e-07     9.96e-06
    402    20     1.99e-07     1.99e-07     5.14e-06
    402    30     1.27e-07     1.27e-07     4.18e-06
    402    40     2.32e-07     2.32e-07     6.75e-06
    402    50     3.17e-07     3.17e-07     5.46e-06
    402    60     2.01e-07     2.01e-07     6.42e-06
    402    61     2.17e-06     2.17e-06     1.87e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             402 22128.805    0.005      1.8e-06      1.8e-06     1.67e-05
! Validation        402 22128.805    0.005     3.49e-07     3.49e-07     7.38e-06
Wall time: 22128.805798999998
training
# Epoch batch         loss       loss_e      e/N_mae
    403    10     1.32e-05     1.32e-05     5.09e-05
    403    20     4.25e-06     4.25e-06     2.73e-05
    403    30     9.46e-06     9.46e-06      4.6e-05
    403    40     1.55e-05     1.55e-05     6.09e-05
    403    48     5.01e-06     5.01e-06     3.21e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    403    10     2.83e-07     2.83e-07     8.03e-06
    403    20     2.98e-07     2.98e-07     8.99e-06
    403    30     5.54e-07     5.54e-07     7.71e-06
    403    40     3.49e-07     3.49e-07     7.71e-06
    403    50     5.71e-07     5.71e-07     8.67e-06
    403    60     2.11e-07     2.11e-07     6.75e-06
    403    61     2.77e-06     2.77e-06     2.25e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             403 22183.845    0.005     7.38e-06     7.38e-06      3.6e-05
! Validation        403 22183.845    0.005     5.22e-07     5.22e-07     9.27e-06
Wall time: 22183.845755166
training
# Epoch batch         loss       loss_e      e/N_mae
    404    10     2.37e-06     2.37e-06      2.1e-05
    404    20     1.07e-05     1.07e-05     4.67e-05
    404    30      8.9e-06      8.9e-06     3.84e-05
    404    40     3.24e-06     3.24e-06     2.39e-05
    404    48     1.29e-06     1.29e-06     1.69e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    404    10     2.37e-07     2.37e-07     7.39e-06
    404    20      2.2e-07      2.2e-07     7.07e-06
    404    30      1.5e-07      1.5e-07     5.14e-06
    404    40     1.31e-07     1.31e-07      4.5e-06
    404    50     1.15e-06     1.15e-06      1.7e-05
    404    60     2.71e-07     2.71e-07     8.35e-06
    404    61     3.28e-06     3.28e-06     2.46e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             404 22238.948    0.005     6.58e-06     6.58e-06     3.29e-05
! Validation        404 22238.948    0.005     6.08e-07     6.08e-07     9.73e-06
Wall time: 22238.948690333
training
# Epoch batch         loss       loss_e      e/N_mae
    405    10     3.55e-06     3.55e-06     2.54e-05
    405    20     1.45e-06     1.45e-06     1.67e-05
    405    30     4.15e-07     4.15e-07     8.46e-06
    405    40     3.12e-07     3.12e-07     7.28e-06
    405    48     1.06e-08     1.06e-08     1.61e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    405    10     1.12e-07     1.12e-07     5.46e-06
    405    20      2.6e-07      2.6e-07     8.35e-06
    405    30     1.67e-07     1.67e-07     5.14e-06
    405    40     2.05e-07     2.05e-07     6.75e-06
    405    50     1.01e-06     1.01e-06     1.54e-05
    405    60     2.39e-07     2.39e-07     7.39e-06
    405    61     3.08e-06     3.08e-06      2.2e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             405 22293.824    0.005     1.38e-06     1.38e-06      1.5e-05
! Validation        405 22293.824    0.005     5.27e-07     5.27e-07     8.87e-06
Wall time: 22293.824994541
training
# Epoch batch         loss       loss_e      e/N_mae
    406    10     5.18e-07     5.18e-07     9.96e-06
    406    20     9.22e-07     9.22e-07     1.31e-05
    406    30     1.64e-06     1.64e-06     1.77e-05
    406    40      7.5e-07      7.5e-07     1.09e-05
    406    48     9.77e-07     9.77e-07     1.53e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    406    10     1.25e-07     1.25e-07     5.46e-06
    406    20     1.23e-07     1.23e-07     5.78e-06
    406    30     1.18e-07     1.18e-07     4.82e-06
    406    40     1.48e-07     1.48e-07      6.1e-06
    406    50     5.58e-07     5.58e-07     1.09e-05
    406    60     5.03e-07     5.03e-07     8.99e-06
    406    61     2.94e-06     2.94e-06     2.09e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             406 22348.941    0.005     1.05e-06     1.05e-06     1.34e-05
! Validation        406 22348.941    0.005     4.39e-07     4.39e-07     8.26e-06
Wall time: 22348.94082625
training
# Epoch batch         loss       loss_e      e/N_mae
    407    10     5.81e-07     5.81e-07     1.02e-05
    407    20     4.05e-07     4.05e-07     8.67e-06
    407    30     6.73e-07     6.73e-07      1.1e-05
    407    40     2.13e-06     2.13e-06     2.06e-05
    407    48     1.26e-05     1.26e-05     5.78e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    407    10      7.4e-08      7.4e-08     3.85e-06
    407    20     1.99e-07     1.99e-07     6.42e-06
    407    30     2.79e-07     2.79e-07      6.1e-06
    407    40     2.37e-07     2.37e-07     7.07e-06
    407    50     5.43e-07     5.43e-07     1.03e-05
    407    60     4.95e-07     4.95e-07     7.39e-06
    407    61      2.8e-06      2.8e-06      2.2e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             407 22404.151    0.005      1.9e-06      1.9e-06     1.65e-05
! Validation        407 22404.151    0.005     3.92e-07     3.92e-07     7.74e-06
Wall time: 22404.152422625
training
# Epoch batch         loss       loss_e      e/N_mae
    408    10     5.18e-06     5.18e-06     3.02e-05
    408    20     3.73e-06     3.73e-06     2.73e-05
    408    30     5.56e-06     5.56e-06     2.99e-05
    408    40     1.87e-06     1.87e-06     1.88e-05
    408    48      2.9e-06      2.9e-06     2.81e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    408    10     1.73e-07     1.73e-07     6.42e-06
    408    20     1.42e-07     1.42e-07     4.82e-06
    408    30      2.2e-07      2.2e-07     6.75e-06
    408    40     2.85e-07     2.85e-07     8.03e-06
    408    50     5.35e-07     5.35e-07     1.03e-05
    408    60     4.44e-07     4.44e-07     9.64e-06
    408    61     2.38e-06     2.38e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             408 22459.188    0.005     7.06e-06     7.06e-06     3.34e-05
! Validation        408 22459.188    0.005     4.83e-07     4.83e-07     8.92e-06
Wall time: 22459.188005333
training
# Epoch batch         loss       loss_e      e/N_mae
    409    10     1.08e-06     1.08e-06     1.35e-05
    409    20     2.37e-06     2.37e-06     2.24e-05
    409    30     2.88e-06     2.88e-06     2.28e-05
    409    40      1.1e-06      1.1e-06     1.42e-05
    409    48     1.53e-07     1.53e-07     6.42e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    409    10     2.22e-07     2.22e-07      6.1e-06
    409    20     2.77e-07     2.77e-07     7.07e-06
    409    30     1.31e-07     1.31e-07     4.82e-06
    409    40     2.11e-07     2.11e-07     6.75e-06
    409    50     3.87e-07     3.87e-07     7.71e-06
    409    60     2.87e-07     2.87e-07     8.35e-06
    409    61     2.85e-06     2.85e-06     2.03e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             409 22514.440    0.005     2.34e-06     2.34e-06     2.02e-05
! Validation        409 22514.440    0.005     4.57e-07     4.57e-07     8.55e-06
Wall time: 22514.441503583
training
# Epoch batch         loss       loss_e      e/N_mae
    410    10     9.33e-07     9.33e-07     1.32e-05
    410    20     1.67e-06     1.67e-06     1.67e-05
    410    30     1.23e-06     1.23e-06     1.42e-05
    410    40     1.72e-06     1.72e-06     1.77e-05
    410    48     1.56e-06     1.56e-06     2.09e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    410    10     8.88e-08     8.88e-08     3.85e-06
    410    20     3.61e-07     3.61e-07     6.75e-06
    410    30     1.18e-07     1.18e-07     4.82e-06
    410    40     1.99e-07     1.99e-07     6.75e-06
    410    50     6.57e-07     6.57e-07     9.64e-06
    410    60     1.92e-07     1.92e-07     6.75e-06
    410    61     3.56e-06     3.56e-06     2.46e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             410 22569.425    0.005     1.01e-06     1.01e-06      1.3e-05
! Validation        410 22569.425    0.005      4.2e-07      4.2e-07     7.87e-06
Wall time: 22569.426438749997
training
# Epoch batch         loss       loss_e      e/N_mae
    411    10     6.76e-07     6.76e-07     1.07e-05
    411    20     2.54e-07     2.54e-07     6.32e-06
    411    30     6.97e-07     6.97e-07     9.42e-06
    411    40      1.1e-06      1.1e-06     1.45e-05
    411    48     4.23e-07     4.23e-07     9.64e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    411    10     1.01e-07     1.01e-07     4.82e-06
    411    20     2.32e-07     2.32e-07     5.78e-06
    411    30     1.25e-07     1.25e-07     5.14e-06
    411    40     2.26e-07     2.26e-07     6.42e-06
    411    50      4.9e-07      4.9e-07     8.67e-06
    411    60     2.75e-07     2.75e-07     7.71e-06
    411    61     2.23e-06     2.23e-06     2.03e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             411 22624.631    0.005      1.4e-06      1.4e-06     1.42e-05
! Validation        411 22624.631    0.005     3.65e-07     3.65e-07     7.65e-06
Wall time: 22624.631486874998
training
# Epoch batch         loss       loss_e      e/N_mae
    412    10      4.2e-07      4.2e-07     8.89e-06
    412    20     5.46e-07     5.46e-07     1.04e-05
    412    30      6.3e-07      6.3e-07     8.03e-06
    412    40     2.83e-07     2.83e-07     7.07e-06
    412    48     8.98e-07     8.98e-07      1.2e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    412    10     9.72e-08     9.72e-08      4.5e-06
    412    20     1.42e-07     1.42e-07     5.46e-06
    412    30     1.99e-07     1.99e-07      6.1e-06
    412    40     8.88e-08     8.88e-08     4.82e-06
    412    50      5.2e-07      5.2e-07     9.32e-06
    412    60     1.44e-07     1.44e-07     4.82e-06
    412    61     2.26e-06     2.26e-06     1.87e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             412 22679.692    0.005      4.9e-07      4.9e-07     8.95e-06
! Validation        412 22679.692    0.005     3.34e-07     3.34e-07     7.29e-06
Wall time: 22679.691832458
training
# Epoch batch         loss       loss_e      e/N_mae
    413    10     2.58e-07     2.58e-07     5.89e-06
    413    20     2.71e-07     2.71e-07     6.85e-06
    413    30     3.98e-07     3.98e-07     8.35e-06
    413    40      3.9e-07      3.9e-07     9.21e-06
    413    48     1.06e-08     1.06e-08     1.61e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    413    10     8.24e-08     8.24e-08     3.53e-06
    413    20     1.71e-07     1.71e-07     6.42e-06
    413    30     1.16e-07     1.16e-07      4.5e-06
    413    40     7.82e-08     7.82e-08     3.53e-06
    413    50     4.97e-07     4.97e-07     8.99e-06
    413    60     2.77e-07     2.77e-07     5.78e-06
    413    61     2.44e-06     2.44e-06     2.03e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             413 22734.915    0.005     4.52e-07     4.52e-07     8.62e-06
! Validation        413 22734.915    0.005     3.18e-07     3.18e-07     6.91e-06
Wall time: 22734.915601333
training
# Epoch batch         loss       loss_e      e/N_mae
    414    10     1.55e-07     1.55e-07     5.35e-06
    414    20     3.33e-07     3.33e-07     8.57e-06
    414    30      4.2e-07      4.2e-07     8.25e-06
    414    40     1.65e-06     1.65e-06     1.77e-05
    414    48     5.34e-07     5.34e-07     9.64e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    414    10     1.06e-07     1.06e-07     3.85e-06
    414    20     1.27e-07     1.27e-07     5.14e-06
    414    30     8.66e-08     8.66e-08      4.5e-06
    414    40     1.16e-07     1.16e-07     3.53e-06
    414    50     4.54e-07     4.54e-07     8.35e-06
    414    60     1.82e-07     1.82e-07     5.78e-06
    414    61     2.32e-06     2.32e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             414 22789.945    0.005     6.02e-07     6.02e-07     9.96e-06
! Validation        414 22789.945    0.005     3.04e-07     3.04e-07     6.85e-06
Wall time: 22789.945911332998
training
# Epoch batch         loss       loss_e      e/N_mae
    415    10      8.6e-07      8.6e-07     1.31e-05
    415    20     2.32e-07     2.32e-07     6.53e-06
    415    30     1.18e-06     1.18e-06     1.56e-05
    415    40     3.87e-07     3.87e-07     8.46e-06
    415    48     4.76e-08     4.76e-08     3.21e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    415    10     1.78e-07     1.78e-07     3.85e-06
    415    20     2.32e-07     2.32e-07      6.1e-06
    415    30     1.23e-07     1.23e-07     4.82e-06
    415    40     9.72e-08     9.72e-08     3.85e-06
    415    50     5.69e-07     5.69e-07     1.03e-05
    415    60     1.78e-07     1.78e-07     5.78e-06
    415    61      2.2e-06      2.2e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             415 22844.778    0.005     6.59e-07     6.59e-07     1.05e-05
! Validation        415 22844.778    0.005     3.07e-07     3.07e-07     6.71e-06
Wall time: 22844.778079
training
# Epoch batch         loss       loss_e      e/N_mae
    416    10     7.52e-07     7.52e-07     1.27e-05
    416    20      5.2e-07      5.2e-07     1.11e-05
    416    30      6.9e-07      6.9e-07     8.25e-06
    416    40     3.59e-07     3.59e-07     7.82e-06
    416    48     2.38e-07     2.38e-07     7.23e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    416    10     1.78e-07     1.78e-07     3.85e-06
    416    20     1.16e-07     1.16e-07     4.82e-06
    416    30     6.55e-08     6.55e-08     3.85e-06
    416    40     1.65e-07     1.65e-07      4.5e-06
    416    50     3.38e-07     3.38e-07     8.03e-06
    416    60     1.65e-07     1.65e-07     4.82e-06
    416    61     2.74e-06     2.74e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             416 22899.897    0.005     5.64e-07     5.64e-07     9.68e-06
! Validation        416 22899.897    0.005      2.9e-07      2.9e-07     6.49e-06
Wall time: 22899.897584832997
training
# Epoch batch         loss       loss_e      e/N_mae
    417    10     3.52e-07     3.52e-07     8.25e-06
    417    20     2.56e-07     2.56e-07     7.07e-06
    417    30     2.62e-07     2.62e-07     6.64e-06
    417    40     9.71e-07     9.71e-07     1.27e-05
    417    48     6.13e-07     6.13e-07      1.2e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    417    10     3.09e-07     3.09e-07      4.5e-06
    417    20     1.61e-07     1.61e-07     5.14e-06
    417    30     1.06e-07     1.06e-07     4.82e-06
    417    40     1.78e-07     1.78e-07     5.14e-06
    417    50     4.46e-07     4.46e-07     8.35e-06
    417    60     1.59e-07     1.59e-07     4.82e-06
    417    61     3.14e-06     3.14e-06     2.14e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             417 22954.953    0.005     4.06e-07     4.06e-07     8.24e-06
! Validation        417 22954.953    0.005     3.11e-07     3.11e-07     6.67e-06
Wall time: 22954.952697458
training
# Epoch batch         loss       loss_e      e/N_mae
    418    10     2.21e-07     2.21e-07     6.42e-06
    418    20     6.99e-07     6.99e-07     1.17e-05
    418    30     5.14e-07     5.14e-07     9.85e-06
    418    40     1.97e-07     1.97e-07     5.68e-06
    418    48     4.33e-07     4.33e-07     8.03e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    418    10     2.75e-07     2.75e-07     5.14e-06
    418    20     9.09e-08     9.09e-08      4.5e-06
    418    30     1.73e-07     1.73e-07      6.1e-06
    418    40     1.14e-07     1.14e-07      4.5e-06
    418    50     3.44e-07     3.44e-07     7.71e-06
    418    60     2.09e-07     2.09e-07     5.14e-06
    418    61     3.19e-06     3.19e-06     2.14e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             418 23010.287    0.005     5.45e-07     5.45e-07     9.68e-06
! Validation        418 23010.287    0.005     2.98e-07     2.98e-07     6.55e-06
Wall time: 23010.288044791
training
# Epoch batch         loss       loss_e      e/N_mae
    419    10     3.61e-07     3.61e-07      9.1e-06
    419    20      2.2e-07      2.2e-07     6.64e-06
    419    30     1.41e-07     1.41e-07     3.96e-06
    419    40     2.78e-07     2.78e-07     7.07e-06
    419    48     2.64e-07     2.64e-07     8.83e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    419    10     2.26e-07     2.26e-07     4.82e-06
    419    20     1.25e-07     1.25e-07     5.14e-06
    419    30     1.75e-07     1.75e-07     6.42e-06
    419    40      1.2e-07      1.2e-07     3.53e-06
    419    50     3.87e-07     3.87e-07     8.99e-06
    419    60      1.2e-07      1.2e-07      4.5e-06
    419    61     2.56e-06     2.56e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             419 23065.498    0.005     5.49e-07     5.49e-07     9.72e-06
! Validation        419 23065.498    0.005     2.86e-07     2.86e-07     6.43e-06
Wall time: 23065.498722165998
training
# Epoch batch         loss       loss_e      e/N_mae
    420    10     2.85e-06     2.85e-06     1.95e-05
    420    20      2.6e-06      2.6e-06     2.16e-05
    420    30     8.37e-07     8.37e-07     1.28e-05
    420    40     1.79e-06     1.79e-06     1.81e-05
    420    48     2.25e-06     2.25e-06     2.33e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    420    10     2.73e-07     2.73e-07     4.82e-06
    420    20      1.2e-07      1.2e-07     4.82e-06
    420    30     1.61e-07     1.61e-07     5.46e-06
    420    40     4.86e-08     4.86e-08     2.89e-06
    420    50     3.49e-07     3.49e-07     8.67e-06
    420    60     1.46e-07     1.46e-07     5.46e-06
    420    61      2.1e-06      2.1e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             420 23120.351    0.005     1.71e-06     1.71e-06     1.66e-05
! Validation        420 23120.351    0.005     2.85e-07     2.85e-07     6.42e-06
Wall time: 23120.352813874997
training
# Epoch batch         loss       loss_e      e/N_mae
    421    10     2.32e-06     2.32e-06     2.15e-05
    421    20     3.92e-06     3.92e-06     2.23e-05
    421    30     4.84e-06     4.84e-06     3.05e-05
    421    40     2.23e-06     2.23e-06      2.2e-05
    421    48     2.34e-06     2.34e-06     2.33e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    421    10     1.67e-07     1.67e-07     4.82e-06
    421    20     3.17e-07     3.17e-07     8.99e-06
    421    30     2.56e-07     2.56e-07     5.78e-06
    421    40     6.34e-08     6.34e-08     3.85e-06
    421    50     3.53e-07     3.53e-07     7.07e-06
    421    60      7.4e-08      7.4e-08     3.21e-06
    421    61     2.57e-06     2.57e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             421 23175.430    0.005     4.71e-06     4.71e-06     2.48e-05
! Validation        421 23175.430    0.005     3.72e-07     3.72e-07     7.11e-06
Wall time: 23175.430547875
training
# Epoch batch         loss       loss_e      e/N_mae
    422    10     9.03e-06     9.03e-06     3.64e-05
    422    20     4.91e-06     4.91e-06     3.23e-05
    422    30     1.93e-06     1.93e-06     1.86e-05
    422    40     3.11e-06     3.11e-06      2.4e-05
    422    48     5.76e-07     5.76e-07     1.04e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    422    10      2.3e-07      2.3e-07     6.42e-06
    422    20     2.94e-07     2.94e-07     8.67e-06
    422    30     2.13e-07     2.13e-07     6.75e-06
    422    40     2.49e-07     2.49e-07     6.75e-06
    422    50        3e-07        3e-07     6.75e-06
    422    60     1.33e-07     1.33e-07     5.14e-06
    422    61      3.3e-06      3.3e-06     2.41e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             422 23230.644    0.005     4.39e-06     4.39e-06     2.72e-05
! Validation        422 23230.644    0.005     4.31e-07     4.31e-07     7.92e-06
Wall time: 23230.644543290997
training
# Epoch batch         loss       loss_e      e/N_mae
    423    10      1.9e-06      1.9e-06     1.83e-05
    423    20     9.66e-07     9.66e-07     1.45e-05
    423    30     4.54e-07     4.54e-07     8.35e-06
    423    40     1.12e-06     1.12e-06     1.33e-05
    423    48     9.51e-08     9.51e-08     5.62e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    423    10     2.16e-07     2.16e-07     6.75e-06
    423    20     2.01e-07     2.01e-07     7.07e-06
    423    30     1.73e-07     1.73e-07      6.1e-06
    423    40     9.09e-08     9.09e-08     3.85e-06
    423    50     3.61e-07     3.61e-07     8.35e-06
    423    60     5.92e-08     5.92e-08     2.57e-06
    423    61     3.13e-06     3.13e-06      2.3e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             423 23285.768    0.005      1.4e-06      1.4e-06     1.56e-05
! Validation        423 23285.768    0.005     3.48e-07     3.48e-07     7.15e-06
Wall time: 23285.768691791
training
# Epoch batch         loss       loss_e      e/N_mae
    424    10     9.46e-07     9.46e-07     1.43e-05
    424    20     5.48e-07     5.48e-07     1.05e-05
    424    30      2.8e-07      2.8e-07     6.85e-06
    424    40     8.98e-07     8.98e-07     1.05e-05
    424    48     1.06e-08     1.06e-08     1.61e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    424    10     2.07e-07     2.07e-07     6.75e-06
    424    20     3.23e-07     3.23e-07     8.35e-06
    424    30     2.01e-07     2.01e-07     7.39e-06
    424    40      1.2e-07      1.2e-07      4.5e-06
    424    50     3.36e-07     3.36e-07     7.71e-06
    424    60     8.88e-08     8.88e-08     4.18e-06
    424    61     3.22e-06     3.22e-06      2.3e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             424 23340.863    0.005     8.25e-07     8.25e-07     1.17e-05
! Validation        424 23340.863    0.005     3.25e-07     3.25e-07     6.91e-06
Wall time: 23340.863896875
training
# Epoch batch         loss       loss_e      e/N_mae
    425    10     4.21e-07     4.21e-07     8.78e-06
    425    20     6.62e-06     6.62e-06     2.68e-05
    425    30     2.48e-06     2.48e-06     1.99e-05
    425    40     3.19e-06     3.19e-06     2.54e-05
    425    48     7.87e-07     7.87e-07     1.45e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    425    10     1.61e-07     1.61e-07     6.42e-06
    425    20     3.06e-07     3.06e-07     8.35e-06
    425    30     4.14e-07     4.14e-07     9.64e-06
    425    40     6.34e-08     6.34e-08     3.53e-06
    425    50     2.35e-07     2.35e-07     5.78e-06
    425    60     7.19e-08     7.19e-08     4.18e-06
    425    61     2.66e-06     2.66e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             425 23395.929    0.005     3.09e-06     3.09e-06     1.98e-05
! Validation        425 23395.929    0.005     3.49e-07     3.49e-07     7.15e-06
Wall time: 23395.929547165997
training
# Epoch batch         loss       loss_e      e/N_mae
    426    10     6.72e-06     6.72e-06     3.31e-05
    426    20     5.96e-06     5.96e-06     3.24e-05
    426    30     7.25e-06     7.25e-06     3.42e-05
    426    40     1.99e-06     1.99e-06     1.92e-05
    426    48     2.56e-06     2.56e-06     2.65e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    426    10     2.75e-07     2.75e-07     6.42e-06
    426    20      3.8e-07      3.8e-07     9.64e-06
    426    30     2.77e-07     2.77e-07     8.03e-06
    426    40     2.07e-07     2.07e-07      6.1e-06
    426    50     2.77e-07     2.77e-07     7.07e-06
    426    60     3.17e-08     3.17e-08     2.57e-06
    426    61     3.32e-06     3.32e-06      2.3e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             426 23450.837    0.005     4.24e-06     4.24e-06     2.57e-05
! Validation        426 23450.837    0.005     3.87e-07     3.87e-07     7.73e-06
Wall time: 23450.838290083
training
# Epoch batch         loss       loss_e      e/N_mae
    427    10     2.36e-06     2.36e-06     2.03e-05
    427    20     1.44e-06     1.44e-06      1.7e-05
    427    30     5.88e-07     5.88e-07     1.03e-05
    427    40     6.19e-07     6.19e-07     9.85e-06
    427    48     2.64e-07     2.64e-07     6.42e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    427    10     2.98e-07     2.98e-07     6.42e-06
    427    20     4.33e-07     4.33e-07     8.35e-06
    427    30     1.94e-07     1.94e-07      6.1e-06
    427    40     6.55e-08     6.55e-08     3.85e-06
    427    50     4.95e-07     4.95e-07     8.67e-06
    427    60     1.59e-07     1.59e-07      6.1e-06
    427    61     3.27e-06     3.27e-06     2.36e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             427 23506.032    0.005      1.2e-06      1.2e-06     1.44e-05
! Validation        427 23506.032    0.005     3.88e-07     3.88e-07     7.71e-06
Wall time: 23506.033434208
training
# Epoch batch         loss       loss_e      e/N_mae
    428    10     2.85e-07     2.85e-07     7.17e-06
    428    20     4.46e-07     4.46e-07      9.1e-06
    428    30     1.48e-06     1.48e-06     1.69e-05
    428    40     6.73e-07     6.73e-07     1.06e-05
    428    48     8.66e-07     8.66e-07     1.53e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    428    10     2.79e-07     2.79e-07     7.39e-06
    428    20      2.6e-07      2.6e-07     7.07e-06
    428    30     2.62e-07     2.62e-07     8.03e-06
    428    40     9.72e-08     9.72e-08     4.18e-06
    428    50     4.14e-07     4.14e-07     8.67e-06
    428    60     1.65e-07     1.65e-07      6.1e-06
    428    61     3.17e-06     3.17e-06     2.25e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             428 23561.200    0.005     1.03e-06     1.03e-06     1.36e-05
! Validation        428 23561.200    0.005     3.55e-07     3.55e-07     7.41e-06
Wall time: 23561.201690415997
training
# Epoch batch         loss       loss_e      e/N_mae
    429    10     7.49e-07     7.49e-07      1.2e-05
    429    20      6.2e-07      6.2e-07     1.15e-05
    429    30     1.98e-06     1.98e-06     1.78e-05
    429    40     1.09e-06     1.09e-06     1.34e-05
    429    48      2.8e-07      2.8e-07     7.23e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    429    10     2.81e-07     2.81e-07     6.42e-06
    429    20     3.42e-07     3.42e-07     8.03e-06
    429    30     3.25e-07     3.25e-07     8.67e-06
    429    40     1.59e-07     1.59e-07      4.5e-06
    429    50     3.68e-07     3.68e-07     8.03e-06
    429    60     1.92e-07     1.92e-07     6.42e-06
    429    61     2.94e-06     2.94e-06     2.09e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             429 23616.258    0.005     8.79e-07     8.79e-07     1.23e-05
! Validation        429 23616.258    0.005     3.49e-07     3.49e-07     7.29e-06
Wall time: 23616.258897916
training
# Epoch batch         loss       loss_e      e/N_mae
    430    10     2.17e-06     2.17e-06     1.94e-05
    430    20     9.31e-07     9.31e-07     1.21e-05
    430    30     5.71e-07     5.71e-07     1.09e-05
    430    40     9.57e-07     9.57e-07     1.32e-05
    430    48     3.86e-07     3.86e-07     1.04e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    430    10     1.25e-07     1.25e-07     4.18e-06
    430    20     1.04e-07     1.04e-07     4.82e-06
    430    30     3.02e-07     3.02e-07     7.71e-06
    430    40     1.61e-07     1.61e-07     4.82e-06
    430    50     3.99e-07     3.99e-07     7.71e-06
    430    60     1.14e-07     1.14e-07     4.82e-06
    430    61     2.69e-06     2.69e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             430 23671.318    0.005     1.72e-06     1.72e-06     1.66e-05
! Validation        430 23671.318    0.005     3.58e-07     3.58e-07     7.16e-06
Wall time: 23671.3193115
training
# Epoch batch         loss       loss_e      e/N_mae
    431    10     1.67e-06     1.67e-06     1.71e-05
    431    20     1.11e-06     1.11e-06     1.46e-05
    431    30     5.23e-07     5.23e-07     9.85e-06
    431    40     4.98e-07     4.98e-07     1.02e-05
    431    48     4.23e-08     4.23e-08     4.02e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    431    10     1.59e-07     1.59e-07     4.18e-06
    431    20     1.01e-07     1.01e-07      4.5e-06
    431    30     2.58e-07     2.58e-07     7.39e-06
    431    40     2.68e-07     2.68e-07     5.78e-06
    431    50      3.7e-07      3.7e-07     8.35e-06
    431    60     3.19e-07     3.19e-07     8.03e-06
    431    61        3e-06        3e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             431 23726.346    0.005     1.78e-06     1.78e-06     1.71e-05
! Validation        431 23726.346    0.005     3.63e-07     3.63e-07     7.35e-06
Wall time: 23726.347532416
training
# Epoch batch         loss       loss_e      e/N_mae
    432    10      2.6e-07      2.6e-07     7.07e-06
    432    20     3.97e-07     3.97e-07      9.1e-06
    432    30     2.01e-07     2.01e-07     5.78e-06
    432    40     4.37e-07     4.37e-07     1.04e-05
    432    48     8.45e-08     8.45e-08     3.21e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    432    10     1.67e-07     1.67e-07     5.14e-06
    432    20     9.51e-08     9.51e-08     4.18e-06
    432    30     1.61e-07     1.61e-07      6.1e-06
    432    40      2.3e-07      2.3e-07     4.82e-06
    432    50     4.46e-07     4.46e-07     8.35e-06
    432    60     3.57e-07     3.57e-07     8.99e-06
    432    61     3.47e-06     3.47e-06     2.09e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             432 23781.459    0.005     4.71e-07     4.71e-07      9.1e-06
! Validation        432 23781.459    0.005     3.59e-07     3.59e-07     7.06e-06
Wall time: 23781.460073457998
training
# Epoch batch         loss       loss_e      e/N_mae
    433    10     2.66e-07     2.66e-07     6.53e-06
    433    20     5.48e-07     5.48e-07     9.85e-06
    433    30     2.01e-06     2.01e-06     1.88e-05
    433    40     1.45e-06     1.45e-06     1.56e-05
    433    48     2.11e-07     2.11e-07     7.23e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    433    10     1.54e-07     1.54e-07      6.1e-06
    433    20     9.93e-08     9.93e-08     4.82e-06
    433    30     2.13e-07     2.13e-07     7.07e-06
    433    40     2.01e-07     2.01e-07     6.42e-06
    433    50     4.67e-07     4.67e-07     9.64e-06
    433    60     1.94e-07     1.94e-07     7.07e-06
    433    61     2.85e-06     2.85e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             433 23836.529    0.005     1.08e-06     1.08e-06     1.25e-05
! Validation        433 23836.529    0.005      3.4e-07      3.4e-07     7.09e-06
Wall time: 23836.530239958
training
# Epoch batch         loss       loss_e      e/N_mae
    434    10     7.04e-07     7.04e-07     1.16e-05
    434    20     3.88e-07     3.88e-07     9.21e-06
    434    30     4.68e-07     4.68e-07     8.25e-06
    434    40     4.45e-07     4.45e-07     8.35e-06
    434    48     8.98e-08     8.98e-08     4.02e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    434    10      1.9e-07      1.9e-07     5.46e-06
    434    20     1.42e-07     1.42e-07     5.78e-06
    434    30     1.37e-07     1.37e-07     5.14e-06
    434    40     2.07e-07     2.07e-07      6.1e-06
    434    50     5.88e-07     5.88e-07     9.32e-06
    434    60     1.63e-07     1.63e-07     5.14e-06
    434    61     2.33e-06     2.33e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             434 23891.829    0.005     6.39e-07     6.39e-07     1.05e-05
! Validation        434 23891.829    0.005     3.19e-07     3.19e-07     6.92e-06
Wall time: 23891.828991874998
training
# Epoch batch         loss       loss_e      e/N_mae
    435    10     4.49e-07     4.49e-07     9.96e-06
    435    20     4.49e-07     4.49e-07     9.85e-06
    435    30     1.43e-06     1.43e-06     1.72e-05
    435    40      4.4e-07      4.4e-07     8.46e-06
    435    48     5.28e-08     5.28e-08     3.21e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    435    10     2.41e-07     2.41e-07      6.1e-06
    435    20     9.09e-08     9.09e-08     3.85e-06
    435    30     1.23e-07     1.23e-07     5.14e-06
    435    40     2.26e-07     2.26e-07      6.1e-06
    435    50     6.11e-07     6.11e-07     1.06e-05
    435    60     1.61e-07     1.61e-07     4.82e-06
    435    61     2.75e-06     2.75e-06     2.09e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             435 23946.895    0.005     5.22e-07     5.22e-07     9.14e-06
! Validation        435 23946.895    0.005     3.04e-07     3.04e-07     6.64e-06
Wall time: 23946.896262666
training
# Epoch batch         loss       loss_e      e/N_mae
    436    10      3.1e-07      3.1e-07     6.53e-06
    436    20     2.06e-07     2.06e-07     6.64e-06
    436    30     6.87e-07     6.87e-07     1.01e-05
    436    40     2.87e-07     2.87e-07     7.28e-06
    436    48     3.06e-07     3.06e-07     8.83e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    436    10     1.67e-07     1.67e-07     4.82e-06
    436    20     1.71e-07     1.71e-07      6.1e-06
    436    30     1.71e-07     1.71e-07     5.14e-06
    436    40      1.8e-07      1.8e-07     4.82e-06
    436    50     4.37e-07     4.37e-07     8.99e-06
    436    60     2.58e-07     2.58e-07      6.1e-06
    436    61     2.69e-06     2.69e-06     1.87e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             436 24002.157    0.005     3.52e-07     3.52e-07     7.74e-06
! Validation        436 24002.157    0.005     2.98e-07     2.98e-07     6.53e-06
Wall time: 24002.158148958
training
# Epoch batch         loss       loss_e      e/N_mae
    437    10     4.91e-07     4.91e-07     9.32e-06
    437    20     4.85e-07     4.85e-07     9.64e-06
    437    30     2.87e-07     2.87e-07     7.71e-06
    437    40     4.28e-07     4.28e-07     7.82e-06
    437    48     1.53e-07     1.53e-07     6.42e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    437    10     1.61e-07     1.61e-07      4.5e-06
    437    20     1.01e-07     1.01e-07      4.5e-06
    437    30     9.72e-08     9.72e-08     4.18e-06
    437    40      1.2e-07      1.2e-07     4.18e-06
    437    50     5.79e-07     5.79e-07     1.03e-05
    437    60     2.05e-07     2.05e-07      4.5e-06
    437    61      2.8e-06      2.8e-06     2.14e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             437 24057.070    0.005     3.73e-07     3.73e-07     8.12e-06
! Validation        437 24057.070    0.005     2.87e-07     2.87e-07     6.34e-06
Wall time: 24057.070014375
training
# Epoch batch         loss       loss_e      e/N_mae
    438    10     1.54e-07     1.54e-07     5.25e-06
    438    20     6.33e-07     6.33e-07     9.85e-06
    438    30      3.8e-07      3.8e-07     8.25e-06
    438    40     2.95e-07     2.95e-07     8.14e-06
    438    48     5.13e-07     5.13e-07     1.12e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    438    10     2.24e-07     2.24e-07      6.1e-06
    438    20     7.19e-08     7.19e-08     4.18e-06
    438    30     1.56e-07     1.56e-07     5.78e-06
    438    40     1.92e-07     1.92e-07     4.82e-06
    438    50     3.87e-07     3.87e-07     8.67e-06
    438    60     1.59e-07     1.59e-07      4.5e-06
    438    61     2.32e-06     2.32e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             438 24112.139    0.005     5.99e-07     5.99e-07     9.81e-06
! Validation        438 24112.139    0.005     2.82e-07     2.82e-07     6.35e-06
Wall time: 24112.140283333
training
# Epoch batch         loss       loss_e      e/N_mae
    439    10     5.07e-07     5.07e-07     1.06e-05
    439    20     5.47e-07     5.47e-07     9.74e-06
    439    30     3.14e-07     3.14e-07     7.39e-06
    439    40     2.87e-07     2.87e-07     6.96e-06
    439    48     1.08e-06     1.08e-06     1.61e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    439    10     1.42e-07     1.42e-07     4.82e-06
    439    20     1.18e-07     1.18e-07     5.14e-06
    439    30     1.16e-07     1.16e-07      4.5e-06
    439    40     1.25e-07     1.25e-07     4.18e-06
    439    50      5.3e-07      5.3e-07     9.32e-06
    439    60     1.42e-07     1.42e-07     6.42e-06
    439    61     2.94e-06     2.94e-06     2.09e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             439 24167.339    0.005     8.93e-07     8.93e-07     1.23e-05
! Validation        439 24167.339    0.005     2.76e-07     2.76e-07     6.18e-06
Wall time: 24167.339600624997
training
# Epoch batch         loss       loss_e      e/N_mae
    440    10     1.03e-06     1.03e-06     1.26e-05
    440    20     1.79e-06     1.79e-06     1.83e-05
    440    30     7.16e-07     7.16e-07     1.12e-05
    440    40     2.38e-06     2.38e-06     2.24e-05
    440    48     1.37e-07     1.37e-07     5.62e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    440    10     1.78e-07     1.78e-07     5.14e-06
    440    20     1.23e-07     1.23e-07     5.14e-06
    440    30     9.72e-08     9.72e-08     5.14e-06
    440    40     2.09e-07     2.09e-07     5.46e-06
    440    50     3.32e-07     3.32e-07     7.07e-06
    440    60     2.16e-07     2.16e-07     7.07e-06
    440    61     2.54e-06     2.54e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             440 24222.410    0.005     1.45e-06     1.45e-06     1.57e-05
! Validation        440 24222.410    0.005      2.8e-07      2.8e-07      6.4e-06
Wall time: 24222.410636665998
training
# Epoch batch         loss       loss_e      e/N_mae
    441    10     1.44e-06     1.44e-06     1.78e-05
    441    20     9.33e-07     9.33e-07     1.32e-05
    441    30     1.71e-06     1.71e-06      1.5e-05
    441    40     2.59e-06     2.59e-06     2.38e-05
    441    48     1.95e-07     1.95e-07     6.42e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    441    10     1.25e-07     1.25e-07     4.18e-06
    441    20     1.99e-07     1.99e-07     6.42e-06
    441    30     1.33e-07     1.33e-07     5.46e-06
    441    40     1.54e-07     1.54e-07     4.18e-06
    441    50     5.26e-07     5.26e-07     9.64e-06
    441    60     9.72e-08     9.72e-08     5.14e-06
    441    61      2.8e-06      2.8e-06     2.03e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             441 24277.217    0.005     1.43e-06     1.43e-06     1.58e-05
! Validation        441 24277.217    0.005      2.9e-07      2.9e-07     6.61e-06
Wall time: 24277.218347208
training
# Epoch batch         loss       loss_e      e/N_mae
    442    10     6.87e-07     6.87e-07     1.09e-05
    442    20     7.21e-07     7.21e-07     1.11e-05
    442    30     8.85e-07     8.85e-07     1.18e-05
    442    40     5.45e-07     5.45e-07     1.07e-05
    442    48     1.55e-06     1.55e-06     1.61e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    442    10     2.09e-07     2.09e-07      6.1e-06
    442    20     1.39e-07     1.39e-07     5.14e-06
    442    30     1.31e-07     1.31e-07     5.78e-06
    442    40     1.18e-07     1.18e-07     3.85e-06
    442    50     4.99e-07     4.99e-07     9.96e-06
    442    60     1.08e-07     1.08e-07     4.18e-06
    442    61     2.61e-06     2.61e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             442 24332.254    0.005     1.31e-06     1.31e-06     1.51e-05
! Validation        442 24332.254    0.005     3.11e-07     3.11e-07     6.73e-06
Wall time: 24332.254238291
training
# Epoch batch         loss       loss_e      e/N_mae
    443    10     2.13e-06     2.13e-06     1.98e-05
    443    20     4.48e-06     4.48e-06     2.68e-05
    443    30     1.56e-06     1.56e-06     1.78e-05
    443    40     2.65e-07     2.65e-07     6.75e-06
    443    48     1.07e-06     1.07e-06     1.69e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    443    10     3.51e-07     3.51e-07     7.07e-06
    443    20        3e-07        3e-07     7.39e-06
    443    30      1.8e-07      1.8e-07     6.42e-06
    443    40     1.31e-07     1.31e-07      4.5e-06
    443    50     2.49e-07     2.49e-07     7.39e-06
    443    60     7.61e-08     7.61e-08     3.53e-06
    443    61     2.61e-06     2.61e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             443 24387.408    0.005     2.46e-06     2.46e-06     1.93e-05
! Validation        443 24387.408    0.005      3.4e-07      3.4e-07     7.06e-06
Wall time: 24387.4083305
training
# Epoch batch         loss       loss_e      e/N_mae
    444    10     2.27e-06     2.27e-06     1.53e-05
    444    20      6.3e-07      6.3e-07     1.14e-05
    444    30     3.89e-07     3.89e-07     8.78e-06
    444    40     4.64e-07     4.64e-07     9.32e-06
    444    48     1.17e-06     1.17e-06     1.61e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    444    10     3.53e-07     3.53e-07     8.35e-06
    444    20     2.41e-07     2.41e-07     7.07e-06
    444    30     1.33e-07     1.33e-07      4.5e-06
    444    40     1.31e-07     1.31e-07      4.5e-06
    444    50     2.79e-07     2.79e-07     7.39e-06
    444    60     1.06e-07     1.06e-07     4.82e-06
    444    61     2.04e-06     2.04e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             444 24442.506    0.005     1.16e-06     1.16e-06     1.39e-05
! Validation        444 24442.506    0.005     3.08e-07     3.08e-07     6.85e-06
Wall time: 24442.506712958
training
# Epoch batch         loss       loss_e      e/N_mae
    445    10     1.46e-06     1.46e-06     1.63e-05
    445    20     3.85e-07     3.85e-07      7.6e-06
    445    30        7e-07        7e-07     1.04e-05
    445    40     8.42e-07     8.42e-07      1.3e-05
    445    48     5.13e-07     5.13e-07      1.2e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    445    10     2.49e-07     2.49e-07     6.75e-06
    445    20     1.48e-07     1.48e-07     4.82e-06
    445    30     1.42e-07     1.42e-07     5.78e-06
    445    40     2.35e-07     2.35e-07      6.1e-06
    445    50     3.21e-07     3.21e-07     8.03e-06
    445    60     1.54e-07     1.54e-07      6.1e-06
    445    61     2.62e-06     2.62e-06     2.09e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             445 24497.770    0.005     9.12e-07     9.12e-07     1.24e-05
! Validation        445 24497.770    0.005     3.13e-07     3.13e-07     6.89e-06
Wall time: 24497.770528166
training
# Epoch batch         loss       loss_e      e/N_mae
    446    10     4.08e-07     4.08e-07     8.57e-06
    446    20     7.02e-07     7.02e-07     1.15e-05
    446    30     6.54e-07     6.54e-07     9.64e-06
    446    40     1.22e-06     1.22e-06     1.46e-05
    446    48     2.59e-07     2.59e-07     6.42e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    446    10     3.19e-07     3.19e-07     8.67e-06
    446    20     2.28e-07     2.28e-07     5.78e-06
    446    30     3.59e-08     3.59e-08     3.21e-06
    446    40     2.47e-07     2.47e-07     5.46e-06
    446    50     4.54e-07     4.54e-07     8.99e-06
    446    60     9.09e-08     9.09e-08     3.85e-06
    446    61     2.75e-06     2.75e-06     2.09e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             446 24552.828    0.005     5.56e-07     5.56e-07      9.7e-06
! Validation        446 24552.828    0.005     3.11e-07     3.11e-07     6.73e-06
Wall time: 24552.82960225
training
# Epoch batch         loss       loss_e      e/N_mae
    447    10     1.12e-06     1.12e-06     1.52e-05
    447    20      3.9e-07      3.9e-07     8.78e-06
    447    30     7.37e-07     7.37e-07     1.28e-05
    447    40     3.71e-07     3.71e-07     8.89e-06
    447    48     2.64e-07     2.64e-07     9.64e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    447    10      3.8e-07      3.8e-07     8.99e-06
    447    20     1.67e-07     1.67e-07     5.46e-06
    447    30     1.06e-07     1.06e-07     5.14e-06
    447    40     2.85e-07     2.85e-07     6.75e-06
    447    50     2.51e-07     2.51e-07     6.42e-06
    447    60     1.04e-07     1.04e-07      4.5e-06
    447    61     2.99e-06     2.99e-06     2.09e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             447 24607.894    0.005     7.64e-07     7.64e-07     1.17e-05
! Validation        447 24607.894    0.005     3.15e-07     3.15e-07     6.81e-06
Wall time: 24607.894983708
training
# Epoch batch         loss       loss_e      e/N_mae
    448    10     2.45e-07     2.45e-07     7.28e-06
    448    20     2.42e-07     2.42e-07     6.85e-06
    448    30     4.45e-07     4.45e-07     8.35e-06
    448    40     4.85e-07     4.85e-07     8.03e-06
    448    48     4.49e-07     4.49e-07     8.83e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    448    10        3e-07        3e-07     7.39e-06
    448    20     2.71e-07     2.71e-07     6.42e-06
    448    30     1.16e-07     1.16e-07     5.14e-06
    448    40     2.66e-07     2.66e-07     5.78e-06
    448    50     4.21e-07     4.21e-07     8.35e-06
    448    60     1.35e-07     1.35e-07     5.46e-06
    448    61     2.74e-06     2.74e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             448 24663.064    0.005     7.04e-07     7.04e-07     1.08e-05
! Validation        448 24663.064    0.005     2.98e-07     2.98e-07     6.62e-06
Wall time: 24663.063774374998
training
# Epoch batch         loss       loss_e      e/N_mae
    449    10     4.69e-07     4.69e-07     9.21e-06
    449    20     7.78e-07     7.78e-07     1.17e-05
    449    30     3.57e-07     3.57e-07     8.78e-06
    449    40     1.26e-06     1.26e-06     1.55e-05
    449    48     3.94e-06     3.94e-06     2.97e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    449    10     2.94e-07     2.94e-07     7.71e-06
    449    20     1.69e-07     1.69e-07     5.46e-06
    449    30     1.48e-07     1.48e-07     5.46e-06
    449    40     2.43e-07     2.43e-07     5.46e-06
    449    50     2.75e-07     2.75e-07     7.39e-06
    449    60     2.01e-07     2.01e-07     5.78e-06
    449    61     2.69e-06     2.69e-06     1.87e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             449 24718.217    0.005     1.22e-06     1.22e-06      1.4e-05
! Validation        449 24718.217    0.005     3.09e-07     3.09e-07     6.71e-06
Wall time: 24718.218239208
training
# Epoch batch         loss       loss_e      e/N_mae
    450    10      1.6e-06      1.6e-06     1.65e-05
    450    20     2.05e-06     2.05e-06     1.79e-05
    450    30     1.28e-06     1.28e-06     1.43e-05
    450    40     2.35e-06     2.35e-06     2.08e-05
    450    48     2.64e-08     2.64e-08     2.41e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    450    10     1.12e-07     1.12e-07     5.46e-06
    450    20     2.18e-07     2.18e-07      6.1e-06
    450    30     1.06e-07     1.06e-07     4.82e-06
    450    40     3.74e-07     3.74e-07     7.07e-06
    450    50     2.68e-07     2.68e-07     6.42e-06
    450    60     1.27e-07     1.27e-07     5.46e-06
    450    61     3.46e-06     3.46e-06      2.3e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             450 24773.195    0.005     1.62e-06     1.62e-06     1.68e-05
! Validation        450 24773.195    0.005     3.27e-07     3.27e-07     6.94e-06
Wall time: 24773.196216499997
training
# Epoch batch         loss       loss_e      e/N_mae
    451    10     3.37e-06     3.37e-06     2.55e-05
    451    20     9.91e-06     9.91e-06     4.37e-05
    451    30      3.9e-06      3.9e-06     2.13e-05
    451    40     2.84e-06     2.84e-06     2.55e-05
    451    48     3.59e-07     3.59e-07     8.03e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    451    10     1.35e-07     1.35e-07     4.82e-06
    451    20     2.58e-07     2.58e-07     7.71e-06
    451    30     1.73e-07     1.73e-07     5.46e-06
    451    40     5.16e-07     5.16e-07     9.32e-06
    451    50     4.71e-07     4.71e-07     8.35e-06
    451    60     9.72e-08     9.72e-08     4.82e-06
    451    61     2.86e-06     2.86e-06     2.09e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             451 24828.204    0.005     4.95e-06     4.95e-06     2.93e-05
! Validation        451 24828.204    0.005     3.29e-07     3.29e-07        7e-06
Wall time: 24828.204692083
training
# Epoch batch         loss       loss_e      e/N_mae
    452    10     2.76e-06     2.76e-06     2.27e-05
    452    20     2.02e-06     2.02e-06     1.73e-05
    452    30     1.46e-06     1.46e-06     1.48e-05
    452    40     1.89e-06     1.89e-06     1.77e-05
    452    48     1.19e-06     1.19e-06     1.37e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    452    10     1.48e-07     1.48e-07      4.5e-06
    452    20     2.16e-07     2.16e-07     8.03e-06
    452    30     1.12e-07     1.12e-07     4.82e-06
    452    40      3.4e-07      3.4e-07     7.71e-06
    452    50     4.46e-07     4.46e-07     7.71e-06
    452    60      3.8e-08      3.8e-08     2.89e-06
    452    61     3.19e-06     3.19e-06     2.14e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             452 24883.601    0.005     1.99e-06     1.99e-06     1.87e-05
! Validation        452 24883.601    0.005     3.69e-07     3.69e-07     7.53e-06
Wall time: 24883.600983458
training
# Epoch batch         loss       loss_e      e/N_mae
    453    10     3.93e-07     3.93e-07     8.67e-06
    453    20     1.77e-06     1.77e-06     1.68e-05
    453    30     2.26e-06     2.26e-06     2.05e-05
    453    40     4.11e-06     4.11e-06     2.61e-05
    453    48     2.64e-08     2.64e-08     2.41e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    453    10     1.46e-07     1.46e-07      6.1e-06
    453    20     2.26e-07     2.26e-07     7.39e-06
    453    30     4.65e-08     4.65e-08     3.21e-06
    453    40     6.15e-07     6.15e-07     8.03e-06
    453    50     6.07e-07     6.07e-07     1.03e-05
    453    60      1.1e-07      1.1e-07      4.5e-06
    453    61     3.61e-06     3.61e-06      2.3e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             453 24938.643    0.005     4.75e-06     4.75e-06     2.59e-05
! Validation        453 24938.643    0.005     3.77e-07     3.77e-07     7.42e-06
Wall time: 24938.644236665998
training
# Epoch batch         loss       loss_e      e/N_mae
    454    10     4.05e-06     4.05e-06     2.62e-05
    454    20     5.16e-06     5.16e-06     2.93e-05
    454    30     2.49e-06     2.49e-06      2.1e-05
    454    40     7.88e-06     7.88e-06     3.75e-05
    454    48      8.8e-06      8.8e-06     4.82e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    454    10     1.65e-07     1.65e-07      6.1e-06
    454    20      2.2e-07      2.2e-07     5.78e-06
    454    30     4.65e-08     4.65e-08     3.85e-06
    454    40     2.51e-07     2.51e-07     5.46e-06
    454    50     3.91e-07     3.91e-07     8.35e-06
    454    60     1.69e-07     1.69e-07     5.46e-06
    454    61     3.89e-06     3.89e-06     2.36e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             454 24993.924    0.005     6.07e-06     6.07e-06     3.08e-05
! Validation        454 24993.924    0.005     4.49e-07     4.49e-07        8e-06
Wall time: 24993.925370999998
training
# Epoch batch         loss       loss_e      e/N_mae
    455    10     2.61e-05     2.61e-05     6.89e-05
    455    20     4.54e-06     4.54e-06     2.97e-05
    455    30     9.51e-06     9.51e-06     4.51e-05
    455    40     1.49e-05     1.49e-05     5.54e-05
    455    48     7.66e-07     7.66e-07     1.12e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    455    10     2.87e-07     2.87e-07     6.42e-06
    455    20     3.02e-07     3.02e-07     8.35e-06
    455    30     9.24e-07     9.24e-07     1.45e-05
    455    40     8.39e-07     8.39e-07     1.22e-05
    455    50     1.99e-07     1.99e-07     6.42e-06
    455    60     4.88e-07     4.88e-07     1.06e-05
    455    61     3.15e-06     3.15e-06     2.52e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             455 25048.996    0.005      1.5e-05      1.5e-05     5.05e-05
! Validation        455 25048.996    0.005     8.94e-07     8.94e-07     1.19e-05
Wall time: 25048.996398125
training
# Epoch batch         loss       loss_e      e/N_mae
    456    10     2.82e-06     2.82e-06     2.07e-05
    456    20     3.86e-06     3.86e-06      2.9e-05
    456    30     1.44e-06     1.44e-06     1.64e-05
    456    40     1.41e-06     1.41e-06     1.48e-05
    456    48     6.87e-08     6.87e-08     4.02e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    456    10     2.66e-07     2.66e-07     6.42e-06
    456    20     2.49e-07     2.49e-07     6.42e-06
    456    30     8.52e-07     8.52e-07     1.32e-05
    456    40     5.98e-07     5.98e-07     1.03e-05
    456    50      2.3e-07      2.3e-07     5.46e-06
    456    60     2.41e-07     2.41e-07     7.07e-06
    456    61     4.04e-06     4.04e-06     2.73e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             456 25103.832    0.005     3.93e-06     3.93e-06     2.55e-05
! Validation        456 25103.832    0.005     7.59e-07     7.59e-07     1.09e-05
Wall time: 25103.831873207997
training
# Epoch batch         loss       loss_e      e/N_mae
    457    10      1.6e-06      1.6e-06     1.57e-05
    457    20     6.59e-07     6.59e-07     1.09e-05
    457    30     1.65e-06     1.65e-06     1.85e-05
    457    40     8.32e-07     8.32e-07     1.23e-05
    457    48     2.08e-06     2.08e-06     2.33e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    457    10     2.05e-07     2.05e-07     5.46e-06
    457    20      4.9e-07      4.9e-07     9.64e-06
    457    30     4.92e-07     4.92e-07     1.12e-05
    457    40     3.19e-07     3.19e-07     7.71e-06
    457    50     2.83e-07     2.83e-07     7.71e-06
    457    60     2.07e-07     2.07e-07     6.42e-06
    457    61     4.12e-06     4.12e-06     2.57e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             457 25158.985    0.005     1.33e-06     1.33e-06     1.45e-05
! Validation        457 25158.985    0.005     5.89e-07     5.89e-07     9.55e-06
Wall time: 25158.9861665
training
# Epoch batch         loss       loss_e      e/N_mae
    458    10     2.46e-06     2.46e-06     1.81e-05
    458    20     6.57e-07     6.57e-07     1.05e-05
    458    30     7.04e-07     7.04e-07     1.04e-05
    458    40     3.94e-07     3.94e-07     7.82e-06
    458    48     1.06e-07     1.06e-07     5.62e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    458    10     2.22e-07     2.22e-07     5.46e-06
    458    20     4.61e-07     4.61e-07     8.99e-06
    458    30     2.16e-07     2.16e-07     7.39e-06
    458    40     3.49e-07     3.49e-07     7.71e-06
    458    50        3e-07        3e-07     8.03e-06
    458    60     1.73e-07     1.73e-07     6.75e-06
    458    61     4.15e-06     4.15e-06     2.68e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             458 25214.169    0.005     1.39e-06     1.39e-06     1.44e-05
! Validation        458 25214.169    0.005        5e-07        5e-07     8.48e-06
Wall time: 25214.169658875
training
# Epoch batch         loss       loss_e      e/N_mae
    459    10     4.12e-07     4.12e-07     8.99e-06
    459    20     1.04e-06     1.04e-06     1.36e-05
    459    30      5.8e-07      5.8e-07     8.57e-06
    459    40     5.09e-07     5.09e-07     9.96e-06
    459    48     1.17e-06     1.17e-06     1.69e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    459    10     8.24e-08     8.24e-08     3.53e-06
    459    20     3.72e-07     3.72e-07     8.67e-06
    459    30     1.86e-07     1.86e-07      6.1e-06
    459    40     2.87e-07     2.87e-07     6.75e-06
    459    50     5.85e-07     5.85e-07     9.64e-06
    459    60     1.08e-07     1.08e-07     5.78e-06
    459    61     4.05e-06     4.05e-06     2.57e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             459 25269.129    0.005     8.75e-07     8.75e-07     1.16e-05
! Validation        459 25269.129    0.005     4.11e-07     4.11e-07     7.56e-06
Wall time: 25269.129651916
training
# Epoch batch         loss       loss_e      e/N_mae
    460    10     5.08e-07     5.08e-07     9.42e-06
    460    20     1.02e-06     1.02e-06     1.25e-05
    460    30      8.7e-07      8.7e-07     1.26e-05
    460    40     3.71e-07     3.71e-07     8.57e-06
    460    48     8.45e-07     8.45e-07     1.28e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    460    10     1.14e-07     1.14e-07     3.21e-06
    460    20     3.32e-07     3.32e-07     8.03e-06
    460    30     1.97e-07     1.97e-07     7.39e-06
    460    40     3.42e-07     3.42e-07     7.39e-06
    460    50     3.87e-07     3.87e-07     8.99e-06
    460    60      7.4e-08      7.4e-08     4.18e-06
    460    61     3.99e-06     3.99e-06     2.57e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             460 25324.233    0.005     1.46e-06     1.46e-06     1.43e-05
! Validation        460 25324.233    0.005     3.97e-07     3.97e-07     7.34e-06
Wall time: 25324.234138707998
training
# Epoch batch         loss       loss_e      e/N_mae
    461    10     5.78e-07     5.78e-07     9.74e-06
    461    20        8e-07        8e-07     1.15e-05
    461    30     3.35e-07     3.35e-07     7.39e-06
    461    40     7.56e-07     7.56e-07     1.14e-05
    461    48     1.06e-07     1.06e-07     4.82e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    461    10     1.12e-07     1.12e-07     3.53e-06
    461    20     3.64e-07     3.64e-07     8.35e-06
    461    30     2.11e-07     2.11e-07     6.75e-06
    461    40     3.28e-07     3.28e-07     5.46e-06
    461    50      5.3e-07      5.3e-07     1.12e-05
    461    60     8.24e-08     8.24e-08      4.5e-06
    461    61     3.47e-06     3.47e-06     2.36e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             461 25379.276    0.005     5.57e-07     5.57e-07     9.53e-06
! Validation        461 25379.276    0.005     3.69e-07     3.69e-07     7.16e-06
Wall time: 25379.277065874998
training
# Epoch batch         loss       loss_e      e/N_mae
    462    10     3.64e-07     3.64e-07      7.5e-06
    462    20     2.27e-07     2.27e-07     6.75e-06
    462    30     1.56e-07     1.56e-07     5.46e-06
    462    40        1e-07        1e-07     4.71e-06
    462    48     1.06e-08     1.06e-08     1.61e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    462    10     1.84e-07     1.84e-07      4.5e-06
    462    20     1.67e-07     1.67e-07     5.46e-06
    462    30     1.35e-07     1.35e-07     5.46e-06
    462    40     2.85e-07     2.85e-07     5.46e-06
    462    50     5.43e-07     5.43e-07     1.12e-05
    462    60     1.23e-07     1.23e-07     5.78e-06
    462    61     3.52e-06     3.52e-06      2.2e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             462 25434.385    0.005     2.91e-07     2.91e-07     7.17e-06
! Validation        462 25434.385    0.005     3.31e-07     3.31e-07     6.72e-06
Wall time: 25434.386422375
training
# Epoch batch         loss       loss_e      e/N_mae
    463    10     1.99e-07     1.99e-07     5.46e-06
    463    20     2.57e-07     2.57e-07     7.39e-06
    463    30     6.79e-07     6.79e-07     1.06e-05
    463    40     8.22e-07     8.22e-07     1.21e-05
    463    48     1.38e-06     1.38e-06     1.77e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    463    10     2.68e-07     2.68e-07     6.42e-06
    463    20     1.63e-07     1.63e-07     5.46e-06
    463    30     7.61e-08     7.61e-08     4.18e-06
    463    40     2.62e-07     2.62e-07     6.75e-06
    463    50      3.8e-07      3.8e-07     9.64e-06
    463    60     9.51e-08     9.51e-08     3.85e-06
    463    61     3.23e-06     3.23e-06     2.03e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             463 25489.668    0.005     4.22e-07     4.22e-07     8.21e-06
! Validation        463 25489.668    0.005     3.22e-07     3.22e-07     6.57e-06
Wall time: 25489.669298708
training
# Epoch batch         loss       loss_e      e/N_mae
    464    10     3.14e-07     3.14e-07      7.6e-06
    464    20     2.82e-07     2.82e-07     7.71e-06
    464    30     2.64e-07     2.64e-07     6.53e-06
    464    40     4.18e-07     4.18e-07     9.21e-06
    464    48     5.13e-07     5.13e-07     1.12e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    464    10     3.95e-07     3.95e-07     7.07e-06
    464    20     1.88e-07     1.88e-07     5.78e-06
    464    30     9.09e-08     9.09e-08     3.85e-06
    464    40     2.71e-07     2.71e-07     7.39e-06
    464    50     4.21e-07     4.21e-07     8.99e-06
    464    60      1.1e-07      1.1e-07     4.82e-06
    464    61      3.9e-06      3.9e-06      2.2e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             464 25544.717    0.005     5.71e-07     5.71e-07     9.83e-06
! Validation        464 25544.717    0.005     3.24e-07     3.24e-07     6.49e-06
Wall time: 25544.718408957997
training
# Epoch batch         loss       loss_e      e/N_mae
    465    10     8.34e-07     8.34e-07     1.07e-05
    465    20      3.9e-07      3.9e-07     7.28e-06
    465    30      5.8e-07      5.8e-07     9.32e-06
    465    40     3.72e-07     3.72e-07     8.35e-06
    465    48     4.33e-07     4.33e-07     8.83e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    465    10     3.78e-07     3.78e-07     5.46e-06
    465    20      1.1e-07      1.1e-07     3.85e-06
    465    30     1.61e-07     1.61e-07     5.46e-06
    465    40      2.6e-07      2.6e-07     7.07e-06
    465    50     3.53e-07     3.53e-07     7.71e-06
    465    60     1.29e-07     1.29e-07     5.14e-06
    465    61     3.01e-06     3.01e-06     2.03e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             465 25599.758    0.005     5.34e-07     5.34e-07     9.48e-06
! Validation        465 25599.758    0.005     2.98e-07     2.98e-07     6.28e-06
Wall time: 25599.758745125
training
# Epoch batch         loss       loss_e      e/N_mae
    466    10     3.81e-07     3.81e-07     8.99e-06
    466    20     8.65e-07     8.65e-07      1.1e-05
    466    30     6.68e-07     6.68e-07     1.16e-05
    466    40     4.86e-07     4.86e-07     8.99e-06
    466    48     6.87e-07     6.87e-07     1.12e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    466    10     1.86e-07     1.86e-07      4.5e-06
    466    20     2.01e-07     2.01e-07      6.1e-06
    466    30     6.34e-08     6.34e-08     3.85e-06
    466    40     4.08e-07     4.08e-07     8.35e-06
    466    50     3.32e-07     3.32e-07     8.03e-06
    466    60     9.09e-08     9.09e-08      4.5e-06
    466    61     3.21e-06     3.21e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             466 25654.899    0.005     5.76e-07     5.76e-07     9.76e-06
! Validation        466 25654.899    0.005     3.01e-07     3.01e-07     6.32e-06
Wall time: 25654.899897916
training
# Epoch batch         loss       loss_e      e/N_mae
    467    10        1e-06        1e-06     1.31e-05
    467    20     5.02e-07     5.02e-07     9.64e-06
    467    30     6.42e-07     6.42e-07     1.14e-05
    467    40      1.1e-06      1.1e-06     1.27e-05
    467    48     2.75e-07     2.75e-07     8.03e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    467    10     2.54e-07     2.54e-07      6.1e-06
    467    20     1.86e-07     1.86e-07     6.75e-06
    467    30     7.19e-08     7.19e-08     3.53e-06
    467    40     2.51e-07     2.51e-07     6.42e-06
    467    50     2.62e-07     2.62e-07     7.71e-06
    467    60      1.1e-07      1.1e-07     4.82e-06
    467    61     2.78e-06     2.78e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             467 25709.952    0.005     8.07e-07     8.07e-07     1.17e-05
! Validation        467 25709.952    0.005     2.92e-07     2.92e-07     6.38e-06
Wall time: 25709.952320041
training
# Epoch batch         loss       loss_e      e/N_mae
    468    10     5.79e-07     5.79e-07     1.07e-05
    468    20     7.85e-07     7.85e-07     1.16e-05
    468    30     1.81e-06     1.81e-06      1.8e-05
    468    40      4.2e-07      4.2e-07     8.57e-06
    468    48     2.64e-07     2.64e-07     8.83e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    468    10     3.34e-07     3.34e-07      6.1e-06
    468    20     1.67e-07     1.67e-07     6.42e-06
    468    30     6.34e-08     6.34e-08     3.53e-06
    468    40     3.36e-07     3.36e-07     7.71e-06
    468    50     3.68e-07     3.68e-07     8.35e-06
    468    60     1.29e-07     1.29e-07     5.14e-06
    468    61     3.19e-06     3.19e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             468 25765.011    0.005     6.62e-07     6.62e-07     1.07e-05
! Validation        468 25765.011    0.005     2.87e-07     2.87e-07     6.37e-06
Wall time: 25765.012196624997
training
# Epoch batch         loss       loss_e      e/N_mae
    469    10     5.54e-07     5.54e-07      9.1e-06
    469    20     6.92e-07     6.92e-07      1.1e-05
    469    30     1.59e-06     1.59e-06     1.61e-05
    469    40     5.46e-06     5.46e-06     3.24e-05
    469    48     1.12e-05     1.12e-05      4.1e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    469    10     2.51e-07     2.51e-07     5.78e-06
    469    20     6.76e-08     6.76e-08     2.89e-06
    469    30     1.14e-07     1.14e-07     5.78e-06
    469    40      4.5e-07      4.5e-07     9.64e-06
    469    50     4.46e-07     4.46e-07     9.32e-06
    469    60     1.67e-07     1.67e-07     5.78e-06
    469    61     2.78e-06     2.78e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             469 25820.194    0.005     1.93e-06     1.93e-06     1.56e-05
! Validation        469 25820.194    0.005     2.93e-07     2.93e-07     6.44e-06
Wall time: 25820.194779957998
training
# Epoch batch         loss       loss_e      e/N_mae
    470    10     5.21e-06     5.21e-06     3.15e-05
    470    20     4.23e-06     4.23e-06     3.01e-05
    470    30     1.37e-05     1.37e-05     4.18e-05
    470    40     8.21e-06     8.21e-06     3.92e-05
    470    48      5.2e-06      5.2e-06     3.69e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    470    10     1.67e-07     1.67e-07     5.78e-06
    470    20     9.72e-08     9.72e-08      4.5e-06
    470    30     2.64e-07     2.64e-07     7.07e-06
    470    40     4.71e-07     4.71e-07     9.96e-06
    470    50     3.32e-07     3.32e-07     6.42e-06
    470    60     9.93e-08     9.93e-08     4.18e-06
    470    61     3.21e-06     3.21e-06     2.03e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             470 25875.297    0.005     9.35e-06     9.35e-06     3.68e-05
! Validation        470 25875.297    0.005     5.17e-07     5.17e-07     8.71e-06
Wall time: 25875.298140458
training
# Epoch batch         loss       loss_e      e/N_mae
    471    10     2.65e-05     2.65e-05      6.9e-05
    471    20     9.14e-06     9.14e-06     4.03e-05
    471    30     1.09e-06     1.09e-06     1.34e-05
    471    40     2.79e-06     2.79e-06     2.47e-05
    471    48     2.82e-06     2.82e-06     2.09e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    471    10     1.73e-07     1.73e-07      6.1e-06
    471    20     2.16e-07     2.16e-07     7.07e-06
    471    30     3.17e-07     3.17e-07     8.99e-06
    471    40     8.75e-07     8.75e-07     1.22e-05
    471    50     1.42e-07     1.42e-07      4.5e-06
    471    60     2.35e-07     2.35e-07     6.42e-06
    471    61     3.05e-06     3.05e-06     2.14e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             471 25930.305    0.005     6.31e-06     6.31e-06     3.21e-05
! Validation        471 25930.305    0.005     5.62e-07     5.62e-07     9.35e-06
Wall time: 25930.305645416
training
# Epoch batch         loss       loss_e      e/N_mae
    472    10     1.08e-06     1.08e-06     1.42e-05
    472    20     2.02e-06     2.02e-06     1.87e-05
    472    30     1.38e-06     1.38e-06     1.63e-05
    472    40      1.7e-06      1.7e-06     1.82e-05
    472    48     1.42e-06     1.42e-06     2.01e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    472    10     1.23e-07     1.23e-07     5.78e-06
    472    20     8.24e-08     8.24e-08     4.82e-06
    472    30     2.39e-07     2.39e-07     8.03e-06
    472    40     5.54e-07     5.54e-07     9.32e-06
    472    50     1.61e-07     1.61e-07      6.1e-06
    472    60     1.67e-07     1.67e-07      6.1e-06
    472    61     3.02e-06     3.02e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             472 25985.434    0.005     1.35e-06     1.35e-06     1.51e-05
! Validation        472 25985.434    0.005     4.89e-07     4.89e-07     8.66e-06
Wall time: 25985.435167249998
training
# Epoch batch         loss       loss_e      e/N_mae
    473    10     3.03e-06     3.03e-06     2.54e-05
    473    20     1.92e-06     1.92e-06     1.81e-05
    473    30     9.67e-07     9.67e-07     1.23e-05
    473    40     8.07e-07     8.07e-07     1.23e-05
    473    48     2.42e-06     2.42e-06     2.57e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    473    10     1.08e-07     1.08e-07     5.46e-06
    473    20     1.08e-07     1.08e-07     5.46e-06
    473    30     3.61e-07     3.61e-07     8.67e-06
    473    40     2.94e-07     2.94e-07     7.71e-06
    473    50     2.09e-07     2.09e-07     6.42e-06
    473    60     1.54e-07     1.54e-07     5.14e-06
    473    61     3.39e-06     3.39e-06      2.3e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             473 26040.582    0.005     1.87e-06     1.87e-06     1.74e-05
! Validation        473 26040.582    0.005     4.55e-07     4.55e-07     8.33e-06
Wall time: 26040.583126791
training
# Epoch batch         loss       loss_e      e/N_mae
    474    10     1.64e-06     1.64e-06     1.66e-05
    474    20     4.99e-07     4.99e-07     8.89e-06
    474    30     8.79e-07     8.79e-07     1.24e-05
    474    40     5.65e-07     5.65e-07     1.09e-05
    474    48     1.15e-06     1.15e-06     1.61e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    474    10     9.09e-08     9.09e-08     4.82e-06
    474    20     1.92e-07     1.92e-07     6.42e-06
    474    30     2.16e-07     2.16e-07     5.46e-06
    474    40     2.16e-07     2.16e-07     7.39e-06
    474    50     3.55e-07     3.55e-07     8.03e-06
    474    60     2.45e-07     2.45e-07      6.1e-06
    474    61     2.62e-06     2.62e-06     2.09e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             474 26095.807    0.005     7.97e-07     7.97e-07     1.14e-05
! Validation        474 26095.807    0.005     3.89e-07     3.89e-07     7.76e-06
Wall time: 26095.808474499998
training
# Epoch batch         loss       loss_e      e/N_mae
    475    10     5.49e-07     5.49e-07     8.46e-06
    475    20     2.91e-07     2.91e-07     7.28e-06
    475    30     3.64e-07     3.64e-07     8.35e-06
    475    40     5.47e-07     5.47e-07     9.96e-06
    475    48      6.6e-06      6.6e-06     4.02e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    475    10      7.4e-08      7.4e-08     3.85e-06
    475    20     1.52e-07     1.52e-07     6.42e-06
    475    30     2.54e-07     2.54e-07     8.03e-06
    475    40     1.88e-07     1.88e-07     5.78e-06
    475    50     2.94e-07     2.94e-07     7.07e-06
    475    60     2.28e-07     2.28e-07      6.1e-06
    475    61     2.97e-06     2.97e-06      2.2e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             475 26150.923    0.005     6.72e-07     6.72e-07     9.43e-06
! Validation        475 26150.923    0.005      3.6e-07      3.6e-07     7.17e-06
Wall time: 26150.924080375
training
# Epoch batch         loss       loss_e      e/N_mae
    476    10     1.67e-05     1.67e-05      5.6e-05
    476    20     9.37e-06     9.37e-06     4.09e-05
    476    30     2.59e-06     2.59e-06     1.81e-05
    476    40     1.32e-06     1.32e-06     1.71e-05
    476    48     2.13e-06     2.13e-06     1.85e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    476    10     1.14e-07     1.14e-07     3.85e-06
    476    20     4.31e-07     4.31e-07     8.03e-06
    476    30      1.5e-07      1.5e-07     5.14e-06
    476    40     2.39e-07     2.39e-07     6.42e-06
    476    50     4.54e-07     4.54e-07     1.03e-05
    476    60     2.24e-07     2.24e-07      4.5e-06
    476    61     3.79e-06     3.79e-06     2.57e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             476 26205.975    0.005     4.94e-06     4.94e-06     2.61e-05
! Validation        476 26205.975    0.005     4.46e-07     4.46e-07     7.87e-06
Wall time: 26205.976158125
training
# Epoch batch         loss       loss_e      e/N_mae
    477    10     8.34e-07     8.34e-07     1.25e-05
    477    20     7.08e-07     7.08e-07     1.07e-05
    477    30     5.61e-07     5.61e-07     8.89e-06
    477    40     1.67e-06     1.67e-06      1.9e-05
    477    48     1.57e-06     1.57e-06     1.69e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    477    10     7.19e-08     7.19e-08     3.53e-06
    477    20     1.75e-07     1.75e-07     5.78e-06
    477    30     1.35e-07     1.35e-07     4.82e-06
    477    40     2.68e-07     2.68e-07     7.07e-06
    477    50     4.76e-07     4.76e-07     1.03e-05
    477    60     2.77e-07     2.77e-07     6.42e-06
    477    61     3.77e-06     3.77e-06     2.52e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             477 26260.805    0.005     1.25e-06     1.25e-06     1.46e-05
! Validation        477 26260.805    0.005     4.21e-07     4.21e-07     7.69e-06
Wall time: 26260.805222125
training
# Epoch batch         loss       loss_e      e/N_mae
    478    10     2.09e-06     2.09e-06        2e-05
    478    20     1.56e-06     1.56e-06      1.5e-05
    478    30        7e-07        7e-07     9.64e-06
    478    40     5.13e-06     5.13e-06      3.2e-05
    478    48     5.59e-06     5.59e-06     3.85e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    478    10     4.65e-08     4.65e-08     2.89e-06
    478    20     1.92e-07     1.92e-07      6.1e-06
    478    30     2.98e-07     2.98e-07     6.42e-06
    478    40     3.83e-07     3.83e-07     7.71e-06
    478    50     5.79e-07     5.79e-07     1.19e-05
    478    60     2.07e-07     2.07e-07     6.42e-06
    478    61     3.53e-06     3.53e-06     2.36e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             478 26315.940    0.005     3.07e-06     3.07e-06      2.2e-05
! Validation        478 26315.940    0.005     4.06e-07     4.06e-07     7.78e-06
Wall time: 26315.940141416
training
# Epoch batch         loss       loss_e      e/N_mae
    479    10     8.97e-06     8.97e-06     3.84e-05
    479    20     3.69e-06     3.69e-06     2.53e-05
    479    30     2.63e-06     2.63e-06     2.02e-05
    479    40        3e-06        3e-06     2.41e-05
    479    48     1.72e-06     1.72e-06     1.61e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    479    10     1.08e-07     1.08e-07      4.5e-06
    479    20     2.13e-07     2.13e-07     6.75e-06
    479    30     4.23e-08     4.23e-08     2.57e-06
    479    40     1.84e-07     1.84e-07     5.78e-06
    479    50      4.1e-07      4.1e-07     9.32e-06
    479    60     1.92e-07     1.92e-07     5.14e-06
    479    61     3.19e-06     3.19e-06      2.2e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             479 26371.275    0.005     3.87e-06     3.87e-06     2.56e-05
! Validation        479 26371.275    0.005     3.81e-07     3.81e-07      7.4e-06
Wall time: 26371.27567875
training
# Epoch batch         loss       loss_e      e/N_mae
    480    10      9.2e-07      9.2e-07      1.2e-05
    480    20      1.4e-06      1.4e-06     1.47e-05
    480    30     1.28e-06     1.28e-06     1.66e-05
    480    40     6.59e-07     6.59e-07     9.96e-06
    480    48     2.11e-06     2.11e-06     2.41e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    480    10     2.07e-07     2.07e-07     5.46e-06
    480    20     1.35e-07     1.35e-07     5.14e-06
    480    30     2.41e-07     2.41e-07     6.75e-06
    480    40      1.9e-07      1.9e-07     5.14e-06
    480    50     4.78e-07     4.78e-07     8.67e-06
    480    60     3.32e-07     3.32e-07     7.07e-06
    480    61     2.73e-06     2.73e-06     2.09e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             480 26426.383    0.005     1.47e-06     1.47e-06     1.53e-05
! Validation        480 26426.383    0.005     3.86e-07     3.86e-07     7.54e-06
Wall time: 26426.382804875
training
# Epoch batch         loss       loss_e      e/N_mae
    481    10     1.89e-06     1.89e-06     1.95e-05
    481    20     1.01e-06     1.01e-06     1.36e-05
    481    30     8.18e-07     8.18e-07      1.3e-05
    481    40     1.37e-06     1.37e-06     1.71e-05
    481    48     1.87e-06     1.87e-06     2.09e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    481    10     2.49e-07     2.49e-07     7.71e-06
    481    20     1.52e-07     1.52e-07     5.46e-06
    481    30     1.67e-07     1.67e-07     5.78e-06
    481    40     1.69e-07     1.69e-07      4.5e-06
    481    50     5.43e-07     5.43e-07     8.99e-06
    481    60     2.54e-07     2.54e-07     6.75e-06
    481    61      2.9e-06      2.9e-06     2.14e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             481 26481.660    0.005     1.45e-06     1.45e-06     1.54e-05
! Validation        481 26481.660    0.005     3.59e-07     3.59e-07     7.35e-06
Wall time: 26481.660186582998
training
# Epoch batch         loss       loss_e      e/N_mae
    482    10     2.94e-07     2.94e-07     6.96e-06
    482    20     1.81e-07     1.81e-07     5.03e-06
    482    30      5.3e-07      5.3e-07     1.01e-05
    482    40     4.88e-07     4.88e-07     9.32e-06
    482    48     1.95e-07     1.95e-07     5.62e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    482    10     2.09e-07     2.09e-07     6.42e-06
    482    20     1.33e-07     1.33e-07     5.46e-06
    482    30      1.5e-07      1.5e-07     4.82e-06
    482    40     1.37e-07     1.37e-07     5.14e-06
    482    50     4.48e-07     4.48e-07     9.32e-06
    482    60     3.42e-07     3.42e-07     8.99e-06
    482    61     3.02e-06     3.02e-06      2.3e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             482 26536.488    0.005     6.01e-07     6.01e-07     9.97e-06
! Validation        482 26536.488    0.005     3.26e-07     3.26e-07     6.91e-06
Wall time: 26536.488761124998
training
# Epoch batch         loss       loss_e      e/N_mae
    483    10     3.54e-07     3.54e-07      7.5e-06
    483    20     2.91e-07     2.91e-07     7.17e-06
    483    30     1.87e-07     1.87e-07     5.78e-06
    483    40     5.09e-07     5.09e-07     8.57e-06
    483    48     3.43e-07     3.43e-07     8.83e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    483    10     2.75e-07     2.75e-07     7.39e-06
    483    20     1.16e-07     1.16e-07      4.5e-06
    483    30     1.16e-07     1.16e-07     4.82e-06
    483    40     1.39e-07     1.39e-07     5.46e-06
    483    50     4.02e-07     4.02e-07     8.67e-06
    483    60     2.22e-07     2.22e-07     7.07e-06
    483    61     2.56e-06     2.56e-06     2.09e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             483 26591.689    0.005     3.18e-07     3.18e-07     7.24e-06
! Validation        483 26591.689    0.005     2.91e-07     2.91e-07     6.53e-06
Wall time: 26591.688965082998
training
# Epoch batch         loss       loss_e      e/N_mae
    484    10     3.06e-07     3.06e-07     7.39e-06
    484    20     3.02e-07     3.02e-07     7.82e-06
    484    30     5.72e-07     5.72e-07     1.08e-05
    484    40     4.05e-07     4.05e-07     6.75e-06
    484    48     2.64e-08     2.64e-08     2.41e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    484    10     2.66e-07     2.66e-07     6.75e-06
    484    20     1.37e-07     1.37e-07     5.14e-06
    484    30     1.01e-07     1.01e-07     4.82e-06
    484    40     6.76e-08     6.76e-08     3.85e-06
    484    50     4.97e-07     4.97e-07     9.96e-06
    484    60     2.35e-07     2.35e-07     7.07e-06
    484    61     2.77e-06     2.77e-06     2.14e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             484 26646.882    0.005     3.74e-07     3.74e-07     8.07e-06
! Validation        484 26646.882    0.005     2.88e-07     2.88e-07     6.44e-06
Wall time: 26646.883208416
training
# Epoch batch         loss       loss_e      e/N_mae
    485    10     4.58e-07     4.58e-07     8.89e-06
    485    20     4.15e-07     4.15e-07     8.46e-06
    485    30     6.26e-07     6.26e-07     1.09e-05
    485    40     2.19e-07     2.19e-07     6.42e-06
    485    48     6.87e-08     6.87e-08     4.82e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    485    10     3.06e-07     3.06e-07     6.42e-06
    485    20      1.1e-07      1.1e-07     5.14e-06
    485    30     1.16e-07     1.16e-07     5.14e-06
    485    40     7.19e-08     7.19e-08     3.85e-06
    485    50     3.25e-07     3.25e-07     7.39e-06
    485    60     1.48e-07     1.48e-07     5.46e-06
    485    61     2.22e-06     2.22e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             485 26701.989    0.005     4.48e-07     4.48e-07     8.81e-06
! Validation        485 26701.989    0.005     2.66e-07     2.66e-07     6.22e-06
Wall time: 26701.989523375
! Best model      485    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    486    10      4.1e-07      4.1e-07     8.03e-06
    486    20     3.66e-07     3.66e-07     8.03e-06
    486    30     1.73e-07     1.73e-07     5.46e-06
    486    40     4.35e-07     4.35e-07     8.25e-06
    486    48     6.87e-08     6.87e-08     4.82e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    486    10     2.24e-07     2.24e-07     7.07e-06
    486    20     1.12e-07     1.12e-07     5.14e-06
    486    30     8.03e-08     8.03e-08     4.18e-06
    486    40      1.1e-07      1.1e-07      4.5e-06
    486    50     3.74e-07     3.74e-07     7.71e-06
    486    60      2.3e-07      2.3e-07     7.07e-06
    486    61     2.51e-06     2.51e-06     1.87e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             486 26757.071    0.005      3.5e-07      3.5e-07     7.73e-06
! Validation        486 26757.071    0.005     2.61e-07     2.61e-07     6.11e-06
Wall time: 26757.072128
! Best model      486    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    487    10     1.48e-07     1.48e-07     5.35e-06
    487    20      4.1e-07      4.1e-07     8.99e-06
    487    30     1.25e-07     1.25e-07      4.5e-06
    487    40     1.67e-07     1.67e-07     5.35e-06
    487    48     3.43e-07     3.43e-07     7.23e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    487    10     1.29e-07     1.29e-07     5.14e-06
    487    20     1.67e-07     1.67e-07     5.46e-06
    487    30     8.45e-08     8.45e-08      4.5e-06
    487    40     1.25e-07     1.25e-07     4.82e-06
    487    50     3.32e-07     3.32e-07     7.71e-06
    487    60     1.67e-07     1.67e-07     5.78e-06
    487    61     2.56e-06     2.56e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             487 26812.096    0.005      2.5e-07      2.5e-07     6.51e-06
! Validation        487 26812.096    0.005     2.68e-07     2.68e-07     6.22e-06
Wall time: 26812.096774832997
training
# Epoch batch         loss       loss_e      e/N_mae
    488    10     6.69e-07     6.69e-07     1.14e-05
    488    20     2.85e-07     2.85e-07     7.07e-06
    488    30     6.82e-07     6.82e-07     1.17e-05
    488    40     2.41e-07     2.41e-07     6.96e-06
    488    48     8.45e-08     8.45e-08     3.21e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    488    10      2.6e-07      2.6e-07     7.07e-06
    488    20     8.03e-08     8.03e-08     3.85e-06
    488    30     8.88e-08     8.88e-08     4.18e-06
    488    40     1.08e-07     1.08e-07     4.18e-06
    488    50     3.53e-07     3.53e-07     7.71e-06
    488    60     9.51e-08     9.51e-08      4.5e-06
    488    61     2.27e-06     2.27e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             488 26867.193    0.005     3.44e-07     3.44e-07     7.75e-06
! Validation        488 26867.193    0.005     2.57e-07     2.57e-07     6.05e-06
Wall time: 26867.194188957998
! Best model      488    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    489    10     2.54e-07     2.54e-07     6.96e-06
    489    20     2.99e-07     2.99e-07     7.17e-06
    489    30     3.45e-07     3.45e-07     7.82e-06
    489    40     1.16e-06     1.16e-06     1.61e-05
    489    48     2.38e-07     2.38e-07     8.03e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    489    10     2.62e-07     2.62e-07     7.39e-06
    489    20     4.44e-08     4.44e-08     2.57e-06
    489    30     7.61e-08     7.61e-08     3.53e-06
    489    40     1.71e-07     1.71e-07     6.42e-06
    489    50      3.8e-07      3.8e-07     7.39e-06
    489    60     1.71e-07     1.71e-07     5.78e-06
    489    61     2.44e-06     2.44e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             489 26922.345    0.005     5.28e-07     5.28e-07     9.12e-06
! Validation        489 26922.345    0.005     2.52e-07     2.52e-07     6.01e-06
Wall time: 26922.345193666
! Best model      489    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    490    10     4.62e-07     4.62e-07     9.32e-06
    490    20     7.67e-07     7.67e-07     1.19e-05
    490    30     1.36e-06     1.36e-06     1.57e-05
    490    40     3.73e-07     3.73e-07     7.39e-06
    490    48     4.23e-07     4.23e-07     1.04e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    490    10     2.13e-07     2.13e-07     7.07e-06
    490    20     7.19e-08     7.19e-08     4.18e-06
    490    30     9.51e-08     9.51e-08     4.18e-06
    490    40     1.65e-07     1.65e-07      6.1e-06
    490    50     5.85e-07     5.85e-07     9.64e-06
    490    60     2.51e-07     2.51e-07     7.07e-06
    490    61     2.27e-06     2.27e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             490 26977.530    0.005     7.25e-07     7.25e-07     1.11e-05
! Validation        490 26977.530    0.005     2.43e-07     2.43e-07     5.75e-06
Wall time: 26977.530812166
! Best model      490    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    491    10     5.51e-07     5.51e-07     9.85e-06
    491    20     5.59e-07     5.59e-07     1.15e-05
    491    30     1.05e-06     1.05e-06     1.51e-05
    491    40     6.99e-07     6.99e-07     1.21e-05
    491    48     1.23e-06     1.23e-06     1.69e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    491    10     1.84e-07     1.84e-07     5.78e-06
    491    20     1.31e-07     1.31e-07     5.14e-06
    491    30     1.12e-07     1.12e-07     5.14e-06
    491    40     1.84e-07     1.84e-07     6.42e-06
    491    50     3.34e-07     3.34e-07     7.39e-06
    491    60     2.75e-07     2.75e-07     7.39e-06
    491    61     2.14e-06     2.14e-06     1.87e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             491 27032.563    0.005     8.96e-07     8.96e-07     1.19e-05
! Validation        491 27032.563    0.005     2.53e-07     2.53e-07     6.07e-06
Wall time: 27032.563877499997
training
# Epoch batch         loss       loss_e      e/N_mae
    492    10     2.06e-07     2.06e-07     6.64e-06
    492    20     2.99e-07     2.99e-07      7.5e-06
    492    30     1.39e-07     1.39e-07      4.5e-06
    492    40     3.37e-07     3.37e-07     6.64e-06
    492    48     3.91e-07     3.91e-07     9.64e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    492    10     2.11e-07     2.11e-07     6.75e-06
    492    20     1.39e-07     1.39e-07     5.46e-06
    492    30     9.93e-08     9.93e-08     5.14e-06
    492    40     1.63e-07     1.63e-07     5.78e-06
    492    50     3.95e-07     3.95e-07     7.71e-06
    492    60     2.35e-07     2.35e-07     7.07e-06
    492    61     2.36e-06     2.36e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             492 27087.497    0.005     4.96e-07     4.96e-07     9.06e-06
! Validation        492 27087.497    0.005     2.63e-07     2.63e-07     6.14e-06
Wall time: 27087.498502208
training
# Epoch batch         loss       loss_e      e/N_mae
    493    10     4.49e-07     4.49e-07     8.99e-06
    493    20      8.6e-07      8.6e-07     1.16e-05
    493    30     1.13e-06     1.13e-06     1.49e-05
    493    40     4.33e-07     4.33e-07     9.32e-06
    493    48     1.06e-08     1.06e-08     1.61e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    493    10      4.4e-07      4.4e-07     9.64e-06
    493    20     1.48e-07     1.48e-07     5.14e-06
    493    30     1.99e-07     1.99e-07     6.75e-06
    493    40     1.78e-07     1.78e-07     5.46e-06
    493    50     4.46e-07     4.46e-07     8.35e-06
    493    60     2.11e-07     2.11e-07     7.71e-06
    493    61     2.15e-06     2.15e-06     1.87e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             493 27142.583    0.005     9.74e-07     9.74e-07     1.28e-05
! Validation        493 27142.583    0.005     2.78e-07     2.78e-07     6.38e-06
Wall time: 27142.584186665998
training
# Epoch batch         loss       loss_e      e/N_mae
    494    10     6.83e-07     6.83e-07     1.05e-05
    494    20     1.58e-06     1.58e-06     1.83e-05
    494    30     3.16e-07     3.16e-07     7.92e-06
    494    40     1.61e-06     1.61e-06     1.66e-05
    494    48      1.4e-06      1.4e-06     1.61e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    494    10     2.73e-07     2.73e-07     8.03e-06
    494    20     5.07e-08     5.07e-08     3.21e-06
    494    30     6.34e-08     6.34e-08     3.53e-06
    494    40     1.56e-07     1.56e-07     5.78e-06
    494    50     4.95e-07     4.95e-07     9.32e-06
    494    60     1.39e-07     1.39e-07      4.5e-06
    494    61      2.5e-06      2.5e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             494 27197.720    0.005      9.9e-07      9.9e-07     1.29e-05
! Validation        494 27197.720    0.005     2.85e-07     2.85e-07     6.33e-06
Wall time: 27197.721504125
training
# Epoch batch         loss       loss_e      e/N_mae
    495    10     5.14e-07     5.14e-07     9.85e-06
    495    20     3.83e-07     3.83e-07     8.25e-06
    495    30     2.85e-07     2.85e-07     6.53e-06
    495    40        6e-07        6e-07     9.96e-06
    495    48     2.35e-06     2.35e-06     2.41e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    495    10     3.64e-07     3.64e-07     8.99e-06
    495    20     6.55e-08     6.55e-08     3.53e-06
    495    30     5.92e-08     5.92e-08     3.53e-06
    495    40     2.22e-07     2.22e-07     7.39e-06
    495    50     4.97e-07     4.97e-07     8.99e-06
    495    60     2.35e-07     2.35e-07     6.42e-06
    495    61     3.33e-06     3.33e-06      2.3e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             495 27252.702    0.005     7.37e-07     7.37e-07     1.05e-05
! Validation        495 27252.702    0.005     2.98e-07     2.98e-07     6.34e-06
Wall time: 27252.703114582997
training
# Epoch batch         loss       loss_e      e/N_mae
    496    10     5.58e-07     5.58e-07     1.02e-05
    496    20     2.35e-06     2.35e-06     1.94e-05
    496    30     5.13e-07     5.13e-07     9.85e-06
    496    40     1.62e-06     1.62e-06     1.85e-05
    496    48     1.95e-06     1.95e-06     2.25e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    496    10     4.02e-07     4.02e-07     8.99e-06
    496    20     9.93e-08     9.93e-08      4.5e-06
    496    30     8.45e-08     8.45e-08     4.18e-06
    496    40     1.59e-07     1.59e-07     5.78e-06
    496    50      4.8e-07      4.8e-07     7.71e-06
    496    60        3e-07        3e-07     7.39e-06
    496    61     3.05e-06     3.05e-06     2.09e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             496 27307.787    0.005     1.21e-06     1.21e-06     1.39e-05
! Validation        496 27307.787    0.005     3.06e-07     3.06e-07     6.53e-06
Wall time: 27307.787568416
training
# Epoch batch         loss       loss_e      e/N_mae
    497    10      3.3e-06      3.3e-06     2.35e-05
    497    20     2.88e-06     2.88e-06     2.52e-05
    497    30     3.08e-07     3.08e-07     6.85e-06
    497    40     7.57e-07     7.57e-07     1.07e-05
    497    48     2.37e-06     2.37e-06     2.25e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    497    10     2.24e-07     2.24e-07     6.75e-06
    497    20     8.88e-08     8.88e-08      4.5e-06
    497    30      1.8e-07      1.8e-07     5.78e-06
    497    40     2.16e-07     2.16e-07     6.75e-06
    497    50     3.06e-07     3.06e-07     6.42e-06
    497    60     1.25e-07     1.25e-07     5.14e-06
    497    61     3.02e-06     3.02e-06     2.03e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             497 27362.760    0.005     1.51e-06     1.51e-06     1.55e-05
! Validation        497 27362.760    0.005      2.9e-07      2.9e-07     6.33e-06
Wall time: 27362.760966374997
training
# Epoch batch         loss       loss_e      e/N_mae
    498    10     1.48e-06     1.48e-06     1.78e-05
    498    20     2.79e-06     2.79e-06     2.53e-05
    498    30     2.04e-06     2.04e-06      2.1e-05
    498    40     1.98e-06     1.98e-06     1.82e-05
    498    48     1.88e-06     1.88e-06     2.17e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    498    10     2.24e-07     2.24e-07      6.1e-06
    498    20     2.77e-07     2.77e-07     9.32e-06
    498    30     1.08e-07     1.08e-07      4.5e-06
    498    40        3e-07        3e-07     8.03e-06
    498    50     3.38e-07     3.38e-07     8.03e-06
    498    60     2.62e-07     2.62e-07     8.35e-06
    498    61     2.05e-06     2.05e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             498 27417.972    0.005     2.79e-06     2.79e-06     2.19e-05
! Validation        498 27417.972    0.005      3.2e-07      3.2e-07     7.01e-06
Wall time: 27417.973237958
training
# Epoch batch         loss       loss_e      e/N_mae
    499    10     2.59e-06     2.59e-06     2.32e-05
    499    20     1.89e-06     1.89e-06     1.71e-05
    499    30      4.8e-06      4.8e-06     2.81e-05
    499    40     5.97e-06     5.97e-06     3.04e-05
    499    48     3.09e-06     3.09e-06     2.73e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    499    10     2.51e-07     2.51e-07     7.39e-06
    499    20     2.98e-07     2.98e-07     7.71e-06
    499    30     1.84e-07     1.84e-07     4.18e-06
    499    40     4.12e-07     4.12e-07     1.03e-05
    499    50     2.01e-07     2.01e-07     5.78e-06
    499    60     1.84e-07     1.84e-07     6.75e-06
    499    61     2.84e-06     2.84e-06      2.3e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             499 27473.159    0.005     3.79e-06     3.79e-06      2.4e-05
! Validation        499 27473.159    0.005     3.48e-07     3.48e-07     7.27e-06
Wall time: 27473.159089875
training
# Epoch batch         loss       loss_e      e/N_mae
    500    10     1.78e-05     1.78e-05     5.81e-05
    500    20     8.49e-06     8.49e-06     4.02e-05
    500    30     5.75e-06     5.75e-06     3.17e-05
    500    40     2.09e-06     2.09e-06      2.1e-05
    500    48      1.4e-06      1.4e-06     1.61e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    500    10     8.45e-08     8.45e-08     4.18e-06
    500    20     2.41e-07     2.41e-07     7.07e-06
    500    30     2.09e-07     2.09e-07     5.78e-06
    500    40     1.65e-07     1.65e-07     5.46e-06
    500    50     3.28e-07     3.28e-07     7.07e-06
    500    60     3.28e-07     3.28e-07     6.42e-06
    500    61     2.57e-06     2.57e-06     2.25e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             500 27528.096    0.005     1.14e-05     1.14e-05     4.28e-05
! Validation        500 27528.096    0.005     4.75e-07     4.75e-07     8.58e-06
Wall time: 27528.096027665997
training
# Epoch batch         loss       loss_e      e/N_mae
    501    10     1.64e-06     1.64e-06     1.53e-05
    501    20     1.84e-06     1.84e-06      1.7e-05
    501    30     3.24e-06     3.24e-06     2.39e-05
    501    40     1.83e-06     1.83e-06     1.97e-05
    501    48     5.67e-06     5.67e-06     3.29e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    501    10     2.49e-07     2.49e-07     7.07e-06
    501    20      4.1e-07      4.1e-07     9.32e-06
    501    30     2.26e-07     2.26e-07     5.78e-06
    501    40     2.75e-07     2.75e-07     7.39e-06
    501    50     4.78e-07     4.78e-07     9.96e-06
    501    60     1.94e-07     1.94e-07     6.75e-06
    501    61     3.83e-06     3.83e-06     2.57e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             501 27583.263    0.005     2.89e-06     2.89e-06     2.13e-05
! Validation        501 27583.263    0.005     5.09e-07     5.09e-07     9.08e-06
Wall time: 27583.264129249997
training
# Epoch batch         loss       loss_e      e/N_mae
    502    10     1.39e-06     1.39e-06     1.43e-05
    502    20     2.32e-06     2.32e-06     1.96e-05
    502    30     3.57e-07     3.57e-07     8.25e-06
    502    40     1.88e-06     1.88e-06        2e-05
    502    48      3.9e-06      3.9e-06     2.57e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    502    10     3.28e-07     3.28e-07     7.07e-06
    502    20     5.88e-07     5.88e-07     1.03e-05
    502    30     2.03e-07     2.03e-07     6.75e-06
    502    40     4.35e-07     4.35e-07     8.67e-06
    502    50     5.28e-07     5.28e-07     8.67e-06
    502    60     1.84e-07     1.84e-07     5.46e-06
    502    61     3.63e-06     3.63e-06     2.57e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             502 27638.273    0.005     1.56e-06     1.56e-06     1.57e-05
! Validation        502 27638.273    0.005     4.59e-07     4.59e-07     8.37e-06
Wall time: 27638.274180458
training
# Epoch batch         loss       loss_e      e/N_mae
    503    10     1.07e-06     1.07e-06     1.34e-05
    503    20     1.94e-06     1.94e-06     1.95e-05
    503    30     3.47e-07     3.47e-07     8.67e-06
    503    40     8.66e-07     8.66e-07     1.32e-05
    503    48     2.17e-07     2.17e-07     7.23e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    503    10      2.2e-07      2.2e-07     5.78e-06
    503    20     6.07e-07     6.07e-07     1.12e-05
    503    30     1.82e-07     1.82e-07     4.82e-06
    503    40     5.11e-07     5.11e-07     9.96e-06
    503    50     4.78e-07     4.78e-07     8.67e-06
    503    60     1.12e-07     1.12e-07     3.53e-06
    503    61     3.83e-06     3.83e-06     2.57e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             503 27693.277    0.005      1.9e-06      1.9e-06     1.73e-05
! Validation        503 27693.277    0.005     4.26e-07     4.26e-07     7.79e-06
Wall time: 27693.277630582998
training
# Epoch batch         loss       loss_e      e/N_mae
    504    10      1.1e-06      1.1e-06     1.46e-05
    504    20     4.92e-07     4.92e-07     9.42e-06
    504    30      5.8e-07      5.8e-07     1.15e-05
    504    40     1.43e-07     1.43e-07     4.93e-06
    504    48     2.17e-07     2.17e-07     7.23e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    504    10     1.23e-07     1.23e-07     5.46e-06
    504    20     4.16e-07     4.16e-07     9.96e-06
    504    30     1.18e-07     1.18e-07     4.82e-06
    504    40     4.21e-07     4.21e-07     8.99e-06
    504    50     3.44e-07     3.44e-07     6.42e-06
    504    60     1.23e-07     1.23e-07     4.82e-06
    504    61     3.25e-06     3.25e-06     2.25e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             504 27748.448    0.005     6.24e-07     6.24e-07     9.97e-06
! Validation        504 27748.448    0.005     3.61e-07     3.61e-07     7.23e-06
Wall time: 27748.44793925
training
# Epoch batch         loss       loss_e      e/N_mae
    505    10     2.87e-07     2.87e-07     6.42e-06
    505    20     1.03e-06     1.03e-06     1.27e-05
    505    30      2.2e-07      2.2e-07     5.89e-06
    505    40     8.19e-07     8.19e-07     1.28e-05
    505    48     3.59e-07     3.59e-07     8.03e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    505    10      2.6e-07      2.6e-07      6.1e-06
    505    20        3e-07        3e-07     8.35e-06
    505    30      2.2e-07      2.2e-07     5.46e-06
    505    40     4.67e-07     4.67e-07     9.64e-06
    505    50     2.09e-07     2.09e-07     5.14e-06
    505    60     1.84e-07     1.84e-07     6.42e-06
    505    61     3.29e-06     3.29e-06     2.25e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             505 27803.614    0.005     5.89e-07     5.89e-07     9.92e-06
! Validation        505 27803.614    0.005     3.44e-07     3.44e-07     7.03e-06
Wall time: 27803.614971375
training
# Epoch batch         loss       loss_e      e/N_mae
    506    10     1.49e-06     1.49e-06     1.63e-05
    506    20     2.51e-07     2.51e-07     7.28e-06
    506    30     2.26e-06     2.26e-06     2.05e-05
    506    40     5.88e-07     5.88e-07     8.67e-06
    506    48     4.33e-07     4.33e-07     8.03e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    506    10     3.04e-07     3.04e-07     8.35e-06
    506    20     3.44e-07     3.44e-07     8.67e-06
    506    30     2.18e-07     2.18e-07     6.42e-06
    506    40     4.69e-07     4.69e-07     8.67e-06
    506    50     3.66e-07     3.66e-07     6.42e-06
    506    60     8.24e-08     8.24e-08      4.5e-06
    506    61      3.3e-06      3.3e-06     2.09e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             506 27858.602    0.005     8.32e-07     8.32e-07      1.2e-05
! Validation        506 27858.602    0.005      3.2e-07      3.2e-07     6.78e-06
Wall time: 27858.602931333
training
# Epoch batch         loss       loss_e      e/N_mae
    507    10     5.47e-07     5.47e-07     1.02e-05
    507    20     2.68e-07     2.68e-07     6.21e-06
    507    30     3.85e-07     3.85e-07      7.5e-06
    507    40     2.06e-07     2.06e-07        6e-06
    507    48      1.8e-07      1.8e-07     6.42e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    507    10     2.54e-07     2.54e-07     6.42e-06
    507    20     2.22e-07     2.22e-07     6.75e-06
    507    30     2.18e-07     2.18e-07     6.75e-06
    507    40      2.9e-07      2.9e-07     7.07e-06
    507    50     3.04e-07     3.04e-07     6.75e-06
    507    60     9.93e-08     9.93e-08      4.5e-06
    507    61      3.1e-06      3.1e-06      2.2e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             507 27913.769    0.005     3.74e-07     3.74e-07     7.77e-06
! Validation        507 27913.769    0.005        3e-07        3e-07     6.56e-06
Wall time: 27913.770105290998
training
# Epoch batch         loss       loss_e      e/N_mae
    508    10     2.47e-07     2.47e-07     6.32e-06
    508    20     8.24e-07     8.24e-07      1.3e-05
    508    30     6.63e-07     6.63e-07     1.06e-05
    508    40     1.64e-06     1.64e-06     1.51e-05
    508    48     2.64e-07     2.64e-07     7.23e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    508    10     2.18e-07     2.18e-07     6.42e-06
    508    20     1.39e-07     1.39e-07     4.82e-06
    508    30     1.35e-07     1.35e-07     5.46e-06
    508    40     2.75e-07     2.75e-07     6.75e-06
    508    50     2.94e-07     2.94e-07     6.42e-06
    508    60     1.78e-07     1.78e-07     6.75e-06
    508    61     3.37e-06     3.37e-06     2.36e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             508 27968.796    0.005     4.79e-07     4.79e-07     8.86e-06
! Validation        508 27968.796    0.005     2.91e-07     2.91e-07     6.44e-06
Wall time: 27968.7965365
training
# Epoch batch         loss       loss_e      e/N_mae
    509    10     6.88e-07     6.88e-07     1.16e-05
    509    20     8.66e-07     8.66e-07     1.38e-05
    509    30     1.11e-06     1.11e-06     1.28e-05
    509    40     1.38e-06     1.38e-06     1.51e-05
    509    48      6.6e-07      6.6e-07     1.28e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    509    10     4.02e-07     4.02e-07     8.67e-06
    509    20     2.07e-07     2.07e-07     5.14e-06
    509    30     1.42e-07     1.42e-07     5.78e-06
    509    40     2.58e-07     2.58e-07     5.78e-06
    509    50     3.25e-07     3.25e-07      6.1e-06
    509    60     2.18e-07     2.18e-07     7.07e-06
    509    61     2.34e-06     2.34e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             509 28023.841    0.005     8.83e-07     8.83e-07     1.22e-05
! Validation        509 28023.841    0.005     2.74e-07     2.74e-07     6.35e-06
Wall time: 28023.840908291
training
# Epoch batch         loss       loss_e      e/N_mae
    510    10     5.33e-07     5.33e-07     8.99e-06
    510    20     7.73e-07     7.73e-07     1.14e-05
    510    30     3.38e-07     3.38e-07     8.14e-06
    510    40     5.95e-07     5.95e-07     1.07e-05
    510    48     1.37e-07     1.37e-07     4.82e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    510    10      2.2e-07      2.2e-07     6.75e-06
    510    20     3.13e-07     3.13e-07     6.75e-06
    510    30     4.86e-08     4.86e-08     3.21e-06
    510    40     1.78e-07     1.78e-07     5.78e-06
    510    50     3.23e-07     3.23e-07     5.78e-06
    510    60     1.67e-07     1.67e-07     6.42e-06
    510    61     2.51e-06     2.51e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             510 28079.064    0.005     5.26e-07     5.26e-07     9.46e-06
! Validation        510 28079.064    0.005     2.73e-07     2.73e-07     6.28e-06
Wall time: 28079.064755458
training
# Epoch batch         loss       loss_e      e/N_mae
    511    10     2.35e-07     2.35e-07     6.64e-06
    511    20     1.22e-07     1.22e-07     4.71e-06
    511    30     4.25e-07     4.25e-07     9.42e-06
    511    40      2.4e-07      2.4e-07     6.21e-06
    511    48     1.06e-07     1.06e-07     4.82e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    511    10     2.16e-07     2.16e-07     5.14e-06
    511    20      1.8e-07      1.8e-07     5.46e-06
    511    30     8.88e-08     8.88e-08     4.82e-06
    511    40     2.01e-07     2.01e-07     4.82e-06
    511    50        3e-07        3e-07      6.1e-06
    511    60     1.25e-07     1.25e-07     5.14e-06
    511    61     2.93e-06     2.93e-06     2.03e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             511 28134.166    0.005     3.94e-07     3.94e-07     8.17e-06
! Validation        511 28134.166    0.005      2.7e-07      2.7e-07     6.07e-06
Wall time: 28134.16744825
training
# Epoch batch         loss       loss_e      e/N_mae
    512    10     2.59e-07     2.59e-07     5.68e-06
    512    20     2.68e-07     2.68e-07     6.96e-06
    512    30     2.53e-07     2.53e-07     5.57e-06
    512    40     1.02e-07     1.02e-07     4.82e-06
    512    48     1.32e-07     1.32e-07     6.42e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    512    10     2.83e-07     2.83e-07     6.75e-06
    512    20     1.06e-07     1.06e-07     4.18e-06
    512    30     1.31e-07     1.31e-07     5.46e-06
    512    40     1.99e-07     1.99e-07     5.78e-06
    512    50     3.99e-07     3.99e-07     7.71e-06
    512    60     8.24e-08     8.24e-08      4.5e-06
    512    61     2.85e-06     2.85e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             512 28189.182    0.005     3.57e-07     3.57e-07      7.6e-06
! Validation        512 28189.182    0.005     2.66e-07     2.66e-07     5.89e-06
Wall time: 28189.181835207997
training
# Epoch batch         loss       loss_e      e/N_mae
    513    10     1.21e-07     1.21e-07     4.39e-06
    513    20     4.17e-07     4.17e-07     8.57e-06
    513    30     4.47e-07     4.47e-07     9.42e-06
    513    40     3.23e-07     3.23e-07     7.82e-06
    513    48      8.3e-07      8.3e-07     1.37e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    513    10        3e-07        3e-07      6.1e-06
    513    20     1.82e-07     1.82e-07     5.46e-06
    513    30     1.23e-07     1.23e-07     4.82e-06
    513    40     2.35e-07     2.35e-07     7.07e-06
    513    50     3.76e-07     3.76e-07     7.39e-06
    513    60     1.33e-07     1.33e-07     5.14e-06
    513    61     2.33e-06     2.33e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             513 28244.133    0.005     4.34e-07     4.34e-07      8.5e-06
! Validation        513 28244.133    0.005     2.48e-07     2.48e-07     5.75e-06
Wall time: 28244.133963458
training
# Epoch batch         loss       loss_e      e/N_mae
    514    10     8.59e-07     8.59e-07     1.27e-05
    514    20     3.92e-07     3.92e-07      7.6e-06
    514    30     2.88e-07     2.88e-07     7.39e-06
    514    40     3.16e-07     3.16e-07     7.28e-06
    514    48     1.06e-07     1.06e-07     5.62e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    514    10     3.55e-07     3.55e-07     8.35e-06
    514    20     1.16e-07     1.16e-07      4.5e-06
    514    30     1.29e-07     1.29e-07     5.14e-06
    514    40      2.2e-07      2.2e-07     6.75e-06
    514    50     4.02e-07     4.02e-07     7.39e-06
    514    60     1.39e-07     1.39e-07     5.46e-06
    514    61     2.12e-06     2.12e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             514 28299.249    0.005     3.82e-07     3.82e-07        8e-06
! Validation        514 28299.249    0.005     2.48e-07     2.48e-07     5.84e-06
Wall time: 28299.248729707997
training
# Epoch batch         loss       loss_e      e/N_mae
    515    10      1.8e-07      1.8e-07     5.35e-06
    515    20     5.38e-07     5.38e-07      1.1e-05
    515    30     3.58e-07     3.58e-07     8.14e-06
    515    40     7.48e-07     7.48e-07     1.16e-05
    515    48     4.23e-07     4.23e-07     1.04e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    515    10        3e-07        3e-07     8.35e-06
    515    20     2.43e-07     2.43e-07     7.07e-06
    515    30     6.76e-08     6.76e-08      4.5e-06
    515    40     2.81e-07     2.81e-07     7.71e-06
    515    50     2.79e-07     2.79e-07     5.46e-06
    515    60     9.09e-08     9.09e-08      4.5e-06
    515    61      2.7e-06      2.7e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             515 28354.300    0.005     4.55e-07     4.55e-07     8.38e-06
! Validation        515 28354.300    0.005     2.63e-07     2.63e-07     6.07e-06
Wall time: 28354.301137332997
training
# Epoch batch         loss       loss_e      e/N_mae
    516    10     9.07e-07     9.07e-07     1.32e-05
    516    20     5.45e-07     5.45e-07     1.08e-05
    516    30     5.41e-07     5.41e-07     9.64e-06
    516    40     3.66e-07     3.66e-07     6.96e-06
    516    48     1.69e-07     1.69e-07     6.42e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    516    10     3.76e-07     3.76e-07     7.39e-06
    516    20     1.65e-07     1.65e-07     5.78e-06
    516    30     1.75e-07     1.75e-07      6.1e-06
    516    40     1.61e-07     1.61e-07     5.14e-06
    516    50     1.73e-07     1.73e-07     5.46e-06
    516    60     1.56e-07     1.56e-07      6.1e-06
    516    61     2.56e-06     2.56e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             516 28409.442    0.005     7.17e-07     7.17e-07     1.09e-05
! Validation        516 28409.442    0.005     2.58e-07     2.58e-07        6e-06
Wall time: 28409.4433955
training
# Epoch batch         loss       loss_e      e/N_mae
    517    10     3.95e-07     3.95e-07     7.92e-06
    517    20     3.34e-07     3.34e-07     7.28e-06
    517    30     6.11e-07     6.11e-07     1.06e-05
    517    40     2.63e-07     2.63e-07      7.6e-06
    517    48     4.23e-08     4.23e-08     3.21e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    517    10     3.25e-07     3.25e-07     8.35e-06
    517    20     1.92e-07     1.92e-07     5.78e-06
    517    30     1.92e-07     1.92e-07      6.1e-06
    517    40     1.31e-07     1.31e-07     5.14e-06
    517    50      2.2e-07      2.2e-07      6.1e-06
    517    60     1.33e-07     1.33e-07     4.18e-06
    517    61      2.3e-06      2.3e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             517 28464.694    0.005     3.92e-07     3.92e-07     8.15e-06
! Validation        517 28464.694    0.005     2.54e-07     2.54e-07     6.01e-06
Wall time: 28464.695093666
training
# Epoch batch         loss       loss_e      e/N_mae
    518    10     3.35e-07     3.35e-07     7.28e-06
    518    20     2.04e-07     2.04e-07     6.32e-06
    518    30     2.69e-07     2.69e-07      7.6e-06
    518    40     2.14e-07     2.14e-07      6.1e-06
    518    48     3.22e-07     3.22e-07     9.64e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    518    10     2.18e-07     2.18e-07     6.42e-06
    518    20     1.56e-07     1.56e-07      4.5e-06
    518    30     1.23e-07     1.23e-07     5.78e-06
    518    40     2.09e-07     2.09e-07     6.42e-06
    518    50     1.97e-07     1.97e-07     5.78e-06
    518    60     1.61e-07     1.61e-07      6.1e-06
    518    61     1.61e-06     1.61e-06     1.45e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             518 28519.510    0.005     2.74e-07     2.74e-07     6.91e-06
! Validation        518 28519.510    0.005     2.27e-07     2.27e-07     5.68e-06
Wall time: 28519.510692875
! Best model      518    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    519    10     2.27e-07     2.27e-07      7.5e-06
    519    20     4.96e-07     4.96e-07     8.35e-06
    519    30     5.42e-07     5.42e-07     8.78e-06
    519    40     1.91e-06     1.91e-06     1.93e-05
    519    48     1.65e-06     1.65e-06     2.09e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    519    10     2.13e-07     2.13e-07     6.42e-06
    519    20     2.01e-07     2.01e-07     5.46e-06
    519    30     1.04e-07     1.04e-07      4.5e-06
    519    40     2.94e-07     2.94e-07     7.71e-06
    519    50     2.92e-07     2.92e-07     7.39e-06
    519    60      9.3e-08      9.3e-08     4.18e-06
    519    61      1.5e-06      1.5e-06      1.5e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             519 28574.736    0.005     1.03e-06     1.03e-06     1.29e-05
! Validation        519 28574.736    0.005     2.47e-07     2.47e-07     6.06e-06
Wall time: 28574.737497583
training
# Epoch batch         loss       loss_e      e/N_mae
    520    10     2.13e-06     2.13e-06     1.99e-05
    520    20     2.15e-06     2.15e-06     1.79e-05
    520    30     3.76e-06     3.76e-06     2.82e-05
    520    40     9.15e-07     9.15e-07     1.17e-05
    520    48     3.86e-07     3.86e-07     9.64e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    520    10     3.66e-07     3.66e-07     7.71e-06
    520    20     2.18e-07     2.18e-07      6.1e-06
    520    30     1.31e-07     1.31e-07     5.14e-06
    520    40     1.73e-07     1.73e-07     5.78e-06
    520    50     2.26e-07     2.26e-07     6.42e-06
    520    60     6.34e-08     6.34e-08     3.21e-06
    520    61     2.43e-06     2.43e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             520 28629.989    0.005     1.93e-06     1.93e-06     1.85e-05
! Validation        520 28629.989    0.005     2.82e-07     2.82e-07     6.25e-06
Wall time: 28629.989757332998
training
# Epoch batch         loss       loss_e      e/N_mae
    521    10     5.78e-07     5.78e-07     1.07e-05
    521    20     2.04e-06     2.04e-06     2.08e-05
    521    30     5.49e-07     5.49e-07     1.08e-05
    521    40     4.54e-07     4.54e-07     9.85e-06
    521    48     1.06e-08     1.06e-08     1.61e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    521    10     5.11e-07     5.11e-07     1.09e-05
    521    20     1.69e-07     1.69e-07     5.46e-06
    521    30     4.86e-08     4.86e-08     3.21e-06
    521    40     2.11e-07     2.11e-07      6.1e-06
    521    50     1.99e-07     1.99e-07      6.1e-06
    521    60     1.65e-07     1.65e-07      4.5e-06
    521    61     2.38e-06     2.38e-06     1.87e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             521 28685.073    0.005     1.35e-06     1.35e-06     1.45e-05
! Validation        521 28685.073    0.005     2.85e-07     2.85e-07     6.31e-06
Wall time: 28685.073596166
training
# Epoch batch         loss       loss_e      e/N_mae
    522    10     5.11e-06     5.11e-06     3.19e-05
    522    20     6.88e-07     6.88e-07     1.08e-05
    522    30     3.09e-06     3.09e-06     2.33e-05
    522    40     6.81e-06     6.81e-06     2.92e-05
    522    48     1.88e-05     1.88e-05     6.99e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    522    10      4.8e-07      4.8e-07     9.32e-06
    522    20     8.24e-08     8.24e-08     3.53e-06
    522    30     5.49e-08     5.49e-08     2.89e-06
    522    40     2.66e-07     2.66e-07     6.75e-06
    522    50     3.19e-07     3.19e-07     6.42e-06
    522    60      1.9e-07      1.9e-07      4.5e-06
    522    61     2.09e-06     2.09e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             522 28740.106    0.005     2.53e-06     2.53e-06     1.87e-05
! Validation        522 28740.106    0.005     2.67e-07     2.67e-07     6.08e-06
Wall time: 28740.107010207998
training
# Epoch batch         loss       loss_e      e/N_mae
    523    10      2.4e-06      2.4e-06     2.06e-05
    523    20     4.95e-06     4.95e-06     3.02e-05
    523    30     7.32e-06     7.32e-06     3.97e-05
    523    40     5.13e-06     5.13e-06     3.26e-05
    523    48     2.22e-06     2.22e-06     2.49e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    523    10     5.92e-07     5.92e-07     9.64e-06
    523    20      7.4e-08      7.4e-08     3.85e-06
    523    30     1.65e-07     1.65e-07     5.78e-06
    523    40     7.82e-08     7.82e-08     4.18e-06
    523    50     3.13e-07     3.13e-07     7.39e-06
    523    60     6.97e-08     6.97e-08     3.85e-06
    523    61     3.49e-06     3.49e-06     2.25e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             523 28795.052    0.005     6.27e-06     6.27e-06     3.16e-05
! Validation        523 28795.052    0.005     3.77e-07     3.77e-07     6.99e-06
Wall time: 28795.052488833
training
# Epoch batch         loss       loss_e      e/N_mae
    524    10     2.86e-06     2.86e-06     2.57e-05
    524    20     3.19e-06     3.19e-06     2.13e-05
    524    30     4.82e-06     4.82e-06     3.08e-05
    524    40     3.02e-06     3.02e-06     2.47e-05
    524    48     8.98e-08     8.98e-08     5.62e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    524    10     3.21e-07     3.21e-07     8.35e-06
    524    20     1.23e-07     1.23e-07     5.14e-06
    524    30     6.34e-08     6.34e-08     3.21e-06
    524    40     2.37e-07     2.37e-07     7.39e-06
    524    50      1.8e-07      1.8e-07     5.78e-06
    524    60     1.84e-07     1.84e-07      6.1e-06
    524    61     3.61e-06     3.61e-06     2.25e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             524 28850.137    0.005     2.46e-06     2.46e-06     2.05e-05
! Validation        524 28850.137    0.005      3.6e-07      3.6e-07     6.94e-06
Wall time: 28850.138231582998
training
# Epoch batch         loss       loss_e      e/N_mae
    525    10     7.45e-06     7.45e-06     2.94e-05
    525    20     1.98e-06     1.98e-06     1.95e-05
    525    30      2.5e-06      2.5e-06     2.06e-05
    525    40     1.49e-06     1.49e-06     1.69e-05
    525    48     1.37e-07     1.37e-07     5.62e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    525    10     3.42e-07     3.42e-07     6.75e-06
    525    20     1.14e-07     1.14e-07      4.5e-06
    525    30     1.27e-08     1.27e-08     1.28e-06
    525    40     2.37e-07     2.37e-07      6.1e-06
    525    50     2.43e-07     2.43e-07     7.07e-06
    525    60      9.3e-08      9.3e-08     4.82e-06
    525    61     2.99e-06     2.99e-06     2.14e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             525 28905.320    0.005     1.73e-06     1.73e-06     1.66e-05
! Validation        525 28905.320    0.005     3.11e-07     3.11e-07     6.52e-06
Wall time: 28905.320525790998
training
# Epoch batch         loss       loss_e      e/N_mae
    526    10     5.83e-07     5.83e-07     1.03e-05
    526    20     3.58e-07     3.58e-07     8.14e-06
    526    30     6.42e-07     6.42e-07     1.11e-05
    526    40     7.48e-07     7.48e-07     1.23e-05
    526    48     1.37e-07     1.37e-07     4.82e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    526    10     4.12e-07     4.12e-07     8.03e-06
    526    20     2.51e-07     2.51e-07     6.42e-06
    526    30     3.38e-08     3.38e-08     3.53e-06
    526    40     1.63e-07     1.63e-07     5.78e-06
    526    50     3.87e-07     3.87e-07     8.35e-06
    526    60     5.07e-08     5.07e-08     3.53e-06
    526    61     2.94e-06     2.94e-06     2.09e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             526 28960.515    0.005     7.98e-07     7.98e-07     1.13e-05
! Validation        526 28960.515    0.005     3.06e-07     3.06e-07     6.62e-06
Wall time: 28960.515244125
training
# Epoch batch         loss       loss_e      e/N_mae
    527    10      2.5e-07      2.5e-07     6.96e-06
    527    20      4.3e-07      4.3e-07     7.17e-06
    527    30     2.95e-07     2.95e-07     8.14e-06
    527    40     3.13e-07     3.13e-07     7.82e-06
    527    48     2.17e-07     2.17e-07     8.03e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    527    10     3.78e-07     3.78e-07     5.46e-06
    527    20     1.48e-07     1.48e-07     5.14e-06
    527    30     8.88e-08     8.88e-08     4.18e-06
    527    40     2.03e-07     2.03e-07      6.1e-06
    527    50     2.68e-07     2.68e-07     7.71e-06
    527    60     8.45e-08     8.45e-08     4.82e-06
    527    61     2.63e-06     2.63e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             527 29015.464    0.005     4.77e-07     4.77e-07     8.95e-06
! Validation        527 29015.464    0.005     2.87e-07     2.87e-07      6.5e-06
Wall time: 29015.464257833
training
# Epoch batch         loss       loss_e      e/N_mae
    528    10     7.04e-07     7.04e-07     1.07e-05
    528    20     7.55e-07     7.55e-07     1.16e-05
    528    30     1.09e-06     1.09e-06     1.52e-05
    528    40     3.49e-07     3.49e-07      7.6e-06
    528    48      1.8e-07      1.8e-07     6.42e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    528    10     4.31e-07     4.31e-07     7.71e-06
    528    20     1.73e-07     1.73e-07      6.1e-06
    528    30     5.49e-08     5.49e-08     3.53e-06
    528    40     2.47e-07     2.47e-07     6.42e-06
    528    50     2.77e-07     2.77e-07     7.07e-06
    528    60     1.12e-07     1.12e-07     5.46e-06
    528    61     2.41e-06     2.41e-06     2.03e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             528 29070.399    0.005     6.92e-07     6.92e-07     1.09e-05
! Validation        528 29070.399    0.005     2.97e-07     2.97e-07     6.62e-06
Wall time: 29070.399461833
training
# Epoch batch         loss       loss_e      e/N_mae
    529    10     2.75e-06     2.75e-06     2.32e-05
    529    20     2.38e-06     2.38e-06     1.99e-05
    529    30     2.19e-06     2.19e-06      1.8e-05
    529    40     2.76e-06     2.76e-06     2.35e-05
    529    48     1.37e-06     1.37e-06     1.85e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    529    10     2.32e-07     2.32e-07     5.78e-06
    529    20     1.97e-07     1.97e-07     5.14e-06
    529    30     3.17e-08     3.17e-08     2.25e-06
    529    40     2.16e-07     2.16e-07     6.42e-06
    529    50     3.28e-07     3.28e-07     7.07e-06
    529    60     1.73e-07     1.73e-07     5.46e-06
    529    61     2.56e-06     2.56e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             529 29125.505    0.005     2.29e-06     2.29e-06     1.94e-05
! Validation        529 29125.505    0.005     2.96e-07     2.96e-07     6.62e-06
Wall time: 29125.505965999997
training
# Epoch batch         loss       loss_e      e/N_mae
    530    10     1.16e-05     1.16e-05     4.55e-05
    530    20      4.5e-06      4.5e-06     2.49e-05
    530    30     2.99e-06     2.99e-06     2.47e-05
    530    40     4.51e-06     4.51e-06     3.04e-05
    530    48     1.38e-05     1.38e-05     5.62e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    530    10     1.63e-07     1.63e-07     5.78e-06
    530    20     1.84e-07     1.84e-07     4.82e-06
    530    30     8.88e-08     8.88e-08     5.14e-06
    530    40     3.15e-07     3.15e-07     7.07e-06
    530    50     3.02e-07     3.02e-07     7.07e-06
    530    60     6.55e-08     6.55e-08     4.18e-06
    530    61     2.43e-06     2.43e-06     1.87e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             530 29180.599    0.005     6.67e-06     6.67e-06     3.08e-05
! Validation        530 29180.599    0.005     3.41e-07     3.41e-07     7.18e-06
Wall time: 29180.598947749997
training
# Epoch batch         loss       loss_e      e/N_mae
    531    10     5.95e-06     5.95e-06     3.26e-05
    531    20     6.09e-06     6.09e-06     2.93e-05
    531    30     1.86e-06     1.86e-06     1.95e-05
    531    40      3.5e-06      3.5e-06     2.52e-05
    531    48     1.56e-06     1.56e-06     2.01e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    531    10     4.27e-07     4.27e-07     8.99e-06
    531    20     4.71e-07     4.71e-07     9.96e-06
    531    30     4.69e-07     4.69e-07     9.64e-06
    531    40     6.02e-07     6.02e-07     1.19e-05
    531    50     6.17e-07     6.17e-07     1.12e-05
    531    60     1.92e-07     1.92e-07     5.46e-06
    531    61     3.22e-06     3.22e-06     2.46e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             531 29235.796    0.005     7.27e-06     7.27e-06     3.28e-05
! Validation        531 29235.796    0.005      7.4e-07      7.4e-07     1.15e-05
Wall time: 29235.796434916
training
# Epoch batch         loss       loss_e      e/N_mae
    532    10      1.1e-06      1.1e-06     1.42e-05
    532    20      1.6e-06      1.6e-06     1.69e-05
    532    30     8.88e-07     8.88e-07     1.18e-05
    532    40     7.91e-07     7.91e-07      1.2e-05
    532    48     3.86e-07     3.86e-07     8.83e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    532    10     4.31e-07     4.31e-07     8.99e-06
    532    20      6.3e-07      6.3e-07     1.09e-05
    532    30     4.63e-07     4.63e-07     9.64e-06
    532    40     4.04e-07     4.04e-07     8.99e-06
    532    50     3.51e-07     3.51e-07     8.03e-06
    532    60     1.94e-07     1.94e-07     6.75e-06
    532    61     3.23e-06     3.23e-06     2.46e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             532 29291.011    0.005      1.5e-06      1.5e-06     1.54e-05
! Validation        532 29291.011    0.005     6.39e-07     6.39e-07     1.06e-05
Wall time: 29291.011775583
training
# Epoch batch         loss       loss_e      e/N_mae
    533    10      4.9e-07      4.9e-07     9.21e-06
    533    20     8.38e-08     8.38e-08     3.96e-06
    533    30     3.98e-07     3.98e-07     8.78e-06
    533    40     2.99e-07     2.99e-07      7.6e-06
    533    48     9.56e-07     9.56e-07     1.61e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    533    10      2.3e-07      2.3e-07     7.07e-06
    533    20     6.07e-07     6.07e-07     9.96e-06
    533    30     3.49e-07     3.49e-07     8.99e-06
    533    40     3.57e-07     3.57e-07     7.39e-06
    533    50     1.23e-07     1.23e-07     4.18e-06
    533    60     1.39e-07     1.39e-07      4.5e-06
    533    61     2.93e-06     2.93e-06     2.25e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             533 29345.952    0.005     5.51e-07     5.51e-07     9.41e-06
! Validation        533 29345.952    0.005     4.55e-07     4.55e-07     8.65e-06
Wall time: 29345.953168375
training
# Epoch batch         loss       loss_e      e/N_mae
    534    10        2e-07        2e-07     6.42e-06
    534    20     3.37e-07     3.37e-07     7.07e-06
    534    30     3.35e-07     3.35e-07      7.5e-06
    534    40     6.45e-07     6.45e-07     1.12e-05
    534    48     7.19e-07     7.19e-07     1.28e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    534    10     4.02e-07     4.02e-07     8.67e-06
    534    20     4.78e-07     4.78e-07     7.71e-06
    534    30     2.26e-07     2.26e-07     7.39e-06
    534    40     3.44e-07     3.44e-07     7.39e-06
    534    50     1.73e-07     1.73e-07     5.46e-06
    534    60     1.27e-07     1.27e-07     4.18e-06
    534    61     2.59e-06     2.59e-06     2.25e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             534 29401.072    0.005     4.37e-07     4.37e-07     8.42e-06
! Validation        534 29401.072    0.005     3.43e-07     3.43e-07     7.21e-06
Wall time: 29401.07338775
training
# Epoch batch         loss       loss_e      e/N_mae
    535    10     2.98e-07     2.98e-07     7.39e-06
    535    20     2.23e-07     2.23e-07     6.21e-06
    535    30     5.24e-07     5.24e-07     1.01e-05
    535    40      7.5e-07      7.5e-07     1.31e-05
    535    48     8.98e-08     8.98e-08     4.02e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    535    10     3.44e-07     3.44e-07     8.03e-06
    535    20     3.28e-07     3.28e-07     7.39e-06
    535    30      2.3e-07      2.3e-07     7.71e-06
    535    40     4.46e-07     4.46e-07     8.35e-06
    535    50     1.92e-07     1.92e-07     6.75e-06
    535    60     1.16e-07     1.16e-07     5.14e-06
    535    61      2.8e-06      2.8e-06     2.36e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             535 29456.263    0.005     5.04e-07     5.04e-07     9.46e-06
! Validation        535 29456.263    0.005      3.2e-07      3.2e-07     6.89e-06
Wall time: 29456.26356525
training
# Epoch batch         loss       loss_e      e/N_mae
    536    10     4.02e-07     4.02e-07     8.67e-06
    536    20     9.62e-07     9.62e-07      1.3e-05
    536    30     1.76e-07     1.76e-07      6.1e-06
    536    40     8.59e-07     8.59e-07     1.22e-05
    536    48     4.49e-07     4.49e-07     1.04e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    536    10      2.6e-07      2.6e-07     6.42e-06
    536    20     2.66e-07     2.66e-07     7.39e-06
    536    30     1.31e-07     1.31e-07     5.46e-06
    536    40      2.9e-07      2.9e-07     7.07e-06
    536    50     3.17e-07     3.17e-07     8.03e-06
    536    60     1.08e-07     1.08e-07     5.14e-06
    536    61     2.56e-06     2.56e-06     2.03e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             536 29511.358    0.005     5.02e-07     5.02e-07     8.99e-06
! Validation        536 29511.358    0.005      2.7e-07      2.7e-07     6.45e-06
Wall time: 29511.358274041
training
# Epoch batch         loss       loss_e      e/N_mae
    537    10      1.3e-06      1.3e-06     1.47e-05
    537    20     6.11e-07     6.11e-07     9.96e-06
    537    30     2.99e-07     2.99e-07     7.82e-06
    537    40     4.26e-07     4.26e-07     9.32e-06
    537    48     1.53e-07     1.53e-07     6.42e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    537    10     1.33e-07     1.33e-07      4.5e-06
    537    20     2.24e-07     2.24e-07     5.46e-06
    537    30     1.18e-07     1.18e-07     5.78e-06
    537    40     2.49e-07     2.49e-07     5.78e-06
    537    50     3.17e-07     3.17e-07     8.03e-06
    537    60     6.76e-08     6.76e-08     4.18e-06
    537    61     2.32e-06     2.32e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             537 29566.611    0.005     6.53e-07     6.53e-07     1.04e-05
! Validation        537 29566.611    0.005     2.47e-07     2.47e-07     6.03e-06
Wall time: 29566.611062124997
training
# Epoch batch         loss       loss_e      e/N_mae
    538    10     6.33e-07     6.33e-07     1.08e-05
    538    20     3.71e-07     3.71e-07      7.6e-06
    538    30     1.01e-06     1.01e-06     1.53e-05
    538    40     1.04e-06     1.04e-06     1.46e-05
    538    48     1.06e-08     1.06e-08     1.61e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    538    10     1.33e-07     1.33e-07      4.5e-06
    538    20     2.03e-07     2.03e-07      6.1e-06
    538    30     1.14e-07     1.14e-07     5.14e-06
    538    40     2.92e-07     2.92e-07     7.39e-06
    538    50        3e-07        3e-07     6.75e-06
    538    60     7.61e-08     7.61e-08     3.53e-06
    538    61     2.09e-06     2.09e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             538 29621.629    0.005     6.41e-07     6.41e-07     1.06e-05
! Validation        538 29621.629    0.005     2.52e-07     2.52e-07     6.11e-06
Wall time: 29621.630084040997
training
# Epoch batch         loss       loss_e      e/N_mae
    539    10     2.71e-07     2.71e-07     6.75e-06
    539    20     3.04e-07     3.04e-07     7.28e-06
    539    30     4.84e-07     4.84e-07     9.74e-06
    539    40     2.78e-07     2.78e-07     6.64e-06
    539    48     5.34e-07     5.34e-07     9.64e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    539    10     2.43e-07     2.43e-07     6.42e-06
    539    20     1.56e-07     1.56e-07     5.14e-06
    539    30      9.3e-08      9.3e-08      4.5e-06
    539    40     2.75e-07     2.75e-07     6.75e-06
    539    50     2.85e-07     2.85e-07     7.07e-06
    539    60     1.54e-07     1.54e-07      6.1e-06
    539    61     1.99e-06     1.99e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             539 29676.545    0.005     4.76e-07     4.76e-07     8.97e-06
! Validation        539 29676.545    0.005     2.43e-07     2.43e-07     6.08e-06
Wall time: 29676.545633915997
training
# Epoch batch         loss       loss_e      e/N_mae
    540    10     3.54e-07     3.54e-07      7.6e-06
    540    20     5.97e-07     5.97e-07      1.1e-05
    540    30     1.14e-07     1.14e-07     4.39e-06
    540    40     9.83e-07     9.83e-07     9.42e-06
    540    48     5.28e-08     5.28e-08     3.21e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    540    10     2.73e-07     2.73e-07     6.42e-06
    540    20     1.39e-07     1.39e-07     5.46e-06
    540    30     1.27e-07     1.27e-07     5.14e-06
    540    40     3.25e-07     3.25e-07     8.67e-06
    540    50     3.11e-07     3.11e-07     8.03e-06
    540    60     8.03e-08     8.03e-08     3.53e-06
    540    61     2.34e-06     2.34e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             540 29731.653    0.005     5.32e-07     5.32e-07     9.21e-06
! Validation        540 29731.653    0.005     2.64e-07     2.64e-07     6.18e-06
Wall time: 29731.653555582998
training
# Epoch batch         loss       loss_e      e/N_mae
    541    10     3.01e-07     3.01e-07     7.82e-06
    541    20     4.66e-07     4.66e-07     8.03e-06
    541    30     2.43e-07     2.43e-07     6.75e-06
    541    40     4.35e-07     4.35e-07     9.32e-06
    541    48     1.04e-06     1.04e-06     1.28e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    541    10     3.09e-07     3.09e-07     6.42e-06
    541    20     1.14e-07     1.14e-07     5.14e-06
    541    30     1.37e-07     1.37e-07     5.14e-06
    541    40     2.11e-07     2.11e-07      6.1e-06
    541    50      3.3e-07      3.3e-07     8.03e-06
    541    60     6.34e-08     6.34e-08     4.18e-06
    541    61     2.56e-06     2.56e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             541 29786.791    0.005     4.21e-07     4.21e-07     8.34e-06
! Validation        541 29786.791    0.005     2.68e-07     2.68e-07     6.17e-06
Wall time: 29786.792706707998
training
# Epoch batch         loss       loss_e      e/N_mae
    542    10     1.45e-06     1.45e-06     1.67e-05
    542    20     3.38e-06     3.38e-06     2.42e-05
    542    30     5.34e-06     5.34e-06     3.26e-05
    542    40     5.63e-06     5.63e-06     3.17e-05
    542    48     2.64e-08     2.64e-08     2.41e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    542    10     3.13e-07     3.13e-07     7.39e-06
    542    20     2.92e-07     2.92e-07     6.42e-06
    542    30     1.54e-07     1.54e-07      4.5e-06
    542    40     5.07e-07     5.07e-07     9.32e-06
    542    50     2.11e-07     2.11e-07     5.46e-06
    542    60     1.08e-07     1.08e-07     4.82e-06
    542    61     2.33e-06     2.33e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             542 29841.764    0.005     4.08e-06     4.08e-06     2.46e-05
! Validation        542 29841.764    0.005     2.95e-07     2.95e-07     6.51e-06
Wall time: 29841.765334165997
training
# Epoch batch         loss       loss_e      e/N_mae
    543    10     2.08e-06     2.08e-06     2.12e-05
    543    20     2.73e-06     2.73e-06     2.03e-05
    543    30     9.07e-07     9.07e-07     1.25e-05
    543    40     4.19e-07     4.19e-07     9.53e-06
    543    48     3.58e-06     3.58e-06     2.33e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    543    10     2.35e-07     2.35e-07     6.75e-06
    543    20     2.01e-07     2.01e-07     5.46e-06
    543    30     4.23e-08     4.23e-08     3.21e-06
    543    40     6.23e-07     6.23e-07     9.96e-06
    543    50     2.35e-07     2.35e-07     7.07e-06
    543    60      7.4e-08      7.4e-08     3.85e-06
    543    61     2.73e-06     2.73e-06     2.36e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             543 29896.887    0.005     1.47e-06     1.47e-06     1.48e-05
! Validation        543 29896.887    0.005     2.99e-07     2.99e-07     6.48e-06
Wall time: 29896.887323458
training
# Epoch batch         loss       loss_e      e/N_mae
    544    10        1e-06        1e-06     1.23e-05
    544    20     2.09e-06     2.09e-06     1.91e-05
    544    30     2.14e-06     2.14e-06     1.68e-05
    544    40     1.57e-06     1.57e-06     1.58e-05
    544    48      3.8e-07      3.8e-07     1.04e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    544    10     2.68e-07     2.68e-07     4.82e-06
    544    20     2.11e-07     2.11e-07     6.75e-06
    544    30     1.06e-08     1.06e-08     9.64e-07
    544    40     4.46e-07     4.46e-07     9.64e-06
    544    50     2.47e-07     2.47e-07     6.42e-06
    544    60     6.13e-08     6.13e-08     4.18e-06
    544    61     2.12e-06     2.12e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             544 29951.864    0.005     1.89e-06     1.89e-06     1.77e-05
! Validation        544 29951.864    0.005     2.94e-07     2.94e-07     6.54e-06
Wall time: 29951.864694582997
training
# Epoch batch         loss       loss_e      e/N_mae
    545    10     1.27e-06     1.27e-06     1.51e-05
    545    20     6.36e-07     6.36e-07     1.12e-05
    545    30     7.24e-07     7.24e-07      1.3e-05
    545    40     1.04e-06     1.04e-06      1.4e-05
    545    48      8.3e-07      8.3e-07     1.45e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    545    10     3.36e-07     3.36e-07     6.75e-06
    545    20     2.35e-07     2.35e-07     6.75e-06
    545    30     2.32e-08     2.32e-08     1.93e-06
    545    40     3.74e-07     3.74e-07     7.71e-06
    545    50     3.42e-07     3.42e-07     8.03e-06
    545    60     1.71e-07     1.71e-07     6.75e-06
    545    61     2.02e-06     2.02e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             545 30006.862    0.005     1.29e-06     1.29e-06      1.5e-05
! Validation        545 30006.862    0.005     2.92e-07     2.92e-07     6.63e-06
Wall time: 30006.862963958
training
# Epoch batch         loss       loss_e      e/N_mae
    546    10     5.69e-07     5.69e-07     1.04e-05
    546    20     5.73e-07     5.73e-07     9.74e-06
    546    30     3.67e-07     3.67e-07     7.71e-06
    546    40     3.63e-07     3.63e-07     7.92e-06
    546    48     5.76e-07     5.76e-07      1.2e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    546    10     2.37e-07     2.37e-07     5.46e-06
    546    20      2.9e-07      2.9e-07     6.42e-06
    546    30     2.96e-08     2.96e-08     1.93e-06
    546    40     4.84e-07     4.84e-07     9.64e-06
    546    50     3.28e-07     3.28e-07     8.03e-06
    546    60     1.35e-07     1.35e-07     4.82e-06
    546    61     1.78e-06     1.78e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             546 30062.074    0.005     6.19e-07     6.19e-07     1.02e-05
! Validation        546 30062.074    0.005     2.68e-07     2.68e-07     6.42e-06
Wall time: 30062.075601916
training
# Epoch batch         loss       loss_e      e/N_mae
    547    10     5.33e-07     5.33e-07     9.64e-06
    547    20      2.1e-07      2.1e-07     6.21e-06
    547    30     2.47e-07     2.47e-07     6.42e-06
    547    40     2.94e-07     2.94e-07     6.85e-06
    547    48      3.8e-07      3.8e-07     1.04e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    547    10     3.25e-07     3.25e-07     5.78e-06
    547    20     2.54e-07     2.54e-07     6.75e-06
    547    30     4.65e-08     4.65e-08     2.89e-06
    547    40      2.6e-07      2.6e-07     7.07e-06
    547    50     3.76e-07     3.76e-07     8.03e-06
    547    60     1.69e-07     1.69e-07     5.46e-06
    547    61     1.89e-06     1.89e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             547 30117.198    0.005     4.85e-07     4.85e-07      9.1e-06
! Validation        547 30117.198    0.005     2.67e-07     2.67e-07     6.35e-06
Wall time: 30117.198789374997
training
# Epoch batch         loss       loss_e      e/N_mae
    548    10     9.31e-07     9.31e-07     1.36e-05
    548    20     3.22e-07     3.22e-07     8.35e-06
    548    30     8.21e-07     8.21e-07     1.16e-05
    548    40     8.07e-07     8.07e-07     1.17e-05
    548    48     1.29e-06     1.29e-06     1.93e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    548    10     4.04e-07     4.04e-07     7.07e-06
    548    20     2.32e-07     2.32e-07     7.39e-06
    548    30     9.51e-08     9.51e-08     5.46e-06
    548    40     2.92e-07     2.92e-07     8.03e-06
    548    50     3.44e-07     3.44e-07     8.67e-06
    548    60     6.13e-08     6.13e-08     3.53e-06
    548    61     2.17e-06     2.17e-06     1.87e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             548 30172.238    0.005        1e-06        1e-06     1.28e-05
! Validation        548 30172.238    0.005     2.76e-07     2.76e-07     6.47e-06
Wall time: 30172.239021125
training
# Epoch batch         loss       loss_e      e/N_mae
    549    10     1.06e-06     1.06e-06     1.27e-05
    549    20     3.25e-06     3.25e-06     2.45e-05
    549    30     2.25e-06     2.25e-06      1.7e-05
    549    40     1.05e-06     1.05e-06     1.39e-05
    549    48     4.15e-06     4.15e-06     2.41e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    549    10     2.37e-07     2.37e-07     6.75e-06
    549    20     2.09e-07     2.09e-07     6.75e-06
    549    30     5.92e-08     5.92e-08     3.53e-06
    549    40     2.28e-07     2.28e-07     7.39e-06
    549    50     3.99e-07     3.99e-07     7.71e-06
    549    60     9.72e-08     9.72e-08     4.18e-06
    549    61     2.51e-06     2.51e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             549 30227.205    0.005     2.32e-06     2.32e-06     1.92e-05
! Validation        549 30227.205    0.005     2.69e-07     2.69e-07     6.17e-06
Wall time: 30227.205830290997
training
# Epoch batch         loss       loss_e      e/N_mae
    550    10     1.58e-06     1.58e-06     1.47e-05
    550    20      1.1e-06      1.1e-06     1.37e-05
    550    30     4.87e-07     4.87e-07     1.02e-05
    550    40     1.51e-06     1.51e-06     1.66e-05
    550    48     5.13e-06     5.13e-06     3.69e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    550    10     2.62e-07     2.62e-07      4.5e-06
    550    20     2.85e-07     2.85e-07     6.75e-06
    550    30      1.1e-07      1.1e-07     5.14e-06
    550    40     1.01e-07     1.01e-07     4.82e-06
    550    50     2.41e-07     2.41e-07     6.75e-06
    550    60     4.65e-08     4.65e-08     2.89e-06
    550    61     2.57e-06     2.57e-06     2.03e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             550 30282.403    0.005     1.71e-06     1.71e-06     1.66e-05
! Validation        550 30282.403    0.005     2.86e-07     2.86e-07     6.34e-06
Wall time: 30282.403030666
training
# Epoch batch         loss       loss_e      e/N_mae
    551    10     3.12e-06     3.12e-06     2.33e-05
    551    20      9.5e-07      9.5e-07     1.33e-05
    551    30     7.72e-07     7.72e-07     1.23e-05
    551    40     1.31e-06     1.31e-06     1.58e-05
    551    48     1.53e-07     1.53e-07     5.62e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    551    10     2.49e-07     2.49e-07      6.1e-06
    551    20     1.42e-07     1.42e-07     5.14e-06
    551    30     5.71e-08     5.71e-08     4.18e-06
    551    40     1.52e-07     1.52e-07     5.14e-06
    551    50     3.25e-07     3.25e-07     7.39e-06
    551    60     4.86e-08     4.86e-08     3.53e-06
    551    61      2.5e-06      2.5e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             551 30337.425    0.005      1.5e-06      1.5e-06     1.61e-05
! Validation        551 30337.425    0.005     3.03e-07     3.03e-07     6.62e-06
Wall time: 30337.426151124997
training
# Epoch batch         loss       loss_e      e/N_mae
    552    10     1.17e-06     1.17e-06     1.51e-05
    552    20     8.55e-07     8.55e-07     1.25e-05
    552    30      6.8e-07      6.8e-07     1.15e-05
    552    40      6.2e-07      6.2e-07     1.14e-05
    552    48     9.51e-08     9.51e-08     4.82e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    552    10      2.2e-07      2.2e-07      4.5e-06
    552    20     2.18e-07     2.18e-07     7.07e-06
    552    30     8.88e-08     8.88e-08      4.5e-06
    552    40      1.2e-07      1.2e-07     4.18e-06
    552    50     3.49e-07     3.49e-07     7.71e-06
    552    60     5.07e-08     5.07e-08     3.53e-06
    552    61     2.75e-06     2.75e-06     2.14e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             552 30392.513    0.005     9.83e-07     9.83e-07      1.3e-05
! Validation        552 30392.513    0.005     2.86e-07     2.86e-07     6.24e-06
Wall time: 30392.512890125
training
# Epoch batch         loss       loss_e      e/N_mae
    553    10      5.6e-06      5.6e-06     3.08e-05
    553    20     1.62e-06     1.62e-06     1.75e-05
    553    30     2.95e-06     2.95e-06     2.36e-05
    553    40     1.45e-06     1.45e-06     1.64e-05
    553    48     1.37e-07     1.37e-07     5.62e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    553    10     3.02e-07     3.02e-07     8.03e-06
    553    20     1.92e-07     1.92e-07     6.75e-06
    553    30     4.44e-08     4.44e-08     2.25e-06
    553    40     1.54e-07     1.54e-07     5.46e-06
    553    50     3.09e-07     3.09e-07     6.75e-06
    553    60      1.9e-07      1.9e-07     5.14e-06
    553    61     3.01e-06     3.01e-06     2.03e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             553 30447.739    0.005     2.19e-06     2.19e-06     1.88e-05
! Validation        553 30447.739    0.005      3.3e-07      3.3e-07     6.93e-06
Wall time: 30447.740273833
training
# Epoch batch         loss       loss_e      e/N_mae
    554    10     1.22e-06     1.22e-06     1.45e-05
    554    20     7.09e-07     7.09e-07     1.15e-05
    554    30     4.16e-06     4.16e-06     2.78e-05
    554    40      1.9e-06      1.9e-06     1.86e-05
    554    48     1.87e-06     1.87e-06     2.09e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    554    10     1.97e-07     1.97e-07     6.75e-06
    554    20     2.35e-07     2.35e-07     6.42e-06
    554    30     6.76e-08     6.76e-08     3.53e-06
    554    40      2.2e-07      2.2e-07     6.42e-06
    554    50        3e-07        3e-07     7.39e-06
    554    60     8.24e-08     8.24e-08     3.53e-06
    554    61     2.69e-06     2.69e-06     1.87e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             554 30502.596    0.005     2.01e-06     2.01e-06     1.76e-05
! Validation        554 30502.596    0.005     3.04e-07     3.04e-07     6.53e-06
Wall time: 30502.597036749998
training
# Epoch batch         loss       loss_e      e/N_mae
    555    10     6.57e-07     6.57e-07     1.14e-05
    555    20     1.88e-06     1.88e-06     1.78e-05
    555    30     4.47e-07     4.47e-07     1.03e-05
    555    40     7.46e-07     7.46e-07     9.96e-06
    555    48     7.82e-07     7.82e-07      1.2e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    555    10     1.92e-07     1.92e-07     5.78e-06
    555    20      1.9e-07      1.9e-07     5.78e-06
    555    30     1.14e-07     1.14e-07     3.21e-06
    555    40     8.66e-08     8.66e-08     4.18e-06
    555    50     3.13e-07     3.13e-07     6.75e-06
    555    60     2.22e-07     2.22e-07     7.07e-06
    555    61     2.43e-06     2.43e-06     1.87e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             555 30557.857    0.005     1.22e-06     1.22e-06     1.42e-05
! Validation        555 30557.857    0.005     3.03e-07     3.03e-07     6.49e-06
Wall time: 30557.856702833
training
# Epoch batch         loss       loss_e      e/N_mae
    556    10      8.3e-07      8.3e-07      1.3e-05
    556    20     2.25e-07     2.25e-07     7.17e-06
    556    30     4.58e-07     4.58e-07     9.42e-06
    556    40     3.49e-07     3.49e-07      7.5e-06
    556    48      1.8e-07      1.8e-07     6.42e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    556    10     2.83e-07     2.83e-07     8.35e-06
    556    20     1.29e-07     1.29e-07     5.46e-06
    556    30     1.25e-07     1.25e-07     5.14e-06
    556    40     1.84e-07     1.84e-07     5.78e-06
    556    50     3.95e-07     3.95e-07     8.35e-06
    556    60        3e-07        3e-07     7.39e-06
    556    61     2.74e-06     2.74e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             556 30612.875    0.005     4.91e-07     4.91e-07     9.01e-06
! Validation        556 30612.875    0.005     3.03e-07     3.03e-07     6.62e-06
Wall time: 30612.876143499998
training
# Epoch batch         loss       loss_e      e/N_mae
    557    10     2.51e-07     2.51e-07     6.32e-06
    557    20     1.97e-07     1.97e-07     5.78e-06
    557    30     7.04e-07     7.04e-07     9.96e-06
    557    40     1.02e-06     1.02e-06     1.34e-05
    557    48     8.98e-07     8.98e-07     1.28e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    557    10      3.7e-07      3.7e-07     6.75e-06
    557    20      1.5e-07      1.5e-07     5.46e-06
    557    30     9.93e-08     9.93e-08      4.5e-06
    557    40     1.84e-07     1.84e-07     6.42e-06
    557    50     4.14e-07     4.14e-07     8.67e-06
    557    60     2.81e-07     2.81e-07     7.71e-06
    557    61     1.97e-06     1.97e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             557 30668.113    0.005     5.56e-07     5.56e-07     9.45e-06
! Validation        557 30668.113    0.005      2.8e-07      2.8e-07     6.37e-06
Wall time: 30668.114487083
training
# Epoch batch         loss       loss_e      e/N_mae
    558    10     9.12e-07     9.12e-07     1.26e-05
    558    20     7.95e-07     7.95e-07     1.26e-05
    558    30      8.4e-07      8.4e-07     1.31e-05
    558    40     1.03e-06     1.03e-06     1.36e-05
    558    48     9.56e-07     9.56e-07     1.69e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    558    10     2.94e-07     2.94e-07     6.75e-06
    558    20     1.65e-07     1.65e-07     5.46e-06
    558    30     1.23e-07     1.23e-07     5.78e-06
    558    40     2.39e-07     2.39e-07     6.75e-06
    558    50     4.35e-07     4.35e-07     8.03e-06
    558    60     1.18e-07     1.18e-07     4.82e-06
    558    61     1.93e-06     1.93e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             558 30723.175    0.005     9.78e-07     9.78e-07     1.29e-05
! Validation        558 30723.175    0.005     2.56e-07     2.56e-07     6.12e-06
Wall time: 30723.176222208
training
# Epoch batch         loss       loss_e      e/N_mae
    559    10     2.25e-06     2.25e-06     1.69e-05
    559    20     2.81e-06     2.81e-06     2.13e-05
    559    30     1.52e-06     1.52e-06     1.69e-05
    559    40     4.52e-07     4.52e-07     9.21e-06
    559    48     8.98e-07     8.98e-07      1.2e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    559    10     4.52e-07     4.52e-07     9.64e-06
    559    20     1.33e-07     1.33e-07     5.46e-06
    559    30      1.2e-07      1.2e-07     4.82e-06
    559    40     8.03e-08     8.03e-08     3.85e-06
    559    50     2.75e-07     2.75e-07     6.75e-06
    559    60     1.08e-07     1.08e-07      4.5e-06
    559    61     2.33e-06     2.33e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             559 30777.941    0.005      1.2e-06      1.2e-06     1.36e-05
! Validation        559 30777.941    0.005     2.69e-07     2.69e-07     6.26e-06
Wall time: 30777.94176925
training
# Epoch batch         loss       loss_e      e/N_mae
    560    10     3.75e-07     3.75e-07     8.35e-06
    560    20      5.3e-07      5.3e-07     1.05e-05
    560    30     3.18e-07     3.18e-07     7.82e-06
    560    40     3.32e-07     3.32e-07     8.25e-06
    560    48     4.23e-07     4.23e-07     1.04e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    560    10     6.72e-07     6.72e-07     1.03e-05
    560    20     1.46e-07     1.46e-07     5.78e-06
    560    30     1.67e-07     1.67e-07     6.42e-06
    560    40     1.16e-07     1.16e-07     4.82e-06
    560    50     2.68e-07     2.68e-07     6.42e-06
    560    60     1.33e-07     1.33e-07     5.78e-06
    560    61     2.44e-06     2.44e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             560 30833.109    0.005     5.69e-07     5.69e-07     9.65e-06
! Validation        560 30833.109    0.005     2.69e-07     2.69e-07     6.13e-06
Wall time: 30833.109516582997
training
# Epoch batch         loss       loss_e      e/N_mae
    561    10     6.27e-07     6.27e-07      1.1e-05
    561    20     1.55e-07     1.55e-07     4.71e-06
    561    30     6.42e-07     6.42e-07     1.18e-05
    561    40     2.44e-07     2.44e-07     6.32e-06
    561    48     6.87e-08     6.87e-08     4.02e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    561    10      3.3e-07      3.3e-07     6.75e-06
    561    20     9.09e-08     9.09e-08     3.53e-06
    561    30     1.73e-07     1.73e-07     5.46e-06
    561    40      1.5e-07      1.5e-07     4.82e-06
    561    50     2.92e-07     2.92e-07     7.71e-06
    561    60     1.42e-07     1.42e-07     5.78e-06
    561    61      2.6e-06      2.6e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             561 30888.159    0.005     4.06e-07     4.06e-07     8.41e-06
! Validation        561 30888.159    0.005     2.55e-07     2.55e-07      5.9e-06
Wall time: 30888.159199540998
training
# Epoch batch         loss       loss_e      e/N_mae
    562    10     9.69e-07     9.69e-07     1.39e-05
    562    20     9.29e-07     9.29e-07     1.38e-05
    562    30     4.12e-07     4.12e-07     8.89e-06
    562    40     3.94e-07     3.94e-07     8.67e-06
    562    48     1.55e-06     1.55e-06     1.61e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    562    10     4.84e-07     4.84e-07     7.39e-06
    562    20     1.12e-07     1.12e-07     4.18e-06
    562    30     1.08e-07     1.08e-07      4.5e-06
    562    40     1.31e-07     1.31e-07     5.14e-06
    562    50     1.92e-07     1.92e-07     5.78e-06
    562    60     1.75e-07     1.75e-07     6.42e-06
    562    61     2.45e-06     2.45e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             562 30943.114    0.005     6.23e-07     6.23e-07        1e-05
! Validation        562 30943.114    0.005     2.43e-07     2.43e-07     5.68e-06
Wall time: 30943.1138245
training
# Epoch batch         loss       loss_e      e/N_mae
    563    10     2.16e-06     2.16e-06     1.85e-05
    563    20      1.3e-06      1.3e-06     1.34e-05
    563    30     1.97e-06     1.97e-06     1.86e-05
    563    40     8.89e-07     8.89e-07      1.3e-05
    563    48     1.03e-06     1.03e-06     1.53e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    563    10     3.49e-07     3.49e-07     7.07e-06
    563    20     9.09e-08     9.09e-08     4.18e-06
    563    30     9.09e-08     9.09e-08      4.5e-06
    563    40     1.46e-07     1.46e-07     4.18e-06
    563    50     4.44e-07     4.44e-07     8.67e-06
    563    60     1.82e-07     1.82e-07      6.1e-06
    563    61     2.33e-06     2.33e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             563 30998.304    0.005     1.62e-06     1.62e-06     1.64e-05
! Validation        563 30998.304    0.005     2.53e-07     2.53e-07      5.7e-06
Wall time: 30998.305107207998
training
# Epoch batch         loss       loss_e      e/N_mae
    564    10     2.81e-06     2.81e-06     2.08e-05
    564    20     5.29e-06     5.29e-06     2.36e-05
    564    30     1.07e-06     1.07e-06     1.41e-05
    564    40     8.11e-07     8.11e-07     1.24e-05
    564    48     4.76e-08     4.76e-08     3.21e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    564    10     5.05e-07     5.05e-07     8.35e-06
    564    20     1.33e-07     1.33e-07     5.14e-06
    564    30     6.13e-08     6.13e-08     3.21e-06
    564    40     2.09e-07     2.09e-07      6.1e-06
    564    50      2.6e-07      2.6e-07     7.07e-06
    564    60     1.65e-07     1.65e-07     5.46e-06
    564    61     1.83e-06     1.83e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             564 31053.321    0.005     1.44e-06     1.44e-06     1.53e-05
! Validation        564 31053.321    0.005      2.4e-07      2.4e-07     5.84e-06
Wall time: 31053.321800166
training
# Epoch batch         loss       loss_e      e/N_mae
    565    10     2.57e-07     2.57e-07     6.42e-06
    565    20     6.69e-07     6.69e-07     1.11e-05
    565    30      6.3e-07      6.3e-07     1.06e-05
    565    40     2.44e-07     2.44e-07     6.32e-06
    565    48     6.87e-07     6.87e-07     1.12e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    565    10     3.99e-07     3.99e-07      6.1e-06
    565    20     1.82e-07     1.82e-07     4.18e-06
    565    30     7.19e-08     7.19e-08      4.5e-06
    565    40     1.67e-07     1.67e-07     6.42e-06
    565    50     2.41e-07     2.41e-07     7.39e-06
    565    60     2.39e-07     2.39e-07     6.42e-06
    565    61     2.22e-06     2.22e-06     1.87e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             565 31108.327    0.005     5.25e-07     5.25e-07     9.35e-06
! Validation        565 31108.327    0.005     2.38e-07     2.38e-07     5.69e-06
Wall time: 31108.327523333
training
# Epoch batch         loss       loss_e      e/N_mae
    566    10     9.79e-07     9.79e-07     1.25e-05
    566    20     8.23e-07     8.23e-07     1.27e-05
    566    30     1.07e-06     1.07e-06     1.55e-05
    566    40     4.08e-07     4.08e-07      9.1e-06
    566    48      1.8e-06      1.8e-06     2.25e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    566    10     2.64e-07     2.64e-07      6.1e-06
    566    20     1.86e-07     1.86e-07     4.82e-06
    566    30     8.24e-08     8.24e-08     4.82e-06
    566    40     8.88e-08     8.88e-08      4.5e-06
    566    50     2.41e-07     2.41e-07     7.39e-06
    566    60     1.78e-07     1.78e-07      6.1e-06
    566    61     2.27e-06     2.27e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             566 31163.563    0.005     9.29e-07     9.29e-07     1.19e-05
! Validation        566 31163.563    0.005     2.44e-07     2.44e-07     5.88e-06
Wall time: 31163.563848332997
training
# Epoch batch         loss       loss_e      e/N_mae
    567    10     3.69e-06     3.69e-06     2.57e-05
    567    20     3.81e-06     3.81e-06     2.67e-05
    567    30     1.85e-06     1.85e-06     1.83e-05
    567    40     3.09e-06     3.09e-06     2.48e-05
    567    48     6.45e-06     6.45e-06     3.94e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    567    10     7.16e-07     7.16e-07     9.64e-06
    567    20      1.9e-07      1.9e-07      6.1e-06
    567    30     1.84e-07     1.84e-07      4.5e-06
    567    40     2.24e-07     2.24e-07     7.39e-06
    567    50     1.29e-07     1.29e-07     5.14e-06
    567    60     3.59e-07     3.59e-07     8.67e-06
    567    61     2.39e-06     2.39e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             567 31218.814    0.005     5.29e-06     5.29e-06     2.83e-05
! Validation        567 31218.814    0.005     2.66e-07     2.66e-07     5.96e-06
Wall time: 31218.814393582998
training
# Epoch batch         loss       loss_e      e/N_mae
    568    10     3.71e-06     3.71e-06     2.77e-05
    568    20     2.99e-06     2.99e-06     2.37e-05
    568    30     1.67e-06     1.67e-06      1.8e-05
    568    40     4.28e-06     4.28e-06     2.74e-05
    568    48     8.08e-07     8.08e-07     1.28e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    568    10     6.09e-07     6.09e-07     9.32e-06
    568    20     1.09e-06     1.09e-06     1.51e-05
    568    30     3.89e-07     3.89e-07     8.03e-06
    568    40     4.88e-07     4.88e-07     1.09e-05
    568    50     1.27e-07     1.27e-07     4.18e-06
    568    60     1.29e-07     1.29e-07     4.18e-06
    568    61     3.17e-06     3.17e-06     2.62e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             568 31273.833    0.005     5.19e-06     5.19e-06     2.92e-05
! Validation        568 31273.833    0.005     4.84e-07     4.84e-07      8.9e-06
Wall time: 31273.834196833
training
# Epoch batch         loss       loss_e      e/N_mae
    569    10     3.59e-06     3.59e-06     2.59e-05
    569    20     9.88e-07     9.88e-07     1.27e-05
    569    30     1.47e-06     1.47e-06     1.63e-05
    569    40     9.88e-07     9.88e-07     1.33e-05
    569    48     9.51e-08     9.51e-08     4.82e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    569    10     4.63e-07     4.63e-07     9.64e-06
    569    20     5.33e-07     5.33e-07     1.09e-05
    569    30     3.59e-07     3.59e-07     7.71e-06
    569    40     3.53e-07     3.53e-07     8.99e-06
    569    50     2.13e-07     2.13e-07      6.1e-06
    569    60     1.84e-07     1.84e-07     6.42e-06
    569    61     3.77e-06     3.77e-06     2.73e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             569 31328.936    0.005     1.67e-06     1.67e-06     1.66e-05
! Validation        569 31328.936    0.005     4.49e-07     4.49e-07     8.41e-06
Wall time: 31328.936717208
training
# Epoch batch         loss       loss_e      e/N_mae
    570    10     4.05e-07     4.05e-07     8.78e-06
    570    20     5.65e-07     5.65e-07     1.03e-05
    570    30     5.89e-07     5.89e-07     1.09e-05
    570    40     4.64e-07     4.64e-07     9.32e-06
    570    48     7.66e-07     7.66e-07     1.45e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    570    10     4.92e-07     4.92e-07     9.64e-06
    570    20     2.68e-07     2.68e-07     7.07e-06
    570    30     2.85e-07     2.85e-07     6.75e-06
    570    40      3.3e-07      3.3e-07     8.67e-06
    570    50     2.66e-07     2.66e-07     7.71e-06
    570    60     2.13e-07     2.13e-07      6.1e-06
    570    61      2.7e-06      2.7e-06     2.14e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             570 31383.963    0.005     6.23e-07     6.23e-07     1.03e-05
! Validation        570 31383.963    0.005     3.37e-07     3.37e-07     7.02e-06
Wall time: 31383.964219208
training
# Epoch batch         loss       loss_e      e/N_mae
    571    10     3.98e-07     3.98e-07     7.71e-06
    571    20     3.25e-07     3.25e-07      7.5e-06
    571    30     5.62e-07     5.62e-07      1.1e-05
    571    40     2.78e-07     2.78e-07     7.71e-06
    571    48     2.64e-08     2.64e-08     2.41e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    571    10      4.8e-07      4.8e-07     8.99e-06
    571    20     2.47e-07     2.47e-07     6.75e-06
    571    30     2.73e-07     2.73e-07     7.71e-06
    571    40     2.66e-07     2.66e-07     6.75e-06
    571    50     1.25e-07     1.25e-07     5.14e-06
    571    60     1.39e-07     1.39e-07     5.46e-06
    571    61     2.64e-06     2.64e-06     2.09e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             571 31439.184    0.005     3.66e-07     3.66e-07     7.93e-06
! Validation        571 31439.184    0.005        3e-07        3e-07     6.44e-06
Wall time: 31439.184650875
training
# Epoch batch         loss       loss_e      e/N_mae
    572    10     1.82e-07     1.82e-07     5.25e-06
    572    20     2.84e-07     2.84e-07     6.85e-06
    572    30     3.38e-07     3.38e-07     8.14e-06
    572    40     2.73e-07     2.73e-07     6.64e-06
    572    48     5.13e-07     5.13e-07     1.04e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    572    10     5.14e-07     5.14e-07     9.64e-06
    572    20     2.16e-07     2.16e-07     5.78e-06
    572    30     2.26e-07     2.26e-07     5.78e-06
    572    40     3.93e-07     3.93e-07     8.67e-06
    572    50     1.31e-07     1.31e-07     4.82e-06
    572    60     1.97e-07     1.97e-07     6.42e-06
    572    61     2.85e-06     2.85e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             572 31494.341    0.005     5.82e-07     5.82e-07     9.67e-06
! Validation        572 31494.341    0.005     2.81e-07     2.81e-07     6.12e-06
Wall time: 31494.340944707998
training
# Epoch batch         loss       loss_e      e/N_mae
    573    10     1.76e-06     1.76e-06     2.05e-05
    573    20        3e-07        3e-07     6.96e-06
    573    30     9.39e-07     9.39e-07     1.06e-05
    573    40     2.34e-07     2.34e-07     6.96e-06
    573    48     6.87e-07     6.87e-07      1.2e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    573    10     3.19e-07     3.19e-07     6.75e-06
    573    20     2.49e-07     2.49e-07      6.1e-06
    573    30      1.9e-07      1.9e-07     4.82e-06
    573    40     2.16e-07     2.16e-07     6.75e-06
    573    50     1.33e-07     1.33e-07      4.5e-06
    573    60     1.18e-07     1.18e-07     4.82e-06
    573    61     3.09e-06     3.09e-06     2.09e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             573 31549.515    0.005        1e-06        1e-06     1.31e-05
! Validation        573 31549.515    0.005     2.57e-07     2.57e-07     5.83e-06
Wall time: 31549.516174916
training
# Epoch batch         loss       loss_e      e/N_mae
    574    10      7.2e-07      7.2e-07     1.22e-05
    574    20     3.64e-07     3.64e-07     8.35e-06
    574    30     2.73e-07     2.73e-07     7.71e-06
    574    40     4.75e-07     4.75e-07     9.64e-06
    574    48     2.11e-08     2.11e-08     1.61e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    574    10     3.85e-07     3.85e-07     7.71e-06
    574    20     1.44e-07     1.44e-07     4.82e-06
    574    30     1.71e-07     1.71e-07     4.18e-06
    574    40     1.54e-07     1.54e-07     5.78e-06
    574    50     2.45e-07     2.45e-07      6.1e-06
    574    60     1.44e-07     1.44e-07     3.85e-06
    574    61     3.05e-06     3.05e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             574 31604.516    0.005     5.73e-07     5.73e-07     9.96e-06
! Validation        574 31604.516    0.005     2.51e-07     2.51e-07     5.74e-06
Wall time: 31604.516087582997
training
# Epoch batch         loss       loss_e      e/N_mae
    575    10     1.37e-07     1.37e-07     5.14e-06
    575    20     3.51e-07     3.51e-07     8.67e-06
    575    30     3.46e-07     3.46e-07     8.57e-06
    575    40     5.07e-07     5.07e-07     8.25e-06
    575    48      5.6e-07      5.6e-07     1.12e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    575    10     2.26e-07     2.26e-07     4.82e-06
    575    20     1.39e-07     1.39e-07     5.46e-06
    575    30     9.72e-08     9.72e-08     3.21e-06
    575    40     1.29e-07     1.29e-07     5.14e-06
    575    50     1.12e-07     1.12e-07     3.85e-06
    575    60     1.14e-07     1.14e-07     4.82e-06
    575    61     2.48e-06     2.48e-06     1.87e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             575 31659.586    0.005     2.84e-07     2.84e-07     6.79e-06
! Validation        575 31659.586    0.005      2.3e-07      2.3e-07     5.58e-06
Wall time: 31659.587136125
training
# Epoch batch         loss       loss_e      e/N_mae
    576    10     3.61e-07     3.61e-07     6.96e-06
    576    20     3.84e-07     3.84e-07     9.32e-06
    576    30     3.06e-07     3.06e-07     7.17e-06
    576    40     3.66e-07     3.66e-07     8.35e-06
    576    48     3.43e-07     3.43e-07     8.83e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    576    10     2.45e-07     2.45e-07     5.78e-06
    576    20     8.88e-08     8.88e-08     4.18e-06
    576    30      1.9e-07      1.9e-07     5.46e-06
    576    40     1.08e-07     1.08e-07     5.14e-06
    576    50     1.73e-07     1.73e-07     5.46e-06
    576    60     1.18e-07     1.18e-07      4.5e-06
    576    61     2.91e-06     2.91e-06     2.14e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             576 31714.827    0.005      3.5e-07      3.5e-07     7.43e-06
! Validation        576 31714.827    0.005     2.22e-07     2.22e-07     5.35e-06
Wall time: 31714.8284745
! Best model      576    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    577    10     2.09e-07     2.09e-07      6.1e-06
    577    20     1.37e-06     1.37e-06     1.61e-05
    577    30     6.32e-07     6.32e-07     1.11e-05
    577    40      7.9e-07      7.9e-07     1.24e-05
    577    48     4.76e-07     4.76e-07     1.04e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    577    10     2.64e-07     2.64e-07     7.07e-06
    577    20     1.25e-07     1.25e-07     5.14e-06
    577    30     6.55e-08     6.55e-08     3.53e-06
    577    40      2.2e-07      2.2e-07     6.75e-06
    577    50      1.8e-07      1.8e-07      4.5e-06
    577    60     1.06e-07     1.06e-07      4.5e-06
    577    61     3.02e-06     3.02e-06      2.3e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             577 31769.919    0.005     8.31e-07     8.31e-07     1.22e-05
! Validation        577 31769.919    0.005     2.26e-07     2.26e-07     5.26e-06
Wall time: 31769.919093791
training
# Epoch batch         loss       loss_e      e/N_mae
    578    10     1.65e-06     1.65e-06     1.35e-05
    578    20     5.21e-07     5.21e-07     7.92e-06
    578    30     3.07e-07     3.07e-07      7.6e-06
    578    40      5.1e-07      5.1e-07     8.78e-06
    578    48      8.3e-07      8.3e-07     1.53e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    578    10     2.66e-07     2.66e-07     6.75e-06
    578    20     1.18e-07     1.18e-07     4.18e-06
    578    30     5.71e-08     5.71e-08     3.21e-06
    578    40     2.16e-07     2.16e-07     6.75e-06
    578    50      2.6e-07      2.6e-07     6.42e-06
    578    60     1.27e-07     1.27e-07     4.82e-06
    578    61     2.69e-06     2.69e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             578 31825.037    0.005     6.81e-07     6.81e-07     1.08e-05
! Validation        578 31825.037    0.005     2.22e-07     2.22e-07     5.29e-06
Wall time: 31825.038503707998
training
# Epoch batch         loss       loss_e      e/N_mae
    579    10      4.8e-07      4.8e-07     9.42e-06
    579    20     2.36e-07     2.36e-07     6.42e-06
    579    30     3.48e-07     3.48e-07     8.03e-06
    579    40     2.97e-07     2.97e-07     7.28e-06
    579    48     1.06e-07     1.06e-07     5.62e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    579    10     3.68e-07     3.68e-07     8.35e-06
    579    20      9.3e-08      9.3e-08     3.85e-06
    579    30     4.65e-08     4.65e-08     3.85e-06
    579    40     1.31e-07     1.31e-07     5.14e-06
    579    50     2.16e-07     2.16e-07     5.46e-06
    579    60     1.35e-07     1.35e-07     5.46e-06
    579    61     2.61e-06     2.61e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             579 31880.165    0.005     3.88e-07     3.88e-07     8.09e-06
! Validation        579 31880.165    0.005     2.18e-07     2.18e-07     5.19e-06
Wall time: 31880.165360958
! Best model      579    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    580    10     2.55e-07     2.55e-07     7.39e-06
    580    20      2.4e-07      2.4e-07        6e-06
    580    30     5.95e-07     5.95e-07     1.01e-05
    580    40     3.11e-07     3.11e-07     7.71e-06
    580    48     1.37e-07     1.37e-07     4.82e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    580    10     4.06e-07     4.06e-07     7.71e-06
    580    20     6.55e-08     6.55e-08     3.53e-06
    580    30     4.44e-08     4.44e-08     3.53e-06
    580    40     2.09e-07     2.09e-07     6.75e-06
    580    50     1.14e-07     1.14e-07     4.82e-06
    580    60     2.13e-07     2.13e-07     6.42e-06
    580    61     2.21e-06     2.21e-06     1.55e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             580 31934.979    0.005      3.2e-07      3.2e-07     7.34e-06
! Validation        580 31934.979    0.005     2.12e-07     2.12e-07     5.26e-06
Wall time: 31934.979968333
! Best model      580    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    581    10     2.84e-07     2.84e-07     6.21e-06
    581    20     3.57e-07     3.57e-07     8.46e-06
    581    30     2.69e-07     2.69e-07     6.42e-06
    581    40     2.21e-07     2.21e-07     6.32e-06
    581    48     8.93e-07     8.93e-07     1.12e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    581    10     3.99e-07     3.99e-07     7.71e-06
    581    20     4.02e-08     4.02e-08     2.89e-06
    581    30     1.27e-08     1.27e-08     1.61e-06
    581    40     3.19e-07     3.19e-07     8.03e-06
    581    50     1.61e-07     1.61e-07     4.82e-06
    581    60     1.16e-07     1.16e-07     5.14e-06
    581    61     2.05e-06     2.05e-06     1.55e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             581 31990.122    0.005     3.29e-07     3.29e-07     7.22e-06
! Validation        581 31990.122    0.005      2.1e-07      2.1e-07     5.05e-06
Wall time: 31990.121963666
! Best model      581    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    582    10     6.28e-07     6.28e-07     1.08e-05
    582    20     4.26e-07     4.26e-07     7.82e-06
    582    30     3.76e-07     3.76e-07     8.89e-06
    582    40     3.33e-07     3.33e-07     6.96e-06
    582    48     1.06e-07     1.06e-07     5.62e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    582    10     2.51e-07     2.51e-07     5.78e-06
    582    20     1.75e-07     1.75e-07      6.1e-06
    582    30     8.03e-08     8.03e-08      4.5e-06
    582    40     1.84e-07     1.84e-07      6.1e-06
    582    50     1.97e-07     1.97e-07     5.14e-06
    582    60     1.39e-07     1.39e-07     5.46e-06
    582    61     2.44e-06     2.44e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             582 32045.369    0.005        6e-07        6e-07     1.02e-05
! Validation        582 32045.369    0.005     2.22e-07     2.22e-07     5.25e-06
Wall time: 32045.370189957997
training
# Epoch batch         loss       loss_e      e/N_mae
    583    10      3.8e-07      3.8e-07     7.71e-06
    583    20     2.01e-07     2.01e-07     6.32e-06
    583    30     5.74e-07     5.74e-07     1.04e-05
    583    40     1.94e-07     1.94e-07        6e-06
    583    48     6.87e-08     6.87e-08     4.82e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    583    10     2.28e-07     2.28e-07      6.1e-06
    583    20     1.94e-07     1.94e-07     6.42e-06
    583    30     6.34e-08     6.34e-08     3.53e-06
    583    40     1.56e-07     1.56e-07      6.1e-06
    583    50     1.52e-07     1.52e-07     5.46e-06
    583    60     1.65e-07     1.65e-07      6.1e-06
    583    61     2.43e-06     2.43e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             583 32100.333    0.005      2.7e-07      2.7e-07     6.75e-06
! Validation        583 32100.333    0.005     2.19e-07     2.19e-07     5.29e-06
Wall time: 32100.334255666
training
# Epoch batch         loss       loss_e      e/N_mae
    584    10     7.92e-07     7.92e-07     1.18e-05
    584    20      3.8e-07      3.8e-07      7.6e-06
    584    30     1.68e-07     1.68e-07     5.78e-06
    584    40      3.8e-07      3.8e-07     7.71e-06
    584    48     5.28e-08     5.28e-08     3.21e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    584    10     2.68e-07     2.68e-07     6.42e-06
    584    20     1.65e-07     1.65e-07     4.82e-06
    584    30     1.08e-07     1.08e-07     5.46e-06
    584    40     1.18e-07     1.18e-07     5.46e-06
    584    50     1.54e-07     1.54e-07      4.5e-06
    584    60     2.75e-07     2.75e-07     8.03e-06
    584    61     2.22e-06     2.22e-06     1.55e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             584 32155.480    0.005     3.62e-07     3.62e-07     7.83e-06
! Validation        584 32155.480    0.005     2.16e-07     2.16e-07     5.25e-06
Wall time: 32155.481365624997
training
# Epoch batch         loss       loss_e      e/N_mae
    585    10     8.47e-07     8.47e-07     1.22e-05
    585    20     2.92e-07     2.92e-07     6.53e-06
    585    30     4.04e-07     4.04e-07     8.89e-06
    585    40     3.37e-07     3.37e-07     7.71e-06
    585    48     4.76e-07     4.76e-07     1.04e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    585    10     2.18e-07     2.18e-07     6.42e-06
    585    20     1.78e-07     1.78e-07     5.46e-06
    585    30     6.34e-08     6.34e-08     3.53e-06
    585    40     2.32e-07     2.32e-07     7.39e-06
    585    50     1.23e-07     1.23e-07     4.82e-06
    585    60     1.56e-07     1.56e-07      6.1e-06
    585    61      2.7e-06      2.7e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             585 32210.499    0.005     3.91e-07     3.91e-07     8.02e-06
! Validation        585 32210.499    0.005     2.18e-07     2.18e-07     5.25e-06
Wall time: 32210.498874457997
training
# Epoch batch         loss       loss_e      e/N_mae
    586    10     2.85e-07     2.85e-07      7.5e-06
    586    20     3.08e-07     3.08e-07     7.28e-06
    586    30     4.69e-07     4.69e-07     9.64e-06
    586    40     1.88e-07     1.88e-07     5.46e-06
    586    48     3.06e-07     3.06e-07     9.64e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    586    10     2.94e-07     2.94e-07     8.03e-06
    586    20     1.01e-07     1.01e-07     4.18e-06
    586    30     4.02e-08     4.02e-08     3.21e-06
    586    40     1.78e-07     1.78e-07      6.1e-06
    586    50     1.82e-07     1.82e-07     4.18e-06
    586    60     1.37e-07     1.37e-07     5.78e-06
    586    61     2.27e-06     2.27e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             586 32265.620    0.005      4.4e-07      4.4e-07     8.27e-06
! Validation        586 32265.620    0.005      2.1e-07      2.1e-07     5.13e-06
Wall time: 32265.621149708
! Best model      586    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    587    10     4.66e-07     4.66e-07     8.67e-06
    587    20     8.85e-07     8.85e-07     1.19e-05
    587    30     7.19e-07     7.19e-07     1.15e-05
    587    40     5.28e-07     5.28e-07     8.99e-06
    587    48     3.06e-07     3.06e-07     8.83e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    587    10     3.09e-07     3.09e-07     7.71e-06
    587    20     1.73e-07     1.73e-07      6.1e-06
    587    30     4.65e-08     4.65e-08     2.89e-06
    587    40     2.11e-07     2.11e-07     7.39e-06
    587    50     2.18e-07     2.18e-07     5.78e-06
    587    60     2.18e-07     2.18e-07     7.07e-06
    587    61     2.47e-06     2.47e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             587 32320.757    0.005     4.64e-07     4.64e-07     8.64e-06
! Validation        587 32320.757    0.005     2.21e-07     2.21e-07     5.29e-06
Wall time: 32320.756715707998
training
# Epoch batch         loss       loss_e      e/N_mae
    588    10     9.93e-07     9.93e-07     1.27e-05
    588    20     1.57e-06     1.57e-06     1.64e-05
    588    30     8.06e-07     8.06e-07     1.26e-05
    588    40     1.04e-06     1.04e-06     1.46e-05
    588    48      4.7e-07      4.7e-07     1.12e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    588    10     1.54e-07     1.54e-07     5.78e-06
    588    20     2.54e-07     2.54e-07      6.1e-06
    588    30     6.13e-08     6.13e-08     4.18e-06
    588    40     2.07e-07     2.07e-07     6.75e-06
    588    50     1.59e-07     1.59e-07     5.78e-06
    588    60     1.84e-07     1.84e-07     5.78e-06
    588    61      2.7e-06      2.7e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             588 32375.751    0.005     7.35e-07     7.35e-07     1.13e-05
! Validation        588 32375.751    0.005      2.2e-07      2.2e-07     5.41e-06
Wall time: 32375.75158375
training
# Epoch batch         loss       loss_e      e/N_mae
    589    10     7.97e-07     7.97e-07     1.33e-05
    589    20     6.24e-07     6.24e-07     1.17e-05
    589    30     3.66e-07     3.66e-07     8.89e-06
    589    40     3.54e-07     3.54e-07     8.03e-06
    589    48     3.86e-07     3.86e-07     9.64e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    589    10     2.28e-07     2.28e-07      6.1e-06
    589    20     1.73e-07     1.73e-07     3.85e-06
    589    30     7.82e-08     7.82e-08     4.82e-06
    589    40     2.75e-07     2.75e-07     8.03e-06
    589    50     1.69e-07     1.69e-07     5.46e-06
    589    60     1.63e-07     1.63e-07     6.42e-06
    589    61     2.43e-06     2.43e-06     1.87e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             589 32430.750    0.005     4.76e-07     4.76e-07     9.01e-06
! Validation        589 32430.750    0.005     2.29e-07     2.29e-07     5.45e-06
Wall time: 32430.751043333
training
# Epoch batch         loss       loss_e      e/N_mae
    590    10     2.62e-07     2.62e-07     6.32e-06
    590    20     3.75e-07     3.75e-07     8.78e-06
    590    30     3.84e-07     3.84e-07      7.5e-06
    590    40     5.65e-07     5.65e-07     1.03e-05
    590    48     4.49e-07     4.49e-07      1.2e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    590    10      1.8e-07      1.8e-07     6.42e-06
    590    20     1.48e-07     1.48e-07     4.18e-06
    590    30     3.38e-08     3.38e-08     2.89e-06
    590    40     1.92e-07     1.92e-07      6.1e-06
    590    50     1.29e-07     1.29e-07     5.14e-06
    590    60     8.03e-08     8.03e-08     3.21e-06
    590    61     2.66e-06     2.66e-06     1.87e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             590 32485.771    0.005     5.59e-07     5.59e-07     9.64e-06
! Validation        590 32485.771    0.005     2.31e-07     2.31e-07     5.54e-06
Wall time: 32485.770780458
training
# Epoch batch         loss       loss_e      e/N_mae
    591    10     2.49e-07     2.49e-07     7.28e-06
    591    20     1.33e-06     1.33e-06     1.48e-05
    591    30     4.85e-07     4.85e-07      9.1e-06
    591    40     1.61e-06     1.61e-06     1.91e-05
    591    48     2.11e-08     2.11e-08     2.41e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    591    10     1.71e-07     1.71e-07     5.14e-06
    591    20     1.61e-07     1.61e-07      6.1e-06
    591    30     1.48e-08     1.48e-08     1.93e-06
    591    40     2.47e-07     2.47e-07     7.71e-06
    591    50     1.63e-07     1.63e-07     5.14e-06
    591    60     5.28e-08     5.28e-08     2.25e-06
    591    61     2.63e-06     2.63e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             591 32541.065    0.005     7.25e-07     7.25e-07     1.13e-05
! Validation        591 32541.065    0.005     2.23e-07     2.23e-07     5.26e-06
Wall time: 32541.066368375
training
# Epoch batch         loss       loss_e      e/N_mae
    592    10     1.35e-06     1.35e-06      1.8e-05
    592    20      2.3e-07      2.3e-07     5.57e-06
    592    30     7.33e-07     7.33e-07     1.07e-05
    592    40     5.88e-07     5.88e-07     9.53e-06
    592    48     5.34e-07     5.34e-07     9.64e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    592    10     2.41e-07     2.41e-07     7.07e-06
    592    20     6.55e-08     6.55e-08     3.53e-06
    592    30     4.65e-08     4.65e-08     3.21e-06
    592    40     2.94e-07     2.94e-07     7.71e-06
    592    50     1.67e-07     1.67e-07     5.14e-06
    592    60     1.29e-07     1.29e-07      4.5e-06
    592    61     2.44e-06     2.44e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             592 32596.171    0.005     6.51e-07     6.51e-07     1.04e-05
! Validation        592 32596.171    0.005     2.27e-07     2.27e-07     5.46e-06
Wall time: 32596.171989415998
training
# Epoch batch         loss       loss_e      e/N_mae
    593    10     8.89e-07     8.89e-07     1.16e-05
    593    20      4.3e-07      4.3e-07     9.74e-06
    593    30     4.54e-07     4.54e-07     9.64e-06
    593    40     3.52e-07     3.52e-07     7.92e-06
    593    48     1.21e-06     1.21e-06     1.37e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    593    10     3.21e-07     3.21e-07     8.35e-06
    593    20     1.23e-07     1.23e-07     4.82e-06
    593    30     8.24e-08     8.24e-08      4.5e-06
    593    40     2.49e-07     2.49e-07     7.71e-06
    593    50     1.39e-07     1.39e-07     5.46e-06
    593    60     1.46e-07     1.46e-07     4.82e-06
    593    61      2.1e-06      2.1e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             593 32651.285    0.005     8.58e-07     8.58e-07     1.21e-05
! Validation        593 32651.285    0.005     2.32e-07     2.32e-07     5.57e-06
Wall time: 32651.286184833
training
# Epoch batch         loss       loss_e      e/N_mae
    594    10      9.5e-07      9.5e-07     1.17e-05
    594    20     6.45e-07     6.45e-07     1.06e-05
    594    30     3.85e-06     3.85e-06     2.71e-05
    594    40     2.11e-06     2.11e-06     1.95e-05
    594    48     5.16e-06     5.16e-06     3.77e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    594    10     4.21e-07     4.21e-07     8.99e-06
    594    20      9.3e-08      9.3e-08     3.85e-06
    594    30     2.75e-08     2.75e-08     2.57e-06
    594    40     1.59e-07     1.59e-07     5.46e-06
    594    50      3.8e-08      3.8e-08     2.89e-06
    594    60     1.06e-07     1.06e-07      4.5e-06
    594    61      2.1e-06      2.1e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             594 32706.486    0.005     2.08e-06     2.08e-06     1.81e-05
! Validation        594 32706.486    0.005     2.42e-07     2.42e-07     5.85e-06
Wall time: 32706.487426124997
training
# Epoch batch         loss       loss_e      e/N_mae
    595    10     3.45e-06     3.45e-06     2.54e-05
    595    20     1.21e-06     1.21e-06     1.62e-05
    595    30     1.13e-06     1.13e-06     1.48e-05
    595    40     5.71e-07     5.71e-07     1.01e-05
    595    48     2.94e-06     2.94e-06     2.81e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    595    10        3e-07        3e-07     7.71e-06
    595    20     1.61e-07     1.61e-07     5.46e-06
    595    30     1.18e-07     1.18e-07      4.5e-06
    595    40     2.28e-07     2.28e-07     5.46e-06
    595    50     1.18e-07     1.18e-07     4.18e-06
    595    60     1.18e-07     1.18e-07      4.5e-06
    595    61     2.52e-06     2.52e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             595 32761.346    0.005     2.34e-06     2.34e-06        2e-05
! Validation        595 32761.346    0.005     2.98e-07     2.98e-07     6.49e-06
Wall time: 32761.346624415997
training
# Epoch batch         loss       loss_e      e/N_mae
    596    10     4.59e-06     4.59e-06     2.55e-05
    596    20     1.98e-06     1.98e-06      1.8e-05
    596    30     3.71e-06     3.71e-06     2.84e-05
    596    40     3.08e-06     3.08e-06     2.35e-05
    596    48      5.6e-07      5.6e-07      1.2e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    596    10     2.41e-07     2.41e-07      6.1e-06
    596    20      3.7e-07      3.7e-07     7.71e-06
    596    30     1.78e-07     1.78e-07     6.42e-06
    596    40     1.48e-07     1.48e-07     5.14e-06
    596    50      1.8e-07      1.8e-07     5.14e-06
    596    60     1.69e-08     1.69e-08     1.93e-06
    596    61     2.22e-06     2.22e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             596 32816.609    0.005     4.05e-06     4.05e-06     2.68e-05
! Validation        596 32816.609    0.005     2.68e-07     2.68e-07     6.12e-06
Wall time: 32816.610252291
training
# Epoch batch         loss       loss_e      e/N_mae
    597    10     1.57e-06     1.57e-06     1.78e-05
    597    20     9.17e-07     9.17e-07     1.27e-05
    597    30     7.03e-07     7.03e-07     1.01e-05
    597    40     1.68e-06     1.68e-06     1.65e-05
    597    48      4.4e-06      4.4e-06     3.37e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    597    10     1.35e-07     1.35e-07      4.5e-06
    597    20     6.15e-07     6.15e-07     9.96e-06
    597    30     1.94e-07     1.94e-07     4.82e-06
    597    40     2.07e-07     2.07e-07     6.42e-06
    597    50     2.66e-07     2.66e-07     7.07e-06
    597    60     9.09e-08     9.09e-08     4.18e-06
    597    61     2.63e-06     2.63e-06     2.03e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             597 32871.723    0.005     2.41e-06     2.41e-06     1.94e-05
! Validation        597 32871.723    0.005     2.92e-07     2.92e-07     6.59e-06
Wall time: 32871.723683875
training
# Epoch batch         loss       loss_e      e/N_mae
    598    10     2.07e-06     2.07e-06     1.99e-05
    598    20     6.27e-06     6.27e-06     3.19e-05
    598    30     1.37e-06     1.37e-06     1.42e-05
    598    40     2.61e-06     2.61e-06     2.01e-05
    598    48     2.17e-07     2.17e-07     8.03e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    598    10     7.82e-08     7.82e-08     4.82e-06
    598    20     7.93e-07     7.93e-07     1.22e-05
    598    30     2.66e-07     2.66e-07     7.07e-06
    598    40     2.41e-07     2.41e-07     7.39e-06
    598    50     2.94e-07     2.94e-07     7.39e-06
    598    60     1.29e-07     1.29e-07     5.46e-06
    598    61     2.81e-06     2.81e-06     2.09e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             598 32926.835    0.005     3.62e-06     3.62e-06     2.51e-05
! Validation        598 32926.835    0.005     3.37e-07     3.37e-07     7.15e-06
Wall time: 32926.835436541005
training
# Epoch batch         loss       loss_e      e/N_mae
    599    10     1.39e-06     1.39e-06     1.62e-05
    599    20     1.15e-06     1.15e-06     1.45e-05
    599    30     2.24e-06     2.24e-06     2.09e-05
    599    40     2.15e-06     2.15e-06      1.9e-05
    599    48     1.24e-06     1.24e-06     1.53e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    599    10      2.2e-07      2.2e-07     6.75e-06
    599    20     4.12e-07     4.12e-07     7.71e-06
    599    30     2.98e-07     2.98e-07     6.75e-06
    599    40     1.65e-07     1.65e-07     5.46e-06
    599    50     2.62e-07     2.62e-07     7.07e-06
    599    60     1.33e-07     1.33e-07     4.18e-06
    599    61     2.67e-06     2.67e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             599 32981.921    0.005     2.55e-06     2.55e-06     2.09e-05
! Validation        599 32981.921    0.005     2.88e-07     2.88e-07     6.39e-06
Wall time: 32981.920736541004
training
# Epoch batch         loss       loss_e      e/N_mae
    600    10     6.08e-07     6.08e-07     1.07e-05
    600    20     8.02e-07     8.02e-07     1.34e-05
    600    30     1.56e-06     1.56e-06     1.61e-05
    600    40     7.83e-07     7.83e-07     1.18e-05
    600    48     1.27e-06     1.27e-06     1.61e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    600    10     2.03e-07     2.03e-07     7.07e-06
    600    20     2.81e-07     2.81e-07     7.39e-06
    600    30     2.01e-07     2.01e-07     5.78e-06
    600    40     1.46e-07     1.46e-07     5.14e-06
    600    50     2.07e-07     2.07e-07     4.82e-06
    600    60     8.88e-08     8.88e-08     3.21e-06
    600    61     2.81e-06     2.81e-06     2.09e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             600 33037.002    0.005     1.58e-06     1.58e-06     1.61e-05
! Validation        600 33037.002    0.005     2.95e-07     2.95e-07     6.54e-06
Wall time: 33037.002552666
training
# Epoch batch         loss       loss_e      e/N_mae
    601    10      1.5e-06      1.5e-06     1.63e-05
    601    20     2.67e-06     2.67e-06      2.2e-05
    601    30     1.13e-06     1.13e-06     1.24e-05
    601    40        7e-07        7e-07     1.07e-05
    601    48     5.34e-07     5.34e-07     9.64e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    601    10     2.66e-07     2.66e-07     8.35e-06
    601    20     2.16e-07     2.16e-07     5.78e-06
    601    30     1.73e-07     1.73e-07     5.46e-06
    601    40     1.78e-07     1.78e-07     6.42e-06
    601    50     3.11e-07     3.11e-07     6.75e-06
    601    60     9.51e-08     9.51e-08     4.18e-06
    601    61     3.19e-06     3.19e-06     2.14e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             601 33091.908    0.005     1.38e-06     1.38e-06      1.5e-05
! Validation        601 33091.908    0.005     2.75e-07     2.75e-07     6.17e-06
Wall time: 33091.909395333
training
# Epoch batch         loss       loss_e      e/N_mae
    602    10     7.28e-07     7.28e-07     1.16e-05
    602    20     2.04e-07     2.04e-07     5.57e-06
    602    30     4.68e-07     4.68e-07     9.96e-06
    602    40      4.3e-07      4.3e-07     7.39e-06
    602    48     2.11e-07     2.11e-07     7.23e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    602    10     3.11e-07     3.11e-07     7.39e-06
    602    20     2.81e-07     2.81e-07     6.75e-06
    602    30     4.23e-08     4.23e-08     3.53e-06
    602    40     4.86e-08     4.86e-08     2.89e-06
    602    50      1.9e-07      1.9e-07     5.46e-06
    602    60     8.88e-08     8.88e-08     3.21e-06
    602    61     3.52e-06     3.52e-06      2.3e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             602 33146.994    0.005     6.28e-07     6.28e-07     1.04e-05
! Validation        602 33146.994    0.005     2.67e-07     2.67e-07     6.02e-06
Wall time: 33146.993971583004
training
# Epoch batch         loss       loss_e      e/N_mae
    603    10     9.07e-07     9.07e-07     1.26e-05
    603    20     7.53e-07     7.53e-07     1.28e-05
    603    30      7.1e-07      7.1e-07     1.19e-05
    603    40      3.8e-07      3.8e-07     8.67e-06
    603    48     5.76e-07     5.76e-07     1.04e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    603    10     2.71e-07     2.71e-07     5.78e-06
    603    20     1.31e-07     1.31e-07     5.78e-06
    603    30     1.25e-07     1.25e-07     5.46e-06
    603    40      1.1e-07      1.1e-07      4.5e-06
    603    50     2.09e-07     2.09e-07     6.42e-06
    603    60      9.3e-08      9.3e-08     4.18e-06
    603    61     2.99e-06     2.99e-06     2.14e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             603 33202.191    0.005      5.3e-07      5.3e-07     9.44e-06
! Validation        603 33202.191    0.005     2.57e-07     2.57e-07     6.05e-06
Wall time: 33202.191925583
training
# Epoch batch         loss       loss_e      e/N_mae
    604    10     6.35e-07     6.35e-07     1.06e-05
    604    20     6.59e-07     6.59e-07     9.96e-06
    604    30     5.35e-07     5.35e-07     1.11e-05
    604    40     2.59e-07     2.59e-07     7.71e-06
    604    48     2.11e-07     2.11e-07     6.42e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    604    10     1.99e-07     1.99e-07      6.1e-06
    604    20     1.29e-07     1.29e-07     5.46e-06
    604    30      9.3e-08      9.3e-08     3.53e-06
    604    40     1.16e-07     1.16e-07     4.82e-06
    604    50     1.46e-07     1.46e-07     5.78e-06
    604    60     5.92e-08     5.92e-08     3.53e-06
    604    61     2.74e-06     2.74e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             604 33257.118    0.005     5.18e-07     5.18e-07     9.44e-06
! Validation        604 33257.118    0.005     2.49e-07     2.49e-07     5.92e-06
Wall time: 33257.119067166
training
# Epoch batch         loss       loss_e      e/N_mae
    605    10     8.57e-07     8.57e-07     1.24e-05
    605    20     3.91e-07     3.91e-07     8.14e-06
    605    30     7.65e-07     7.65e-07     1.23e-05
    605    40     1.04e-06     1.04e-06     1.06e-05
    605    48     1.37e-07     1.37e-07     4.82e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    605    10     1.65e-07     1.65e-07     4.82e-06
    605    20     1.04e-07     1.04e-07      4.5e-06
    605    30     9.51e-08     9.51e-08     3.85e-06
    605    40     2.16e-07     2.16e-07     6.42e-06
    605    50     2.98e-07     2.98e-07     7.71e-06
    605    60     2.96e-08     2.96e-08     2.25e-06
    605    61     2.44e-06     2.44e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             605 33312.299    0.005     1.02e-06     1.02e-06     1.22e-05
! Validation        605 33312.299    0.005     2.42e-07     2.42e-07     5.72e-06
Wall time: 33312.298838083
training
# Epoch batch         loss       loss_e      e/N_mae
    606    10      1.3e-06      1.3e-06     1.51e-05
    606    20      1.2e-06      1.2e-06     1.57e-05
    606    30     1.54e-06     1.54e-06     1.38e-05
    606    40     1.09e-06     1.09e-06     1.43e-05
    606    48     6.13e-07     6.13e-07     1.12e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    606    10     2.39e-07     2.39e-07     4.82e-06
    606    20     1.99e-07     1.99e-07     6.75e-06
    606    30     1.29e-07     1.29e-07     4.82e-06
    606    40     2.18e-07     2.18e-07     6.42e-06
    606    50     2.18e-07     2.18e-07     5.78e-06
    606    60     4.65e-08     4.65e-08     3.53e-06
    606    61     2.51e-06     2.51e-06     1.87e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             606 33367.230    0.005     1.49e-06     1.49e-06     1.62e-05
! Validation        606 33367.230    0.005     2.51e-07     2.51e-07     5.82e-06
Wall time: 33367.231074250005
training
# Epoch batch         loss       loss_e      e/N_mae
    607    10     8.41e-07     8.41e-07     1.22e-05
    607    20     2.47e-06     2.47e-06     1.68e-05
    607    30     1.45e-06     1.45e-06     1.56e-05
    607    40     1.34e-06     1.34e-06      1.6e-05
    607    48     3.06e-07     3.06e-07     8.83e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    607    10     2.49e-07     2.49e-07     5.14e-06
    607    20     1.63e-07     1.63e-07     4.82e-06
    607    30     1.65e-07     1.65e-07     4.82e-06
    607    40      2.6e-07      2.6e-07     6.42e-06
    607    50     2.24e-07     2.24e-07      6.1e-06
    607    60     1.27e-08     1.27e-08     1.61e-06
    607    61     3.05e-06     3.05e-06      2.2e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             607 33422.404    0.005     1.23e-06     1.23e-06     1.44e-05
! Validation        607 33422.404    0.005     2.74e-07     2.74e-07     5.94e-06
Wall time: 33422.405378958
training
# Epoch batch         loss       loss_e      e/N_mae
    608    10     4.85e-07     4.85e-07     8.99e-06
    608    20     1.75e-06     1.75e-06     1.78e-05
    608    30     6.42e-07     6.42e-07     1.02e-05
    608    40     4.02e-07     4.02e-07     8.35e-06
    608    48     2.64e-07     2.64e-07     7.23e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    608    10      1.9e-07      1.9e-07      6.1e-06
    608    20     1.78e-07     1.78e-07      6.1e-06
    608    30     1.33e-07     1.33e-07      6.1e-06
    608    40     2.51e-07     2.51e-07     5.46e-06
    608    50     4.23e-07     4.23e-07     5.46e-06
    608    60     6.34e-08     6.34e-08     3.53e-06
    608    61     2.48e-06     2.48e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             608 33477.516    0.005     1.08e-06     1.08e-06     1.32e-05
! Validation        608 33477.516    0.005     2.63e-07     2.63e-07     6.11e-06
Wall time: 33477.516872625005
training
# Epoch batch         loss       loss_e      e/N_mae
    609    10     8.76e-07     8.76e-07     1.17e-05
    609    20     1.41e-06     1.41e-06     1.53e-05
    609    30     4.02e-07     4.02e-07     8.35e-06
    609    40      5.2e-07      5.2e-07     9.21e-06
    609    48     2.17e-07     2.17e-07     7.23e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    609    10     3.25e-07     3.25e-07     8.35e-06
    609    20     1.54e-07     1.54e-07     4.82e-06
    609    30     8.24e-08     8.24e-08      4.5e-06
    609    40     3.28e-07     3.28e-07      6.1e-06
    609    50     2.18e-07     2.18e-07      4.5e-06
    609    60     1.16e-07     1.16e-07     5.14e-06
    609    61     2.93e-06     2.93e-06     2.25e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             609 33532.660    0.005     6.75e-07     6.75e-07     1.07e-05
! Validation        609 33532.660    0.005     2.47e-07     2.47e-07     5.72e-06
Wall time: 33532.66084825
training
# Epoch batch         loss       loss_e      e/N_mae
    610    10     5.57e-07     5.57e-07     9.53e-06
    610    20     5.14e-07     5.14e-07     9.85e-06
    610    30     3.04e-07     3.04e-07     7.39e-06
    610    40     3.67e-07     3.67e-07     8.03e-06
    610    48     6.18e-07     6.18e-07     1.28e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    610    10     3.59e-07     3.59e-07     8.03e-06
    610    20     1.92e-07     1.92e-07     5.14e-06
    610    30     1.29e-07     1.29e-07     5.46e-06
    610    40     2.43e-07     2.43e-07     6.42e-06
    610    50     1.42e-07     1.42e-07     3.85e-06
    610    60     7.19e-08     7.19e-08     3.53e-06
    610    61     3.12e-06     3.12e-06     2.25e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             610 33587.675    0.005     4.51e-07     4.51e-07     8.68e-06
! Validation        610 33587.675    0.005      2.6e-07      2.6e-07     5.87e-06
Wall time: 33587.676746083
training
# Epoch batch         loss       loss_e      e/N_mae
    611    10      4.5e-07      4.5e-07     8.46e-06
    611    20     3.76e-07     3.76e-07     7.92e-06
    611    30      1.4e-07      1.4e-07     5.25e-06
    611    40     3.51e-07     3.51e-07     8.46e-06
    611    48     4.23e-08     4.23e-08     4.02e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    611    10     2.62e-07     2.62e-07     6.75e-06
    611    20     2.43e-07     2.43e-07     7.07e-06
    611    30      9.3e-08      9.3e-08     4.18e-06
    611    40     2.45e-07     2.45e-07     6.75e-06
    611    50     1.46e-07     1.46e-07     3.85e-06
    611    60     1.65e-07     1.65e-07      6.1e-06
    611    61     3.22e-06     3.22e-06     2.36e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             611 33642.555    0.005     3.38e-07     3.38e-07     7.41e-06
! Validation        611 33642.555    0.005     2.48e-07     2.48e-07     5.78e-06
Wall time: 33642.556677291
training
# Epoch batch         loss       loss_e      e/N_mae
    612    10     3.43e-07     3.43e-07     8.67e-06
    612    20     1.76e-07     1.76e-07     5.57e-06
    612    30     1.87e-07     1.87e-07     5.89e-06
    612    40     2.09e-07     2.09e-07        6e-06
    612    48     4.23e-08     4.23e-08     4.02e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    612    10     1.67e-07     1.67e-07     5.78e-06
    612    20      2.2e-07      2.2e-07      6.1e-06
    612    30     8.03e-08     8.03e-08     4.18e-06
    612    40     9.09e-08     9.09e-08      4.5e-06
    612    50     2.22e-07     2.22e-07      4.5e-06
    612    60     9.72e-08     9.72e-08     4.82e-06
    612    61     2.74e-06     2.74e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             612 33697.711    0.005     2.56e-07     2.56e-07     6.73e-06
! Validation        612 33697.711    0.005     2.23e-07     2.23e-07      5.3e-06
Wall time: 33697.711503666
training
# Epoch batch         loss       loss_e      e/N_mae
    613    10     1.08e-07     1.08e-07     4.82e-06
    613    20     1.22e-06     1.22e-06     1.33e-05
    613    30     9.57e-07     9.57e-07     1.41e-05
    613    40     7.05e-07     7.05e-07     1.11e-05
    613    48     2.88e-06     2.88e-06     2.81e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    613    10     3.04e-07     3.04e-07     7.39e-06
    613    20     2.32e-07     2.32e-07     5.46e-06
    613    30     1.01e-07     1.01e-07     4.82e-06
    613    40     3.19e-07     3.19e-07     7.71e-06
    613    50     1.27e-07     1.27e-07     4.18e-06
    613    60     1.73e-07     1.73e-07      6.1e-06
    613    61     3.52e-06     3.52e-06      2.2e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             613 33752.718    0.005     8.79e-07     8.79e-07     1.14e-05
! Validation        613 33752.718    0.005     2.44e-07     2.44e-07     5.54e-06
Wall time: 33752.719422083
training
# Epoch batch         loss       loss_e      e/N_mae
    614    10     9.79e-07     9.79e-07     1.24e-05
    614    20      8.1e-07      8.1e-07      1.4e-05
    614    30     2.22e-06     2.22e-06     2.03e-05
    614    40     1.38e-06     1.38e-06     1.52e-05
    614    48     6.13e-06     6.13e-06      4.1e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    614    10     4.67e-07     4.67e-07     9.64e-06
    614    20     2.28e-07     2.28e-07     4.82e-06
    614    30     4.65e-08     4.65e-08     2.89e-06
    614    40     2.66e-07     2.66e-07     7.39e-06
    614    50     2.62e-07     2.62e-07     6.75e-06
    614    60     7.82e-08     7.82e-08     4.82e-06
    614    61     3.51e-06     3.51e-06     2.52e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             614 33807.882    0.005     1.79e-06     1.79e-06     1.68e-05
! Validation        614 33807.882    0.005     2.68e-07     2.68e-07     5.86e-06
Wall time: 33807.883158333
training
# Epoch batch         loss       loss_e      e/N_mae
    615    10     2.87e-06     2.87e-06     2.24e-05
    615    20     2.67e-06     2.67e-06     2.21e-05
    615    30     3.58e-06     3.58e-06     2.86e-05
    615    40     1.71e-06     1.71e-06      1.5e-05
    615    48     2.75e-07     2.75e-07     8.83e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    615    10     4.99e-07     4.99e-07     9.32e-06
    615    20     4.14e-07     4.14e-07     7.39e-06
    615    30     1.23e-07     1.23e-07     4.18e-06
    615    40     2.54e-07     2.54e-07     7.39e-06
    615    50     1.35e-07     1.35e-07     5.46e-06
    615    60     9.93e-08     9.93e-08      4.5e-06
    615    61     4.15e-06     4.15e-06     2.73e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             615 33863.136    0.005     3.37e-06     3.37e-06      2.4e-05
! Validation        615 33863.136    0.005     3.29e-07     3.29e-07     6.39e-06
Wall time: 33863.137080625005
training
# Epoch batch         loss       loss_e      e/N_mae
    616    10     5.98e-07     5.98e-07     1.01e-05
    616    20     8.29e-07     8.29e-07     1.16e-05
    616    30     8.38e-07     8.38e-07     1.25e-05
    616    40     5.02e-07     5.02e-07     9.74e-06
    616    48     6.18e-07     6.18e-07     1.28e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    616    10     4.02e-07     4.02e-07     9.32e-06
    616    20     4.14e-07     4.14e-07     8.03e-06
    616    30     5.92e-08     5.92e-08     3.85e-06
    616    40     2.49e-07     2.49e-07     6.75e-06
    616    50     7.82e-08     7.82e-08      4.5e-06
    616    60     7.19e-08     7.19e-08     3.85e-06
    616    61     4.36e-06     4.36e-06     2.68e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             616 33917.991    0.005     6.95e-07     6.95e-07     1.09e-05
! Validation        616 33917.991    0.005     3.28e-07     3.28e-07     6.39e-06
Wall time: 33917.991502083
training
# Epoch batch         loss       loss_e      e/N_mae
    617    10     6.63e-07     6.63e-07     1.01e-05
    617    20     5.99e-07     5.99e-07     9.74e-06
    617    30      1.1e-06      1.1e-06     1.43e-05
    617    40     8.16e-07     8.16e-07     9.64e-06
    617    48     2.64e-08     2.64e-08     2.41e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    617    10     2.41e-07     2.41e-07     6.75e-06
    617    20     2.98e-07     2.98e-07     6.75e-06
    617    30     2.13e-07     2.13e-07     6.75e-06
    617    40     2.77e-07     2.77e-07     6.75e-06
    617    50     7.19e-08     7.19e-08     4.18e-06
    617    60     2.32e-08     2.32e-08     2.57e-06
    617    61     3.75e-06     3.75e-06     2.46e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             617 33973.204    0.005     1.28e-06     1.28e-06     1.48e-05
! Validation        617 33973.204    0.005     2.87e-07     2.87e-07     5.93e-06
Wall time: 33973.204254166005
training
# Epoch batch         loss       loss_e      e/N_mae
    618    10      2.6e-06      2.6e-06     2.31e-05
    618    20     4.37e-07     4.37e-07     7.71e-06
    618    30     5.84e-07     5.84e-07     1.08e-05
    618    40     2.71e-07     2.71e-07     7.39e-06
    618    48     3.22e-07     3.22e-07     9.64e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    618    10     1.65e-07     1.65e-07      6.1e-06
    618    20     2.01e-07     2.01e-07     5.78e-06
    618    30     1.35e-07     1.35e-07     5.14e-06
    618    40      2.2e-07      2.2e-07     6.42e-06
    618    50     8.45e-08     8.45e-08     4.18e-06
    618    60     4.86e-08     4.86e-08     3.21e-06
    618    61     3.62e-06     3.62e-06     2.36e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             618 34028.106    0.005     8.74e-07     8.74e-07     1.24e-05
! Validation        618 34028.106    0.005     2.76e-07     2.76e-07     6.06e-06
Wall time: 34028.106535625004
training
# Epoch batch         loss       loss_e      e/N_mae
    619    10     7.02e-07     7.02e-07     1.24e-05
    619    20      3.2e-07      3.2e-07     7.92e-06
    619    30     1.94e-07     1.94e-07     6.53e-06
    619    40     4.83e-07     4.83e-07     9.96e-06
    619    48     5.34e-07     5.34e-07     9.64e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    619    10      1.9e-07      1.9e-07     6.75e-06
    619    20     1.61e-07     1.61e-07     5.14e-06
    619    30     5.28e-08     5.28e-08     3.53e-06
    619    40      2.3e-07      2.3e-07     7.07e-06
    619    50     1.12e-07     1.12e-07     5.14e-06
    619    60     1.67e-07     1.67e-07     5.78e-06
    619    61      3.4e-06      3.4e-06     2.25e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             619 34083.198    0.005     4.16e-07     4.16e-07     8.21e-06
! Validation        619 34083.198    0.005      2.7e-07      2.7e-07     5.89e-06
Wall time: 34083.19939775
training
# Epoch batch         loss       loss_e      e/N_mae
    620    10     3.87e-07     3.87e-07     8.03e-06
    620    20     3.43e-07     3.43e-07     7.28e-06
    620    30     1.53e-07     1.53e-07     5.25e-06
    620    40     1.82e-07     1.82e-07     6.85e-06
    620    48      4.7e-07      4.7e-07     1.04e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    620    10     1.54e-07     1.54e-07     5.46e-06
    620    20     2.43e-07     2.43e-07      6.1e-06
    620    30     5.71e-08     5.71e-08     3.21e-06
    620    40     3.02e-07     3.02e-07     8.35e-06
    620    50     1.16e-07     1.16e-07      4.5e-06
    620    60     5.07e-08     5.07e-08     3.53e-06
    620    61     3.02e-06     3.02e-06      2.3e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             620 34138.326    0.005     3.71e-07     3.71e-07      7.8e-06
! Validation        620 34138.326    0.005     2.45e-07     2.45e-07     5.66e-06
Wall time: 34138.32641875
training
# Epoch batch         loss       loss_e      e/N_mae
    621    10     1.13e-06     1.13e-06     1.37e-05
    621    20     8.76e-07     8.76e-07     1.12e-05
    621    30     2.44e-06     2.44e-06     2.24e-05
    621    40     5.01e-07     5.01e-07     8.14e-06
    621    48     5.28e-08     5.28e-08     4.02e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    621    10     1.42e-07     1.42e-07     5.14e-06
    621    20     1.67e-07     1.67e-07     5.46e-06
    621    30     6.55e-08     6.55e-08     3.85e-06
    621    40     1.67e-07     1.67e-07     6.42e-06
    621    50     1.61e-07     1.61e-07     5.46e-06
    621    60     9.09e-08     9.09e-08     4.82e-06
    621    61      3.5e-06      3.5e-06     2.25e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             621 34193.344    0.005     1.03e-06     1.03e-06     1.32e-05
! Validation        621 34193.344    0.005     2.53e-07     2.53e-07     5.69e-06
Wall time: 34193.344904958
training
# Epoch batch         loss       loss_e      e/N_mae
    622    10     5.47e-07     5.47e-07     1.09e-05
    622    20     1.41e-06     1.41e-06     1.71e-05
    622    30     7.07e-07     7.07e-07     1.26e-05
    622    40     6.33e-07     6.33e-07     1.01e-05
    622    48     7.82e-07     7.82e-07      1.2e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    622    10     2.26e-07     2.26e-07     5.46e-06
    622    20     1.39e-07     1.39e-07     5.78e-06
    622    30     5.49e-08     5.49e-08     3.53e-06
    622    40     2.54e-07     2.54e-07     6.75e-06
    622    50     1.27e-07     1.27e-07     4.82e-06
    622    60     1.48e-08     1.48e-08     1.93e-06
    622    61     3.54e-06     3.54e-06     2.52e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             622 34248.393    0.005     1.12e-06     1.12e-06     1.36e-05
! Validation        622 34248.393    0.005     2.69e-07     2.69e-07     5.71e-06
Wall time: 34248.393739125
training
# Epoch batch         loss       loss_e      e/N_mae
    623    10     4.38e-07     4.38e-07     8.35e-06
    623    20     5.45e-07     5.45e-07     1.06e-05
    623    30     4.57e-07     4.57e-07      9.1e-06
    623    40     1.75e-07     1.75e-07     5.57e-06
    623    48     4.23e-07     4.23e-07     1.04e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    623    10      1.5e-07      1.5e-07     4.18e-06
    623    20     2.56e-07     2.56e-07     5.78e-06
    623    30     1.25e-07     1.25e-07     5.78e-06
    623    40     2.79e-07     2.79e-07     7.39e-06
    623    50     1.42e-07     1.42e-07     5.78e-06
    623    60     4.02e-08     4.02e-08     3.21e-06
    623    61     3.35e-06     3.35e-06     2.41e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             623 34303.695    0.005     5.74e-07     5.74e-07     9.84e-06
! Validation        623 34303.695    0.005      2.8e-07      2.8e-07     5.96e-06
Wall time: 34303.69623575
training
# Epoch batch         loss       loss_e      e/N_mae
    624    10      3.3e-07      3.3e-07     8.35e-06
    624    20     2.59e-07     2.59e-07     6.42e-06
    624    30     5.09e-07     5.09e-07     7.82e-06
    624    40     4.82e-07     4.82e-07     9.32e-06
    624    48     2.64e-07     2.64e-07     6.42e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    624    10     2.98e-07     2.98e-07     6.42e-06
    624    20     2.64e-07     2.64e-07     4.82e-06
    624    30     6.55e-08     6.55e-08     4.18e-06
    624    40      2.6e-07      2.6e-07     6.42e-06
    624    50     3.42e-07     3.42e-07     9.32e-06
    624    60     9.93e-08     9.93e-08     3.85e-06
    624    61     3.08e-06     3.08e-06      2.3e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             624 34358.629    0.005     4.45e-07     4.45e-07     8.53e-06
! Validation        624 34358.629    0.005     2.65e-07     2.65e-07     5.81e-06
Wall time: 34358.629603875
training
# Epoch batch         loss       loss_e      e/N_mae
    625    10     6.52e-07     6.52e-07     1.12e-05
    625    20     4.03e-07     4.03e-07     9.21e-06
    625    30     2.21e-07     2.21e-07     6.21e-06
    625    40     2.22e-07     2.22e-07     5.89e-06
    625    48     1.06e-07     1.06e-07     4.82e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    625    10     4.21e-07     4.21e-07     8.35e-06
    625    20     1.99e-07     1.99e-07     5.78e-06
    625    30     8.24e-08     8.24e-08     4.82e-06
    625    40      1.9e-07      1.9e-07      6.1e-06
    625    50     2.01e-07     2.01e-07     7.07e-06
    625    60     7.19e-08     7.19e-08     3.21e-06
    625    61     2.95e-06     2.95e-06     2.14e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             625 34413.805    0.005     3.67e-07     3.67e-07     7.98e-06
! Validation        625 34413.805    0.005     2.48e-07     2.48e-07     5.45e-06
Wall time: 34413.805352375
training
# Epoch batch         loss       loss_e      e/N_mae
    626    10     8.31e-07     8.31e-07     1.23e-05
    626    20     1.43e-06     1.43e-06     1.58e-05
    626    30        1e-06        1e-06     1.23e-05
    626    40     1.78e-06     1.78e-06     1.68e-05
    626    48     7.71e-07     7.71e-07     1.28e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    626    10     2.85e-07     2.85e-07     7.39e-06
    626    20      1.9e-07      1.9e-07     5.46e-06
    626    30     7.19e-08     7.19e-08     4.82e-06
    626    40     2.09e-07     2.09e-07     5.78e-06
    626    50     1.12e-07     1.12e-07     5.14e-06
    626    60     6.76e-08     6.76e-08     3.21e-06
    626    61     2.67e-06     2.67e-06     2.03e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             626 34468.903    0.005     6.68e-07     6.68e-07     1.02e-05
! Validation        626 34468.903    0.005     2.38e-07     2.38e-07     5.54e-06
Wall time: 34468.903982083
training
# Epoch batch         loss       loss_e      e/N_mae
    627    10      3.9e-07      3.9e-07     8.25e-06
    627    20     8.17e-07     8.17e-07     1.17e-05
    627    30     4.67e-07     4.67e-07     9.96e-06
    627    40     1.37e-07     1.37e-07     3.85e-06
    627    48     4.23e-08     4.23e-08     4.02e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    627    10     3.17e-07     3.17e-07     7.71e-06
    627    20     1.75e-07     1.75e-07      4.5e-06
    627    30     9.72e-08     9.72e-08     5.14e-06
    627    40     2.58e-07     2.58e-07     7.39e-06
    627    50     1.73e-07     1.73e-07      6.1e-06
    627    60     4.23e-08     4.23e-08     2.57e-06
    627    61     2.25e-06     2.25e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             627 34523.922    0.005     6.22e-07     6.22e-07     1.02e-05
! Validation        627 34523.922    0.005      2.3e-07      2.3e-07     5.44e-06
Wall time: 34523.923130541
training
# Epoch batch         loss       loss_e      e/N_mae
    628    10     6.69e-07     6.69e-07     1.09e-05
    628    20     7.24e-07     7.24e-07     1.24e-05
    628    30     5.49e-07     5.49e-07     1.14e-05
    628    40     3.87e-07     3.87e-07     8.14e-06
    628    48     8.45e-08     8.45e-08     3.21e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    628    10     4.56e-07     4.56e-07     6.75e-06
    628    20     2.11e-07     2.11e-07     6.42e-06
    628    30     4.65e-08     4.65e-08     3.85e-06
    628    40     2.41e-07     2.41e-07     6.75e-06
    628    50     1.31e-07     1.31e-07     5.46e-06
    628    60     5.71e-08     5.71e-08     2.89e-06
    628    61     2.97e-06     2.97e-06      2.2e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             628 34579.105    0.005     4.63e-07     4.63e-07     8.79e-06
! Validation        628 34579.105    0.005     2.38e-07     2.38e-07      5.4e-06
Wall time: 34579.105698541
training
# Epoch batch         loss       loss_e      e/N_mae
    629    10      2.4e-07      2.4e-07     6.53e-06
    629    20     2.45e-07     2.45e-07     6.32e-06
    629    30     2.85e-07     2.85e-07     7.07e-06
    629    40     2.13e-07     2.13e-07     6.21e-06
    629    48     8.98e-08     8.98e-08     4.02e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    629    10     3.34e-07     3.34e-07     7.39e-06
    629    20     2.92e-07     2.92e-07     7.39e-06
    629    30     1.12e-07     1.12e-07     5.46e-06
    629    40     2.58e-07     2.58e-07     7.39e-06
    629    50     6.55e-08     6.55e-08     3.85e-06
    629    60     8.24e-08     8.24e-08     3.85e-06
    629    61      3.2e-06      3.2e-06     2.25e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             629 34634.346    0.005     3.66e-07     3.66e-07     7.81e-06
! Validation        629 34634.346    0.005     2.36e-07     2.36e-07     5.48e-06
Wall time: 34634.34728675
training
# Epoch batch         loss       loss_e      e/N_mae
    630    10     4.54e-07     4.54e-07     8.57e-06
    630    20     2.61e-07     2.61e-07     6.96e-06
    630    30     2.63e-07     2.63e-07     6.75e-06
    630    40     9.67e-07     9.67e-07     1.26e-05
    630    48     2.17e-07     2.17e-07     7.23e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    630    10     3.25e-07     3.25e-07     7.39e-06
    630    20     2.32e-07     2.32e-07     6.75e-06
    630    30     6.55e-08     6.55e-08     4.18e-06
    630    40     2.01e-07     2.01e-07     7.07e-06
    630    50     1.18e-07     1.18e-07     4.82e-06
    630    60     4.65e-08     4.65e-08     3.53e-06
    630    61     2.57e-06     2.57e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             630 34689.442    0.005     4.92e-07     4.92e-07     9.28e-06
! Validation        630 34689.442    0.005     2.21e-07     2.21e-07     5.41e-06
Wall time: 34689.443342416
training
# Epoch batch         loss       loss_e      e/N_mae
    631    10     3.64e-07     3.64e-07     8.03e-06
    631    20     2.26e-07     2.26e-07     6.64e-06
    631    30     4.35e-07     4.35e-07     8.99e-06
    631    40     3.35e-07     3.35e-07     7.28e-06
    631    48      5.6e-07      5.6e-07      1.2e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    631    10     2.96e-07     2.96e-07     5.78e-06
    631    20     1.92e-07     1.92e-07     5.14e-06
    631    30     1.23e-07     1.23e-07     4.82e-06
    631    40     1.65e-07     1.65e-07      6.1e-06
    631    50     8.45e-08     8.45e-08     4.18e-06
    631    60     4.23e-08     4.23e-08     2.89e-06
    631    61      2.5e-06      2.5e-06     2.03e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             631 34744.432    0.005     5.03e-07     5.03e-07     9.29e-06
! Validation        631 34744.432    0.005      2.3e-07      2.3e-07     5.56e-06
Wall time: 34744.433205458
training
# Epoch batch         loss       loss_e      e/N_mae
    632    10     3.45e-07     3.45e-07     7.82e-06
    632    20     3.87e-07     3.87e-07     8.14e-06
    632    30     5.37e-07     5.37e-07     1.01e-05
    632    40     5.09e-07     5.09e-07     9.64e-06
    632    48     5.76e-07     5.76e-07     1.12e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    632    10     2.11e-07     2.11e-07     5.46e-06
    632    20     2.49e-07     2.49e-07     7.07e-06
    632    30     1.27e-07     1.27e-07     5.78e-06
    632    40     2.64e-07     2.64e-07     7.07e-06
    632    50     1.08e-07     1.08e-07     5.14e-06
    632    60     5.07e-08     5.07e-08     3.53e-06
    632    61      2.8e-06      2.8e-06     2.03e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             632 34799.564    0.005     4.94e-07     4.94e-07     9.28e-06
! Validation        632 34799.564    0.005     2.34e-07     2.34e-07     5.51e-06
Wall time: 34799.56458725
training
# Epoch batch         loss       loss_e      e/N_mae
    633    10     5.95e-07     5.95e-07      1.1e-05
    633    20     1.23e-06     1.23e-06     1.53e-05
    633    30     8.77e-07     8.77e-07     1.28e-05
    633    40      1.3e-06      1.3e-06     1.42e-05
    633    48     1.32e-07     1.32e-07     4.02e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    633    10     2.07e-07     2.07e-07     5.46e-06
    633    20     1.65e-07     1.65e-07     5.14e-06
    633    30      1.1e-07      1.1e-07     5.14e-06
    633    40     2.07e-07     2.07e-07     6.75e-06
    633    50      1.2e-07      1.2e-07      4.5e-06
    633    60     4.44e-08     4.44e-08     3.21e-06
    633    61     2.57e-06     2.57e-06     2.03e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             633 34854.646    0.005     8.63e-07     8.63e-07     1.22e-05
! Validation        633 34854.646    0.005     2.24e-07     2.24e-07      5.4e-06
Wall time: 34854.647428291006
training
# Epoch batch         loss       loss_e      e/N_mae
    634    10     3.85e-07     3.85e-07     8.25e-06
    634    20     6.97e-07     6.97e-07     1.21e-05
    634    30     1.75e-06     1.75e-06     1.62e-05
    634    40     2.01e-06     2.01e-06        2e-05
    634    48      2.8e-06      2.8e-06     2.01e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    634    10     2.54e-07     2.54e-07     5.78e-06
    634    20     2.32e-07     2.32e-07     5.78e-06
    634    30     1.25e-07     1.25e-07     5.46e-06
    634    40      2.6e-07      2.6e-07     8.03e-06
    634    50     2.16e-07     2.16e-07     5.46e-06
    634    60     6.76e-08     6.76e-08     3.85e-06
    634    61     2.27e-06     2.27e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             634 34909.776    0.005     1.29e-06     1.29e-06     1.43e-05
! Validation        634 34909.776    0.005     2.36e-07     2.36e-07     5.67e-06
Wall time: 34909.777281666
training
# Epoch batch         loss       loss_e      e/N_mae
    635    10     1.38e-06     1.38e-06      1.4e-05
    635    20     2.15e-06     2.15e-06     1.99e-05
    635    30     2.95e-06     2.95e-06      2.4e-05
    635    40     2.88e-06     2.88e-06     2.15e-05
    635    48     4.02e-06     4.02e-06     3.29e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    635    10     2.81e-07     2.81e-07     7.71e-06
    635    20     1.39e-07     1.39e-07     5.46e-06
    635    30     1.59e-07     1.59e-07     5.46e-06
    635    40     2.35e-07     2.35e-07     7.71e-06
    635    50     1.14e-07     1.14e-07     4.82e-06
    635    60     2.96e-08     2.96e-08     2.57e-06
    635    61     2.52e-06     2.52e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             635 34965.029    0.005     3.39e-06     3.39e-06     2.37e-05
! Validation        635 34965.029    0.005     2.48e-07     2.48e-07     5.72e-06
Wall time: 34965.029584166004
training
# Epoch batch         loss       loss_e      e/N_mae
    636    10     5.09e-06     5.09e-06     2.94e-05
    636    20     1.93e-06     1.93e-06     1.94e-05
    636    30     2.86e-06     2.86e-06     2.33e-05
    636    40     1.15e-06     1.15e-06     1.46e-05
    636    48     2.16e-06     2.16e-06     1.93e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    636    10     1.39e-07     1.39e-07     6.42e-06
    636    20     4.99e-07     4.99e-07     7.39e-06
    636    30     1.27e-08     1.27e-08     1.93e-06
    636    40     2.24e-07     2.24e-07     7.39e-06
    636    50     2.83e-07     2.83e-07     8.03e-06
    636    60     1.65e-07     1.65e-07      6.1e-06
    636    61     4.13e-06     4.13e-06     2.84e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             636 35019.837    0.005     4.24e-06     4.24e-06     2.66e-05
! Validation        636 35019.837    0.005     3.26e-07     3.26e-07     6.63e-06
Wall time: 35019.837652333
training
# Epoch batch         loss       loss_e      e/N_mae
    637    10     2.13e-06     2.13e-06     1.92e-05
    637    20      1.5e-06      1.5e-06     1.67e-05
    637    30     8.01e-07     8.01e-07     1.16e-05
    637    40     8.37e-07     8.37e-07     1.18e-05
    637    48      6.6e-07      6.6e-07     1.12e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    637    10     1.65e-07     1.65e-07     5.78e-06
    637    20     5.62e-07     5.62e-07     7.71e-06
    637    30     1.48e-08     1.48e-08     1.93e-06
    637    40     2.49e-07     2.49e-07     8.03e-06
    637    50     3.74e-07     3.74e-07     9.64e-06
    637    60     2.51e-07     2.51e-07     7.39e-06
    637    61     3.19e-06     3.19e-06     2.46e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             637 35075.014    0.005     2.44e-06     2.44e-06     1.95e-05
! Validation        637 35075.014    0.005     3.64e-07     3.64e-07     7.14e-06
Wall time: 35075.014841375
training
# Epoch batch         loss       loss_e      e/N_mae
    638    10     3.23e-07     3.23e-07     7.39e-06
    638    20     5.18e-07     5.18e-07     1.02e-05
    638    30     5.91e-07     5.91e-07     8.78e-06
    638    40     9.59e-07     9.59e-07     1.41e-05
    638    48     8.45e-08     8.45e-08     3.21e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    638    10     2.05e-07     2.05e-07     6.75e-06
    638    20     5.73e-07     5.73e-07     8.03e-06
    638    30     8.45e-09     8.45e-09     1.93e-06
    638    40     3.59e-07     3.59e-07     8.67e-06
    638    50     2.87e-07     2.87e-07     7.71e-06
    638    60     1.39e-07     1.39e-07     5.14e-06
    638    61        3e-06        3e-06      2.3e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             638 35130.072    0.005     8.54e-07     8.54e-07     1.16e-05
! Validation        638 35130.072    0.005      3.1e-07      3.1e-07     6.49e-06
Wall time: 35130.072021333
training
# Epoch batch         loss       loss_e      e/N_mae
    639    10     8.24e-07     8.24e-07     1.37e-05
    639    20     5.11e-07     5.11e-07     1.03e-05
    639    30     1.09e-06     1.09e-06      1.5e-05
    639    40     3.78e-07     3.78e-07        6e-06
    639    48     3.22e-07     3.22e-07     8.83e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    639    10     1.99e-07     1.99e-07     6.42e-06
    639    20     4.52e-07     4.52e-07     7.07e-06
    639    30     2.96e-08     2.96e-08     2.25e-06
    639    40     2.35e-07     2.35e-07     6.42e-06
    639    50     1.56e-07     1.56e-07      6.1e-06
    639    60     1.71e-07     1.71e-07      4.5e-06
    639    61      2.4e-06      2.4e-06     2.14e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             639 35185.065    0.005     4.94e-07     4.94e-07     9.07e-06
! Validation        639 35185.065    0.005     2.58e-07     2.58e-07     6.03e-06
Wall time: 35185.066257083
training
# Epoch batch         loss       loss_e      e/N_mae
    640    10     2.66e-07     2.66e-07     7.17e-06
    640    20     7.54e-08     7.54e-08     3.53e-06
    640    30     1.72e-07     1.72e-07     5.89e-06
    640    40     3.13e-07     3.13e-07     8.14e-06
    640    48     2.64e-08     2.64e-08     2.41e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    640    10      2.3e-07      2.3e-07     6.75e-06
    640    20     3.44e-07     3.44e-07     6.75e-06
    640    30     6.34e-08     6.34e-08     2.89e-06
    640    40     3.68e-07     3.68e-07     8.67e-06
    640    50     1.14e-07     1.14e-07     5.46e-06
    640    60     1.52e-07     1.52e-07     5.46e-06
    640    61     2.29e-06     2.29e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             640 35240.190    0.005     5.49e-07     5.49e-07     9.28e-06
! Validation        640 35240.190    0.005     2.52e-07     2.52e-07     6.01e-06
Wall time: 35240.191250125004
training
# Epoch batch         loss       loss_e      e/N_mae
    641    10     2.93e-07     2.93e-07     7.92e-06
    641    20     2.49e-07     2.49e-07     6.85e-06
    641    30     2.47e-07     2.47e-07     6.85e-06
    641    40      2.9e-07      2.9e-07     6.75e-06
    641    48     2.59e-07     2.59e-07     5.62e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    641    10     2.24e-07     2.24e-07      6.1e-06
    641    20     2.39e-07     2.39e-07     6.42e-06
    641    30     4.02e-08     4.02e-08     2.57e-06
    641    40     3.59e-07     3.59e-07     9.32e-06
    641    50      1.5e-07      1.5e-07     5.78e-06
    641    60     5.07e-08     5.07e-08     3.21e-06
    641    61     2.63e-06     2.63e-06     2.09e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             641 35295.377    0.005     5.41e-07     5.41e-07      9.7e-06
! Validation        641 35295.377    0.005     2.25e-07     2.25e-07      5.5e-06
Wall time: 35295.378307375
training
# Epoch batch         loss       loss_e      e/N_mae
    642    10     1.91e-07     1.91e-07     5.57e-06
    642    20     3.02e-07     3.02e-07     7.07e-06
    642    30     1.87e-07     1.87e-07     5.89e-06
    642    40     1.59e-07     1.59e-07        6e-06
    642    48     5.34e-07     5.34e-07     8.83e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    642    10     2.83e-07     2.83e-07     6.75e-06
    642    20     2.68e-07     2.68e-07     5.46e-06
    642    30     5.28e-08     5.28e-08     3.53e-06
    642    40     1.99e-07     1.99e-07     5.78e-06
    642    50     1.08e-07     1.08e-07      4.5e-06
    642    60     8.45e-08     8.45e-08     4.18e-06
    642    61     2.13e-06     2.13e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             642 35350.297    0.005      3.1e-07      3.1e-07     7.12e-06
! Validation        642 35350.297    0.005      2.1e-07      2.1e-07     5.21e-06
Wall time: 35350.297540916
training
# Epoch batch         loss       loss_e      e/N_mae
    643    10     3.37e-07     3.37e-07     7.39e-06
    643    20     2.45e-07     2.45e-07     6.85e-06
    643    30     2.57e-07     2.57e-07     6.42e-06
    643    40     1.27e-07     1.27e-07     4.82e-06
    643    48     6.87e-08     6.87e-08     4.02e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    643    10     2.05e-07     2.05e-07     6.42e-06
    643    20     1.84e-07     1.84e-07     4.82e-06
    643    30     4.86e-08     4.86e-08     2.89e-06
    643    40     2.03e-07     2.03e-07     6.42e-06
    643    50     1.12e-07     1.12e-07     5.14e-06
    643    60     5.92e-08     5.92e-08     3.53e-06
    643    61     1.37e-06     1.37e-06     1.55e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             643 35405.366    0.005     3.16e-07     3.16e-07     7.22e-06
! Validation        643 35405.366    0.005     1.72e-07     1.72e-07     4.96e-06
Wall time: 35405.365802
! Best model      643    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    644    10     2.63e-07     2.63e-07     6.21e-06
    644    20     9.04e-07     9.04e-07     1.27e-05
    644    30     5.29e-07     5.29e-07     9.53e-06
    644    40     4.71e-07     4.71e-07     9.21e-06
    644    48     1.37e-07     1.37e-07     4.82e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    644    10     2.75e-07     2.75e-07     7.39e-06
    644    20     1.94e-07     1.94e-07     4.82e-06
    644    30     4.02e-08     4.02e-08     3.53e-06
    644    40     2.87e-07     2.87e-07     8.03e-06
    644    50     1.25e-07     1.25e-07     5.14e-06
    644    60     9.72e-08     9.72e-08     4.82e-06
    644    61     1.93e-06     1.93e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             644 35460.653    0.005     4.04e-07     4.04e-07      8.2e-06
! Validation        644 35460.653    0.005     1.86e-07     1.86e-07     4.88e-06
Wall time: 35460.652827583
training
# Epoch batch         loss       loss_e      e/N_mae
    645    10     3.37e-07     3.37e-07     7.07e-06
    645    20     5.16e-07     5.16e-07     8.25e-06
    645    30     8.31e-07     8.31e-07     1.18e-05
    645    40     3.77e-07     3.77e-07     8.78e-06
    645    48     1.53e-06     1.53e-06     1.93e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    645    10     1.52e-07     1.52e-07     5.46e-06
    645    20     2.01e-07     2.01e-07     5.46e-06
    645    30     7.19e-08     7.19e-08      4.5e-06
    645    40     2.94e-07     2.94e-07     6.75e-06
    645    50     1.99e-07     1.99e-07     5.46e-06
    645    60     7.82e-08     7.82e-08     3.53e-06
    645    61     1.88e-06     1.88e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             645 35515.629    0.005      5.1e-07      5.1e-07     8.85e-06
! Validation        645 35515.629    0.005     1.91e-07     1.91e-07     5.13e-06
Wall time: 35515.629307541
training
# Epoch batch         loss       loss_e      e/N_mae
    646    10     3.65e-06     3.65e-06     2.64e-05
    646    20     2.34e-06     2.34e-06     2.12e-05
    646    30     6.98e-06     6.98e-06     3.78e-05
    646    40     6.53e-06     6.53e-06     3.52e-05
    646    48     1.15e-05     1.15e-05     5.46e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    646    10      2.6e-07      2.6e-07     7.71e-06
    646    20     2.83e-07     2.83e-07     6.42e-06
    646    30     6.34e-08     6.34e-08     3.21e-06
    646    40     1.65e-07     1.65e-07     5.46e-06
    646    50     2.11e-08     2.11e-08     1.93e-06
    646    60     8.88e-08     8.88e-08     3.53e-06
    646    61     2.15e-06     2.15e-06     1.87e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             646 35570.807    0.005     4.67e-06     4.67e-06     2.64e-05
! Validation        646 35570.807    0.005     2.44e-07     2.44e-07     5.88e-06
Wall time: 35570.807859208006
training
# Epoch batch         loss       loss_e      e/N_mae
    647    10     1.19e-05     1.19e-05     4.98e-05
    647    20     2.81e-06     2.81e-06     2.15e-05
    647    30     1.83e-06     1.83e-06     1.67e-05
    647    40     2.74e-06     2.74e-06     2.51e-05
    647    48     3.09e-06     3.09e-06     2.25e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    647    10     3.19e-07     3.19e-07     9.32e-06
    647    20     5.22e-07     5.22e-07     9.96e-06
    647    30      3.3e-07      3.3e-07     6.42e-06
    647    40     5.43e-07     5.43e-07     1.06e-05
    647    50     1.44e-07     1.44e-07     5.78e-06
    647    60     1.42e-07     1.42e-07     4.82e-06
    647    61     3.28e-06     3.28e-06     2.36e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             647 35625.651    0.005     5.79e-06     5.79e-06     3.02e-05
! Validation        647 35625.651    0.005     3.93e-07     3.93e-07     7.59e-06
Wall time: 35625.652360458
training
# Epoch batch         loss       loss_e      e/N_mae
    648    10     2.06e-06     2.06e-06     2.06e-05
    648    20     2.36e-06     2.36e-06     1.95e-05
    648    30     2.22e-06     2.22e-06     1.78e-05
    648    40     3.23e-06     3.23e-06     2.64e-05
    648    48      8.3e-07      8.3e-07     1.37e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    648    10     5.66e-07     5.66e-07     1.16e-05
    648    20     4.27e-07     4.27e-07     8.99e-06
    648    30     2.45e-07     2.45e-07      6.1e-06
    648    40     4.76e-07     4.76e-07     9.64e-06
    648    50     1.42e-07     1.42e-07     5.46e-06
    648    60     2.24e-07     2.24e-07     6.42e-06
    648    61     2.86e-06     2.86e-06     2.09e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             648 35680.590    0.005     2.55e-06     2.55e-06     2.14e-05
! Validation        648 35680.590    0.005     3.93e-07     3.93e-07     7.73e-06
Wall time: 35680.590498625
training
# Epoch batch         loss       loss_e      e/N_mae
    649    10     1.26e-06     1.26e-06      1.4e-05
    649    20     1.76e-06     1.76e-06     1.76e-05
    649    30     2.33e-06     2.33e-06     2.22e-05
    649    40     1.58e-06     1.58e-06      1.7e-05
    649    48     2.59e-07     2.59e-07     5.62e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    649    10     4.02e-07     4.02e-07     9.64e-06
    649    20     2.81e-07     2.81e-07     8.35e-06
    649    30     3.57e-07     3.57e-07     7.07e-06
    649    40     5.35e-07     5.35e-07     9.64e-06
    649    50     1.73e-07     1.73e-07     5.78e-06
    649    60     3.09e-07     3.09e-07     7.07e-06
    649    61     2.51e-06     2.51e-06     2.25e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             649 35735.813    0.005     1.96e-06     1.96e-06     1.75e-05
! Validation        649 35735.813    0.005     3.55e-07     3.55e-07     7.54e-06
Wall time: 35735.81450775
training
# Epoch batch         loss       loss_e      e/N_mae
    650    10     4.14e-07     4.14e-07      7.5e-06
    650    20     7.76e-07     7.76e-07     1.27e-05
    650    30     9.56e-07     9.56e-07     1.15e-05
    650    40     5.35e-07     5.35e-07     1.08e-05
    650    48     1.21e-06     1.21e-06     1.45e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    650    10     2.24e-07     2.24e-07     7.07e-06
    650    20      1.9e-07      1.9e-07     7.39e-06
    650    30     2.41e-07     2.41e-07     5.78e-06
    650    40     3.87e-07     3.87e-07     8.35e-06
    650    50     2.01e-07     2.01e-07     5.14e-06
    650    60     2.03e-07     2.03e-07     5.78e-06
    650    61     2.44e-06     2.44e-06     2.03e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             650 35790.811    0.005     7.57e-07     7.57e-07     1.11e-05
! Validation        650 35790.811    0.005     2.93e-07     2.93e-07     6.73e-06
Wall time: 35790.811462208
training
# Epoch batch         loss       loss_e      e/N_mae
    651    10     9.05e-07     9.05e-07     1.38e-05
    651    20     6.14e-07     6.14e-07     1.09e-05
    651    30     8.45e-07     8.45e-07     1.17e-05
    651    40     1.07e-06     1.07e-06     1.35e-05
    651    48     3.06e-07     3.06e-07     9.64e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    651    10      4.4e-07      4.4e-07     8.67e-06
    651    20     3.13e-07     3.13e-07     9.32e-06
    651    30     1.92e-07     1.92e-07     5.46e-06
    651    40     3.09e-07     3.09e-07     8.03e-06
    651    50     2.39e-07     2.39e-07     5.78e-06
    651    60     2.54e-07     2.54e-07     7.07e-06
    651    61     2.62e-06     2.62e-06     2.09e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             651 35845.870    0.005     8.97e-07     8.97e-07      1.2e-05
! Validation        651 35845.870    0.005     3.05e-07     3.05e-07      6.7e-06
Wall time: 35845.870363541006
training
# Epoch batch         loss       loss_e      e/N_mae
    652    10     6.96e-07     6.96e-07     1.07e-05
    652    20     1.63e-07     1.63e-07        6e-06
    652    30     3.93e-07     3.93e-07     8.46e-06
    652    40     3.16e-07     3.16e-07      7.6e-06
    652    48     2.59e-07     2.59e-07     5.62e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    652    10     3.11e-07     3.11e-07     8.67e-06
    652    20      2.6e-07      2.6e-07     7.07e-06
    652    30     3.09e-07     3.09e-07     5.46e-06
    652    40     2.81e-07     2.81e-07     7.71e-06
    652    50     2.73e-07     2.73e-07     6.42e-06
    652    60     1.65e-07     1.65e-07     5.78e-06
    652    61     2.48e-06     2.48e-06     2.14e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             652 35900.883    0.005      4.2e-07      4.2e-07     8.37e-06
! Validation        652 35900.883    0.005     2.78e-07     2.78e-07     6.33e-06
Wall time: 35900.884488208
training
# Epoch batch         loss       loss_e      e/N_mae
    653    10     8.94e-07     8.94e-07      1.2e-05
    653    20     9.35e-07     9.35e-07     1.15e-05
    653    30     3.54e-07     3.54e-07     8.03e-06
    653    40      4.4e-07      4.4e-07     9.21e-06
    653    48     1.99e-06     1.99e-06     2.09e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    653    10     2.85e-07     2.85e-07     8.67e-06
    653    20     2.43e-07     2.43e-07     7.71e-06
    653    30      1.9e-07      1.9e-07     5.78e-06
    653    40     3.13e-07     3.13e-07     8.67e-06
    653    50     1.14e-07     1.14e-07     4.82e-06
    653    60     2.09e-07     2.09e-07     6.42e-06
    653    61     2.64e-06     2.64e-06      2.2e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             653 35956.105    0.005     5.17e-07     5.17e-07     9.02e-06
! Validation        653 35956.105    0.005     2.52e-07     2.52e-07     6.05e-06
Wall time: 35956.106416833005
training
# Epoch batch         loss       loss_e      e/N_mae
    654    10     8.12e-07     8.12e-07     1.25e-05
    654    20     2.58e-06     2.58e-06     2.17e-05
    654    30     1.02e-06     1.02e-06     1.46e-05
    654    40     7.23e-07     7.23e-07     1.03e-05
    654    48     4.76e-08     4.76e-08     3.21e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    654    10     2.87e-07     2.87e-07     8.35e-06
    654    20     4.86e-07     4.86e-07     9.64e-06
    654    30     2.32e-07     2.32e-07      6.1e-06
    654    40     2.35e-07     2.35e-07     7.71e-06
    654    50     1.65e-07     1.65e-07      6.1e-06
    654    60     1.71e-07     1.71e-07     6.42e-06
    654    61     3.27e-06     3.27e-06     2.46e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             654 36011.181    0.005     1.63e-06     1.63e-06     1.61e-05
! Validation        654 36011.181    0.005     2.72e-07     2.72e-07     6.14e-06
Wall time: 36011.182028666
training
# Epoch batch         loss       loss_e      e/N_mae
    655    10      8.7e-07      8.7e-07     1.36e-05
    655    20     1.49e-06     1.49e-06     1.76e-05
    655    30     8.88e-07     8.88e-07     1.31e-05
    655    40     7.47e-07     7.47e-07     1.16e-05
    655    48     1.46e-06     1.46e-06     1.93e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    655    10     3.02e-07     3.02e-07     7.71e-06
    655    20        3e-07        3e-07     6.75e-06
    655    30     9.09e-08     9.09e-08     5.14e-06
    655    40     1.46e-07     1.46e-07     5.78e-06
    655    50     1.39e-07     1.39e-07     5.46e-06
    655    60     8.24e-08     8.24e-08      4.5e-06
    655    61     2.84e-06     2.84e-06      2.3e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             655 36066.347    0.005     1.75e-06     1.75e-06     1.66e-05
! Validation        655 36066.347    0.005     2.63e-07     2.63e-07     6.12e-06
Wall time: 36066.347988208
training
# Epoch batch         loss       loss_e      e/N_mae
    656    10     7.95e-07     7.95e-07     1.04e-05
    656    20     5.47e-07     5.47e-07     9.21e-06
    656    30     4.44e-07     4.44e-07     8.89e-06
    656    40     4.85e-07     4.85e-07     9.53e-06
    656    48     1.56e-06     1.56e-06     2.01e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    656    10     3.09e-07     3.09e-07     6.42e-06
    656    20     2.96e-07     2.96e-07     6.42e-06
    656    30     1.33e-07     1.33e-07     5.46e-06
    656    40     1.78e-07     1.78e-07      6.1e-06
    656    50     2.83e-07     2.83e-07     7.39e-06
    656    60     1.16e-07     1.16e-07     4.82e-06
    656    61     3.36e-06     3.36e-06     2.36e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             656 36121.505    0.005     7.17e-07     7.17e-07     1.09e-05
! Validation        656 36121.505    0.005     2.56e-07     2.56e-07     5.66e-06
Wall time: 36121.506045708
training
# Epoch batch         loss       loss_e      e/N_mae
    657    10     3.94e-07     3.94e-07     8.35e-06
    657    20      8.1e-07      8.1e-07     1.15e-05
    657    30     8.39e-07     8.39e-07     1.19e-05
    657    40     1.02e-06     1.02e-06     1.31e-05
    657    48     1.42e-06     1.42e-06     2.01e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    657    10     2.32e-07     2.32e-07     5.14e-06
    657    20     7.19e-08     7.19e-08     3.53e-06
    657    30     1.39e-07     1.39e-07     5.46e-06
    657    40     2.13e-07     2.13e-07      6.1e-06
    657    50     2.11e-07     2.11e-07     6.75e-06
    657    60     1.84e-07     1.84e-07     6.42e-06
    657    61     2.48e-06     2.48e-06     2.14e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             657 36176.152    0.005     9.95e-07     9.95e-07     1.26e-05
! Validation        657 36176.152    0.005     2.55e-07     2.55e-07     6.01e-06
Wall time: 36176.153540708
training
# Epoch batch         loss       loss_e      e/N_mae
    658    10     2.43e-06     2.43e-06     2.05e-05
    658    20     1.68e-06     1.68e-06     1.75e-05
    658    30     9.78e-07     9.78e-07     1.04e-05
    658    40     8.25e-07     8.25e-07     1.08e-05
    658    48     5.13e-07     5.13e-07     1.12e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    658    10      1.9e-07      1.9e-07     5.46e-06
    658    20     3.44e-07     3.44e-07     8.03e-06
    658    30     1.06e-07     1.06e-07     5.14e-06
    658    40     3.78e-07     3.78e-07     9.32e-06
    658    50     1.99e-07     1.99e-07      6.1e-06
    658    60     1.04e-07     1.04e-07     4.82e-06
    658    61     2.82e-06     2.82e-06      2.2e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             658 36231.316    0.005      1.1e-06      1.1e-06     1.36e-05
! Validation        658 36231.316    0.005     2.72e-07     2.72e-07     6.35e-06
Wall time: 36231.316476291
training
# Epoch batch         loss       loss_e      e/N_mae
    659    10     5.63e-07     5.63e-07     9.32e-06
    659    20     2.39e-07     2.39e-07      6.1e-06
    659    30     7.46e-07     7.46e-07     1.07e-05
    659    40      8.9e-07      8.9e-07     1.39e-05
    659    48     3.43e-07     3.43e-07     9.64e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    659    10     1.35e-07     1.35e-07     5.78e-06
    659    20     3.25e-07     3.25e-07     8.67e-06
    659    30     6.13e-08     6.13e-08     4.18e-06
    659    40     3.44e-07     3.44e-07     8.99e-06
    659    50     1.86e-07     1.86e-07     6.75e-06
    659    60     1.23e-07     1.23e-07     5.46e-06
    659    61     2.63e-06     2.63e-06     2.09e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             659 36286.387    0.005     6.44e-07     6.44e-07     1.04e-05
! Validation        659 36286.387    0.005     2.48e-07     2.48e-07        6e-06
Wall time: 36286.388494666004
training
# Epoch batch         loss       loss_e      e/N_mae
    660    10     4.95e-07     4.95e-07     9.85e-06
    660    20      9.3e-07      9.3e-07     1.18e-05
    660    30      6.5e-07      6.5e-07     1.14e-05
    660    40     5.93e-07     5.93e-07      9.1e-06
    660    48     1.19e-06     1.19e-06     1.77e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    660    10     3.25e-07     3.25e-07     7.39e-06
    660    20     3.34e-07     3.34e-07     8.03e-06
    660    30     9.93e-08     9.93e-08     5.14e-06
    660    40     4.44e-07     4.44e-07     9.32e-06
    660    50     2.01e-07     2.01e-07     6.42e-06
    660    60     1.69e-07     1.69e-07      6.1e-06
    660    61     2.35e-06     2.35e-06     2.09e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             660 36341.441    0.005     8.24e-07     8.24e-07     1.17e-05
! Validation        660 36341.441    0.005     2.49e-07     2.49e-07     5.99e-06
Wall time: 36341.441610916
training
# Epoch batch         loss       loss_e      e/N_mae
    661    10      2.3e-06      2.3e-06     2.08e-05
    661    20     1.36e-06     1.36e-06     1.41e-05
    661    30     1.55e-06     1.55e-06     1.91e-05
    661    40     6.28e-07     6.28e-07     1.07e-05
    661    48      1.8e-07      1.8e-07     7.23e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    661    10     1.67e-07     1.67e-07     5.78e-06
    661    20     3.36e-07     3.36e-07     8.35e-06
    661    30     4.44e-08     4.44e-08     3.53e-06
    661    40     4.63e-07     4.63e-07     1.03e-05
    661    50     1.39e-07     1.39e-07     5.46e-06
    661    60      9.3e-08      9.3e-08     4.82e-06
    661    61     2.68e-06     2.68e-06     2.14e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             661 36396.547    0.005     1.15e-06     1.15e-06     1.34e-05
! Validation        661 36396.547    0.005     2.57e-07     2.57e-07     6.05e-06
Wall time: 36396.548204791005
training
# Epoch batch         loss       loss_e      e/N_mae
    662    10     1.73e-06     1.73e-06     1.73e-05
    662    20     3.87e-07     3.87e-07     7.82e-06
    662    30     7.79e-07     7.79e-07     1.31e-05
    662    40     8.45e-07     8.45e-07     1.07e-05
    662    48     8.45e-07     8.45e-07     1.28e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    662    10     1.84e-07     1.84e-07     6.75e-06
    662    20     2.98e-07     2.98e-07     7.07e-06
    662    30     8.45e-08     8.45e-08     4.18e-06
    662    40     3.74e-07     3.74e-07     9.32e-06
    662    50     1.33e-07     1.33e-07     5.46e-06
    662    60     9.51e-08     9.51e-08      4.5e-06
    662    61     2.74e-06     2.74e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             662 36451.384    0.005     6.29e-07     6.29e-07     1.02e-05
! Validation        662 36451.384    0.005     2.46e-07     2.46e-07     5.77e-06
Wall time: 36451.385174458
training
# Epoch batch         loss       loss_e      e/N_mae
    663    10     3.59e-07     3.59e-07     7.71e-06
    663    20     3.79e-07     3.79e-07     8.35e-06
    663    30      1.9e-07      1.9e-07     5.68e-06
    663    40     1.51e-07     1.51e-07     5.46e-06
    663    48     5.13e-07     5.13e-07     1.12e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    663    10      1.5e-07      1.5e-07     4.18e-06
    663    20     3.64e-07     3.64e-07     8.99e-06
    663    30     1.18e-07     1.18e-07     5.78e-06
    663    40     3.59e-07     3.59e-07     9.32e-06
    663    50     1.65e-07     1.65e-07     5.46e-06
    663    60     7.19e-08     7.19e-08     4.18e-06
    663    61     2.56e-06     2.56e-06     2.03e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             663 36506.475    0.005     5.18e-07     5.18e-07     9.18e-06
! Validation        663 36506.475    0.005     2.42e-07     2.42e-07     5.69e-06
Wall time: 36506.476402208005
training
# Epoch batch         loss       loss_e      e/N_mae
    664    10     3.71e-07     3.71e-07     7.92e-06
    664    20     4.55e-07     4.55e-07     1.01e-05
    664    30     6.98e-07     6.98e-07     1.04e-05
    664    40     3.22e-07     3.22e-07     8.14e-06
    664    48     3.22e-07     3.22e-07     1.04e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    664    10     2.11e-07     2.11e-07     5.14e-06
    664    20      2.6e-07      2.6e-07     4.82e-06
    664    30      3.8e-08      3.8e-08     2.89e-06
    664    40     4.06e-07     4.06e-07     9.32e-06
    664    50     1.29e-07     1.29e-07      4.5e-06
    664    60     4.86e-08     4.86e-08     2.89e-06
    664    61     2.38e-06     2.38e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             664 36561.587    0.005     6.67e-07     6.67e-07     1.03e-05
! Validation        664 36561.587    0.005     2.22e-07     2.22e-07     5.27e-06
Wall time: 36561.587343750005
training
# Epoch batch         loss       loss_e      e/N_mae
    665    10     2.45e-07     2.45e-07     6.21e-06
    665    20      3.3e-07      3.3e-07     7.82e-06
    665    30     1.51e-07     1.51e-07     5.57e-06
    665    40     2.47e-07     2.47e-07     6.53e-06
    665    48     1.06e-08     1.06e-08     1.61e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    665    10     2.18e-07     2.18e-07     5.46e-06
    665    20     3.17e-07     3.17e-07     5.78e-06
    665    30     6.13e-08     6.13e-08     3.85e-06
    665    40     3.36e-07     3.36e-07     8.35e-06
    665    50     1.82e-07     1.82e-07     5.46e-06
    665    60     1.08e-07     1.08e-07     5.14e-06
    665    61     2.22e-06     2.22e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             665 36616.761    0.005     3.35e-07     3.35e-07     7.55e-06
! Validation        665 36616.761    0.005     2.17e-07     2.17e-07     5.41e-06
Wall time: 36616.761051375004
training
# Epoch batch         loss       loss_e      e/N_mae
    666    10      4.8e-07      4.8e-07     8.78e-06
    666    20     1.78e-07     1.78e-07     4.82e-06
    666    30     2.23e-07     2.23e-07     6.75e-06
    666    40     4.56e-07     4.56e-07     9.21e-06
    666    48     2.17e-07     2.17e-07     7.23e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    666    10     2.96e-07     2.96e-07     5.78e-06
    666    20     2.81e-07     2.81e-07      6.1e-06
    666    30     3.17e-08     3.17e-08     2.57e-06
    666    40     3.89e-07     3.89e-07     9.64e-06
    666    50     1.18e-07     1.18e-07     4.82e-06
    666    60      1.5e-07      1.5e-07     5.78e-06
    666    61     1.78e-06     1.78e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             666 36671.723    0.005     3.43e-07     3.43e-07     7.35e-06
! Validation        666 36671.723    0.005     2.04e-07     2.04e-07     5.27e-06
Wall time: 36671.723520875
training
# Epoch batch         loss       loss_e      e/N_mae
    667    10     6.69e-07     6.69e-07     1.16e-05
    667    20     3.99e-07     3.99e-07     8.46e-06
    667    30     2.25e-07     2.25e-07     7.17e-06
    667    40     5.26e-07     5.26e-07     1.14e-05
    667    48      4.7e-07      4.7e-07     1.04e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    667    10     2.62e-07     2.62e-07     6.42e-06
    667    20     2.16e-07     2.16e-07     4.18e-06
    667    30     7.19e-08     7.19e-08     3.53e-06
    667    40     2.07e-07     2.07e-07      6.1e-06
    667    50     1.69e-07     1.69e-07     5.46e-06
    667    60      3.8e-08      3.8e-08     3.21e-06
    667    61      1.6e-06      1.6e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             667 36726.795    0.005     3.81e-07     3.81e-07      8.1e-06
! Validation        667 36726.795    0.005     1.81e-07     1.81e-07     4.98e-06
Wall time: 36726.795071083005
training
# Epoch batch         loss       loss_e      e/N_mae
    668    10     1.32e-06     1.32e-06     1.34e-05
    668    20     1.19e-07     1.19e-07     5.14e-06
    668    30     1.42e-07     1.42e-07     5.57e-06
    668    40     2.87e-07     2.87e-07     7.71e-06
    668    48     5.97e-07     5.97e-07     1.28e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    668    10     2.16e-07     2.16e-07     5.78e-06
    668    20     2.24e-07     2.24e-07     5.46e-06
    668    30     4.02e-08     4.02e-08     2.89e-06
    668    40     2.51e-07     2.51e-07     6.75e-06
    668    50     9.72e-08     9.72e-08     4.82e-06
    668    60      9.3e-08      9.3e-08     5.14e-06
    668    61     2.09e-06     2.09e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             668 36781.928    0.005     3.88e-07     3.88e-07     7.97e-06
! Validation        668 36781.928    0.005     1.95e-07     1.95e-07     5.08e-06
Wall time: 36781.929178458005
training
# Epoch batch         loss       loss_e      e/N_mae
    669    10      1.3e-06      1.3e-06     1.24e-05
    669    20     5.92e-07     5.92e-07     1.01e-05
    669    30     1.98e-06     1.98e-06     1.98e-05
    669    40     7.32e-07     7.32e-07     1.21e-05
    669    48     5.28e-08     5.28e-08     3.21e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    669    10     2.24e-07     2.24e-07     6.42e-06
    669    20     8.66e-08     8.66e-08     3.53e-06
    669    30     2.96e-08     2.96e-08     2.25e-06
    669    40     2.26e-07     2.26e-07      6.1e-06
    669    50     1.06e-07     1.06e-07     4.18e-06
    669    60     1.04e-07     1.04e-07     4.82e-06
    669    61     1.73e-06     1.73e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             669 36836.924    0.005     8.47e-07     8.47e-07     1.23e-05
! Validation        669 36836.924    0.005     1.96e-07     1.96e-07     5.16e-06
Wall time: 36836.924745541
training
# Epoch batch         loss       loss_e      e/N_mae
    670    10     3.65e-07     3.65e-07     8.89e-06
    670    20     4.35e-07     4.35e-07     9.53e-06
    670    30     4.56e-07     4.56e-07     9.32e-06
    670    40     3.35e-07     3.35e-07     7.92e-06
    670    48     2.75e-07     2.75e-07     8.03e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    670    10     1.52e-07     1.52e-07     5.14e-06
    670    20     1.33e-07     1.33e-07      4.5e-06
    670    30     1.69e-08     1.69e-08     1.28e-06
    670    40     3.17e-07     3.17e-07     7.39e-06
    670    50     1.65e-07     1.65e-07     4.82e-06
    670    60      7.4e-08      7.4e-08     3.85e-06
    670    61     1.84e-06     1.84e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             670 36892.045    0.005     5.46e-07     5.46e-07     9.81e-06
! Validation        670 36892.045    0.005     2.01e-07     2.01e-07     5.31e-06
Wall time: 36892.045188125005
training
# Epoch batch         loss       loss_e      e/N_mae
    671    10     5.35e-07     5.35e-07     9.85e-06
    671    20     3.16e-07     3.16e-07     6.42e-06
    671    30     2.82e-07     2.82e-07      7.6e-06
    671    40     4.53e-07     4.53e-07     8.57e-06
    671    48     4.76e-07     4.76e-07     9.64e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    671    10     2.35e-07     2.35e-07      6.1e-06
    671    20     1.84e-07     1.84e-07     4.82e-06
    671    30     4.02e-08     4.02e-08     3.85e-06
    671    40     2.39e-07     2.39e-07     7.39e-06
    671    50     1.33e-07     1.33e-07      4.5e-06
    671    60     9.09e-08     9.09e-08     4.82e-06
    671    61     2.09e-06     2.09e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             671 36947.181    0.005     4.09e-07     4.09e-07     8.29e-06
! Validation        671 36947.181    0.005     1.98e-07     1.98e-07     5.12e-06
Wall time: 36947.182132708
training
# Epoch batch         loss       loss_e      e/N_mae
    672    10     1.65e-06     1.65e-06      1.8e-05
    672    20     6.43e-07     6.43e-07     1.06e-05
    672    30     5.18e-07     5.18e-07     8.99e-06
    672    40     9.95e-07     9.95e-07     1.36e-05
    672    48     3.22e-06     3.22e-06     2.97e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    672    10     2.01e-07     2.01e-07     6.42e-06
    672    20     2.79e-07     2.79e-07     5.78e-06
    672    30     5.71e-08     5.71e-08     3.53e-06
    672    40     2.62e-07     2.62e-07     7.71e-06
    672    50     1.35e-07     1.35e-07     4.82e-06
    672    60     8.24e-08     8.24e-08     3.53e-06
    672    61     2.38e-06     2.38e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             672 37002.155    0.005     8.37e-07     8.37e-07     1.14e-05
! Validation        672 37002.155    0.005     2.22e-07     2.22e-07     5.49e-06
Wall time: 37002.156319583
training
# Epoch batch         loss       loss_e      e/N_mae
    673    10     5.69e-07     5.69e-07     1.15e-05
    673    20      5.7e-07      5.7e-07     1.03e-05
    673    30     7.21e-07     7.21e-07      1.1e-05
    673    40     1.18e-06     1.18e-06     1.57e-05
    673    48     1.42e-06     1.42e-06     2.01e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    673    10     1.14e-07     1.14e-07      4.5e-06
    673    20     3.09e-07     3.09e-07     5.14e-06
    673    30     8.88e-08     8.88e-08     3.85e-06
    673    40     3.42e-07     3.42e-07     8.35e-06
    673    50     2.09e-07     2.09e-07     5.78e-06
    673    60     5.07e-08     5.07e-08     3.21e-06
    673    61     1.73e-06     1.73e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             673 37057.057    0.005     1.65e-06     1.65e-06      1.6e-05
! Validation        673 37057.057    0.005     2.29e-07     2.29e-07     5.75e-06
Wall time: 37057.057984291
training
# Epoch batch         loss       loss_e      e/N_mae
    674    10      7.9e-07      7.9e-07     1.21e-05
    674    20     2.44e-06     2.44e-06     2.12e-05
    674    30     6.66e-07     6.66e-07      1.1e-05
    674    40     7.96e-07     7.96e-07     1.04e-05
    674    48     9.77e-07     9.77e-07     1.61e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    674    10     2.56e-07     2.56e-07     6.75e-06
    674    20     1.71e-07     1.71e-07     5.14e-06
    674    30     1.08e-07     1.08e-07     5.14e-06
    674    40      1.5e-07      1.5e-07     5.78e-06
    674    50     1.01e-07     1.01e-07     4.18e-06
    674    60     1.42e-07     1.42e-07     5.78e-06
    674    61        2e-06        2e-06     1.87e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             674 37112.260    0.005     1.12e-06     1.12e-06     1.34e-05
! Validation        674 37112.260    0.005     2.33e-07     2.33e-07     5.81e-06
Wall time: 37112.260297541005
training
# Epoch batch         loss       loss_e      e/N_mae
    675    10     1.04e-06     1.04e-06     1.34e-05
    675    20     1.52e-06     1.52e-06      1.8e-05
    675    30     5.85e-07     5.85e-07     1.05e-05
    675    40     4.08e-07     4.08e-07     8.99e-06
    675    48     1.57e-06     1.57e-06     1.69e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    675    10     3.99e-07     3.99e-07     7.39e-06
    675    20     1.84e-07     1.84e-07      6.1e-06
    675    30     3.17e-08     3.17e-08     2.57e-06
    675    40     2.05e-07     2.05e-07     6.42e-06
    675    50     1.37e-07     1.37e-07     3.85e-06
    675    60     1.71e-07     1.71e-07     5.46e-06
    675    61     2.55e-06     2.55e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             675 37167.307    0.005     1.24e-06     1.24e-06     1.38e-05
! Validation        675 37167.307    0.005     2.37e-07     2.37e-07     5.58e-06
Wall time: 37167.307566375
training
# Epoch batch         loss       loss_e      e/N_mae
    676    10     7.95e-07     7.95e-07      1.2e-05
    676    20     6.96e-07     6.96e-07     1.05e-05
    676    30     7.18e-07     7.18e-07     1.25e-05
    676    40     2.98e-06     2.98e-06      2.4e-05
    676    48     2.37e-06     2.37e-06     2.25e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    676    10     3.53e-07     3.53e-07     7.71e-06
    676    20     2.13e-07     2.13e-07      6.1e-06
    676    30     1.37e-07     1.37e-07     5.46e-06
    676    40     1.65e-07     1.65e-07      6.1e-06
    676    50     4.23e-08     4.23e-08     2.25e-06
    676    60     3.25e-07     3.25e-07     7.07e-06
    676    61     2.73e-06     2.73e-06     2.03e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             676 37222.447    0.005      1.2e-06      1.2e-06     1.38e-05
! Validation        676 37222.447    0.005     2.45e-07     2.45e-07     5.79e-06
Wall time: 37222.44802075
training
# Epoch batch         loss       loss_e      e/N_mae
    677    10      1.6e-06      1.6e-06     1.69e-05
    677    20     2.47e-06     2.47e-06     1.54e-05
    677    30     2.39e-06     2.39e-06     1.79e-05
    677    40     1.48e-06     1.48e-06     1.65e-05
    677    48     5.49e-07     5.49e-07     1.04e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    677    10     4.92e-07     4.92e-07     9.32e-06
    677    20      1.9e-07      1.9e-07     5.78e-06
    677    30     1.06e-07     1.06e-07     5.14e-06
    677    40     3.11e-07     3.11e-07     8.03e-06
    677    50      1.1e-07      1.1e-07     3.53e-06
    677    60     1.42e-07     1.42e-07     4.82e-06
    677    61     2.41e-06     2.41e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             677 37277.498    0.005     2.01e-06     2.01e-06     1.79e-05
! Validation        677 37277.498    0.005      2.4e-07      2.4e-07     5.63e-06
Wall time: 37277.498012666
training
# Epoch batch         loss       loss_e      e/N_mae
    678    10     8.91e-07     8.91e-07     1.24e-05
    678    20     1.02e-06     1.02e-06     1.27e-05
    678    30     1.04e-06     1.04e-06     1.41e-05
    678    40      4.5e-07      4.5e-07     8.57e-06
    678    48     4.76e-08     4.76e-08     2.41e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    678    10     3.57e-07     3.57e-07     8.67e-06
    678    20     1.06e-07     1.06e-07     4.82e-06
    678    30     6.97e-08     6.97e-08     4.18e-06
    678    40     2.18e-07     2.18e-07     6.42e-06
    678    50     1.14e-07     1.14e-07     5.14e-06
    678    60     1.88e-07     1.88e-07     5.46e-06
    678    61     2.54e-06     2.54e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             678 37332.375    0.005     8.45e-07     8.45e-07     1.14e-05
! Validation        678 37332.375    0.005     2.45e-07     2.45e-07     5.82e-06
Wall time: 37332.376085583004
training
# Epoch batch         loss       loss_e      e/N_mae
    679    10      2.8e-07      2.8e-07     6.85e-06
    679    20     4.02e-07     4.02e-07     6.75e-06
    679    30     7.09e-07     7.09e-07     1.01e-05
    679    40     1.51e-06     1.51e-06     1.54e-05
    679    48     1.99e-06     1.99e-06     1.93e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    679    10     3.25e-07     3.25e-07     8.35e-06
    679    20     2.11e-07     2.11e-07     5.78e-06
    679    30     1.39e-07     1.39e-07     5.14e-06
    679    40     2.94e-07     2.94e-07     7.39e-06
    679    50     7.19e-08     7.19e-08     3.53e-06
    679    60      1.1e-07      1.1e-07      4.5e-06
    679    61     2.81e-06     2.81e-06     2.09e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             679 37387.582    0.005     6.89e-07     6.89e-07     1.01e-05
! Validation        679 37387.582    0.005     2.37e-07     2.37e-07      5.7e-06
Wall time: 37387.581842916
training
# Epoch batch         loss       loss_e      e/N_mae
    680    10     6.19e-07     6.19e-07     1.12e-05
    680    20     3.02e-07     3.02e-07     8.25e-06
    680    30     2.68e-06     2.68e-06     2.01e-05
    680    40     5.38e-06     5.38e-06     3.08e-05
    680    48     6.45e-07     6.45e-07     1.04e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    680    10     1.59e-07     1.59e-07     5.78e-06
    680    20     3.32e-07     3.32e-07     7.07e-06
    680    30     1.25e-07     1.25e-07     5.46e-06
    680    40     1.82e-07     1.82e-07     5.78e-06
    680    50     8.24e-08     8.24e-08     3.85e-06
    680    60     8.45e-08     8.45e-08     3.85e-06
    680    61     2.81e-06     2.81e-06     2.14e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             680 37442.652    0.005     2.17e-06     2.17e-06     1.75e-05
! Validation        680 37442.652    0.005     2.46e-07     2.46e-07     5.94e-06
Wall time: 37442.652023791
training
# Epoch batch         loss       loss_e      e/N_mae
    681    10     3.11e-06     3.11e-06     2.02e-05
    681    20     1.88e-06     1.88e-06     1.84e-05
    681    30     3.08e-06     3.08e-06     2.35e-05
    681    40     3.49e-06     3.49e-06     2.33e-05
    681    48     4.23e-07     4.23e-07     1.04e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    681    10     1.82e-07     1.82e-07      6.1e-06
    681    20     4.71e-07     4.71e-07     9.32e-06
    681    30     2.43e-07     2.43e-07     6.42e-06
    681    40     4.37e-07     4.37e-07     9.64e-06
    681    50     9.09e-08     9.09e-08     4.82e-06
    681    60     1.46e-07     1.46e-07     4.82e-06
    681    61     2.37e-06     2.37e-06     2.03e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             681 37497.724    0.005     2.87e-06     2.87e-06     2.21e-05
! Validation        681 37497.724    0.005     3.02e-07     3.02e-07     6.94e-06
Wall time: 37497.724629666
training
# Epoch batch         loss       loss_e      e/N_mae
    682    10     1.41e-06     1.41e-06     1.84e-05
    682    20     2.52e-06     2.52e-06      2.2e-05
    682    30     5.71e-07     5.71e-07     9.74e-06
    682    40     9.35e-07     9.35e-07     1.24e-05
    682    48     7.87e-07     7.87e-07     1.45e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    682    10     2.32e-08     2.32e-08     1.93e-06
    682    20     6.59e-07     6.59e-07     8.99e-06
    682    30     1.59e-07     1.59e-07     5.78e-06
    682    40     4.21e-07     4.21e-07     9.64e-06
    682    50     2.11e-08     2.11e-08     1.61e-06
    682    60     1.16e-07     1.16e-07     3.53e-06
    682    61     3.47e-06     3.47e-06     2.46e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             682 37552.877    0.005     1.81e-06     1.81e-06     1.72e-05
! Validation        682 37552.877    0.005     3.36e-07     3.36e-07     6.76e-06
Wall time: 37552.877406458
training
# Epoch batch         loss       loss_e      e/N_mae
    683    10     4.53e-07     4.53e-07     9.42e-06
    683    20     1.37e-06     1.37e-06      1.6e-05
    683    30     1.41e-06     1.41e-06     1.47e-05
    683    40     4.06e-07     4.06e-07      7.6e-06
    683    48     2.11e-08     2.11e-08     2.41e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    683    10     5.07e-08     5.07e-08     3.53e-06
    683    20     6.93e-07     6.93e-07     9.64e-06
    683    30     6.34e-08     6.34e-08     2.89e-06
    683    40     4.69e-07     4.69e-07     9.32e-06
    683    50     6.13e-08     6.13e-08     2.57e-06
    683    60     8.24e-08     8.24e-08     3.53e-06
    683    61     3.72e-06     3.72e-06     2.68e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             683 37607.753    0.005     9.12e-07     9.12e-07     1.22e-05
! Validation        683 37607.753    0.005     3.21e-07     3.21e-07      6.6e-06
Wall time: 37607.754177583
training
# Epoch batch         loss       loss_e      e/N_mae
    684    10     1.33e-06     1.33e-06     1.63e-05
    684    20     8.75e-07     8.75e-07     1.07e-05
    684    30     8.19e-07     8.19e-07     1.22e-05
    684    40      5.2e-07      5.2e-07     9.32e-06
    684    48      1.4e-06      1.4e-06     1.93e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    684    10     4.02e-08     4.02e-08     2.57e-06
    684    20     5.24e-07     5.24e-07     8.35e-06
    684    30      7.4e-08      7.4e-08     3.85e-06
    684    40     4.23e-07     4.23e-07     9.32e-06
    684    50     9.93e-08     9.93e-08      4.5e-06
    684    60     5.92e-08     5.92e-08     3.21e-06
    684    61     3.28e-06     3.28e-06     2.36e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             684 37662.751    0.005     7.37e-07     7.37e-07     1.08e-05
! Validation        684 37662.751    0.005     2.81e-07     2.81e-07      6.1e-06
Wall time: 37662.750975
training
# Epoch batch         loss       loss_e      e/N_mae
    685    10     1.26e-06     1.26e-06     1.27e-05
    685    20     7.46e-07     7.46e-07     1.06e-05
    685    30     3.97e-07     3.97e-07     8.67e-06
    685    40     6.73e-07     6.73e-07     1.12e-05
    685    48     1.02e-06     1.02e-06     1.61e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    685    10     8.24e-08     8.24e-08     4.82e-06
    685    20     4.95e-07     4.95e-07     7.07e-06
    685    30     1.67e-07     1.67e-07     6.75e-06
    685    40     3.83e-07     3.83e-07     8.35e-06
    685    50     1.61e-07     1.61e-07     5.46e-06
    685    60     7.19e-08     7.19e-08     3.21e-06
    685    61        3e-06        3e-06      2.3e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             685 37717.897    0.005      7.6e-07      7.6e-07     1.08e-05
! Validation        685 37717.897    0.005     2.53e-07     2.53e-07        6e-06
Wall time: 37717.89861725
training
# Epoch batch         loss       loss_e      e/N_mae
    686    10     1.15e-06     1.15e-06     1.39e-05
    686    20     6.78e-07     6.78e-07     1.12e-05
    686    30     5.97e-07     5.97e-07     9.85e-06
    686    40     5.39e-07     5.39e-07     9.32e-06
    686    48     2.64e-07     2.64e-07     6.42e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    686    10     1.48e-07     1.48e-07     4.82e-06
    686    20     5.07e-07     5.07e-07     8.03e-06
    686    30     1.27e-07     1.27e-07     5.78e-06
    686    40      2.6e-07      2.6e-07     6.42e-06
    686    50     1.12e-07     1.12e-07     5.14e-06
    686    60     9.72e-08     9.72e-08     3.85e-06
    686    61     2.72e-06     2.72e-06     2.14e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             686 37773.107    0.005     1.01e-06     1.01e-06     1.33e-05
! Validation        686 37773.107    0.005     2.33e-07     2.33e-07     5.61e-06
Wall time: 37773.106749416
training
# Epoch batch         loss       loss_e      e/N_mae
    687    10      8.6e-07      8.6e-07     1.37e-05
    687    20     6.95e-07     6.95e-07     1.12e-05
    687    30     6.64e-07     6.64e-07      1.1e-05
    687    40     5.59e-07     5.59e-07     1.01e-05
    687    48     4.76e-08     4.76e-08     2.41e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    687    10     3.99e-07     3.99e-07     8.67e-06
    687    20     3.93e-07     3.93e-07     6.42e-06
    687    30     1.08e-07     1.08e-07     5.46e-06
    687    40     4.18e-07     4.18e-07     8.03e-06
    687    50     2.05e-07     2.05e-07     7.07e-06
    687    60     1.16e-07     1.16e-07     4.18e-06
    687    61     2.55e-06     2.55e-06     2.14e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             687 37828.122    0.005     1.16e-06     1.16e-06      1.4e-05
! Validation        687 37828.122    0.005     2.43e-07     2.43e-07     5.76e-06
Wall time: 37828.122721166
training
# Epoch batch         loss       loss_e      e/N_mae
    688    10     4.83e-07     4.83e-07     9.53e-06
    688    20     4.33e-07     4.33e-07     9.32e-06
    688    30     5.71e-07     5.71e-07     1.08e-05
    688    40     4.66e-07     4.66e-07     9.64e-06
    688    48      3.8e-07      3.8e-07     9.64e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    688    10     2.94e-07     2.94e-07     7.07e-06
    688    20     3.34e-07     3.34e-07     6.42e-06
    688    30     8.24e-08     8.24e-08     4.82e-06
    688    40     3.53e-07     3.53e-07     7.71e-06
    688    50     6.34e-08     6.34e-08     3.53e-06
    688    60     5.71e-08     5.71e-08     2.89e-06
    688    61      2.8e-06      2.8e-06      2.2e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             688 37883.175    0.005     4.84e-07     4.84e-07      8.9e-06
! Validation        688 37883.175    0.005     2.44e-07     2.44e-07      5.8e-06
Wall time: 37883.176425000005
training
# Epoch batch         loss       loss_e      e/N_mae
    689    10     1.12e-06     1.12e-06     1.52e-05
    689    20     4.04e-07     4.04e-07     8.35e-06
    689    30     1.18e-06     1.18e-06     1.39e-05
    689    40     3.83e-07     3.83e-07     8.46e-06
    689    48     1.36e-06     1.36e-06     1.45e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    689    10     4.18e-07     4.18e-07     8.03e-06
    689    20     3.42e-07     3.42e-07     6.42e-06
    689    30     8.45e-08     8.45e-08     4.18e-06
    689    40     3.42e-07     3.42e-07     7.39e-06
    689    50     8.45e-08     8.45e-08     4.18e-06
    689    60     2.32e-08     2.32e-08     2.25e-06
    689    61     2.63e-06     2.63e-06     2.14e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             689 37938.345    0.005     6.63e-07     6.63e-07     1.05e-05
! Validation        689 37938.345    0.005     2.39e-07     2.39e-07     5.61e-06
Wall time: 37938.345796916
training
# Epoch batch         loss       loss_e      e/N_mae
    690    10     3.66e-07     3.66e-07     8.67e-06
    690    20     3.15e-07     3.15e-07     8.67e-06
    690    30     4.64e-07     4.64e-07     1.02e-05
    690    40     7.14e-07     7.14e-07     1.14e-05
    690    48     2.11e-07     2.11e-07     7.23e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    690    10     2.07e-07     2.07e-07      6.1e-06
    690    20     3.87e-07     3.87e-07     6.75e-06
    690    30     3.17e-08     3.17e-08     2.89e-06
    690    40     2.24e-07     2.24e-07     6.75e-06
    690    50     1.35e-07     1.35e-07     5.46e-06
    690    60     8.45e-08     8.45e-08     3.85e-06
    690    61     2.21e-06     2.21e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             690 37993.415    0.005     4.49e-07     4.49e-07     8.95e-06
! Validation        690 37993.415    0.005     2.24e-07     2.24e-07     5.58e-06
Wall time: 37993.415546541
training
# Epoch batch         loss       loss_e      e/N_mae
    691    10     4.86e-07     4.86e-07     1.04e-05
    691    20     2.64e-07     2.64e-07     7.17e-06
    691    30     5.13e-07     5.13e-07     9.53e-06
    691    40     1.92e-07     1.92e-07     5.89e-06
    691    48      1.8e-07      1.8e-07     6.42e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    691    10     2.22e-07     2.22e-07     5.78e-06
    691    20     1.92e-07     1.92e-07     5.46e-06
    691    30     4.02e-08     4.02e-08     3.53e-06
    691    40      4.1e-07      4.1e-07     8.99e-06
    691    50     9.51e-08     9.51e-08     3.85e-06
    691    60     8.24e-08     8.24e-08     3.53e-06
    691    61     1.91e-06     1.91e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             691 38048.679    0.005     3.11e-07     3.11e-07     7.15e-06
! Validation        691 38048.679    0.005     2.01e-07     2.01e-07     5.35e-06
Wall time: 38048.680396625
training
# Epoch batch         loss       loss_e      e/N_mae
    692    10     2.38e-07     2.38e-07     6.85e-06
    692    20      1.2e-07      1.2e-07     3.75e-06
    692    30     1.42e-07     1.42e-07     4.28e-06
    692    40     1.41e-07     1.41e-07     5.03e-06
    692    48     9.14e-07     9.14e-07     1.28e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    692    10     2.24e-07     2.24e-07     5.78e-06
    692    20     2.87e-07     2.87e-07     6.42e-06
    692    30     4.02e-08     4.02e-08     3.53e-06
    692    40     3.19e-07     3.19e-07     7.71e-06
    692    50      3.8e-08      3.8e-08     2.89e-06
    692    60     8.24e-08     8.24e-08     3.53e-06
    692    61     1.76e-06     1.76e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             692 38103.641    0.005     2.42e-07     2.42e-07      6.1e-06
! Validation        692 38103.641    0.005     2.04e-07     2.04e-07      5.3e-06
Wall time: 38103.641947166005
training
# Epoch batch         loss       loss_e      e/N_mae
    693    10     6.16e-07     6.16e-07     1.15e-05
    693    20     3.64e-07     3.64e-07     7.28e-06
    693    30     1.95e-07     1.95e-07     5.89e-06
    693    40     2.78e-07     2.78e-07     6.75e-06
    693    48     2.38e-07     2.38e-07     7.23e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    693    10     2.47e-07     2.47e-07     6.42e-06
    693    20     1.75e-07     1.75e-07     5.14e-06
    693    30     7.61e-08     7.61e-08      4.5e-06
    693    40     4.56e-07     4.56e-07     9.96e-06
    693    50     5.71e-08     5.71e-08     3.21e-06
    693    60     1.44e-07     1.44e-07     6.42e-06
    693    61     2.26e-06     2.26e-06     1.87e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             693 38158.655    0.005     3.74e-07     3.74e-07     7.86e-06
! Validation        693 38158.655    0.005      2.2e-07      2.2e-07      5.5e-06
Wall time: 38158.656016333
training
# Epoch batch         loss       loss_e      e/N_mae
    694    10     2.39e-07     2.39e-07     7.07e-06
    694    20     1.09e-06     1.09e-06     1.26e-05
    694    30     5.26e-07     5.26e-07     1.04e-05
    694    40     4.71e-07     4.71e-07      9.1e-06
    694    48     5.13e-07     5.13e-07     1.04e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    694    10     3.44e-07     3.44e-07     8.67e-06
    694    20     1.14e-07     1.14e-07     3.85e-06
    694    30     1.48e-07     1.48e-07      6.1e-06
    694    40     5.22e-07     5.22e-07     1.03e-05
    694    50     1.23e-07     1.23e-07     5.46e-06
    694    60      1.9e-07      1.9e-07     5.46e-06
    694    61     1.99e-06     1.99e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             694 38213.733    0.005     5.38e-07     5.38e-07     9.42e-06
! Validation        694 38213.733    0.005      2.1e-07      2.1e-07     5.39e-06
Wall time: 38213.734333500004
training
# Epoch batch         loss       loss_e      e/N_mae
    695    10     1.24e-06     1.24e-06     1.49e-05
    695    20     6.38e-07     6.38e-07     1.01e-05
    695    30     2.02e-06     2.02e-06     2.02e-05
    695    40     1.44e-06     1.44e-06     1.52e-05
    695    48     6.18e-07     6.18e-07      1.2e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    695    10     2.71e-07     2.71e-07     5.78e-06
    695    20     1.97e-07     1.97e-07     5.14e-06
    695    30     5.71e-08     5.71e-08     4.18e-06
    695    40     3.59e-07     3.59e-07     8.03e-06
    695    50     7.61e-08     7.61e-08     3.21e-06
    695    60     1.42e-07     1.42e-07      6.1e-06
    695    61     1.81e-06     1.81e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             695 38268.804    0.005     7.56e-07     7.56e-07     1.11e-05
! Validation        695 38268.804    0.005     2.07e-07     2.07e-07     5.39e-06
Wall time: 38268.803981583005
training
# Epoch batch         loss       loss_e      e/N_mae
    696    10     2.03e-06     2.03e-06     1.98e-05
    696    20     9.86e-07     9.86e-07     1.17e-05
    696    30     2.24e-06     2.24e-06     1.88e-05
    696    40     7.28e-07     7.28e-07     1.08e-05
    696    48     9.77e-07     9.77e-07     1.61e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    696    10     2.98e-07     2.98e-07     5.46e-06
    696    20     4.99e-07     4.99e-07     7.07e-06
    696    30     6.13e-08     6.13e-08      4.5e-06
    696    40      2.6e-07      2.6e-07     7.07e-06
    696    50     1.75e-07     1.75e-07     6.42e-06
    696    60     7.61e-08     7.61e-08     3.53e-06
    696    61     2.15e-06     2.15e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             696 38323.789    0.005     1.45e-06     1.45e-06     1.54e-05
! Validation        696 38323.789    0.005     2.19e-07     2.19e-07     5.49e-06
Wall time: 38323.790287166004
training
# Epoch batch         loss       loss_e      e/N_mae
    697    10     8.36e-07     8.36e-07     1.35e-05
    697    20     5.45e-07     5.45e-07     1.01e-05
    697    30     1.23e-06     1.23e-06     1.47e-05
    697    40        6e-07        6e-07     1.08e-05
    697    48     7.99e-06     7.99e-06     4.26e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    697    10     5.79e-07     5.79e-07     8.03e-06
    697    20     4.04e-07     4.04e-07     7.39e-06
    697    30     1.23e-07     1.23e-07     5.14e-06
    697    40     1.75e-07     1.75e-07      6.1e-06
    697    50     8.88e-08     8.88e-08     3.21e-06
    697    60     9.09e-08     9.09e-08     3.85e-06
    697    61     2.31e-06     2.31e-06     2.14e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             697 38378.884    0.005     1.28e-06     1.28e-06     1.39e-05
! Validation        697 38378.884    0.005     2.38e-07     2.38e-07     5.78e-06
Wall time: 38378.884381125004
training
# Epoch batch         loss       loss_e      e/N_mae
    698    10     4.16e-06     4.16e-06     2.72e-05
    698    20      8.4e-06      8.4e-06     4.25e-05
    698    30     7.42e-06     7.42e-06     3.77e-05
    698    40     4.59e-06     4.59e-06     2.72e-05
    698    48     9.56e-07     9.56e-07     1.61e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    698    10     1.75e-07     1.75e-07     5.14e-06
    698    20     6.66e-07     6.66e-07     9.32e-06
    698    30     1.29e-07     1.29e-07      6.1e-06
    698    40     1.65e-07     1.65e-07     5.78e-06
    698    50     1.16e-07     1.16e-07     5.14e-06
    698    60     1.25e-07     1.25e-07     4.82e-06
    698    61     2.67e-06     2.67e-06      2.3e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             698 38433.864    0.005      4.1e-06      4.1e-06     2.65e-05
! Validation        698 38433.864    0.005     2.53e-07     2.53e-07     6.02e-06
Wall time: 38433.865043458005
training
# Epoch batch         loss       loss_e      e/N_mae
    699    10     1.31e-06     1.31e-06      1.6e-05
    699    20     1.37e-06     1.37e-06     1.49e-05
    699    30     8.62e-07     8.62e-07      1.4e-05
    699    40     1.07e-06     1.07e-06     1.18e-05
    699    48     7.71e-07     7.71e-07     1.28e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    699    10     1.94e-07     1.94e-07     5.14e-06
    699    20      4.9e-07      4.9e-07     7.07e-06
    699    30     5.28e-08     5.28e-08     3.85e-06
    699    40     2.11e-07     2.11e-07     6.42e-06
    699    50     6.34e-08     6.34e-08     2.89e-06
    699    60     6.13e-08     6.13e-08     3.21e-06
    699    61     3.26e-06     3.26e-06      2.3e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             699 38488.936    0.005     1.45e-06     1.45e-06     1.56e-05
! Validation        699 38488.936    0.005     2.54e-07     2.54e-07     5.85e-06
Wall time: 38488.9368065
training
# Epoch batch         loss       loss_e      e/N_mae
    700    10     2.75e-06     2.75e-06     2.38e-05
    700    20     2.87e-06     2.87e-06     2.33e-05
    700    30     2.25e-06     2.25e-06     1.94e-05
    700    40     8.07e-07     8.07e-07     1.19e-05
    700    48     1.46e-06     1.46e-06     1.93e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    700    10     2.49e-07     2.49e-07     5.14e-06
    700    20     5.22e-07     5.22e-07     9.32e-06
    700    30     6.76e-08     6.76e-08     3.85e-06
    700    40     1.04e-07     1.04e-07     4.18e-06
    700    50     1.06e-07     1.06e-07     4.82e-06
    700    60     1.65e-07     1.65e-07     5.78e-06
    700    61     2.99e-06     2.99e-06     2.46e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             700 38544.149    0.005     1.48e-06     1.48e-06     1.56e-05
! Validation        700 38544.149    0.005     2.62e-07     2.62e-07     5.96e-06
Wall time: 38544.150227083
training
# Epoch batch         loss       loss_e      e/N_mae
    701    10     1.09e-06     1.09e-06     1.43e-05
    701    20     6.52e-07     6.52e-07     1.01e-05
    701    30      9.6e-07      9.6e-07     1.31e-05
    701    40     3.59e-07     3.59e-07     8.46e-06
    701    48     1.57e-06     1.57e-06     1.69e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    701    10     1.84e-07     1.84e-07     4.82e-06
    701    20     5.43e-07     5.43e-07     9.32e-06
    701    30     4.86e-08     4.86e-08     3.21e-06
    701    40     1.73e-07     1.73e-07     5.14e-06
    701    50     2.51e-07     2.51e-07     7.07e-06
    701    60      1.1e-07      1.1e-07     4.82e-06
    701    61     2.98e-06     2.98e-06     2.25e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             701 38599.123    0.005     8.83e-07     8.83e-07     1.18e-05
! Validation        701 38599.123    0.005     2.43e-07     2.43e-07     5.68e-06
Wall time: 38599.1233985
training
# Epoch batch         loss       loss_e      e/N_mae
    702    10     1.03e-06     1.03e-06     1.35e-05
    702    20     3.72e-07     3.72e-07     8.46e-06
    702    30     4.51e-07     4.51e-07     8.35e-06
    702    40     7.75e-07     7.75e-07      1.2e-05
    702    48     9.77e-07     9.77e-07     1.45e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    702    10     3.72e-07     3.72e-07     7.07e-06
    702    20     7.25e-07     7.25e-07     1.16e-05
    702    30     8.24e-08     8.24e-08      4.5e-06
    702    40      1.5e-07      1.5e-07     4.82e-06
    702    50     1.08e-07     1.08e-07      4.5e-06
    702    60     7.61e-08     7.61e-08     4.18e-06
    702    61     2.99e-06     2.99e-06      2.3e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             702 38654.461    0.005     8.12e-07     8.12e-07     1.18e-05
! Validation        702 38654.461    0.005     2.68e-07     2.68e-07     6.14e-06
Wall time: 38654.462467541
training
# Epoch batch         loss       loss_e      e/N_mae
    703    10     1.12e-06     1.12e-06     1.41e-05
    703    20     5.98e-07     5.98e-07     1.11e-05
    703    30     1.54e-06     1.54e-06     1.72e-05
    703    40     2.73e-07     2.73e-07     7.28e-06
    703    48     3.43e-07     3.43e-07     9.64e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    703    10     3.76e-07     3.76e-07     7.39e-06
    703    20     4.52e-07     4.52e-07     8.35e-06
    703    30     4.86e-08     4.86e-08     3.21e-06
    703    40     1.39e-07     1.39e-07     5.14e-06
    703    50     1.73e-07     1.73e-07     5.46e-06
    703    60     8.88e-08     8.88e-08     4.18e-06
    703    61     2.84e-06     2.84e-06     2.25e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             703 38709.466    0.005     9.04e-07     9.04e-07     1.26e-05
! Validation        703 38709.466    0.005     2.44e-07     2.44e-07     5.62e-06
Wall time: 38709.466735083
training
# Epoch batch         loss       loss_e      e/N_mae
    704    10     3.52e-07     3.52e-07     6.96e-06
    704    20     4.33e-07     4.33e-07     8.99e-06
    704    30     1.28e-06     1.28e-06     1.45e-05
    704    40     9.91e-07     9.91e-07     1.36e-05
    704    48     6.18e-07     6.18e-07     1.28e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    704    10     1.97e-07     1.97e-07     4.82e-06
    704    20      4.8e-07      4.8e-07     8.03e-06
    704    30     6.55e-08     6.55e-08     4.18e-06
    704    40     2.79e-07     2.79e-07     7.39e-06
    704    50     5.07e-08     5.07e-08     3.21e-06
    704    60     1.18e-07     1.18e-07     4.82e-06
    704    61     3.08e-06     3.08e-06      2.2e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             704 38764.422    0.005     1.68e-06     1.68e-06     1.58e-05
! Validation        704 38764.422    0.005     2.31e-07     2.31e-07     5.38e-06
Wall time: 38764.423135625
training
# Epoch batch         loss       loss_e      e/N_mae
    705    10     4.76e-06     4.76e-06     2.87e-05
    705    20     4.52e-06     4.52e-06     2.67e-05
    705    30     1.44e-06     1.44e-06     1.69e-05
    705    40     7.59e-07     7.59e-07      1.2e-05
    705    48     1.61e-06     1.61e-06     1.85e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    705    10     1.78e-07     1.78e-07     5.46e-06
    705    20     4.46e-07     4.46e-07     8.67e-06
    705    30     1.25e-07     1.25e-07     5.46e-06
    705    40     3.32e-07     3.32e-07     8.99e-06
    705    50     1.23e-07     1.23e-07     4.18e-06
    705    60     2.96e-08     2.96e-08     2.57e-06
    705    61     2.78e-06     2.78e-06     2.36e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             705 38819.580    0.005     1.72e-06     1.72e-06     1.66e-05
! Validation        705 38819.580    0.005     2.55e-07     2.55e-07     6.03e-06
Wall time: 38819.579805583
training
# Epoch batch         loss       loss_e      e/N_mae
    706    10     9.33e-07     9.33e-07      1.4e-05
    706    20     5.12e-07     5.12e-07     9.96e-06
    706    30     5.71e-07     5.71e-07      1.1e-05
    706    40      2.8e-07      2.8e-07     6.96e-06
    706    48     1.06e-07     1.06e-07     5.62e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    706    10     1.01e-07     1.01e-07     3.85e-06
    706    20     3.91e-07     3.91e-07     7.71e-06
    706    30     1.54e-07     1.54e-07     5.14e-06
    706    40     2.94e-07     2.94e-07     7.71e-06
    706    50     7.82e-08     7.82e-08     4.82e-06
    706    60     6.97e-08     6.97e-08     2.89e-06
    706    61      2.9e-06      2.9e-06     2.25e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             706 38874.685    0.005     8.53e-07     8.53e-07     1.23e-05
! Validation        706 38874.685    0.005     2.52e-07     2.52e-07     5.85e-06
Wall time: 38874.685538708
training
# Epoch batch         loss       loss_e      e/N_mae
    707    10     2.76e-07     2.76e-07     6.96e-06
    707    20     4.66e-07     4.66e-07     9.21e-06
    707    30     1.07e-07     1.07e-07     4.71e-06
    707    40     2.49e-07     2.49e-07     6.21e-06
    707    48     3.43e-07     3.43e-07     9.64e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    707    10     1.14e-07     1.14e-07     4.82e-06
    707    20     2.49e-07     2.49e-07     6.42e-06
    707    30     1.33e-07     1.33e-07      6.1e-06
    707    40     2.75e-07     2.75e-07     7.39e-06
    707    50     1.23e-07     1.23e-07     5.14e-06
    707    60     8.24e-08     8.24e-08     3.53e-06
    707    61     3.09e-06     3.09e-06      2.3e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             707 38929.661    0.005     3.49e-07     3.49e-07     7.44e-06
! Validation        707 38929.661    0.005     2.33e-07     2.33e-07     5.53e-06
Wall time: 38929.660776125005
training
# Epoch batch         loss       loss_e      e/N_mae
    708    10      2.2e-07      2.2e-07     6.32e-06
    708    20     5.31e-07     5.31e-07     9.85e-06
    708    30     6.85e-07     6.85e-07     1.02e-05
    708    40     5.15e-07     5.15e-07     1.02e-05
    708    48     1.53e-06     1.53e-06     1.93e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    708    10     6.34e-08     6.34e-08     2.57e-06
    708    20     2.68e-07     2.68e-07     5.14e-06
    708    30     7.19e-08     7.19e-08     4.18e-06
    708    40     3.44e-07     3.44e-07     8.35e-06
    708    50      2.3e-07      2.3e-07     6.42e-06
    708    60     1.08e-07     1.08e-07     4.18e-06
    708    61     2.81e-06     2.81e-06     2.14e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             708 38984.730    0.005     5.24e-07     5.24e-07     8.78e-06
! Validation        708 38984.730    0.005     2.26e-07     2.26e-07     5.41e-06
Wall time: 38984.73053
training
# Epoch batch         loss       loss_e      e/N_mae
    709    10     7.27e-07     7.27e-07     1.12e-05
    709    20     2.19e-06     2.19e-06     2.12e-05
    709    30        8e-07        8e-07      1.3e-05
    709    40     3.66e-07     3.66e-07     8.25e-06
    709    48     5.49e-07     5.49e-07     9.64e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    709    10     1.08e-07     1.08e-07     4.18e-06
    709    20     2.07e-07     2.07e-07     5.46e-06
    709    30     1.65e-07     1.65e-07      6.1e-06
    709    40     2.51e-07     2.51e-07     7.71e-06
    709    50     1.08e-07     1.08e-07      4.5e-06
    709    60     6.97e-08     6.97e-08     3.53e-06
    709    61      2.3e-06      2.3e-06     2.03e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             709 39039.685    0.005     1.04e-06     1.04e-06     1.32e-05
! Validation        709 39039.685    0.005     2.26e-07     2.26e-07     5.65e-06
Wall time: 39039.68604275
training
# Epoch batch         loss       loss_e      e/N_mae
    710    10     3.99e-07     3.99e-07      9.1e-06
    710    20     3.62e-07     3.62e-07     7.92e-06
    710    30      4.4e-07      4.4e-07     7.92e-06
    710    40     9.92e-07     9.92e-07     1.18e-05
    710    48     2.64e-07     2.64e-07     6.42e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    710    10     1.23e-07     1.23e-07      4.5e-06
    710    20     1.65e-07     1.65e-07     4.82e-06
    710    30     1.23e-07     1.23e-07     5.14e-06
    710    40     2.41e-07     2.41e-07     6.75e-06
    710    50     6.76e-08     6.76e-08     3.53e-06
    710    60     6.34e-08     6.34e-08     3.21e-06
    710    61     2.49e-06     2.49e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             710 39094.650    0.005     5.14e-07     5.14e-07     9.08e-06
! Validation        710 39094.650    0.005     2.23e-07     2.23e-07      5.5e-06
Wall time: 39094.650312541
training
# Epoch batch         loss       loss_e      e/N_mae
    711    10     1.86e-06     1.86e-06     1.46e-05
    711    20      1.1e-06      1.1e-06     1.24e-05
    711    30     6.14e-07     6.14e-07     1.09e-05
    711    40     8.74e-07     8.74e-07     1.18e-05
    711    48     2.11e-07     2.11e-07     6.42e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    711    10     2.73e-07     2.73e-07     6.42e-06
    711    20     2.94e-07     2.94e-07     6.75e-06
    711    30     1.23e-07     1.23e-07     4.82e-06
    711    40     2.73e-07     2.73e-07     7.71e-06
    711    50     6.13e-08     6.13e-08     3.21e-06
    711    60     1.92e-07     1.92e-07     5.46e-06
    711    61      2.4e-06      2.4e-06     2.09e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             711 39149.883    0.005     6.08e-07     6.08e-07      9.9e-06
! Validation        711 39149.883    0.005     2.29e-07     2.29e-07     5.51e-06
Wall time: 39149.882991916005
training
# Epoch batch         loss       loss_e      e/N_mae
    712    10     1.44e-07     1.44e-07     5.03e-06
    712    20     4.09e-07     4.09e-07      9.1e-06
    712    30     1.26e-06     1.26e-06     1.48e-05
    712    40     9.54e-07     9.54e-07     1.31e-05
    712    48     1.36e-06     1.36e-06     1.45e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    712    10     2.68e-07     2.68e-07     8.03e-06
    712    20      3.7e-07      3.7e-07     5.78e-06
    712    30     1.37e-07     1.37e-07     5.46e-06
    712    40     2.24e-07     2.24e-07     7.39e-06
    712    50     1.08e-07     1.08e-07     5.14e-06
    712    60     1.59e-07     1.59e-07     5.46e-06
    712    61      2.8e-06      2.8e-06      2.2e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             712 39204.907    0.005     1.07e-06     1.07e-06     1.27e-05
! Validation        712 39204.907    0.005     2.36e-07     2.36e-07     5.59e-06
Wall time: 39204.907565458
training
# Epoch batch         loss       loss_e      e/N_mae
    713    10     1.52e-06     1.52e-06     1.65e-05
    713    20     4.84e-07     4.84e-07     8.67e-06
    713    30     7.35e-07     7.35e-07      1.3e-05
    713    40     6.06e-07     6.06e-07     1.08e-05
    713    48     4.33e-07     4.33e-07     8.03e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    713    10     1.94e-07     1.94e-07      6.1e-06
    713    20      4.1e-07      4.1e-07     7.39e-06
    713    30     6.76e-08     6.76e-08     4.18e-06
    713    40      3.4e-07      3.4e-07     8.35e-06
    713    50     1.04e-07     1.04e-07     3.85e-06
    713    60     1.42e-07     1.42e-07     4.82e-06
    713    61     2.91e-06     2.91e-06      2.3e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             713 39260.064    0.005     1.24e-06     1.24e-06     1.38e-05
! Validation        713 39260.064    0.005     2.43e-07     2.43e-07     5.66e-06
Wall time: 39260.06437275
training
# Epoch batch         loss       loss_e      e/N_mae
    714    10     4.83e-07     4.83e-07     9.53e-06
    714    20     1.68e-07     1.68e-07     6.21e-06
    714    30     2.37e-07     2.37e-07     6.85e-06
    714    40     2.54e-07     2.54e-07     7.39e-06
    714    48     3.06e-07     3.06e-07     8.83e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    714    10     3.19e-07     3.19e-07     7.71e-06
    714    20     3.44e-07     3.44e-07     6.75e-06
    714    30      9.3e-08      9.3e-08     5.14e-06
    714    40     4.27e-07     4.27e-07     9.32e-06
    714    50     8.45e-08     8.45e-08     4.18e-06
    714    60      9.3e-08      9.3e-08     4.18e-06
    714    61        3e-06        3e-06      2.3e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             714 39315.096    0.005     3.66e-07     3.66e-07     7.94e-06
! Validation        714 39315.096    0.005     2.36e-07     2.36e-07     5.66e-06
Wall time: 39315.096602166
training
# Epoch batch         loss       loss_e      e/N_mae
    715    10     4.97e-07     4.97e-07     7.71e-06
    715    20     2.47e-07     2.47e-07     6.85e-06
    715    30      7.3e-07      7.3e-07     1.08e-05
    715    40     2.18e-07     2.18e-07     6.21e-06
    715    48     4.49e-07     4.49e-07     1.12e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    715    10     2.83e-07     2.83e-07     6.75e-06
    715    20     2.68e-07     2.68e-07     5.14e-06
    715    30     6.76e-08     6.76e-08      4.5e-06
    715    40     2.94e-07     2.94e-07     8.35e-06
    715    50     1.14e-07     1.14e-07     4.18e-06
    715    60     9.72e-08     9.72e-08     3.85e-06
    715    61     2.81e-06     2.81e-06     2.25e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             715 39370.277    0.005     3.15e-07     3.15e-07     7.15e-06
! Validation        715 39370.277    0.005     2.15e-07     2.15e-07     5.33e-06
Wall time: 39370.277134208
training
# Epoch batch         loss       loss_e      e/N_mae
    716    10     5.35e-07     5.35e-07     9.21e-06
    716    20     2.99e-07     2.99e-07     7.17e-06
    716    30     2.24e-07     2.24e-07      6.1e-06
    716    40      6.4e-07      6.4e-07     1.02e-05
    716    48     1.06e-07     1.06e-07     4.82e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    716    10     2.32e-07     2.32e-07      6.1e-06
    716    20     4.18e-07     4.18e-07     8.99e-06
    716    30     3.17e-08     3.17e-08     2.89e-06
    716    40     2.51e-07     2.51e-07     7.07e-06
    716    50     9.09e-08     9.09e-08     3.85e-06
    716    60     8.03e-08     8.03e-08     3.85e-06
    716    61     2.13e-06     2.13e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             716 39425.386    0.005     4.18e-07     4.18e-07      8.5e-06
! Validation        716 39425.386    0.005     2.11e-07     2.11e-07     5.32e-06
Wall time: 39425.386496625004
training
# Epoch batch         loss       loss_e      e/N_mae
    717    10     1.18e-07     1.18e-07      4.6e-06
    717    20     1.44e-07     1.44e-07     5.25e-06
    717    30     4.06e-07     4.06e-07     8.78e-06
    717    40     2.28e-07     2.28e-07     6.85e-06
    717    48     5.28e-09     5.28e-09     8.03e-07
validation
# Epoch batch         loss       loss_e      e/N_mae
    717    10     1.84e-07     1.84e-07     5.78e-06
    717    20        3e-07        3e-07     7.39e-06
    717    30     7.19e-08     7.19e-08     4.18e-06
    717    40     2.58e-07     2.58e-07     7.39e-06
    717    50     1.56e-07     1.56e-07     4.82e-06
    717    60     6.76e-08     6.76e-08     3.85e-06
    717    61     2.11e-06     2.11e-06     2.03e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             717 39480.577    0.005     3.42e-07     3.42e-07     7.68e-06
! Validation        717 39480.577    0.005      1.9e-07      1.9e-07        5e-06
Wall time: 39480.578449791
training
# Epoch batch         loss       loss_e      e/N_mae
    718    10     1.94e-07     1.94e-07     5.46e-06
    718    20     1.23e-07     1.23e-07     3.96e-06
    718    30      2.3e-07      2.3e-07      6.1e-06
    718    40     1.44e-07     1.44e-07     4.07e-06
    718    48     2.38e-07     2.38e-07     8.03e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    718    10     3.99e-07     3.99e-07     7.39e-06
    718    20     4.02e-07     4.02e-07     7.71e-06
    718    30     6.34e-08     6.34e-08     3.85e-06
    718    40     3.44e-07     3.44e-07     8.67e-06
    718    50     9.93e-08     9.93e-08      4.5e-06
    718    60     1.27e-07     1.27e-07     5.14e-06
    718    61     1.79e-06     1.79e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             718 39535.798    0.005     2.69e-07     2.69e-07     6.62e-06
! Validation        718 39535.798    0.005     1.88e-07     1.88e-07     5.08e-06
Wall time: 39535.799038791
training
# Epoch batch         loss       loss_e      e/N_mae
    719    10     3.66e-07     3.66e-07     8.14e-06
    719    20     2.53e-07     2.53e-07     7.28e-06
    719    30     1.39e-07     1.39e-07     4.18e-06
    719    40     4.75e-07     4.75e-07     8.78e-06
    719    48     1.06e-08     1.06e-08     1.61e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    719    10     5.47e-07     5.47e-07     8.99e-06
    719    20     3.61e-07     3.61e-07     5.46e-06
    719    30     7.61e-08     7.61e-08     3.85e-06
    719    40     3.47e-07     3.47e-07     8.35e-06
    719    50     8.88e-08     8.88e-08     3.53e-06
    719    60     8.45e-08     8.45e-08     3.85e-06
    719    61     2.06e-06     2.06e-06     1.87e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             719 39590.690    0.005     2.85e-07     2.85e-07     7.04e-06
! Validation        719 39590.690    0.005     2.02e-07     2.02e-07     5.05e-06
Wall time: 39590.691350208
training
# Epoch batch         loss       loss_e      e/N_mae
    720    10     1.67e-06     1.67e-06     1.86e-05
    720    20     7.86e-07     7.86e-07     1.35e-05
    720    30     6.05e-07     6.05e-07     9.74e-06
    720    40     5.68e-07     5.68e-07     1.09e-05
    720    48     2.17e-07     2.17e-07     7.23e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    720    10     3.25e-07     3.25e-07     6.75e-06
    720    20     3.23e-07     3.23e-07      6.1e-06
    720    30      3.8e-08      3.8e-08     3.21e-06
    720    40      5.9e-07      5.9e-07     1.12e-05
    720    50     6.34e-08     6.34e-08     2.89e-06
    720    60     1.48e-08     1.48e-08     1.61e-06
    720    61     2.49e-06     2.49e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             720 39645.824    0.005      6.1e-07      6.1e-07     1.02e-05
! Validation        720 39645.824    0.005     2.22e-07     2.22e-07     5.47e-06
Wall time: 39645.824031833
training
# Epoch batch         loss       loss_e      e/N_mae
    721    10     2.17e-07     2.17e-07     6.21e-06
    721    20     2.66e-07     2.66e-07     6.64e-06
    721    30     5.94e-07     5.94e-07     1.07e-05
    721    40     1.97e-06     1.97e-06     1.51e-05
    721    48     6.18e-07     6.18e-07      1.2e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    721    10     3.66e-07     3.66e-07     7.07e-06
    721    20     4.29e-07     4.29e-07     6.75e-06
    721    30     4.44e-08     4.44e-08     2.89e-06
    721    40     3.89e-07     3.89e-07     9.64e-06
    721    50     1.44e-07     1.44e-07     5.46e-06
    721    60     5.92e-08     5.92e-08     3.53e-06
    721    61     2.13e-06     2.13e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             721 39700.954    0.005     6.78e-07     6.78e-07     1.03e-05
! Validation        721 39700.954    0.005     2.09e-07     2.09e-07     5.23e-06
Wall time: 39700.95540325
training
# Epoch batch         loss       loss_e      e/N_mae
    722    10     1.14e-06     1.14e-06     1.54e-05
    722    20     3.53e-06     3.53e-06     2.05e-05
    722    30     1.61e-06     1.61e-06     1.87e-05
    722    40     3.35e-06     3.35e-06     2.55e-05
    722    48     4.74e-06     4.74e-06     3.29e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    722    10     1.16e-07     1.16e-07     4.18e-06
    722    20     5.16e-07     5.16e-07     8.03e-06
    722    30     8.45e-08     8.45e-08     4.82e-06
    722    40     3.87e-07     3.87e-07     9.96e-06
    722    50     1.16e-07     1.16e-07     5.14e-06
    722    60     8.03e-08     8.03e-08     4.18e-06
    722    61     2.36e-06     2.36e-06      2.2e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             722 39755.949    0.005     2.27e-06     2.27e-06     1.85e-05
! Validation        722 39755.949    0.005     2.17e-07     2.17e-07     5.59e-06
Wall time: 39755.949498958005
training
# Epoch batch         loss       loss_e      e/N_mae
    723    10     3.92e-06     3.92e-06     2.43e-05
    723    20     1.02e-06     1.02e-06      1.4e-05
    723    30     4.87e-06     4.87e-06     2.93e-05
    723    40     1.41e-06     1.41e-06     1.66e-05
    723    48     1.32e-07     1.32e-07     6.42e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    723    10     3.83e-07     3.83e-07     7.71e-06
    723    20     5.28e-07     5.28e-07     8.99e-06
    723    30     1.63e-07     1.63e-07     5.14e-06
    723    40     3.42e-07     3.42e-07     8.03e-06
    723    50     9.09e-08     9.09e-08     4.82e-06
    723    60     2.11e-08     2.11e-08     1.93e-06
    723    61     2.77e-06     2.77e-06      2.2e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             723 39811.148    0.005     3.95e-06     3.95e-06     2.61e-05
! Validation        723 39811.148    0.005     2.93e-07     2.93e-07     6.49e-06
Wall time: 39811.148802083
training
# Epoch batch         loss       loss_e      e/N_mae
    724    10     9.17e-07     9.17e-07     1.23e-05
    724    20     8.29e-07     8.29e-07     1.18e-05
    724    30     1.65e-06     1.65e-06     1.75e-05
    724    40     1.04e-06     1.04e-06     1.37e-05
    724    48     2.69e-06     2.69e-06     2.33e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    724    10      2.6e-07      2.6e-07     6.42e-06
    724    20     5.54e-07     5.54e-07     8.99e-06
    724    30     2.24e-07     2.24e-07     5.78e-06
    724    40     3.36e-07     3.36e-07     8.67e-06
    724    50     2.09e-07     2.09e-07     7.07e-06
    724    60     2.32e-08     2.32e-08     2.25e-06
    724    61     2.93e-06     2.93e-06      2.3e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             724 39866.043    0.005     1.46e-06     1.46e-06     1.56e-05
! Validation        724 39866.043    0.005     2.95e-07     2.95e-07     6.52e-06
Wall time: 39866.043577166005
training
# Epoch batch         loss       loss_e      e/N_mae
    725    10      6.5e-06      6.5e-06     2.96e-05
    725    20     3.19e-06     3.19e-06      2.3e-05
    725    30     1.76e-06     1.76e-06     1.85e-05
    725    40     6.47e-06     6.47e-06     2.82e-05
    725    48     7.11e-06     7.11e-06     3.61e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    725    10     6.55e-08     6.55e-08     4.18e-06
    725    20      8.2e-07      8.2e-07     1.12e-05
    725    30     1.44e-07     1.44e-07     3.21e-06
    725    40     4.35e-07     4.35e-07     1.03e-05
    725    50     7.82e-08     7.82e-08     3.85e-06
    725    60     1.16e-07     1.16e-07     3.85e-06
    725    61     3.28e-06     3.28e-06     2.36e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             725 39921.003    0.005     3.57e-06     3.57e-06     2.25e-05
! Validation        725 39921.003    0.005     2.85e-07     2.85e-07     6.27e-06
Wall time: 39921.003972416
training
# Epoch batch         loss       loss_e      e/N_mae
    726    10     7.68e-06     7.68e-06     3.61e-05
    726    20     5.27e-06     5.27e-06     3.07e-05
    726    30     8.47e-06     8.47e-06     4.19e-05
    726    40     8.62e-06     8.62e-06     4.28e-05
    726    48     1.65e-06     1.65e-06     2.17e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    726    10     1.25e-07     1.25e-07     5.46e-06
    726    20     4.54e-07     4.54e-07     8.35e-06
    726    30     2.58e-07     2.58e-07     8.03e-06
    726    40     6.13e-07     6.13e-07     1.16e-05
    726    50     9.72e-08     9.72e-08     5.14e-06
    726    60     1.44e-07     1.44e-07     4.82e-06
    726    61     2.82e-06     2.82e-06     2.25e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             726 39976.134    0.005     5.13e-06     5.13e-06     2.97e-05
! Validation        726 39976.134    0.005     3.22e-07     3.22e-07     7.08e-06
Wall time: 39976.13525625
training
# Epoch batch         loss       loss_e      e/N_mae
    727    10     5.52e-07     5.52e-07     1.04e-05
    727    20     9.19e-07     9.19e-07     1.25e-05
    727    30     7.83e-07     7.83e-07     1.24e-05
    727    40     1.37e-06     1.37e-06     1.62e-05
    727    48     3.83e-06     3.83e-06     3.13e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    727    10     8.03e-08     8.03e-08     4.18e-06
    727    20     5.62e-07     5.62e-07     7.07e-06
    727    30     1.88e-07     1.88e-07     7.07e-06
    727    40     4.56e-07     4.56e-07     9.96e-06
    727    50     4.65e-08     4.65e-08     3.21e-06
    727    60     1.35e-07     1.35e-07     4.82e-06
    727    61     3.25e-06     3.25e-06     2.57e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             727 40031.263    0.005     1.55e-06     1.55e-06     1.58e-05
! Validation        727 40031.263    0.005     3.34e-07     3.34e-07     6.87e-06
Wall time: 40031.263996416004
training
# Epoch batch         loss       loss_e      e/N_mae
    728    10     3.54e-06     3.54e-06     2.73e-05
    728    20     2.82e-06     2.82e-06     2.02e-05
    728    30     4.38e-06     4.38e-06     2.47e-05
    728    40     5.78e-06     5.78e-06     3.32e-05
    728    48     8.66e-07     8.66e-07     1.53e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    728    10     3.02e-07     3.02e-07     8.67e-06
    728    20     4.33e-07     4.33e-07     6.75e-06
    728    30     3.55e-07     3.55e-07     8.67e-06
    728    40     4.08e-07     4.08e-07     9.96e-06
    728    50     1.08e-07     1.08e-07     5.46e-06
    728    60     2.35e-07     2.35e-07     6.42e-06
    728    61     3.19e-06     3.19e-06     2.62e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             728 40086.293    0.005     4.71e-06     4.71e-06     2.73e-05
! Validation        728 40086.293    0.005     3.21e-07     3.21e-07     6.82e-06
Wall time: 40086.293376875
training
# Epoch batch         loss       loss_e      e/N_mae
    729    10     7.21e-06     7.21e-06     4.11e-05
    729    20     1.05e-06     1.05e-06      1.5e-05
    729    30     3.54e-07     3.54e-07     8.78e-06
    729    40     1.26e-06     1.26e-06     1.18e-05
    729    48     6.87e-08     6.87e-08     4.02e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    729    10     4.21e-07     4.21e-07     8.35e-06
    729    20     4.35e-07     4.35e-07     6.42e-06
    729    30     1.88e-07     1.88e-07     6.75e-06
    729    40     5.05e-07     5.05e-07     1.09e-05
    729    50     3.17e-08     3.17e-08     2.57e-06
    729    60     1.71e-07     1.71e-07     5.46e-06
    729    61     3.05e-06     3.05e-06     2.36e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             729 40141.175    0.005      2.1e-06      2.1e-06     1.79e-05
! Validation        729 40141.175    0.005     3.23e-07     3.23e-07     6.85e-06
Wall time: 40141.176141375
training
# Epoch batch         loss       loss_e      e/N_mae
    730    10     4.41e-07     4.41e-07     8.25e-06
    730    20     4.77e-07     4.77e-07     8.99e-06
    730    30     2.49e-07     2.49e-07     6.85e-06
    730    40     6.52e-07     6.52e-07     1.12e-05
    730    48     2.44e-06     2.44e-06     2.49e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    730    10      4.4e-07      4.4e-07     8.67e-06
    730    20     2.24e-07     2.24e-07     5.46e-06
    730    30     1.99e-07     1.99e-07     6.42e-06
    730    40     3.99e-07     3.99e-07     8.35e-06
    730    50     2.11e-08     2.11e-08     2.25e-06
    730    60     1.94e-07     1.94e-07      4.5e-06
    730    61     3.27e-06     3.27e-06     2.46e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             730 40196.355    0.005     5.28e-07     5.28e-07     9.22e-06
! Validation        730 40196.355    0.005     2.93e-07     2.93e-07     6.33e-06
Wall time: 40196.35604025
training
# Epoch batch         loss       loss_e      e/N_mae
    731    10     8.45e-07     8.45e-07     1.21e-05
    731    20     8.98e-07     8.98e-07     1.17e-05
    731    30     1.46e-06     1.46e-06     1.61e-05
    731    40     9.71e-07     9.71e-07      1.3e-05
    731    48     2.11e-06     2.11e-06     2.25e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    731    10     2.98e-07     2.98e-07     6.42e-06
    731    20     3.36e-07     3.36e-07     6.75e-06
    731    30     2.01e-07     2.01e-07     5.78e-06
    731    40      3.8e-07      3.8e-07     8.99e-06
    731    50      3.8e-08      3.8e-08     1.93e-06
    731    60     2.35e-07     2.35e-07      6.1e-06
    731    61     3.08e-06     3.08e-06      2.3e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             731 40251.351    0.005     1.46e-06     1.46e-06     1.56e-05
! Validation        731 40251.351    0.005     2.66e-07     2.66e-07     5.99e-06
Wall time: 40251.351715083
training
# Epoch batch         loss       loss_e      e/N_mae
    732    10     1.72e-06     1.72e-06     1.69e-05
    732    20     4.19e-07     4.19e-07     8.35e-06
    732    30     6.21e-07     6.21e-07     9.96e-06
    732    40        1e-06        1e-06     1.37e-05
    732    48     2.97e-06     2.97e-06     2.73e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    732    10     3.25e-07     3.25e-07     6.75e-06
    732    20     3.93e-07     3.93e-07     6.42e-06
    732    30     2.62e-07     2.62e-07     7.39e-06
    732    40     3.23e-07     3.23e-07     7.71e-06
    732    50     5.71e-08     5.71e-08     3.85e-06
    732    60     2.24e-07     2.24e-07     6.75e-06
    732    61     3.17e-06     3.17e-06      2.3e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             732 40306.578    0.005     1.19e-06     1.19e-06     1.34e-05
! Validation        732 40306.578    0.005     2.72e-07     2.72e-07     6.11e-06
Wall time: 40306.57852725
training
# Epoch batch         loss       loss_e      e/N_mae
    733    10     1.53e-06     1.53e-06     1.51e-05
    733    20      8.9e-07      8.9e-07     1.21e-05
    733    30     7.71e-07     7.71e-07     1.37e-05
    733    40      6.4e-07      6.4e-07     1.05e-05
    733    48     5.49e-07     5.49e-07     1.04e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    733    10     2.11e-07     2.11e-07     6.42e-06
    733    20     4.37e-07     4.37e-07     6.42e-06
    733    30     1.99e-07     1.99e-07     6.75e-06
    733    40     2.81e-07     2.81e-07     7.39e-06
    733    50     4.65e-08     4.65e-08     2.89e-06
    733    60     1.31e-07     1.31e-07     5.46e-06
    733    61     2.46e-06     2.46e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             733 40361.761    0.005     1.33e-06     1.33e-06     1.44e-05
! Validation        733 40361.761    0.005     2.54e-07     2.54e-07      6.1e-06
Wall time: 40361.762456541
training
# Epoch batch         loss       loss_e      e/N_mae
    734    10      8.5e-07      8.5e-07     1.07e-05
    734    20     2.08e-07     2.08e-07     6.64e-06
    734    30     6.86e-07     6.86e-07     1.08e-05
    734    40     4.72e-07     4.72e-07     9.32e-06
    734    48     1.32e-07     1.32e-07     5.62e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    734    10     2.64e-07     2.64e-07     6.42e-06
    734    20     2.79e-07     2.79e-07     5.46e-06
    734    30     1.31e-07     1.31e-07     5.78e-06
    734    40      3.7e-07      3.7e-07     7.71e-06
    734    50     8.66e-08     8.66e-08      4.5e-06
    734    60     1.42e-07     1.42e-07     5.14e-06
    734    61     2.38e-06     2.38e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             734 40416.736    0.005     5.06e-07     5.06e-07     9.06e-06
! Validation        734 40416.736    0.005     2.42e-07     2.42e-07     5.92e-06
Wall time: 40416.737116041004
training
# Epoch batch         loss       loss_e      e/N_mae
    735    10     1.36e-07     1.36e-07      4.6e-06
    735    20      3.6e-07      3.6e-07     6.42e-06
    735    30     2.41e-07     2.41e-07     6.53e-06
    735    40     1.44e-07     1.44e-07     4.93e-06
    735    48     1.06e-07     1.06e-07     4.82e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    735    10     1.84e-07     1.84e-07      6.1e-06
    735    20     3.17e-07     3.17e-07     5.78e-06
    735    30     1.23e-07     1.23e-07     5.14e-06
    735    40     3.53e-07     3.53e-07     8.03e-06
    735    50     9.93e-08     9.93e-08      4.5e-06
    735    60     9.72e-08     9.72e-08     4.82e-06
    735    61     1.93e-06     1.93e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             735 40471.816    0.005     2.15e-07     2.15e-07     5.98e-06
! Validation        735 40471.816    0.005     2.15e-07     2.15e-07     5.63e-06
Wall time: 40471.817401791
training
# Epoch batch         loss       loss_e      e/N_mae
    736    10     9.51e-08     9.51e-08      4.6e-06
    736    20     8.88e-08     8.88e-08     3.43e-06
    736    30     3.89e-07     3.89e-07     7.82e-06
    736    40     1.79e-07     1.79e-07     5.89e-06
    736    48     6.87e-08     6.87e-08     4.02e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    736    10     1.82e-07     1.82e-07     3.85e-06
    736    20     3.78e-07     3.78e-07     6.42e-06
    736    30     6.55e-08     6.55e-08     4.18e-06
    736    40     2.68e-07     2.68e-07     7.07e-06
    736    50     4.86e-08     4.86e-08     3.21e-06
    736    60     3.17e-08     3.17e-08     2.25e-06
    736    61     2.38e-06     2.38e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             736 40526.915    0.005     1.58e-07     1.58e-07     5.05e-06
! Validation        736 40526.915    0.005     2.14e-07     2.14e-07     5.52e-06
Wall time: 40526.914713291
training
# Epoch batch         loss       loss_e      e/N_mae
    737    10     1.07e-07     1.07e-07      4.5e-06
    737    20     7.19e-08     7.19e-08     3.64e-06
    737    30     8.52e-08     8.52e-08     3.64e-06
    737    40     9.58e-08     9.58e-08     4.18e-06
    737    48      1.9e-07      1.9e-07     4.82e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    737    10     2.37e-07     2.37e-07     5.14e-06
    737    20     2.66e-07     2.66e-07     6.42e-06
    737    30     8.03e-08     8.03e-08     3.85e-06
    737    40     3.32e-07     3.32e-07     8.67e-06
    737    50     7.82e-08     7.82e-08     3.85e-06
    737    60     4.44e-08     4.44e-08     3.21e-06
    737    61     1.78e-06     1.78e-06     1.87e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             737 40581.950    0.005     1.21e-07     1.21e-07     4.46e-06
! Validation        737 40581.950    0.005     1.93e-07     1.93e-07     5.24e-06
Wall time: 40581.949786875004
training
# Epoch batch         loss       loss_e      e/N_mae
    738    10     2.32e-07     2.32e-07     7.28e-06
    738    20     3.44e-07     3.44e-07     8.25e-06
    738    30     2.28e-07     2.28e-07     6.85e-06
    738    40     1.42e-07     1.42e-07     5.25e-06
    738    48      1.8e-07      1.8e-07     7.23e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    738    10     3.32e-07     3.32e-07      6.1e-06
    738    20     3.15e-07     3.15e-07     5.46e-06
    738    30     1.18e-07     1.18e-07     5.46e-06
    738    40      2.2e-07      2.2e-07     6.42e-06
    738    50      1.2e-07      1.2e-07      4.5e-06
    738    60      9.3e-08      9.3e-08     3.85e-06
    738    61     1.76e-06     1.76e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             738 40636.929    0.005     2.54e-07     2.54e-07     6.65e-06
! Validation        738 40636.929    0.005     2.01e-07     2.01e-07     5.34e-06
Wall time: 40636.929111833
training
# Epoch batch         loss       loss_e      e/N_mae
    739    10     1.38e-07     1.38e-07     5.46e-06
    739    20     2.16e-07     2.16e-07     6.75e-06
    739    30     2.49e-07     2.49e-07     5.35e-06
    739    40     3.17e-07     3.17e-07     7.71e-06
    739    48     9.56e-07     9.56e-07     1.53e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    739    10     4.12e-07     4.12e-07     8.99e-06
    739    20     2.22e-07     2.22e-07     4.82e-06
    739    30     1.06e-07     1.06e-07      4.5e-06
    739    40     1.84e-07     1.84e-07     6.42e-06
    739    50     1.67e-07     1.67e-07     5.78e-06
    739    60      1.2e-07      1.2e-07     5.14e-06
    739    61      2.1e-06      2.1e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             739 40692.152    0.005      3.4e-07      3.4e-07     7.44e-06
! Validation        739 40692.152    0.005     1.98e-07     1.98e-07      5.2e-06
Wall time: 40692.152872833
training
# Epoch batch         loss       loss_e      e/N_mae
    740    10     1.09e-06     1.09e-06     1.39e-05
    740    20     6.08e-07     6.08e-07     9.42e-06
    740    30     4.87e-07     4.87e-07     1.07e-05
    740    40     3.13e-07     3.13e-07     8.03e-06
    740    48     8.56e-07     8.56e-07     1.53e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    740    10     2.68e-07     2.68e-07     6.42e-06
    740    20     2.24e-07     2.24e-07     5.14e-06
    740    30     7.82e-08     7.82e-08     4.18e-06
    740    40     2.58e-07     2.58e-07     6.75e-06
    740    50     6.76e-08     6.76e-08     4.18e-06
    740    60     1.08e-07     1.08e-07     5.14e-06
    740    61     2.37e-06     2.37e-06     2.14e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             740 40747.036    0.005     5.71e-07     5.71e-07     9.69e-06
! Validation        740 40747.036    0.005     2.04e-07     2.04e-07     5.23e-06
Wall time: 40747.037390416
training
# Epoch batch         loss       loss_e      e/N_mae
    741    10     2.58e-07     2.58e-07     7.28e-06
    741    20     7.91e-07     7.91e-07     1.21e-05
    741    30      1.9e-07      1.9e-07     5.78e-06
    741    40     2.71e-07     2.71e-07     6.96e-06
    741    48     1.95e-07     1.95e-07     5.62e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    741    10     3.19e-07     3.19e-07     7.71e-06
    741    20     2.37e-07     2.37e-07     5.46e-06
    741    30     7.82e-08     7.82e-08     4.82e-06
    741    40     1.82e-07     1.82e-07     6.75e-06
    741    50     1.29e-07     1.29e-07     5.78e-06
    741    60     1.56e-07     1.56e-07      6.1e-06
    741    61     2.55e-06     2.55e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             741 40802.154    0.005     3.89e-07     3.89e-07     8.17e-06
! Validation        741 40802.154    0.005     2.13e-07     2.13e-07     5.46e-06
Wall time: 40802.154632041005
training
# Epoch batch         loss       loss_e      e/N_mae
    742    10     3.14e-07     3.14e-07     6.96e-06
    742    20     4.04e-07     4.04e-07     8.14e-06
    742    30     2.85e-07     2.85e-07     7.82e-06
    742    40     1.92e-07     1.92e-07     6.21e-06
    742    48     3.59e-07     3.59e-07     8.83e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    742    10     4.02e-07     4.02e-07     8.03e-06
    742    20     3.97e-07     3.97e-07     6.75e-06
    742    30     8.03e-08     8.03e-08     4.18e-06
    742    40     2.11e-07     2.11e-07     6.75e-06
    742    50     6.76e-08     6.76e-08     4.18e-06
    742    60     4.86e-08     4.86e-08     2.89e-06
    742    61     2.16e-06     2.16e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             742 40857.370    0.005     3.19e-07     3.19e-07     7.32e-06
! Validation        742 40857.370    0.005     1.88e-07     1.88e-07     4.95e-06
Wall time: 40857.371365875006
training
# Epoch batch         loss       loss_e      e/N_mae
    743    10     6.76e-08     6.76e-08     3.64e-06
    743    20     2.92e-07     2.92e-07     7.71e-06
    743    30     5.47e-07     5.47e-07     1.05e-05
    743    40     1.16e-07     1.16e-07     5.35e-06
    743    48     3.22e-07     3.22e-07     9.64e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    743    10     3.34e-07     3.34e-07     7.07e-06
    743    20     3.02e-07     3.02e-07     6.42e-06
    743    30     5.07e-08     5.07e-08     3.53e-06
    743    40     3.28e-07     3.28e-07     8.99e-06
    743    50      7.4e-08      7.4e-08     3.21e-06
    743    60     1.04e-07     1.04e-07     5.14e-06
    743    61     2.09e-06     2.09e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             743 40912.456    0.005     2.92e-07     2.92e-07     7.06e-06
! Validation        743 40912.456    0.005     1.95e-07     1.95e-07     5.14e-06
Wall time: 40912.457439625
training
# Epoch batch         loss       loss_e      e/N_mae
    744    10     1.04e-06     1.04e-06     1.15e-05
    744    20     6.38e-07     6.38e-07     1.12e-05
    744    30     2.49e-07     2.49e-07     6.85e-06
    744    40     1.61e-07     1.61e-07     5.35e-06
    744    48      1.8e-07      1.8e-07     6.42e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    744    10     2.49e-07     2.49e-07     5.14e-06
    744    20     2.64e-07     2.64e-07     6.42e-06
    744    30     4.44e-08     4.44e-08     3.21e-06
    744    40     2.94e-07     2.94e-07     8.35e-06
    744    50      9.3e-08      9.3e-08     4.18e-06
    744    60     1.65e-07     1.65e-07      6.1e-06
    744    61     1.78e-06     1.78e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             744 40967.646    0.005     3.55e-07     3.55e-07     7.55e-06
! Validation        744 40967.646    0.005     1.86e-07     1.86e-07     4.97e-06
Wall time: 40967.646509583
training
# Epoch batch         loss       loss_e      e/N_mae
    745    10     9.09e-08     9.09e-08     3.96e-06
    745    20     6.48e-08     6.48e-08     3.11e-06
    745    30     6.55e-08     6.55e-08     3.43e-06
    745    40     7.26e-08     7.26e-08     3.75e-06
    745    48     4.23e-08     4.23e-08     4.02e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    745    10     2.49e-07     2.49e-07     5.14e-06
    745    20     3.28e-07     3.28e-07     7.71e-06
    745    30     2.75e-08     2.75e-08     2.89e-06
    745    40     3.66e-07     3.66e-07     8.99e-06
    745    50     1.16e-07     1.16e-07     5.14e-06
    745    60     8.03e-08     8.03e-08     4.18e-06
    745    61     1.84e-06     1.84e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             745 41022.552   0.0025     1.41e-07     1.41e-07      4.8e-06
! Validation        745 41022.552   0.0025     1.88e-07     1.88e-07     4.91e-06
Wall time: 41022.552843791
training
# Epoch batch         loss       loss_e      e/N_mae
    746    10      6.2e-08      6.2e-08     2.89e-06
    746    20     8.31e-08     8.31e-08     3.96e-06
    746    30     7.75e-08     7.75e-08     3.85e-06
    746    40     6.55e-08     6.55e-08        3e-06
    746    48     2.64e-08     2.64e-08     2.41e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    746    10     2.75e-07     2.75e-07     5.78e-06
    746    20     2.58e-07     2.58e-07      6.1e-06
    746    30     4.23e-08     4.23e-08     3.21e-06
    746    40     1.97e-07     1.97e-07     6.75e-06
    746    50      7.4e-08      7.4e-08     3.21e-06
    746    60     1.16e-07     1.16e-07     5.14e-06
    746    61     1.99e-06     1.99e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             746 41077.629   0.0025     8.73e-08     8.73e-08     3.76e-06
! Validation        746 41077.629   0.0025     1.83e-07     1.83e-07     4.82e-06
Wall time: 41077.6301465
training
# Epoch batch         loss       loss_e      e/N_mae
    747    10     3.52e-08     3.52e-08     2.46e-06
    747    20     5.64e-08     5.64e-08     3.32e-06
    747    30     5.64e-08     5.64e-08     3.32e-06
    747    40     1.52e-07     1.52e-07      4.6e-06
    747    48     1.06e-08     1.06e-08     2.41e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    747    10     3.15e-07     3.15e-07     6.75e-06
    747    20     3.04e-07     3.04e-07     7.39e-06
    747    30     4.86e-08     4.86e-08     3.53e-06
    747    40     2.62e-07     2.62e-07     8.03e-06
    747    50     8.88e-08     8.88e-08     3.53e-06
    747    60     1.16e-07     1.16e-07     4.82e-06
    747    61     1.76e-06     1.76e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             747 41132.606   0.0025     9.38e-08     9.38e-08     3.92e-06
! Validation        747 41132.606   0.0025     1.79e-07     1.79e-07     4.92e-06
Wall time: 41132.606640000005
training
# Epoch batch         loss       loss_e      e/N_mae
    748    10     7.04e-08     7.04e-08     3.53e-06
    748    20     6.76e-08     6.76e-08     3.11e-06
    748    30     5.14e-08     5.14e-08     2.78e-06
    748    40     8.45e-08     8.45e-08     3.75e-06
    748    48     2.64e-08     2.64e-08     2.41e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    748    10     1.48e-07     1.48e-07      4.5e-06
    748    20     2.64e-07     2.64e-07     7.07e-06
    748    30     2.54e-08     2.54e-08     2.25e-06
    748    40     2.77e-07     2.77e-07     7.39e-06
    748    50     6.55e-08     6.55e-08     3.85e-06
    748    60     8.45e-08     8.45e-08     3.85e-06
    748    61     1.93e-06     1.93e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             748 41187.609   0.0025     7.87e-08     7.87e-08     3.64e-06
! Validation        748 41187.609   0.0025     1.73e-07     1.73e-07     4.83e-06
Wall time: 41187.610059416
training
# Epoch batch         loss       loss_e      e/N_mae
    749    10     9.65e-08     9.65e-08     4.39e-06
    749    20      1.2e-07      1.2e-07     4.93e-06
    749    30     1.07e-07     1.07e-07     4.71e-06
    749    40     1.27e-07     1.27e-07     4.82e-06
    749    48     4.76e-08     4.76e-08     2.41e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    749    10      1.5e-07      1.5e-07     4.82e-06
    749    20     1.73e-07     1.73e-07     5.46e-06
    749    30     2.96e-08     2.96e-08     3.21e-06
    749    40     2.49e-07     2.49e-07     8.03e-06
    749    50     7.19e-08     7.19e-08     3.53e-06
    749    60     6.55e-08     6.55e-08     3.53e-06
    749    61     1.73e-06     1.73e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             749 41242.696   0.0025     8.64e-08     8.64e-08     3.73e-06
! Validation        749 41242.696   0.0025     1.75e-07     1.75e-07     4.77e-06
Wall time: 41242.697523416005
training
# Epoch batch         loss       loss_e      e/N_mae
    750    10     1.28e-07     1.28e-07     4.82e-06
    750    20     9.79e-08     9.79e-08     4.28e-06
    750    30     5.07e-08     5.07e-08     2.57e-06
    750    40     5.14e-08     5.14e-08     2.89e-06
    750    48     8.45e-08     8.45e-08     3.21e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    750    10     2.07e-07     2.07e-07      4.5e-06
    750    20     1.73e-07     1.73e-07     5.46e-06
    750    30     1.48e-08     1.48e-08     2.25e-06
    750    40     2.54e-07     2.54e-07     8.03e-06
    750    50     2.96e-08     2.96e-08     2.25e-06
    750    60     2.96e-08     2.96e-08     1.93e-06
    750    61     1.63e-06     1.63e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             750 41297.571   0.0025     9.02e-08     9.02e-08     3.86e-06
! Validation        750 41297.571   0.0025     1.68e-07     1.68e-07     4.64e-06
Wall time: 41297.571048666
! Best model      750    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    751    10     6.27e-08     6.27e-08     3.53e-06
    751    20     1.27e-07     1.27e-07     4.39e-06
    751    30     7.19e-08     7.19e-08     3.53e-06
    751    40     3.66e-08     3.66e-08     2.14e-06
    751    48     8.98e-08     8.98e-08     4.02e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    751    10     1.94e-07     1.94e-07      4.5e-06
    751    20     1.73e-07     1.73e-07     5.46e-06
    751    30     1.48e-08     1.48e-08     2.25e-06
    751    40     2.68e-07     2.68e-07     7.71e-06
    751    50     9.72e-08     9.72e-08     3.53e-06
    751    60     4.02e-08     4.02e-08     2.89e-06
    751    61     1.33e-06     1.33e-06     1.55e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             751 41352.825   0.0025     9.25e-08     9.25e-08     3.82e-06
! Validation        751 41352.825   0.0025     1.66e-07     1.66e-07     4.76e-06
Wall time: 41352.826183041005
! Best model      751    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    752    10     4.93e-08     4.93e-08     3.21e-06
    752    20     2.67e-07     2.67e-07     6.42e-06
    752    30     1.18e-07     1.18e-07     4.39e-06
    752    40     1.06e-07     1.06e-07      4.5e-06
    752    48     5.28e-09     5.28e-09     8.03e-07
validation
# Epoch batch         loss       loss_e      e/N_mae
    752    10     2.47e-07     2.47e-07     5.46e-06
    752    20     1.92e-07     1.92e-07     5.14e-06
    752    30     3.17e-08     3.17e-08     2.57e-06
    752    40     2.01e-07     2.01e-07     5.46e-06
    752    50     5.28e-08     5.28e-08     3.21e-06
    752    60     5.07e-08     5.07e-08     3.21e-06
    752    61     1.28e-06     1.28e-06      1.5e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             752 41407.893   0.0025     1.18e-07     1.18e-07     4.35e-06
! Validation        752 41407.893   0.0025     1.65e-07     1.65e-07      4.7e-06
Wall time: 41407.894139083
! Best model      752    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    753    10        5e-08        5e-08     3.32e-06
    753    20     1.13e-07     1.13e-07     4.07e-06
    753    30     1.35e-07     1.35e-07     5.03e-06
    753    40     1.19e-07     1.19e-07     3.96e-06
    753    48     6.87e-08     6.87e-08     4.02e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    753    10      1.5e-07      1.5e-07     4.18e-06
    753    20     1.56e-07     1.56e-07      4.5e-06
    753    30      3.8e-08      3.8e-08     2.89e-06
    753    40     2.66e-07     2.66e-07     6.42e-06
    753    50     1.04e-07     1.04e-07      4.5e-06
    753    60     2.54e-08     2.54e-08     1.93e-06
    753    61     1.73e-06     1.73e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             753 41463.118   0.0025     9.98e-08     9.98e-08     3.99e-06
! Validation        753 41463.118   0.0025     1.79e-07     1.79e-07      4.8e-06
Wall time: 41463.119116666
training
# Epoch batch         loss       loss_e      e/N_mae
    754    10     1.04e-07     1.04e-07     4.18e-06
    754    20     1.49e-07     1.49e-07     4.39e-06
    754    30     7.75e-08     7.75e-08     4.07e-06
    754    40     6.34e-08     6.34e-08     3.43e-06
    754    48     4.23e-08     4.23e-08     3.21e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    754    10     1.27e-07     1.27e-07     3.85e-06
    754    20     1.97e-07     1.97e-07     5.14e-06
    754    30     3.38e-08     3.38e-08     3.53e-06
    754    40     2.43e-07     2.43e-07     7.07e-06
    754    50     4.44e-08     4.44e-08     2.57e-06
    754    60     1.48e-08     1.48e-08     1.61e-06
    754    61     1.93e-06     1.93e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             754 41518.262   0.0025     8.63e-08     8.63e-08     3.86e-06
! Validation        754 41518.262   0.0025     1.69e-07     1.69e-07      4.6e-06
Wall time: 41518.262053750004
training
# Epoch batch         loss       loss_e      e/N_mae
    755    10     7.19e-08     7.19e-08     3.53e-06
    755    20     1.36e-07     1.36e-07      4.5e-06
    755    30     1.63e-07     1.63e-07     4.39e-06
    755    40     5.49e-08     5.49e-08     3.32e-06
    755    48     8.45e-08     8.45e-08     3.21e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    755    10     1.35e-07     1.35e-07      4.5e-06
    755    20     2.24e-07     2.24e-07     4.82e-06
    755    30     3.17e-08     3.17e-08     2.89e-06
    755    40     2.18e-07     2.18e-07     7.07e-06
    755    50     2.96e-08     2.96e-08     2.89e-06
    755    60     4.02e-08     4.02e-08     2.25e-06
    755    61      1.7e-06      1.7e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             755 41573.158   0.0025     1.13e-07     1.13e-07     4.29e-06
! Validation        755 41573.158   0.0025     1.69e-07     1.69e-07      4.7e-06
Wall time: 41573.158671375
training
# Epoch batch         loss       loss_e      e/N_mae
    756    10     1.66e-07     1.66e-07     5.57e-06
    756    20     9.37e-08     9.37e-08     4.07e-06
    756    30     1.26e-07     1.26e-07      4.5e-06
    756    40     1.11e-07     1.11e-07     4.71e-06
    756    48     8.98e-08     8.98e-08     4.02e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    756    10     2.01e-07     2.01e-07     4.82e-06
    756    20     2.75e-07     2.75e-07     5.78e-06
    756    30     5.71e-08     5.71e-08     3.21e-06
    756    40     2.37e-07     2.37e-07     7.39e-06
    756    50      3.8e-08      3.8e-08     2.89e-06
    756    60     4.86e-08     4.86e-08     2.89e-06
    756    61     1.63e-06     1.63e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             756 41628.322   0.0025     1.01e-07     1.01e-07     4.07e-06
! Validation        756 41628.322   0.0025     1.67e-07     1.67e-07     4.59e-06
Wall time: 41628.322898333005
training
# Epoch batch         loss       loss_e      e/N_mae
    757    10     9.79e-08     9.79e-08      4.6e-06
    757    20     1.75e-07     1.75e-07     5.89e-06
    757    30     1.11e-07     1.11e-07      4.5e-06
    757    40     2.06e-07     2.06e-07      6.1e-06
    757    48     8.98e-08     8.98e-08     4.82e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    757    10     1.63e-07     1.63e-07     4.18e-06
    757    20     3.04e-07     3.04e-07     7.07e-06
    757    30      7.4e-08      7.4e-08     3.21e-06
    757    40     2.09e-07     2.09e-07     7.07e-06
    757    50     5.71e-08     5.71e-08     3.85e-06
    757    60     7.61e-08     7.61e-08     3.21e-06
    757    61     1.56e-06     1.56e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             757 41683.509   0.0025     1.27e-07     1.27e-07     4.54e-06
! Validation        757 41683.509   0.0025     1.72e-07     1.72e-07     4.79e-06
Wall time: 41683.509177166
training
# Epoch batch         loss       loss_e      e/N_mae
    758    10     5.85e-08     5.85e-08     3.11e-06
    758    20     1.21e-07     1.21e-07      4.6e-06
    758    30     5.35e-08     5.35e-08     2.89e-06
    758    40     3.95e-08     3.95e-08     2.78e-06
    758    48     2.11e-08     2.11e-08     1.61e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    758    10     2.58e-07     2.58e-07     5.78e-06
    758    20     2.18e-07     2.18e-07     5.78e-06
    758    30     8.24e-08     8.24e-08     4.18e-06
    758    40     3.02e-07     3.02e-07     8.35e-06
    758    50      3.8e-08      3.8e-08     2.89e-06
    758    60     4.65e-08     4.65e-08     2.57e-06
    758    61     1.56e-06     1.56e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             758 41738.644   0.0025     1.14e-07     1.14e-07     4.41e-06
! Validation        758 41738.644   0.0025     1.69e-07     1.69e-07      4.8e-06
Wall time: 41738.645109625
training
# Epoch batch         loss       loss_e      e/N_mae
    759    10      3.8e-08      3.8e-08     2.89e-06
    759    20     6.97e-08     6.97e-08     3.53e-06
    759    30     5.78e-08     5.78e-08        3e-06
    759    40     9.09e-08     9.09e-08     4.39e-06
    759    48     1.06e-08     1.06e-08     1.61e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    759    10     3.06e-07     3.06e-07      6.1e-06
    759    20     2.37e-07     2.37e-07     5.46e-06
    759    30     7.61e-08     7.61e-08      4.5e-06
    759    40     3.17e-07     3.17e-07     8.67e-06
    759    50     1.04e-07     1.04e-07     5.14e-06
    759    60     1.16e-07     1.16e-07     4.18e-06
    759    61     1.59e-06     1.59e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             759 41793.802   0.0025     7.97e-08     7.97e-08     3.71e-06
! Validation        759 41793.802   0.0025     1.78e-07     1.78e-07     4.89e-06
Wall time: 41793.801970416
training
# Epoch batch         loss       loss_e      e/N_mae
    760    10     9.16e-08     9.16e-08     4.07e-06
    760    20     6.27e-08     6.27e-08     3.11e-06
    760    30     1.23e-07     1.23e-07     4.93e-06
    760    40     5.85e-08     5.85e-08     3.53e-06
    760    48     2.64e-07     2.64e-07     6.42e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    760    10     2.26e-07     2.26e-07     4.82e-06
    760    20     2.11e-07     2.11e-07     5.46e-06
    760    30     9.09e-08     9.09e-08     4.18e-06
    760    40     3.19e-07     3.19e-07     8.35e-06
    760    50     8.24e-08     8.24e-08      4.5e-06
    760    60     7.19e-08     7.19e-08     3.21e-06
    760    61     1.68e-06     1.68e-06     1.55e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             760 41848.746   0.0025     8.93e-08     8.93e-08     3.74e-06
! Validation        760 41848.746   0.0025     1.72e-07     1.72e-07     4.77e-06
Wall time: 41848.747571875
training
# Epoch batch         loss       loss_e      e/N_mae
    761    10     1.32e-07     1.32e-07     5.46e-06
    761    20     1.09e-07     1.09e-07      4.5e-06
    761    30     7.54e-08     7.54e-08     3.64e-06
    761    40     9.37e-08     9.37e-08     4.39e-06
    761    48     7.19e-07     7.19e-07     1.37e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    761    10     2.41e-07     2.41e-07     5.14e-06
    761    20     2.11e-07     2.11e-07     5.46e-06
    761    30     8.24e-08     8.24e-08     4.82e-06
    761    40     2.16e-07     2.16e-07     7.39e-06
    761    50     2.54e-08     2.54e-08     2.25e-06
    761    60     7.82e-08     7.82e-08     3.85e-06
    761    61     1.27e-06     1.27e-06     1.45e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             761 41903.891   0.0025     1.34e-07     1.34e-07     4.51e-06
! Validation        761 41903.891   0.0025     1.62e-07     1.62e-07     4.69e-06
Wall time: 41903.891830875
! Best model      761    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    762    10     2.46e-07     2.46e-07     6.64e-06
    762    20     7.63e-07     7.63e-07     1.03e-05
    762    30     3.42e-07     3.42e-07      7.6e-06
    762    40     1.25e-07     1.25e-07     4.71e-06
    762    48     1.06e-08     1.06e-08     1.61e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    762    10     1.75e-07     1.75e-07     4.82e-06
    762    20     1.84e-07     1.84e-07     4.82e-06
    762    30      7.4e-08      7.4e-08     4.18e-06
    762    40        3e-07        3e-07     8.67e-06
    762    50     4.86e-08     4.86e-08     3.21e-06
    762    60     4.44e-08     4.44e-08     2.25e-06
    762    61     1.59e-06     1.59e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             762 41959.077   0.0025     3.31e-07     3.31e-07     7.37e-06
! Validation        762 41959.077   0.0025     1.66e-07     1.66e-07     4.68e-06
Wall time: 41959.077187
training
# Epoch batch         loss       loss_e      e/N_mae
    763    10     8.59e-08     8.59e-08     3.75e-06
    763    20     1.31e-07     1.31e-07      4.5e-06
    763    30      9.3e-08      9.3e-08     3.85e-06
    763    40     1.15e-07     1.15e-07     4.82e-06
    763    48     8.45e-08     8.45e-08     3.21e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    763    10      2.2e-07      2.2e-07     5.46e-06
    763    20     2.18e-07     2.18e-07      4.5e-06
    763    30     7.19e-08     7.19e-08     3.85e-06
    763    40      2.3e-07      2.3e-07     7.07e-06
    763    50     4.23e-08     4.23e-08     2.89e-06
    763    60     4.44e-08     4.44e-08     2.25e-06
    763    61     1.54e-06     1.54e-06      1.5e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             763 42014.183   0.0025     8.87e-08     8.87e-08     3.78e-06
! Validation        763 42014.183   0.0025     1.62e-07     1.62e-07     4.44e-06
Wall time: 42014.184534750006
! Best model      763    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    764    10     6.41e-08     6.41e-08     3.53e-06
    764    20      6.2e-08      6.2e-08     3.11e-06
    764    30     1.23e-07     1.23e-07     4.82e-06
    764    40     1.19e-07     1.19e-07     4.18e-06
    764    48     1.06e-08     1.06e-08     1.61e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    764    10     2.32e-07     2.32e-07      6.1e-06
    764    20     2.64e-07     2.64e-07     5.14e-06
    764    30     4.02e-08     4.02e-08     3.53e-06
    764    40     1.82e-07     1.82e-07     6.75e-06
    764    50     4.65e-08     4.65e-08     2.89e-06
    764    60     6.34e-08     6.34e-08     3.53e-06
    764    61     1.88e-06     1.88e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             764 42069.402   0.0025     1.01e-07     1.01e-07     4.09e-06
! Validation        764 42069.402   0.0025     1.64e-07     1.64e-07     4.55e-06
Wall time: 42069.40168425
training
# Epoch batch         loss       loss_e      e/N_mae
    765    10     7.47e-08     7.47e-08     3.53e-06
    765    20     5.85e-08     5.85e-08     3.32e-06
    765    30     3.17e-08     3.17e-08     2.14e-06
    765    40     8.95e-08     8.95e-08     4.39e-06
    765    48     5.28e-08     5.28e-08     3.21e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    765    10     2.45e-07     2.45e-07      6.1e-06
    765    20     2.87e-07     2.87e-07      6.1e-06
    765    30     2.32e-08     2.32e-08     2.89e-06
    765    40     2.05e-07     2.05e-07     7.07e-06
    765    50     1.48e-08     1.48e-08     1.93e-06
    765    60     7.82e-08     7.82e-08     3.53e-06
    765    61     2.16e-06     2.16e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             765 42124.338   0.0025     9.76e-08     9.76e-08     3.97e-06
! Validation        765 42124.338   0.0025     1.76e-07     1.76e-07     4.72e-06
Wall time: 42124.339098625
training
# Epoch batch         loss       loss_e      e/N_mae
    766    10     1.61e-07     1.61e-07     5.57e-06
    766    20     1.26e-07     1.26e-07     4.93e-06
    766    30     3.73e-08     3.73e-08     2.89e-06
    766    40     1.64e-07     1.64e-07     5.03e-06
    766    48     1.06e-08     1.06e-08     1.61e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    766    10      1.5e-07      1.5e-07     5.14e-06
    766    20     2.83e-07     2.83e-07      6.1e-06
    766    30     7.19e-08     7.19e-08     4.82e-06
    766    40        3e-07        3e-07     8.67e-06
    766    50     7.82e-08     7.82e-08     3.85e-06
    766    60     7.19e-08     7.19e-08     4.18e-06
    766    61     1.89e-06     1.89e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             766 42179.366   0.0025      1.2e-07      1.2e-07     4.48e-06
! Validation        766 42179.366   0.0025     1.69e-07     1.69e-07     4.67e-06
Wall time: 42179.366152541
training
# Epoch batch         loss       loss_e      e/N_mae
    767    10     1.67e-07     1.67e-07     5.25e-06
    767    20     1.05e-07     1.05e-07     4.07e-06
    767    30     8.24e-08     8.24e-08     4.07e-06
    767    40     5.92e-08     5.92e-08     3.32e-06
    767    48     1.32e-07     1.32e-07     4.02e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    767    10     3.38e-07     3.38e-07     6.42e-06
    767    20     2.62e-07     2.62e-07     5.14e-06
    767    30     5.71e-08     5.71e-08     3.21e-06
    767    40     2.77e-07     2.77e-07     8.35e-06
    767    50     3.17e-08     3.17e-08     2.25e-06
    767    60     5.07e-08     5.07e-08     3.53e-06
    767    61     2.05e-06     2.05e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             767 42234.489   0.0025      1.3e-07      1.3e-07     4.51e-06
! Validation        767 42234.489   0.0025     1.72e-07     1.72e-07     4.65e-06
Wall time: 42234.490241375
training
# Epoch batch         loss       loss_e      e/N_mae
    768    10     1.38e-07     1.38e-07     5.57e-06
    768    20     1.28e-07     1.28e-07     5.57e-06
    768    30     1.23e-07     1.23e-07     4.39e-06
    768    40      3.8e-08      3.8e-08     2.36e-06
    768    48     1.53e-07     1.53e-07     5.62e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    768    10     2.28e-07     2.28e-07     5.14e-06
    768    20      2.6e-07      2.6e-07     4.82e-06
    768    30     5.71e-08     5.71e-08     3.21e-06
    768    40     2.73e-07     2.73e-07     8.35e-06
    768    50     4.86e-08     4.86e-08     3.21e-06
    768    60     3.17e-08     3.17e-08     2.25e-06
    768    61     1.88e-06     1.88e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             768 42289.510   0.0025     1.37e-07     1.37e-07     4.81e-06
! Validation        768 42289.510   0.0025     1.68e-07     1.68e-07     4.68e-06
Wall time: 42289.510725625005
training
# Epoch batch         loss       loss_e      e/N_mae
    769    10     1.29e-07     1.29e-07     4.71e-06
    769    20     8.03e-08     8.03e-08     3.64e-06
    769    30     1.16e-07     1.16e-07     4.28e-06
    769    40     1.42e-07     1.42e-07      4.6e-06
    769    48     1.32e-07     1.32e-07     5.62e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    769    10     2.41e-07     2.41e-07     5.78e-06
    769    20     2.92e-07     2.92e-07     5.78e-06
    769    30     3.17e-08     3.17e-08     2.57e-06
    769    40      2.3e-07      2.3e-07     7.71e-06
    769    50     2.75e-08     2.75e-08     1.61e-06
    769    60     7.61e-08     7.61e-08     3.21e-06
    769    61     1.55e-06     1.55e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             769 42344.411   0.0025     1.09e-07     1.09e-07     4.42e-06
! Validation        769 42344.411   0.0025     1.63e-07     1.63e-07     4.49e-06
Wall time: 42344.411170625004
training
# Epoch batch         loss       loss_e      e/N_mae
    770    10      8.1e-08      8.1e-08     4.18e-06
    770    20     5.57e-08     5.57e-08     3.32e-06
    770    30     8.03e-08     8.03e-08     3.32e-06
    770    40     8.52e-08     8.52e-08     3.75e-06
    770    48     4.23e-08     4.23e-08     3.21e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    770    10     2.71e-07     2.71e-07     5.78e-06
    770    20     1.82e-07     1.82e-07      4.5e-06
    770    30      3.8e-08      3.8e-08     2.89e-06
    770    40     2.05e-07     2.05e-07     7.07e-06
    770    50     3.59e-08     3.59e-08     2.57e-06
    770    60      9.3e-08      9.3e-08     4.82e-06
    770    61     1.57e-06     1.57e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             770 42399.617   0.0025     9.35e-08     9.35e-08     4.03e-06
! Validation        770 42399.617   0.0025     1.61e-07     1.61e-07     4.52e-06
Wall time: 42399.618653916004
! Best model      770    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    771    10     8.03e-08     8.03e-08     3.75e-06
    771    20     8.88e-08     8.88e-08     3.85e-06
    771    30     6.97e-08     6.97e-08     3.11e-06
    771    40     9.09e-08     9.09e-08     3.64e-06
    771    48     2.11e-08     2.11e-08     1.61e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    771    10     3.06e-07     3.06e-07     6.75e-06
    771    20      2.3e-07      2.3e-07      6.1e-06
    771    30     1.48e-08     1.48e-08     2.25e-06
    771    40     1.99e-07     1.99e-07     6.75e-06
    771    50      3.8e-08      3.8e-08     2.89e-06
    771    60     1.31e-07     1.31e-07     4.82e-06
    771    61     1.74e-06     1.74e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             771 42454.738   0.0025     8.48e-08     8.48e-08     3.83e-06
! Validation        771 42454.738   0.0025     1.69e-07     1.69e-07     4.52e-06
Wall time: 42454.738706541
training
# Epoch batch         loss       loss_e      e/N_mae
    772    10      4.3e-08      4.3e-08     2.78e-06
    772    20      3.8e-08      3.8e-08     2.68e-06
    772    30     1.12e-07     1.12e-07     5.35e-06
    772    40      9.3e-08      9.3e-08     3.96e-06
    772    48     1.06e-08     1.06e-08     1.61e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    772    10     2.83e-07     2.83e-07     5.78e-06
    772    20     1.99e-07     1.99e-07     6.42e-06
    772    30      3.8e-08      3.8e-08     2.89e-06
    772    40     2.32e-07     2.32e-07     7.39e-06
    772    50     4.23e-08     4.23e-08     2.89e-06
    772    60     1.01e-07     1.01e-07     4.82e-06
    772    61     1.78e-06     1.78e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             772 42509.739   0.0025     1.42e-07     1.42e-07     4.64e-06
! Validation        772 42509.739   0.0025     1.68e-07     1.68e-07     4.61e-06
Wall time: 42509.740448666
training
# Epoch batch         loss       loss_e      e/N_mae
    773    10     2.11e-07     2.11e-07     5.46e-06
    773    20     7.12e-08     7.12e-08     3.85e-06
    773    30     2.09e-07     2.09e-07     4.71e-06
    773    40     7.68e-08     7.68e-08     3.43e-06
    773    48     5.28e-08     5.28e-08     3.21e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    773    10     2.56e-07     2.56e-07     5.46e-06
    773    20     2.18e-07     2.18e-07      6.1e-06
    773    30     4.65e-08     4.65e-08     3.85e-06
    773    40     1.73e-07     1.73e-07     5.78e-06
    773    50      3.8e-08      3.8e-08     2.89e-06
    773    60     1.01e-07     1.01e-07     4.82e-06
    773    61     1.93e-06     1.93e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             773 42564.902   0.0025     1.21e-07     1.21e-07     4.32e-06
! Validation        773 42564.902   0.0025     1.68e-07     1.68e-07     4.63e-06
Wall time: 42564.902696583005
training
# Epoch batch         loss       loss_e      e/N_mae
    774    10     2.54e-08     2.54e-08     2.03e-06
    774    20     1.38e-07     1.38e-07     5.35e-06
    774    30     1.45e-07     1.45e-07     5.25e-06
    774    40     1.09e-07     1.09e-07     4.39e-06
    774    48     1.06e-08     1.06e-08     1.61e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    774    10     2.81e-07     2.81e-07      6.1e-06
    774    20      2.2e-07      2.2e-07     6.75e-06
    774    30     6.13e-08     6.13e-08     4.18e-06
    774    40     1.71e-07     1.71e-07     6.42e-06
    774    50     4.44e-08     4.44e-08     2.57e-06
    774    60     5.07e-08     5.07e-08     3.21e-06
    774    61     1.69e-06     1.69e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             774 42619.957   0.0025     1.16e-07     1.16e-07     4.36e-06
! Validation        774 42619.957   0.0025     1.62e-07     1.62e-07     4.55e-06
Wall time: 42619.957143375
training
# Epoch batch         loss       loss_e      e/N_mae
    775    10     2.23e-07     2.23e-07     6.32e-06
    775    20     5.57e-08     5.57e-08     3.11e-06
    775    30     2.71e-07     2.71e-07     5.78e-06
    775    40     1.83e-07     1.83e-07     5.46e-06
    775    48     1.06e-08     1.06e-08     1.61e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    775    10     2.94e-07     2.94e-07     6.75e-06
    775    20      2.3e-07      2.3e-07     7.07e-06
    775    30     4.86e-08     4.86e-08     3.53e-06
    775    40     1.59e-07     1.59e-07     6.42e-06
    775    50     1.04e-07     1.04e-07      4.5e-06
    775    60     5.92e-08     5.92e-08     3.21e-06
    775    61      1.4e-06      1.4e-06      1.5e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             775 42675.039   0.0025     1.08e-07     1.08e-07     4.23e-06
! Validation        775 42675.039   0.0025     1.59e-07     1.59e-07     4.56e-06
Wall time: 42675.040531875005
! Best model      775    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    776    10     1.25e-07     1.25e-07      4.5e-06
    776    20     8.38e-08     8.38e-08     3.75e-06
    776    30     1.13e-07     1.13e-07      4.5e-06
    776    40     1.39e-07     1.39e-07     5.57e-06
    776    48     2.64e-08     2.64e-08     2.41e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    776    10     2.51e-07     2.51e-07     5.78e-06
    776    20      2.3e-07      2.3e-07     6.75e-06
    776    30     2.32e-08     2.32e-08     1.93e-06
    776    40     1.46e-07     1.46e-07     5.46e-06
    776    50     1.16e-07     1.16e-07      4.5e-06
    776    60     4.65e-08     4.65e-08     3.21e-06
    776    61      1.5e-06      1.5e-06      1.5e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             776 42730.094   0.0025     9.16e-08     9.16e-08     3.99e-06
! Validation        776 42730.094   0.0025     1.63e-07     1.63e-07     4.55e-06
Wall time: 42730.095066541006
training
# Epoch batch         loss       loss_e      e/N_mae
    777    10     6.97e-08     6.97e-08     3.21e-06
    777    20     7.61e-08     7.61e-08     3.85e-06
    777    30     7.12e-08     7.12e-08     3.53e-06
    777    40     3.52e-08     3.52e-08     2.36e-06
    777    48     8.98e-08     8.98e-08     4.82e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    777    10     2.43e-07     2.43e-07     5.46e-06
    777    20     2.11e-07     2.11e-07     6.42e-06
    777    30     5.71e-08     5.71e-08     3.53e-06
    777    40     1.23e-07     1.23e-07     5.14e-06
    777    50     9.51e-08     9.51e-08     3.85e-06
    777    60     4.02e-08     4.02e-08     2.89e-06
    777    61      1.5e-06      1.5e-06     1.45e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             777 42785.300   0.0025     9.75e-08     9.75e-08        4e-06
! Validation        777 42785.300   0.0025     1.65e-07     1.65e-07     4.59e-06
Wall time: 42785.301022708
training
# Epoch batch         loss       loss_e      e/N_mae
    778    10     4.58e-08     4.58e-08     2.78e-06
    778    20     2.85e-07     2.85e-07     7.07e-06
    778    30     1.44e-07     1.44e-07     4.82e-06
    778    40     2.27e-07     2.27e-07      6.1e-06
    778    48     2.11e-07     2.11e-07     7.23e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    778    10     2.07e-07     2.07e-07      4.5e-06
    778    20     1.67e-07     1.67e-07     5.14e-06
    778    30     2.54e-08     2.54e-08     2.57e-06
    778    40     9.93e-08     9.93e-08     4.82e-06
    778    50     1.42e-07     1.42e-07     5.14e-06
    778    60     2.32e-08     2.32e-08     2.25e-06
    778    61     1.73e-06     1.73e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             778 42840.321   0.0025     1.55e-07     1.55e-07     5.06e-06
! Validation        778 42840.321   0.0025     1.65e-07     1.65e-07     4.51e-06
Wall time: 42840.322083291
training
# Epoch batch         loss       loss_e      e/N_mae
    779    10     9.72e-08     9.72e-08     4.07e-06
    779    20     1.42e-07     1.42e-07     5.46e-06
    779    30     4.17e-07     4.17e-07      7.5e-06
    779    40     5.24e-07     5.24e-07     8.25e-06
    779    48      1.8e-07      1.8e-07     7.23e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    779    10     3.11e-07     3.11e-07     5.46e-06
    779    20     1.56e-07     1.56e-07     5.78e-06
    779    30     4.02e-08     4.02e-08     3.85e-06
    779    40     8.88e-08     8.88e-08     3.85e-06
    779    50     1.46e-07     1.46e-07     5.14e-06
    779    60     6.97e-08     6.97e-08     3.53e-06
    779    61     1.24e-06     1.24e-06     1.45e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             779 42895.433   0.0025     2.21e-07     2.21e-07     5.96e-06
! Validation        779 42895.433   0.0025     1.56e-07     1.56e-07     4.55e-06
Wall time: 42895.433608
! Best model      779    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    780    10     2.23e-07     2.23e-07     5.78e-06
    780    20     1.32e-07     1.32e-07     4.93e-06
    780    30     6.06e-08     6.06e-08     3.64e-06
    780    40     1.88e-07     1.88e-07     5.89e-06
    780    48     2.64e-08     2.64e-08     2.41e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    780    10     2.39e-07     2.39e-07     5.14e-06
    780    20     1.42e-07     1.42e-07     5.14e-06
    780    30     5.07e-08     5.07e-08     4.18e-06
    780    40      1.5e-07      1.5e-07     5.46e-06
    780    50     1.27e-07     1.27e-07     4.82e-06
    780    60     7.61e-08     7.61e-08     3.85e-06
    780    61      1.4e-06      1.4e-06      1.5e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             780 42950.676   0.0025     1.69e-07     1.69e-07     5.24e-06
! Validation        780 42950.676   0.0025     1.57e-07     1.57e-07     4.47e-06
Wall time: 42950.67656125
training
# Epoch batch         loss       loss_e      e/N_mae
    781    10     8.88e-08     8.88e-08     3.75e-06
    781    20     8.45e-08     8.45e-08     3.75e-06
    781    30     9.23e-08     9.23e-08     4.07e-06
    781    40     1.02e-07     1.02e-07     4.39e-06
    781    48     8.98e-08     8.98e-08     4.82e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    781    10     2.35e-07     2.35e-07     5.46e-06
    781    20     1.63e-07     1.63e-07     5.14e-06
    781    30     4.86e-08     4.86e-08     3.85e-06
    781    40     1.67e-07     1.67e-07     5.46e-06
    781    50     1.18e-07     1.18e-07     4.82e-06
    781    60     8.03e-08     8.03e-08     3.85e-06
    781    61     1.54e-06     1.54e-06      1.5e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             781 43005.434   0.0025     1.27e-07     1.27e-07     4.51e-06
! Validation        781 43005.434   0.0025     1.59e-07     1.59e-07     4.55e-06
Wall time: 43005.43470125
training
# Epoch batch         loss       loss_e      e/N_mae
    782    10        1e-07        1e-07     3.96e-06
    782    20     1.44e-07     1.44e-07     4.82e-06
    782    30     2.64e-07     2.64e-07     7.17e-06
    782    40     1.17e-07     1.17e-07     4.71e-06
    782    48     2.64e-08     2.64e-08     2.41e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    782    10     1.99e-07     1.99e-07     5.14e-06
    782    20     2.13e-07     2.13e-07     5.46e-06
    782    30     4.44e-08     4.44e-08     3.53e-06
    782    40     1.65e-07     1.65e-07     5.78e-06
    782    50     9.09e-08     9.09e-08     3.85e-06
    782    60     9.72e-08     9.72e-08     3.85e-06
    782    61     1.64e-06     1.64e-06     1.55e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             782 43060.546   0.0025     2.19e-07     2.19e-07     5.95e-06
! Validation        782 43060.546   0.0025     1.67e-07     1.67e-07     4.58e-06
Wall time: 43060.546217625
training
# Epoch batch         loss       loss_e      e/N_mae
    783    10     2.05e-07     2.05e-07     6.75e-06
    783    20      1.5e-07      1.5e-07     5.35e-06
    783    30     8.17e-08     8.17e-08     3.64e-06
    783    40     1.28e-07     1.28e-07     5.03e-06
    783    48     5.28e-09     5.28e-09     8.03e-07
validation
# Epoch batch         loss       loss_e      e/N_mae
    783    10     2.71e-07     2.71e-07     6.42e-06
    783    20     1.39e-07     1.39e-07      4.5e-06
    783    30     2.96e-08     2.96e-08     2.25e-06
    783    40      1.9e-07      1.9e-07     6.42e-06
    783    50     6.13e-08     6.13e-08     2.57e-06
    783    60     7.82e-08     7.82e-08     3.53e-06
    783    61     1.62e-06     1.62e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             783 43115.811   0.0025     1.29e-07     1.29e-07     4.78e-06
! Validation        783 43115.811   0.0025      1.6e-07      1.6e-07     4.41e-06
Wall time: 43115.811518708004
training
# Epoch batch         loss       loss_e      e/N_mae
    784    10     1.07e-07     1.07e-07     4.07e-06
    784    20      1.1e-07      1.1e-07     4.18e-06
    784    30     9.09e-08     9.09e-08     3.43e-06
    784    40     8.66e-08     8.66e-08     3.53e-06
    784    48     4.76e-08     4.76e-08     2.41e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    784    10     2.16e-07     2.16e-07     5.14e-06
    784    20     1.27e-07     1.27e-07      4.5e-06
    784    30     4.02e-08     4.02e-08     3.85e-06
    784    40     1.48e-07     1.48e-07     5.14e-06
    784    50     4.65e-08     4.65e-08     2.89e-06
    784    60     5.28e-08     5.28e-08     3.53e-06
    784    61     1.36e-06     1.36e-06     1.39e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             784 43170.819   0.0025     1.03e-07     1.03e-07     4.08e-06
! Validation        784 43170.819   0.0025     1.57e-07     1.57e-07     4.55e-06
Wall time: 43170.819610666
training
# Epoch batch         loss       loss_e      e/N_mae
    785    10     1.13e-07     1.13e-07     3.64e-06
    785    20     1.51e-07     1.51e-07     4.82e-06
    785    30      7.8e-07      7.8e-07     1.07e-05
    785    40     6.83e-08     6.83e-08     3.53e-06
    785    48     1.53e-07     1.53e-07     6.42e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    785    10     3.42e-07     3.42e-07     6.42e-06
    785    20     1.78e-07     1.78e-07      4.5e-06
    785    30     2.32e-08     2.32e-08     3.21e-06
    785    40     1.99e-07     1.99e-07     6.42e-06
    785    50     7.19e-08     7.19e-08     3.53e-06
    785    60     5.92e-08     5.92e-08     3.21e-06
    785    61     1.81e-06     1.81e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             785 43226.068   0.0025     2.63e-07     2.63e-07      6.4e-06
! Validation        785 43226.068   0.0025     1.61e-07     1.61e-07     4.53e-06
Wall time: 43226.068493291
training
# Epoch batch         loss       loss_e      e/N_mae
    786    10      2.9e-07      2.9e-07     6.96e-06
    786    20     4.47e-07     4.47e-07     8.99e-06
    786    30     1.44e-07     1.44e-07     4.82e-06
    786    40      1.8e-07      1.8e-07     4.82e-06
    786    48     9.51e-07     9.51e-07     1.53e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    786    10     1.67e-07     1.67e-07      6.1e-06
    786    20     1.84e-07     1.84e-07     4.82e-06
    786    30     2.75e-08     2.75e-08     2.57e-06
    786    40     1.59e-07     1.59e-07     5.46e-06
    786    50      3.8e-08      3.8e-08     2.89e-06
    786    60     8.45e-08     8.45e-08     3.85e-06
    786    61      1.4e-06      1.4e-06      1.5e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             786 43280.789   0.0025     4.07e-07     4.07e-07     7.37e-06
! Validation        786 43280.789   0.0025     1.51e-07     1.51e-07     4.37e-06
Wall time: 43280.78932525
! Best model      786    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    787    10     2.91e-07     2.91e-07     7.07e-06
    787    20     8.74e-08     8.74e-08     4.39e-06
    787    30     1.16e-07     1.16e-07     4.71e-06
    787    40     5.18e-07     5.18e-07     9.74e-06
    787    48     2.11e-07     2.11e-07     6.42e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    787    10     2.32e-07     2.32e-07     6.75e-06
    787    20     2.07e-07     2.07e-07     5.14e-06
    787    30     4.44e-08     4.44e-08     3.53e-06
    787    40     1.46e-07     1.46e-07     5.46e-06
    787    50     6.55e-08     6.55e-08     3.85e-06
    787    60     1.06e-07     1.06e-07     3.85e-06
    787    61     1.78e-06     1.78e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             787 43335.811   0.0025     3.14e-07     3.14e-07     7.02e-06
! Validation        787 43335.811   0.0025     1.65e-07     1.65e-07     4.57e-06
Wall time: 43335.812676875
training
# Epoch batch         loss       loss_e      e/N_mae
    788    10     4.26e-07     4.26e-07     8.78e-06
    788    20     2.35e-07     2.35e-07     5.89e-06
    788    30     1.03e-07     1.03e-07     4.07e-06
    788    40     2.97e-07     2.97e-07     6.96e-06
    788    48     3.22e-07     3.22e-07     9.64e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    788    10     3.61e-07     3.61e-07     7.71e-06
    788    20     2.18e-07     2.18e-07     5.78e-06
    788    30     6.34e-09     6.34e-09     1.61e-06
    788    40      1.8e-07      1.8e-07      6.1e-06
    788    50     6.97e-08     6.97e-08     3.85e-06
    788    60     8.24e-08     8.24e-08     3.53e-06
    788    61     1.88e-06     1.88e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             788 43390.938   0.0025     3.46e-07     3.46e-07     7.21e-06
! Validation        788 43390.938   0.0025     1.68e-07     1.68e-07     4.55e-06
Wall time: 43390.938546291
training
# Epoch batch         loss       loss_e      e/N_mae
    789    10     2.91e-07     2.91e-07     7.71e-06
    789    20     1.07e-07     1.07e-07     4.39e-06
    789    30     1.03e-07     1.03e-07      4.6e-06
    789    40     1.54e-07     1.54e-07      4.6e-06
    789    48     1.06e-07     1.06e-07     4.82e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    789    10     3.09e-07     3.09e-07     6.75e-06
    789    20     1.31e-07     1.31e-07      4.5e-06
    789    30      3.8e-08      3.8e-08     3.53e-06
    789    40     1.61e-07     1.61e-07      6.1e-06
    789    50     1.29e-07     1.29e-07      4.5e-06
    789    60     4.44e-08     4.44e-08     2.25e-06
    789    61     1.91e-06     1.91e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             789 43446.024   0.0025     1.43e-07     1.43e-07      4.9e-06
! Validation        789 43446.024   0.0025      1.7e-07      1.7e-07     4.52e-06
Wall time: 43446.024998458
training
# Epoch batch         loss       loss_e      e/N_mae
    790    10     1.32e-07     1.32e-07     5.14e-06
    790    20     1.55e-07     1.55e-07     4.93e-06
    790    30     1.67e-07     1.67e-07     5.68e-06
    790    40     6.55e-08     6.55e-08     3.53e-06
    790    48     5.28e-09     5.28e-09     8.03e-07
validation
# Epoch batch         loss       loss_e      e/N_mae
    790    10     2.05e-07     2.05e-07     5.46e-06
    790    20     1.46e-07     1.46e-07     4.18e-06
    790    30     4.02e-08     4.02e-08     2.89e-06
    790    40     1.16e-07     1.16e-07     4.82e-06
    790    50      7.4e-08      7.4e-08     3.85e-06
    790    60     2.11e-08     2.11e-08     1.93e-06
    790    61     1.89e-06     1.89e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             790 43501.067   0.0025     1.77e-07     1.77e-07     5.35e-06
! Validation        790 43501.067   0.0025     1.72e-07     1.72e-07     4.66e-06
Wall time: 43501.067870958
training
# Epoch batch         loss       loss_e      e/N_mae
    791    10     3.31e-07     3.31e-07     6.85e-06
    791    20     1.69e-07     1.69e-07     6.21e-06
    791    30     1.04e-07     1.04e-07      4.6e-06
    791    40     1.39e-07     1.39e-07     5.25e-06
    791    48     1.95e-07     1.95e-07     6.42e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    791    10     2.16e-07     2.16e-07     5.14e-06
    791    20     1.63e-07     1.63e-07     4.82e-06
    791    30      1.9e-08      1.9e-08     1.93e-06
    791    40     2.03e-07     2.03e-07     6.42e-06
    791    50     9.72e-08     9.72e-08     4.82e-06
    791    60     4.02e-08     4.02e-08     2.89e-06
    791    61     1.67e-06     1.67e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             791 43555.860   0.0025     1.66e-07     1.66e-07     4.99e-06
! Validation        791 43555.860   0.0025     1.64e-07     1.64e-07     4.61e-06
Wall time: 43555.860551041005
training
# Epoch batch         loss       loss_e      e/N_mae
    792    10     1.37e-07     1.37e-07     5.35e-06
    792    20     1.61e-07     1.61e-07     5.25e-06
    792    30     7.96e-08     7.96e-08     3.75e-06
    792    40     1.22e-07     1.22e-07     4.28e-06
    792    48     5.28e-08     5.28e-08     3.21e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    792    10      2.2e-07      2.2e-07      6.1e-06
    792    20      1.2e-07      1.2e-07     4.18e-06
    792    30     1.48e-08     1.48e-08     1.93e-06
    792    40     1.99e-07     1.99e-07     6.75e-06
    792    50     6.34e-08     6.34e-08     3.53e-06
    792    60     8.24e-08     8.24e-08     4.18e-06
    792    61     1.73e-06     1.73e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             792 43611.013   0.0025     1.15e-07     1.15e-07     4.26e-06
! Validation        792 43611.013   0.0025     1.64e-07     1.64e-07     4.52e-06
Wall time: 43611.013757875
training
# Epoch batch         loss       loss_e      e/N_mae
    793    10     1.85e-07     1.85e-07     5.57e-06
    793    20     2.77e-07     2.77e-07     6.85e-06
    793    30     1.63e-07     1.63e-07     5.89e-06
    793    40     1.37e-07     1.37e-07     5.03e-06
    793    48     5.28e-09     5.28e-09     8.03e-07
validation
# Epoch batch         loss       loss_e      e/N_mae
    793    10     2.09e-07     2.09e-07     5.46e-06
    793    20      1.8e-07      1.8e-07     5.78e-06
    793    30     4.02e-08     4.02e-08     3.21e-06
    793    40     2.13e-07     2.13e-07     6.75e-06
    793    50     5.28e-08     5.28e-08     3.21e-06
    793    60     7.82e-08     7.82e-08     3.53e-06
    793    61     2.22e-06     2.22e-06     1.87e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             793 43666.025   0.0025     1.94e-07     1.94e-07     5.54e-06
! Validation        793 43666.025   0.0025     1.71e-07     1.71e-07     4.46e-06
Wall time: 43666.025599125
training
# Epoch batch         loss       loss_e      e/N_mae
    794    10     1.63e-07     1.63e-07     4.93e-06
    794    20      1.1e-07      1.1e-07     3.43e-06
    794    30     1.31e-07     1.31e-07     4.82e-06
    794    40     1.45e-07     1.45e-07     4.93e-06
    794    48     6.87e-08     6.87e-08     4.02e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    794    10     1.56e-07     1.56e-07     3.85e-06
    794    20     1.59e-07     1.59e-07     4.82e-06
    794    30     4.44e-08     4.44e-08     2.57e-06
    794    40      1.8e-07      1.8e-07      6.1e-06
    794    50     6.76e-08     6.76e-08     4.18e-06
    794    60     5.92e-08     5.92e-08     3.21e-06
    794    61     2.06e-06     2.06e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             794 43721.081   0.0025     1.26e-07     1.26e-07     4.61e-06
! Validation        794 43721.081   0.0025     1.66e-07     1.66e-07     4.32e-06
Wall time: 43721.081653166
training
# Epoch batch         loss       loss_e      e/N_mae
    795    10     3.59e-07     3.59e-07     7.39e-06
    795    20     1.45e-07     1.45e-07     4.93e-06
    795    30     9.93e-08     9.93e-08     4.28e-06
    795    40     9.79e-08     9.79e-08     3.85e-06
    795    48     1.53e-07     1.53e-07     5.62e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    795    10     2.43e-07     2.43e-07     5.46e-06
    795    20     2.01e-07     2.01e-07     5.46e-06
    795    30     4.86e-08     4.86e-08     3.21e-06
    795    40     1.39e-07     1.39e-07     5.14e-06
    795    50     6.34e-08     6.34e-08     3.53e-06
    795    60     1.48e-08     1.48e-08     1.61e-06
    795    61     1.85e-06     1.85e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             795 43776.432   0.0025      1.7e-07      1.7e-07     5.38e-06
! Validation        795 43776.432   0.0025     1.68e-07     1.68e-07     4.39e-06
Wall time: 43776.433129833
training
# Epoch batch         loss       loss_e      e/N_mae
    796    10     1.87e-07     1.87e-07     5.78e-06
    796    20     1.01e-07     1.01e-07      4.5e-06
    796    30        2e-07        2e-07        6e-06
    796    40     1.05e-07     1.05e-07     4.39e-06
    796    48     4.23e-08     4.23e-08     3.21e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    796    10     2.81e-07     2.81e-07      6.1e-06
    796    20     1.86e-07     1.86e-07     4.82e-06
    796    30     5.28e-08     5.28e-08     3.21e-06
    796    40     8.45e-08     8.45e-08     3.85e-06
    796    50     5.49e-08     5.49e-08     2.89e-06
    796    60     1.48e-08     1.48e-08     1.61e-06
    796    61     1.94e-06     1.94e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             796 43831.339   0.0025     1.46e-07     1.46e-07     4.82e-06
! Validation        796 43831.339   0.0025     1.69e-07     1.69e-07     4.47e-06
Wall time: 43831.340456083
training
# Epoch batch         loss       loss_e      e/N_mae
    797    10     4.02e-08     4.02e-08     2.89e-06
    797    20     1.64e-07     1.64e-07      6.1e-06
    797    30     3.24e-07     3.24e-07     8.03e-06
    797    40     3.58e-07     3.58e-07     8.35e-06
    797    48     6.39e-07     6.39e-07     1.04e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    797    10      2.6e-07      2.6e-07     6.42e-06
    797    20     1.88e-07     1.88e-07      4.5e-06
    797    30     2.11e-08     2.11e-08     2.57e-06
    797    40     1.31e-07     1.31e-07     5.14e-06
    797    50     6.76e-08     6.76e-08     4.18e-06
    797    60     9.09e-08     9.09e-08     4.18e-06
    797    61     1.99e-06     1.99e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             797 43886.616   0.0025     2.84e-07     2.84e-07     6.73e-06
! Validation        797 43886.616   0.0025     1.69e-07     1.69e-07     4.51e-06
Wall time: 43886.616880416004
training
# Epoch batch         loss       loss_e      e/N_mae
    798    10     2.01e-07     2.01e-07        6e-06
    798    20     1.13e-07     1.13e-07     4.28e-06
    798    30     8.52e-08     8.52e-08     4.39e-06
    798    40     2.29e-07     2.29e-07     7.07e-06
    798    48     6.39e-07     6.39e-07     9.64e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    798    10     2.62e-07     2.62e-07     5.78e-06
    798    20     2.24e-07     2.24e-07     4.82e-06
    798    30     6.34e-08     6.34e-08     2.89e-06
    798    40     2.24e-07     2.24e-07     6.42e-06
    798    50     1.14e-07     1.14e-07     5.46e-06
    798    60     8.88e-08     8.88e-08      4.5e-06
    798    61     1.73e-06     1.73e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             798 43941.624   0.0025     2.42e-07     2.42e-07     6.18e-06
! Validation        798 43941.624   0.0025     1.74e-07     1.74e-07     4.71e-06
Wall time: 43941.623960833
training
# Epoch batch         loss       loss_e      e/N_mae
    799    10     1.54e-07     1.54e-07     5.14e-06
    799    20     4.88e-07     4.88e-07     1.03e-05
    799    30     2.07e-07     2.07e-07     5.68e-06
    799    40     1.09e-07     1.09e-07     4.28e-06
    799    48     1.69e-07     1.69e-07     6.42e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    799    10     2.26e-07     2.26e-07     6.75e-06
    799    20      2.2e-07      2.2e-07      6.1e-06
    799    30     4.23e-08     4.23e-08     2.89e-06
    799    40     1.63e-07     1.63e-07     5.46e-06
    799    50     4.86e-08     4.86e-08     3.21e-06
    799    60     1.16e-07     1.16e-07     4.18e-06
    799    61     1.33e-06     1.33e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             799 43996.644   0.0025     3.13e-07     3.13e-07     7.08e-06
! Validation        799 43996.644   0.0025     1.53e-07     1.53e-07     4.39e-06
Wall time: 43996.6453015
training
# Epoch batch         loss       loss_e      e/N_mae
    800    10     2.24e-07     2.24e-07     6.21e-06
    800    20     2.48e-07     2.48e-07     7.17e-06
    800    30     1.24e-07     1.24e-07     4.18e-06
    800    40     1.15e-07     1.15e-07     4.71e-06
    800    48     2.17e-07     2.17e-07     7.23e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    800    10      2.6e-07      2.6e-07     6.42e-06
    800    20     1.82e-07     1.82e-07     5.46e-06
    800    30     1.69e-08     1.69e-08     2.57e-06
    800    40     1.73e-07     1.73e-07     5.78e-06
    800    50     5.07e-08     5.07e-08     3.53e-06
    800    60     4.23e-08     4.23e-08     2.57e-06
    800    61     1.67e-06     1.67e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             800 44051.890   0.0025     2.09e-07     2.09e-07     6.01e-06
! Validation        800 44051.890   0.0025     1.74e-07     1.74e-07     4.64e-06
Wall time: 44051.890779916
training
# Epoch batch         loss       loss_e      e/N_mae
    801    10      2.1e-07      2.1e-07     5.46e-06
    801    20     4.59e-07     4.59e-07     8.46e-06
    801    30     2.39e-07     2.39e-07     6.42e-06
    801    40     3.38e-07     3.38e-07     7.82e-06
    801    48     2.17e-07     2.17e-07     7.23e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    801    10     3.09e-07     3.09e-07     7.71e-06
    801    20     1.54e-07     1.54e-07      4.5e-06
    801    30     6.34e-09     6.34e-09     1.28e-06
    801    40     2.18e-07     2.18e-07     6.42e-06
    801    50     5.92e-08     5.92e-08     3.53e-06
    801    60     4.86e-08     4.86e-08     2.89e-06
    801    61     2.18e-06     2.18e-06     2.03e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             801 44106.755   0.0025     3.06e-07     3.06e-07     6.94e-06
! Validation        801 44106.755   0.0025      1.7e-07      1.7e-07     4.52e-06
Wall time: 44106.756648333
training
# Epoch batch         loss       loss_e      e/N_mae
    802    10     1.38e-07     1.38e-07     4.93e-06
    802    20     3.47e-07     3.47e-07     8.35e-06
    802    30      1.5e-07      1.5e-07     5.35e-06
    802    40     1.57e-07     1.57e-07     5.57e-06
    802    48     2.64e-07     2.64e-07     7.23e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    802    10     2.85e-07     2.85e-07     7.39e-06
    802    20      1.5e-07      1.5e-07     4.82e-06
    802    30     2.96e-08     2.96e-08     2.25e-06
    802    40     1.92e-07     1.92e-07      6.1e-06
    802    50     9.51e-08     9.51e-08     3.85e-06
    802    60      7.4e-08      7.4e-08     3.53e-06
    802    61     2.09e-06     2.09e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             802 44161.685   0.0025     1.88e-07     1.88e-07     5.55e-06
! Validation        802 44161.685   0.0025     1.61e-07     1.61e-07     4.28e-06
Wall time: 44161.686275208005
training
# Epoch batch         loss       loss_e      e/N_mae
    803    10     1.42e-07     1.42e-07     4.82e-06
    803    20     1.81e-07     1.81e-07     5.46e-06
    803    30     2.63e-07     2.63e-07     6.64e-06
    803    40     3.37e-07     3.37e-07     6.64e-06
    803    48     1.95e-07     1.95e-07     5.62e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    803    10     2.32e-07     2.32e-07      6.1e-06
    803    20     1.86e-07     1.86e-07     5.14e-06
    803    30     2.54e-08     2.54e-08     2.25e-06
    803    40     2.41e-07     2.41e-07      6.1e-06
    803    50     1.48e-07     1.48e-07     5.46e-06
    803    60     1.08e-07     1.08e-07     4.18e-06
    803    61     1.59e-06     1.59e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             803 44216.866   0.0025     2.57e-07     2.57e-07     6.48e-06
! Validation        803 44216.866   0.0025     1.56e-07     1.56e-07     4.41e-06
Wall time: 44216.866326208
training
# Epoch batch         loss       loss_e      e/N_mae
    804    10     6.91e-07     6.91e-07     1.23e-05
    804    20     1.15e-06     1.15e-06     1.41e-05
    804    30     5.49e-07     5.49e-07     8.35e-06
    804    40     2.16e-07     2.16e-07     5.46e-06
    804    48     1.95e-07     1.95e-07     6.42e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    804    10     2.85e-07     2.85e-07     6.42e-06
    804    20     1.39e-07     1.39e-07     3.85e-06
    804    30     1.48e-08     1.48e-08     2.25e-06
    804    40     2.32e-07     2.32e-07      6.1e-06
    804    50     8.45e-08     8.45e-08     4.18e-06
    804    60     5.71e-08     5.71e-08     3.53e-06
    804    61     1.74e-06     1.74e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             804 44271.922   0.0025     3.67e-07     3.67e-07     7.88e-06
! Validation        804 44271.922   0.0025     1.65e-07     1.65e-07     4.53e-06
Wall time: 44271.921953708
training
# Epoch batch         loss       loss_e      e/N_mae
    805    10     2.24e-07     2.24e-07     6.21e-06
    805    20     5.73e-07     5.73e-07     9.53e-06
    805    30      1.4e-07      1.4e-07      4.6e-06
    805    40     2.35e-07     2.35e-07     7.28e-06
    805    48     6.87e-08     6.87e-08     4.82e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    805    10     3.19e-07     3.19e-07     7.71e-06
    805    20     1.73e-07     1.73e-07     3.85e-06
    805    30      1.9e-08      1.9e-08     1.93e-06
    805    40     1.65e-07     1.65e-07     5.78e-06
    805    50     8.45e-08     8.45e-08     4.18e-06
    805    60     9.09e-08     9.09e-08     4.18e-06
    805    61     1.94e-06     1.94e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             805 44327.001   0.0025     3.08e-07     3.08e-07     7.16e-06
! Validation        805 44327.001   0.0025     1.58e-07     1.58e-07     4.33e-06
Wall time: 44327.002164416
training
# Epoch batch         loss       loss_e      e/N_mae
    806    10     1.95e-07     1.95e-07     5.57e-06
    806    20     1.04e-07     1.04e-07     3.85e-06
    806    30      7.4e-08      7.4e-08     3.64e-06
    806    40     4.51e-08     4.51e-08        3e-06
    806    48     2.64e-08     2.64e-08     2.41e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    806    10        3e-07        3e-07     6.42e-06
    806    20     1.84e-07     1.84e-07      4.5e-06
    806    30     4.02e-08     4.02e-08     3.21e-06
    806    40     1.94e-07     1.94e-07     5.78e-06
    806    50     1.08e-07     1.08e-07      4.5e-06
    806    60     6.55e-08     6.55e-08     3.53e-06
    806    61     1.68e-06     1.68e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             806 44382.165   0.0025     9.68e-08     9.68e-08     4.01e-06
! Validation        806 44382.165   0.0025     1.49e-07     1.49e-07     4.16e-06
Wall time: 44382.165669208
! Best model      806    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    807    10      1.3e-07      1.3e-07     5.03e-06
    807    20     3.25e-07     3.25e-07     6.32e-06
    807    30      1.1e-07      1.1e-07     3.96e-06
    807    40     1.32e-07     1.32e-07     5.14e-06
    807    48     3.43e-07     3.43e-07     7.23e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    807    10     2.22e-07     2.22e-07     5.46e-06
    807    20     2.01e-07     2.01e-07     5.46e-06
    807    30     2.96e-08     2.96e-08     2.25e-06
    807    40     1.25e-07     1.25e-07     4.82e-06
    807    50     8.45e-08     8.45e-08     4.18e-06
    807    60     1.27e-07     1.27e-07      4.5e-06
    807    61     1.64e-06     1.64e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             807 44437.272   0.0025     1.76e-07     1.76e-07     5.32e-06
! Validation        807 44437.272   0.0025     1.51e-07     1.51e-07     4.41e-06
Wall time: 44437.273287041004
training
# Epoch batch         loss       loss_e      e/N_mae
    808    10     9.34e-07     9.34e-07     1.37e-05
    808    20     2.93e-07     2.93e-07     7.39e-06
    808    30      1.7e-07      1.7e-07     5.57e-06
    808    40     1.54e-07     1.54e-07     5.46e-06
    808    48      1.8e-07      1.8e-07     8.03e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    808    10     1.56e-07     1.56e-07     5.14e-06
    808    20     1.69e-07     1.69e-07     5.46e-06
    808    30     5.07e-08     5.07e-08     4.18e-06
    808    40      1.5e-07      1.5e-07     5.46e-06
    808    50     1.06e-07     1.06e-07     4.18e-06
    808    60      1.1e-07      1.1e-07      4.5e-06
    808    61     1.58e-06     1.58e-06     1.55e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             808 44492.289   0.0025      2.4e-07      2.4e-07     6.12e-06
! Validation        808 44492.289   0.0025     1.45e-07     1.45e-07     4.35e-06
Wall time: 44492.289486625
! Best model      808    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    809    10     2.02e-07     2.02e-07     5.89e-06
    809    20     3.21e-07     3.21e-07     7.82e-06
    809    30     4.99e-07     4.99e-07     8.25e-06
    809    40     1.38e-07     1.38e-07     4.18e-06
    809    48     2.38e-07     2.38e-07     8.03e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    809    10     2.41e-07     2.41e-07     6.75e-06
    809    20     3.83e-07     3.83e-07     6.42e-06
    809    30      1.9e-08      1.9e-08     1.93e-06
    809    40     1.52e-07     1.52e-07     5.14e-06
    809    50     9.93e-08     9.93e-08      4.5e-06
    809    60     4.86e-08     4.86e-08     2.89e-06
    809    61     1.74e-06     1.74e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             809 44547.583   0.0025     2.44e-07     2.44e-07     6.11e-06
! Validation        809 44547.583   0.0025     1.61e-07     1.61e-07     4.41e-06
Wall time: 44547.583549625
training
# Epoch batch         loss       loss_e      e/N_mae
    810    10     1.37e-07     1.37e-07     4.93e-06
    810    20     9.09e-08     9.09e-08     4.28e-06
    810    30     1.49e-07     1.49e-07     5.14e-06
    810    40     7.61e-08     7.61e-08     3.96e-06
    810    48     1.32e-07     1.32e-07     5.62e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    810    10     3.02e-07     3.02e-07     6.75e-06
    810    20     2.13e-07     2.13e-07     4.18e-06
    810    30     2.32e-08     2.32e-08     2.89e-06
    810    40     1.65e-07     1.65e-07     5.78e-06
    810    50     8.45e-08     8.45e-08     4.18e-06
    810    60     6.34e-08     6.34e-08     2.57e-06
    810    61     2.05e-06     2.05e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             810 44602.731   0.0025     1.63e-07     1.63e-07     5.18e-06
! Validation        810 44602.731   0.0025     1.57e-07     1.57e-07     4.25e-06
Wall time: 44602.732089708
training
# Epoch batch         loss       loss_e      e/N_mae
    811    10     2.05e-07     2.05e-07     5.89e-06
    811    20     2.53e-07     2.53e-07     6.32e-06
    811    30     2.11e-07     2.11e-07     6.32e-06
    811    40     1.06e-07     1.06e-07     4.39e-06
    811    48     1.06e-08     1.06e-08     1.61e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    811    10     2.81e-07     2.81e-07      6.1e-06
    811    20     2.35e-07     2.35e-07     5.14e-06
    811    30      1.9e-08      1.9e-08     1.93e-06
    811    40     1.29e-07     1.29e-07     4.82e-06
    811    50     5.07e-08     5.07e-08     3.53e-06
    811    60     6.13e-08     6.13e-08     3.53e-06
    811    61     1.64e-06     1.64e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             811 44657.806   0.0025      1.4e-07      1.4e-07     4.83e-06
! Validation        811 44657.806   0.0025     1.53e-07     1.53e-07     4.21e-06
Wall time: 44657.806459291
training
# Epoch batch         loss       loss_e      e/N_mae
    812    10     1.05e-07     1.05e-07     4.07e-06
    812    20     1.58e-07     1.58e-07     4.71e-06
    812    30     7.19e-08     7.19e-08     3.43e-06
    812    40     1.04e-07     1.04e-07     3.64e-06
    812    48     5.28e-08     5.28e-08     3.21e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    812    10     2.26e-07     2.26e-07     4.82e-06
    812    20     3.23e-07     3.23e-07     5.78e-06
    812    30     1.48e-08     1.48e-08     2.25e-06
    812    40     1.52e-07     1.52e-07     5.14e-06
    812    50     6.55e-08     6.55e-08     3.85e-06
    812    60     3.59e-08     3.59e-08     2.25e-06
    812    61     1.65e-06     1.65e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             812 44712.829   0.0025      1.2e-07      1.2e-07     4.45e-06
! Validation        812 44712.829   0.0025     1.46e-07     1.46e-07     4.13e-06
Wall time: 44712.830169416
training
# Epoch batch         loss       loss_e      e/N_mae
    813    10     2.06e-07     2.06e-07     4.93e-06
    813    20     3.95e-08     3.95e-08     2.46e-06
    813    30     3.66e-08     3.66e-08     2.68e-06
    813    40     6.41e-08     6.41e-08     4.18e-06
    813    48     5.28e-09     5.28e-09     8.03e-07
validation
# Epoch batch         loss       loss_e      e/N_mae
    813    10     2.66e-07     2.66e-07     5.14e-06
    813    20     3.25e-07     3.25e-07     5.78e-06
    813    30     2.54e-08     2.54e-08     2.57e-06
    813    40     1.42e-07     1.42e-07     5.46e-06
    813    50     3.59e-08     3.59e-08     2.57e-06
    813    60      1.9e-08      1.9e-08     1.61e-06
    813    61     1.79e-06     1.79e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             813 44768.083   0.0025     1.08e-07     1.08e-07     4.23e-06
! Validation        813 44768.083   0.0025     1.52e-07     1.52e-07     4.27e-06
Wall time: 44768.083743166004
training
# Epoch batch         loss       loss_e      e/N_mae
    814    10     8.74e-08     8.74e-08     4.18e-06
    814    20     5.42e-08     5.42e-08     3.11e-06
    814    30     1.22e-07     1.22e-07      4.5e-06
    814    40     9.65e-08     9.65e-08     3.96e-06
    814    48     1.32e-07     1.32e-07     7.23e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    814    10     2.39e-07     2.39e-07     4.82e-06
    814    20     2.26e-07     2.26e-07     5.14e-06
    814    30     1.27e-08     1.27e-08     1.61e-06
    814    40     7.82e-08     7.82e-08     3.53e-06
    814    50     2.32e-08     2.32e-08     2.57e-06
    814    60     6.34e-08     6.34e-08     3.21e-06
    814    61     2.09e-06     2.09e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             814 44823.127   0.0025     9.07e-08     9.07e-08     3.83e-06
! Validation        814 44823.127   0.0025     1.52e-07     1.52e-07     4.09e-06
Wall time: 44823.128201458
training
# Epoch batch         loss       loss_e      e/N_mae
    815    10     9.37e-08     9.37e-08      4.6e-06
    815    20     1.49e-07     1.49e-07     4.82e-06
    815    30     1.64e-07     1.64e-07      6.1e-06
    815    40     5.07e-08     5.07e-08     3.11e-06
    815    48     1.06e-08     1.06e-08     1.61e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    815    10     2.71e-07     2.71e-07     5.14e-06
    815    20      2.2e-07      2.2e-07     4.82e-06
    815    30     8.45e-09     8.45e-09     1.61e-06
    815    40     1.33e-07     1.33e-07     5.46e-06
    815    50     1.69e-08     1.69e-08     2.25e-06
    815    60     6.76e-08     6.76e-08     4.18e-06
    815    61     1.78e-06     1.78e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             815 44878.305   0.0025     1.51e-07     1.51e-07     5.08e-06
! Validation        815 44878.305   0.0025     1.56e-07     1.56e-07     4.36e-06
Wall time: 44878.305395333
training
# Epoch batch         loss       loss_e      e/N_mae
    816    10     3.59e-07     3.59e-07     9.42e-06
    816    20     1.63e-07     1.63e-07     5.57e-06
    816    30     1.56e-07     1.56e-07     5.14e-06
    816    40     1.56e-07     1.56e-07     4.82e-06
    816    48     3.91e-07     3.91e-07     1.04e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    816    10     2.49e-07     2.49e-07     5.14e-06
    816    20     2.71e-07     2.71e-07     5.46e-06
    816    30     5.07e-08     5.07e-08     3.85e-06
    816    40     1.12e-07     1.12e-07     4.82e-06
    816    50     2.32e-08     2.32e-08     1.93e-06
    816    60     4.65e-08     4.65e-08     3.53e-06
    816    61     1.85e-06     1.85e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             816 44933.450   0.0025     1.85e-07     1.85e-07     5.59e-06
! Validation        816 44933.450   0.0025     1.65e-07     1.65e-07     4.42e-06
Wall time: 44933.450790208
training
# Epoch batch         loss       loss_e      e/N_mae
    817    10     2.37e-07     2.37e-07     6.32e-06
    817    20     1.55e-07     1.55e-07     5.68e-06
    817    30     1.37e-07     1.37e-07     4.93e-06
    817    40     2.04e-07     2.04e-07     5.68e-06
    817    48     2.64e-07     2.64e-07     8.03e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    817    10     2.32e-07     2.32e-07     5.14e-06
    817    20     2.68e-07     2.68e-07     5.46e-06
    817    30     4.65e-08     4.65e-08     2.89e-06
    817    40     1.75e-07     1.75e-07      6.1e-06
    817    50      3.8e-08      3.8e-08     2.89e-06
    817    60     5.71e-08     5.71e-08     3.53e-06
    817    61     1.84e-06     1.84e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             817 44988.311   0.0025     1.93e-07     1.93e-07     5.62e-06
! Validation        817 44988.311   0.0025     1.61e-07     1.61e-07     4.35e-06
Wall time: 44988.311732166
training
# Epoch batch         loss       loss_e      e/N_mae
    818    10     1.74e-07     1.74e-07     5.57e-06
    818    20     8.38e-08     8.38e-08     3.53e-06
    818    30      9.3e-08      9.3e-08     4.28e-06
    818    40     6.76e-08     6.76e-08     3.85e-06
    818    48     6.87e-08     6.87e-08     4.02e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    818    10     3.28e-07     3.28e-07     6.75e-06
    818    20     2.01e-07     2.01e-07     5.14e-06
    818    30     2.75e-08     2.75e-08     2.57e-06
    818    40     1.82e-07     1.82e-07     5.46e-06
    818    50      3.8e-08      3.8e-08     2.89e-06
    818    60     2.96e-08     2.96e-08     1.93e-06
    818    61     1.43e-06     1.43e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             818 45043.444   0.0025      1.5e-07      1.5e-07      5.1e-06
! Validation        818 45043.444   0.0025     1.43e-07     1.43e-07     4.19e-06
Wall time: 45043.444172333
! Best model      818    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    819    10     1.32e-07     1.32e-07     3.85e-06
    819    20     1.61e-07     1.61e-07     5.78e-06
    819    30     9.02e-08     9.02e-08     3.96e-06
    819    40     1.93e-07     1.93e-07     6.32e-06
    819    48     4.49e-07     4.49e-07     1.12e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    819    10     1.94e-07     1.94e-07     5.14e-06
    819    20      1.5e-07      1.5e-07      4.5e-06
    819    30     1.48e-08     1.48e-08     2.25e-06
    819    40      2.3e-07      2.3e-07     6.42e-06
    819    50     3.17e-08     3.17e-08     2.57e-06
    819    60     3.38e-08     3.38e-08     2.57e-06
    819    61     1.46e-06     1.46e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             819 45098.751   0.0025     2.56e-07     2.56e-07     6.32e-06
! Validation        819 45098.751   0.0025     1.52e-07     1.52e-07      4.4e-06
Wall time: 45098.751744583
training
# Epoch batch         loss       loss_e      e/N_mae
    820    10     2.38e-06     2.38e-06     2.03e-05
    820    20     2.27e-06     2.27e-06     1.72e-05
    820    30     1.18e-06     1.18e-06     1.52e-05
    820    40      1.1e-06      1.1e-06     1.27e-05
    820    48     4.76e-07     4.76e-07     1.04e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    820    10      1.8e-07      1.8e-07     4.82e-06
    820    20     1.73e-07     1.73e-07     5.46e-06
    820    30     3.17e-08     3.17e-08     2.57e-06
    820    40     2.79e-07     2.79e-07     7.71e-06
    820    50     2.54e-08     2.54e-08     2.25e-06
    820    60     9.09e-08     9.09e-08     3.53e-06
    820    61     1.57e-06     1.57e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             820 45153.719   0.0025      1.5e-06      1.5e-06     1.48e-05
! Validation        820 45153.719   0.0025     1.53e-07     1.53e-07      4.4e-06
Wall time: 45153.719861833
training
# Epoch batch         loss       loss_e      e/N_mae
    821    10     1.15e-06     1.15e-06     1.07e-05
    821    20     1.63e-07     1.63e-07     5.46e-06
    821    30     3.44e-07     3.44e-07     7.92e-06
    821    40     2.04e-07     2.04e-07     5.68e-06
    821    48     1.29e-06     1.29e-06     1.85e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    821    10     1.86e-07     1.86e-07     5.14e-06
    821    20     2.66e-07     2.66e-07     5.14e-06
    821    30     5.71e-08     5.71e-08     4.18e-06
    821    40     1.84e-07     1.84e-07     5.78e-06
    821    50     2.96e-08     2.96e-08     2.89e-06
    821    60     7.82e-08     7.82e-08     3.85e-06
    821    61     1.84e-06     1.84e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             821 45208.859   0.0025     4.45e-07     4.45e-07     8.17e-06
! Validation        821 45208.859   0.0025     1.58e-07     1.58e-07     4.47e-06
Wall time: 45208.859923458
training
# Epoch batch         loss       loss_e      e/N_mae
    822    10     7.86e-07     7.86e-07     1.12e-05
    822    20     3.54e-07     3.54e-07     8.57e-06
    822    30     4.41e-07     4.41e-07     8.14e-06
    822    40     7.12e-08     7.12e-08     3.75e-06
    822    48     3.22e-07     3.22e-07     1.04e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    822    10     1.23e-07     1.23e-07      4.5e-06
    822    20     6.13e-08     6.13e-08     3.21e-06
    822    30      3.8e-08      3.8e-08     3.21e-06
    822    40     9.93e-08     9.93e-08     4.18e-06
    822    50      3.8e-08      3.8e-08     2.89e-06
    822    60     4.02e-08     4.02e-08     2.89e-06
    822    61     1.74e-06     1.74e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             822 45263.911   0.0025     2.91e-07     2.91e-07     6.61e-06
! Validation        822 45263.911   0.0025     1.45e-07     1.45e-07     4.31e-06
Wall time: 45263.912352916
training
# Epoch batch         loss       loss_e      e/N_mae
    823    10     1.99e-07     1.99e-07     6.32e-06
    823    20     9.93e-08     9.93e-08     4.28e-06
    823    30     9.65e-08     9.65e-08     4.07e-06
    823    40     1.63e-07     1.63e-07     5.35e-06
    823    48     4.76e-08     4.76e-08     2.41e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    823    10     1.31e-07     1.31e-07      4.5e-06
    823    20     1.33e-07     1.33e-07      6.1e-06
    823    30      7.4e-08      7.4e-08     3.53e-06
    823    40     1.23e-07     1.23e-07      4.5e-06
    823    50     2.75e-08     2.75e-08     2.57e-06
    823    60     8.03e-08     8.03e-08     3.85e-06
    823    61     1.33e-06     1.33e-06     1.39e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             823 45318.919   0.0025     1.37e-07     1.37e-07     4.83e-06
! Validation        823 45318.919   0.0025     1.38e-07     1.38e-07     4.26e-06
Wall time: 45318.919776916
! Best model      823    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    824    10     1.91e-07     1.91e-07     6.21e-06
    824    20     3.91e-07     3.91e-07     7.92e-06
    824    30     1.84e-07     1.84e-07     5.57e-06
    824    40     2.15e-07     2.15e-07     6.42e-06
    824    48     2.17e-07     2.17e-07     8.03e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    824    10     1.33e-07     1.33e-07      4.5e-06
    824    20     2.01e-07     2.01e-07     6.42e-06
    824    30     3.38e-08     3.38e-08     3.53e-06
    824    40     1.97e-07     1.97e-07      6.1e-06
    824    50     2.54e-08     2.54e-08     2.25e-06
    824    60     1.08e-07     1.08e-07     4.18e-06
    824    61      1.4e-06      1.4e-06      1.5e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             824 45374.173   0.0025     1.77e-07     1.77e-07     5.29e-06
! Validation        824 45374.173   0.0025     1.44e-07     1.44e-07     4.33e-06
Wall time: 45374.173477625
training
# Epoch batch         loss       loss_e      e/N_mae
    825    10     7.47e-08     7.47e-08     3.64e-06
    825    20     2.62e-07     2.62e-07      7.5e-06
    825    30      9.3e-08      9.3e-08     4.28e-06
    825    40     1.08e-07     1.08e-07      4.6e-06
    825    48     4.23e-08     4.23e-08     4.02e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    825    10     1.48e-07     1.48e-07      4.5e-06
    825    20     1.67e-07     1.67e-07     5.46e-06
    825    30     4.02e-08     4.02e-08     2.89e-06
    825    40     1.54e-07     1.54e-07     5.14e-06
    825    50     4.44e-08     4.44e-08     2.57e-06
    825    60     5.07e-08     5.07e-08     3.21e-06
    825    61     1.64e-06     1.64e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             825 45429.187   0.0025     1.16e-07     1.16e-07     4.28e-06
! Validation        825 45429.187   0.0025     1.46e-07     1.46e-07      4.2e-06
Wall time: 45429.188111166004
training
# Epoch batch         loss       loss_e      e/N_mae
    826    10     1.78e-07     1.78e-07     5.68e-06
    826    20     6.27e-08     6.27e-08     3.53e-06
    826    30     6.04e-07     6.04e-07     8.99e-06
    826    40     2.61e-07     2.61e-07     7.71e-06
    826    48     1.06e-08     1.06e-08     1.61e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    826    10     1.97e-07     1.97e-07     4.82e-06
    826    20     1.92e-07     1.92e-07     5.14e-06
    826    30     7.82e-08     7.82e-08      4.5e-06
    826    40      2.2e-07      2.2e-07      6.1e-06
    826    50     4.65e-08     4.65e-08     2.89e-06
    826    60     5.71e-08     5.71e-08     3.53e-06
    826    61     1.99e-06     1.99e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             826 45484.348   0.0025     2.07e-07     2.07e-07     5.91e-06
! Validation        826 45484.348   0.0025     1.56e-07     1.56e-07     4.36e-06
Wall time: 45484.349360416
training
# Epoch batch         loss       loss_e      e/N_mae
    827    10     2.12e-07     2.12e-07     6.53e-06
    827    20     2.66e-07     2.66e-07     6.64e-06
    827    30     1.03e-07     1.03e-07     3.96e-06
    827    40      1.3e-07      1.3e-07     5.57e-06
    827    48     1.69e-07     1.69e-07     6.42e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    827    10      2.3e-07      2.3e-07     5.46e-06
    827    20     2.26e-07     2.26e-07      6.1e-06
    827    30     2.32e-08     2.32e-08     2.25e-06
    827    40     1.99e-07     1.99e-07     5.46e-06
    827    50     4.23e-08     4.23e-08     3.53e-06
    827    60     2.32e-08     2.32e-08     1.61e-06
    827    61     1.46e-06     1.46e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             827 45539.314   0.0025     1.28e-07     1.28e-07     4.62e-06
! Validation        827 45539.314   0.0025     1.42e-07     1.42e-07     4.29e-06
Wall time: 45539.314398083
training
# Epoch batch         loss       loss_e      e/N_mae
    828    10     1.32e-07     1.32e-07     4.28e-06
    828    20     1.14e-07     1.14e-07     4.93e-06
    828    30     9.65e-08     9.65e-08     3.85e-06
    828    40     1.34e-07     1.34e-07     4.71e-06
    828    48     1.95e-07     1.95e-07     6.42e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    828    10     2.49e-07     2.49e-07      6.1e-06
    828    20     1.99e-07     1.99e-07     5.78e-06
    828    30     4.44e-08     4.44e-08     3.53e-06
    828    40     1.37e-07     1.37e-07     4.82e-06
    828    50     4.65e-08     4.65e-08     2.89e-06
    828    60      3.8e-08      3.8e-08     2.57e-06
    828    61     1.15e-06     1.15e-06     1.39e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             828 45594.554   0.0025     1.37e-07     1.37e-07     4.73e-06
! Validation        828 45594.554   0.0025     1.43e-07     1.43e-07     4.45e-06
Wall time: 45594.555087625005
training
# Epoch batch         loss       loss_e      e/N_mae
    829    10     2.78e-07     2.78e-07      7.5e-06
    829    20     8.66e-08     8.66e-08     3.96e-06
    829    30     2.17e-07     2.17e-07     6.85e-06
    829    40     2.76e-07     2.76e-07        6e-06
    829    48     1.37e-07     1.37e-07     4.82e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    829    10     2.43e-07     2.43e-07     5.46e-06
    829    20     2.01e-07     2.01e-07     5.46e-06
    829    30      1.9e-08      1.9e-08     1.28e-06
    829    40     2.18e-07     2.18e-07     6.75e-06
    829    50     5.07e-08     5.07e-08     3.53e-06
    829    60     4.65e-08     4.65e-08     3.21e-06
    829    61     1.28e-06     1.28e-06      1.5e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             829 45649.619   0.0025     1.78e-07     1.78e-07     5.61e-06
! Validation        829 45649.619   0.0025     1.44e-07     1.44e-07     4.27e-06
Wall time: 45649.619466791
training
# Epoch batch         loss       loss_e      e/N_mae
    830    10     1.44e-07     1.44e-07     5.25e-06
    830    20     3.11e-07     3.11e-07     8.78e-06
    830    30     1.45e-07     1.45e-07     4.93e-06
    830    40     2.97e-07     2.97e-07      6.1e-06
    830    48     8.98e-08     8.98e-08     4.02e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    830    10     1.56e-07     1.56e-07      4.5e-06
    830    20     1.73e-07     1.73e-07     5.46e-06
    830    30     1.69e-08     1.69e-08     2.89e-06
    830    40     1.67e-07     1.67e-07     5.46e-06
    830    50     8.66e-08     8.66e-08      4.5e-06
    830    60     2.32e-08     2.32e-08     2.25e-06
    830    61      1.4e-06      1.4e-06      1.5e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             830 45704.806   0.0025     1.92e-07     1.92e-07     5.67e-06
! Validation        830 45704.806   0.0025     1.44e-07     1.44e-07     4.23e-06
Wall time: 45704.806633333
training
# Epoch batch         loss       loss_e      e/N_mae
    831    10     1.73e-07     1.73e-07     5.68e-06
    831    20      7.4e-08      7.4e-08     3.53e-06
    831    30     8.95e-08     8.95e-08     4.18e-06
    831    40     2.08e-07     2.08e-07        6e-06
    831    48     1.32e-07     1.32e-07     5.62e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    831    10     1.69e-07     1.69e-07     5.46e-06
    831    20     1.16e-07     1.16e-07     4.18e-06
    831    30     2.11e-08     2.11e-08     2.57e-06
    831    40      1.8e-07      1.8e-07     5.78e-06
    831    50     5.71e-08     5.71e-08     3.21e-06
    831    60     4.65e-08     4.65e-08     3.21e-06
    831    61      1.5e-06      1.5e-06      1.5e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             831 45760.025   0.0025     1.42e-07     1.42e-07     4.86e-06
! Validation        831 45760.025   0.0025     1.41e-07     1.41e-07     4.06e-06
Wall time: 45760.025628291005
training
# Epoch batch         loss       loss_e      e/N_mae
    832    10     1.74e-07     1.74e-07     5.46e-06
    832    20     5.79e-07     5.79e-07     1.16e-05
    832    30     6.62e-08     6.62e-08     3.96e-06
    832    40     1.41e-07     1.41e-07     5.14e-06
    832    48     1.32e-07     1.32e-07     4.02e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    832    10     2.58e-07     2.58e-07     7.71e-06
    832    20     1.27e-07     1.27e-07      4.5e-06
    832    30     2.54e-08     2.54e-08     2.25e-06
    832    40     1.35e-07     1.35e-07      4.5e-06
    832    50     6.34e-08     6.34e-08     3.53e-06
    832    60     4.44e-08     4.44e-08     2.89e-06
    832    61     1.88e-06     1.88e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             832 45814.949   0.0025     1.84e-07     1.84e-07     5.65e-06
! Validation        832 45814.949   0.0025     1.52e-07     1.52e-07     4.27e-06
Wall time: 45814.949694166
training
# Epoch batch         loss       loss_e      e/N_mae
    833    10     8.31e-08     8.31e-08     3.64e-06
    833    20     1.16e-07     1.16e-07     4.82e-06
    833    30     1.85e-07     1.85e-07        6e-06
    833    40     5.92e-08     5.92e-08     2.57e-06
    833    48     6.87e-08     6.87e-08     4.02e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    833    10     2.13e-07     2.13e-07      6.1e-06
    833    20     2.85e-07     2.85e-07     5.78e-06
    833    30     7.61e-08     7.61e-08     4.18e-06
    833    40     3.11e-07     3.11e-07     8.35e-06
    833    50     6.13e-08     6.13e-08     3.85e-06
    833    60     7.19e-08     7.19e-08     3.85e-06
    833    61     1.91e-06     1.91e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             833 45869.989   0.0025      1.4e-07      1.4e-07     4.64e-06
! Validation        833 45869.989   0.0025     1.62e-07     1.62e-07     4.52e-06
Wall time: 45869.989920958
training
# Epoch batch         loss       loss_e      e/N_mae
    834    10     9.23e-08     9.23e-08      4.5e-06
    834    20     1.38e-07     1.38e-07     5.35e-06
    834    30     9.02e-08     9.02e-08     3.96e-06
    834    40     1.78e-07     1.78e-07     5.78e-06
    834    48     1.06e-08     1.06e-08     1.61e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    834    10      1.9e-07      1.9e-07     5.14e-06
    834    20     2.24e-07     2.24e-07     4.82e-06
    834    30     1.69e-08     1.69e-08     2.25e-06
    834    40     1.82e-07     1.82e-07     6.42e-06
    834    50     5.71e-08     5.71e-08     3.21e-06
    834    60     4.02e-08     4.02e-08     2.89e-06
    834    61     1.78e-06     1.78e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             834 45925.020   0.0025     1.83e-07     1.83e-07     5.44e-06
! Validation        834 45925.020   0.0025     1.53e-07     1.53e-07     4.36e-06
Wall time: 45925.02053175
training
# Epoch batch         loss       loss_e      e/N_mae
    835    10     6.09e-07     6.09e-07     1.07e-05
    835    20     4.28e-07     4.28e-07     8.46e-06
    835    30     1.42e-07     1.42e-07     4.07e-06
    835    40     1.11e-07     1.11e-07     4.28e-06
    835    48     3.22e-07     3.22e-07     9.64e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    835    10     2.01e-07     2.01e-07     5.78e-06
    835    20     2.87e-07     2.87e-07      6.1e-06
    835    30     2.11e-08     2.11e-08     2.57e-06
    835    40     1.67e-07     1.67e-07      6.1e-06
    835    50      7.4e-08      7.4e-08     3.85e-06
    835    60     4.44e-08     4.44e-08     2.89e-06
    835    61     1.67e-06     1.67e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             835 45980.253   0.0025     3.32e-07     3.32e-07     6.94e-06
! Validation        835 45980.253   0.0025     1.54e-07     1.54e-07     4.36e-06
Wall time: 45980.254167125
training
# Epoch batch         loss       loss_e      e/N_mae
    836    10     1.06e-07     1.06e-07     5.35e-06
    836    20     1.01e-07     1.01e-07      4.6e-06
    836    30     1.75e-07     1.75e-07     6.21e-06
    836    40     2.76e-07     2.76e-07     4.71e-06
    836    48     2.75e-07     2.75e-07     8.03e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    836    10     2.09e-07     2.09e-07     4.82e-06
    836    20     2.51e-07     2.51e-07      6.1e-06
    836    30     2.11e-08     2.11e-08     2.57e-06
    836    40     1.56e-07     1.56e-07     5.78e-06
    836    50      3.8e-08      3.8e-08     2.89e-06
    836    60     4.02e-08     4.02e-08     2.89e-06
    836    61     1.73e-06     1.73e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             836 46035.233   0.0025     2.64e-07     2.64e-07     6.45e-06
! Validation        836 46035.233   0.0025     1.49e-07     1.49e-07     4.34e-06
Wall time: 46035.2334405
training
# Epoch batch         loss       loss_e      e/N_mae
    837    10     6.46e-07     6.46e-07     1.02e-05
    837    20        3e-07        3e-07     6.42e-06
    837    30     1.58e-06     1.58e-06     1.86e-05
    837    40      1.6e-07      1.6e-07     5.89e-06
    837    48     1.53e-06     1.53e-06     1.45e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    837    10     2.56e-07     2.56e-07     5.78e-06
    837    20      3.4e-07      3.4e-07     8.03e-06
    837    30     3.38e-08     3.38e-08     3.21e-06
    837    40     1.52e-07     1.52e-07     5.14e-06
    837    50     2.32e-08     2.32e-08     1.61e-06
    837    60     6.34e-09     6.34e-09     9.64e-07
    837    61     1.79e-06     1.79e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             837 46090.294   0.0025     4.52e-07     4.52e-07     8.45e-06
! Validation        837 46090.294   0.0025     1.65e-07     1.65e-07     4.48e-06
Wall time: 46090.293780500004
training
# Epoch batch         loss       loss_e      e/N_mae
    838    10     7.02e-07     7.02e-07     1.19e-05
    838    20        5e-07        5e-07     1.05e-05
    838    30     3.42e-07     3.42e-07     8.25e-06
    838    40     5.06e-07     5.06e-07     1.07e-05
    838    48     2.42e-06     2.42e-06     2.49e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    838    10     2.49e-07     2.49e-07     5.14e-06
    838    20     2.81e-07     2.81e-07     5.78e-06
    838    30     4.65e-08     4.65e-08     3.85e-06
    838    40     1.75e-07     1.75e-07     5.46e-06
    838    50     2.32e-08     2.32e-08     2.57e-06
    838    60     4.44e-08     4.44e-08     2.89e-06
    838    61     2.22e-06     2.22e-06     1.93e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             838 46145.218   0.0025     6.18e-07     6.18e-07     9.86e-06
! Validation        838 46145.218   0.0025     1.72e-07     1.72e-07     4.47e-06
Wall time: 46145.219014958006
training
# Epoch batch         loss       loss_e      e/N_mae
    839    10     8.27e-07     8.27e-07     1.14e-05
    839    20     1.63e-07     1.63e-07     5.25e-06
    839    30     4.04e-07     4.04e-07     8.14e-06
    839    40     4.47e-07     4.47e-07     8.03e-06
    839    48     5.28e-09     5.28e-09     8.03e-07
validation
# Epoch batch         loss       loss_e      e/N_mae
    839    10     6.34e-08     6.34e-08     3.21e-06
    839    20     4.37e-07     4.37e-07     8.67e-06
    839    30     7.19e-08     7.19e-08     4.18e-06
    839    40     1.14e-07     1.14e-07      4.5e-06
    839    50     8.45e-08     8.45e-08     4.18e-06
    839    60     1.48e-08     1.48e-08     1.93e-06
    839    61     1.98e-06     1.98e-06     1.87e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             839 46200.453   0.0025     4.87e-07     4.87e-07     8.86e-06
! Validation        839 46200.453   0.0025     1.56e-07     1.56e-07     4.49e-06
Wall time: 46200.454511375
training
# Epoch batch         loss       loss_e      e/N_mae
    840    10     3.05e-07     3.05e-07     7.07e-06
    840    20     5.96e-07     5.96e-07     9.74e-06
    840    30     2.54e-07     2.54e-07     6.75e-06
    840    40      1.7e-07      1.7e-07     5.78e-06
    840    48     6.13e-07     6.13e-07     1.12e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    840    10     1.12e-07     1.12e-07     3.53e-06
    840    20     4.42e-07     4.42e-07     8.67e-06
    840    30     1.08e-07     1.08e-07      4.5e-06
    840    40     1.01e-07     1.01e-07     3.85e-06
    840    50     1.27e-08     1.27e-08     1.28e-06
    840    60     2.54e-08     2.54e-08     1.93e-06
    840    61     1.98e-06     1.98e-06     1.87e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             840 46255.566   0.0025     2.91e-07     2.91e-07     6.62e-06
! Validation        840 46255.566   0.0025     1.62e-07     1.62e-07     4.45e-06
Wall time: 46255.565748625006
training
# Epoch batch         loss       loss_e      e/N_mae
    841    10     4.56e-07     4.56e-07     8.03e-06
    841    20     4.11e-07     4.11e-07     8.25e-06
    841    30     1.42e-06     1.42e-06      1.6e-05
    841    40      4.3e-07      4.3e-07     9.42e-06
    841    48     2.38e-07     2.38e-07     7.23e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    841    10     1.44e-07     1.44e-07      4.5e-06
    841    20     3.02e-07     3.02e-07     7.71e-06
    841    30     7.61e-08     7.61e-08     4.18e-06
    841    40     1.78e-07     1.78e-07     5.78e-06
    841    50     1.23e-07     1.23e-07     4.18e-06
    841    60     9.93e-08     9.93e-08     4.18e-06
    841    61     1.48e-06     1.48e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             841 46310.654   0.0025     4.17e-07     4.17e-07     8.23e-06
! Validation        841 46310.654   0.0025     1.49e-07     1.49e-07     4.54e-06
Wall time: 46310.655580916005
training
# Epoch batch         loss       loss_e      e/N_mae
    842    10     2.85e-07     2.85e-07     7.92e-06
    842    20     2.04e-07     2.04e-07     6.42e-06
    842    30     7.47e-08     7.47e-08     3.75e-06
    842    40     1.05e-07     1.05e-07     4.28e-06
    842    48     3.06e-07     3.06e-07     8.03e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    842    10     1.65e-07     1.65e-07      4.5e-06
    842    20      4.9e-07      4.9e-07     9.64e-06
    842    30     4.02e-08     4.02e-08     3.53e-06
    842    40      2.2e-07      2.2e-07      6.1e-06
    842    50     5.28e-08     5.28e-08     3.21e-06
    842    60     3.38e-08     3.38e-08     2.57e-06
    842    61     1.45e-06     1.45e-06     1.55e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             842 46365.880   0.0025     3.22e-07     3.22e-07     7.15e-06
! Validation        842 46365.880   0.0025     1.52e-07     1.52e-07     4.38e-06
Wall time: 46365.880831166
training
# Epoch batch         loss       loss_e      e/N_mae
    843    10     1.81e-07     1.81e-07     6.42e-06
    843    20     1.41e-07     1.41e-07     5.25e-06
    843    30     1.32e-07     1.32e-07      4.6e-06
    843    40     2.16e-07     2.16e-07     6.32e-06
    843    48     8.98e-08     8.98e-08     4.02e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    843    10     1.46e-07     1.46e-07     3.53e-06
    843    20      3.4e-07      3.4e-07     6.42e-06
    843    30     4.65e-08     4.65e-08     2.89e-06
    843    40     1.92e-07     1.92e-07     5.78e-06
    843    50     4.86e-08     4.86e-08     3.21e-06
    843    60     2.54e-08     2.54e-08     1.93e-06
    843    61     1.78e-06     1.78e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             843 46420.878   0.0025     1.98e-07     1.98e-07     5.64e-06
! Validation        843 46420.878   0.0025     1.58e-07     1.58e-07     4.43e-06
Wall time: 46420.879195083005
training
# Epoch batch         loss       loss_e      e/N_mae
    844    10     2.59e-07     2.59e-07     7.07e-06
    844    20     1.57e-07     1.57e-07     5.46e-06
    844    30     1.38e-07     1.38e-07     4.93e-06
    844    40     9.16e-08     9.16e-08     4.28e-06
    844    48     2.64e-08     2.64e-08     3.21e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    844    10     1.59e-07     1.59e-07     4.18e-06
    844    20     2.18e-07     2.18e-07      4.5e-06
    844    30     2.96e-08     2.96e-08     2.57e-06
    844    40     1.29e-07     1.29e-07     4.18e-06
    844    50     4.86e-08     4.86e-08     3.21e-06
    844    60     1.48e-08     1.48e-08     1.61e-06
    844    61     1.67e-06     1.67e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             844 46476.044   0.0025     1.54e-07     1.54e-07     5.14e-06
! Validation        844 46476.044   0.0025     1.54e-07     1.54e-07     4.35e-06
Wall time: 46476.043922625
training
# Epoch batch         loss       loss_e      e/N_mae
    845    10     3.45e-08     3.45e-08     2.46e-06
    845    20     9.79e-08     9.79e-08     4.71e-06
    845    30     7.47e-08     7.47e-08     3.53e-06
    845    40     1.32e-07     1.32e-07     4.93e-06
    845    48     4.23e-08     4.23e-08     3.21e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    845    10      1.9e-07      1.9e-07     5.46e-06
    845    20     1.94e-07     1.94e-07     6.75e-06
    845    30     5.07e-08     5.07e-08     3.85e-06
    845    40     1.73e-07     1.73e-07     5.78e-06
    845    50     2.54e-08     2.54e-08     1.93e-06
    845    60     4.65e-08     4.65e-08     2.57e-06
    845    61     1.67e-06     1.67e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             845 46531.210   0.0025      1.2e-07      1.2e-07     4.47e-06
! Validation        845 46531.210   0.0025     1.55e-07     1.55e-07     4.36e-06
Wall time: 46531.210883375
training
# Epoch batch         loss       loss_e      e/N_mae
    846    10     1.42e-07     1.42e-07     5.35e-06
    846    20     1.75e-07     1.75e-07        6e-06
    846    30     1.18e-07     1.18e-07      4.6e-06
    846    40     1.88e-07     1.88e-07     5.25e-06
    846    48     4.23e-08     4.23e-08     3.21e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    846    10     1.16e-07     1.16e-07     3.53e-06
    846    20      1.9e-07      1.9e-07     4.82e-06
    846    30     4.23e-08     4.23e-08     2.89e-06
    846    40     9.72e-08     9.72e-08     3.85e-06
    846    50     2.32e-08     2.32e-08     2.57e-06
    846    60      3.8e-08      3.8e-08     1.93e-06
    846    61     1.93e-06     1.93e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             846 46586.337   0.0025     1.24e-07     1.24e-07     4.41e-06
! Validation        846 46586.337   0.0025     1.48e-07     1.48e-07     4.15e-06
Wall time: 46586.337702041004
training
# Epoch batch         loss       loss_e      e/N_mae
    847    10     3.95e-08     3.95e-08     2.57e-06
    847    20     1.19e-07     1.19e-07     4.71e-06
    847    30        5e-08        5e-08     2.89e-06
    847    40     1.93e-07     1.93e-07     5.35e-06
    847    48     2.17e-07     2.17e-07     8.83e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    847    10     1.63e-07     1.63e-07     4.82e-06
    847    20     1.54e-07     1.54e-07     4.82e-06
    847    30     4.86e-08     4.86e-08     3.53e-06
    847    40     1.14e-07     1.14e-07     3.85e-06
    847    50     4.23e-09     4.23e-09     9.64e-07
    847    60     5.49e-08     5.49e-08     3.21e-06
    847    61     1.31e-06     1.31e-06     1.45e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             847 46641.417   0.0025     9.69e-08     9.69e-08     3.82e-06
! Validation        847 46641.417   0.0025     1.43e-07     1.43e-07     4.34e-06
Wall time: 46641.417965916
training
# Epoch batch         loss       loss_e      e/N_mae
    848    10     1.49e-07     1.49e-07     4.82e-06
    848    20     1.59e-07     1.59e-07     5.25e-06
    848    30     3.59e-08     3.59e-08     2.57e-06
    848    40     2.82e-08     2.82e-08     2.46e-06
    848    48     1.95e-07     1.95e-07     6.42e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    848    10     8.66e-08     8.66e-08     2.89e-06
    848    20     1.97e-07     1.97e-07     5.14e-06
    848    30     5.71e-08     5.71e-08     3.53e-06
    848    40     1.27e-07     1.27e-07      4.5e-06
    848    50     2.32e-08     2.32e-08     2.57e-06
    848    60     3.38e-08     3.38e-08     2.57e-06
    848    61     1.43e-06     1.43e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             848 46696.440   0.0025     1.12e-07     1.12e-07     4.31e-06
! Validation        848 46696.440   0.0025     1.42e-07     1.42e-07     4.26e-06
Wall time: 46696.441126666
training
# Epoch batch         loss       loss_e      e/N_mae
    849    10     1.82e-07     1.82e-07     5.03e-06
    849    20     1.32e-07     1.32e-07      4.6e-06
    849    30     8.95e-08     8.95e-08     3.96e-06
    849    40     8.52e-08     8.52e-08     3.96e-06
    849    48            0            0            0
validation
# Epoch batch         loss       loss_e      e/N_mae
    849    10     1.61e-07     1.61e-07      4.5e-06
    849    20     2.24e-07     2.24e-07     4.82e-06
    849    30     4.02e-08     4.02e-08     2.89e-06
    849    40     1.31e-07     1.31e-07     5.46e-06
    849    50     1.48e-08     1.48e-08     1.93e-06
    849    60     1.48e-07     1.48e-07     5.78e-06
    849    61     1.69e-06     1.69e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             849 46751.546   0.0025      1.1e-07      1.1e-07     4.23e-06
! Validation        849 46751.546   0.0025     1.49e-07     1.49e-07     4.31e-06
Wall time: 46751.54657025
training
# Epoch batch         loss       loss_e      e/N_mae
    850    10     5.35e-08     5.35e-08     2.89e-06
    850    20     4.37e-08     4.37e-08     2.89e-06
    850    30     9.09e-08     9.09e-08     3.96e-06
    850    40     3.73e-08     3.73e-08     2.46e-06
    850    48     5.28e-09     5.28e-09     1.61e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    850    10     1.16e-07     1.16e-07     4.18e-06
    850    20     1.99e-07     1.99e-07     5.46e-06
    850    30     6.34e-08     6.34e-08     3.53e-06
    850    40     1.25e-07     1.25e-07     4.82e-06
    850    50     3.17e-08     3.17e-08     2.57e-06
    850    60     1.14e-07     1.14e-07     5.14e-06
    850    61     1.59e-06     1.59e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             850 46806.743   0.0025     5.75e-08     5.75e-08     3.12e-06
! Validation        850 46806.743   0.0025     1.48e-07     1.48e-07      4.3e-06
Wall time: 46806.744180041
training
# Epoch batch         loss       loss_e      e/N_mae
    851    10     6.97e-08     6.97e-08     3.75e-06
    851    20     1.17e-07     1.17e-07      4.6e-06
    851    30     8.81e-08     8.81e-08     3.75e-06
    851    40      1.2e-07      1.2e-07     4.71e-06
    851    48     5.28e-08     5.28e-08     3.21e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    851    10     9.09e-08     9.09e-08     3.53e-06
    851    20      1.9e-07      1.9e-07     4.82e-06
    851    30     4.86e-08     4.86e-08     3.21e-06
    851    40     1.82e-07     1.82e-07     5.78e-06
    851    50     3.38e-08     3.38e-08     2.89e-06
    851    60     7.19e-08     7.19e-08     3.85e-06
    851    61     1.73e-06     1.73e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             851 46861.954   0.0025     1.11e-07     1.11e-07     4.32e-06
! Validation        851 46861.954   0.0025     1.47e-07     1.47e-07     4.25e-06
Wall time: 46861.954716500004
training
# Epoch batch         loss       loss_e      e/N_mae
    852    10     6.48e-08     6.48e-08     3.11e-06
    852    20     1.13e-07     1.13e-07     5.03e-06
    852    30     1.27e-07     1.27e-07      4.6e-06
    852    40     1.91e-07     1.91e-07     5.78e-06
    852    48     6.87e-07     6.87e-07     1.37e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    852    10     2.49e-07     2.49e-07     5.14e-06
    852    20     1.78e-07     1.78e-07     4.18e-06
    852    30     8.24e-08     8.24e-08     4.18e-06
    852    40     2.01e-07     2.01e-07      6.1e-06
    852    50     3.38e-08     3.38e-08     2.89e-06
    852    60     4.02e-08     4.02e-08     2.25e-06
    852    61     1.46e-06     1.46e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             852 46917.055   0.0025     1.39e-07     1.39e-07     4.57e-06
! Validation        852 46917.055   0.0025     1.43e-07     1.43e-07     4.18e-06
Wall time: 46917.056215875
training
# Epoch batch         loss       loss_e      e/N_mae
    853    10     9.95e-07     9.95e-07     1.15e-05
    853    20     4.45e-07     4.45e-07     8.89e-06
    853    30     1.77e-07     1.77e-07     5.14e-06
    853    40     9.24e-07     9.24e-07     1.38e-05
    853    48     1.24e-06     1.24e-06     1.45e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    853    10     1.84e-07     1.84e-07     5.78e-06
    853    20     2.66e-07     2.66e-07     6.75e-06
    853    30      1.9e-08      1.9e-08     1.93e-06
    853    40     1.73e-07     1.73e-07     5.78e-06
    853    50     8.24e-08     8.24e-08      4.5e-06
    853    60     1.27e-08     1.27e-08     1.28e-06
    853    61     1.37e-06     1.37e-06     1.55e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             853 46971.913   0.0025     7.74e-07     7.74e-07     1.08e-05
! Validation        853 46971.913   0.0025     1.52e-07     1.52e-07      4.5e-06
Wall time: 46971.913962
training
# Epoch batch         loss       loss_e      e/N_mae
    854    10     2.42e-06     2.42e-06     2.25e-05
    854    20     4.95e-07     4.95e-07     9.21e-06
    854    30     2.35e-07     2.35e-07      6.1e-06
    854    40     5.02e-07     5.02e-07     1.06e-05
    854    48     2.11e-08     2.11e-08     1.61e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    854    10     1.48e-07     1.48e-07      4.5e-06
    854    20     2.81e-07     2.81e-07     6.75e-06
    854    30     6.13e-08     6.13e-08     3.21e-06
    854    40      3.7e-07      3.7e-07     9.32e-06
    854    50     7.19e-08     7.19e-08     4.18e-06
    854    60      3.8e-08      3.8e-08     2.89e-06
    854    61     1.08e-06     1.08e-06     1.39e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             854 47027.193   0.0025     9.16e-07     9.16e-07     1.23e-05
! Validation        854 47027.193   0.0025     1.48e-07     1.48e-07     4.53e-06
Wall time: 47027.194251791
training
# Epoch batch         loss       loss_e      e/N_mae
    855    10     1.32e-06     1.32e-06     1.52e-05
    855    20     2.55e-06     2.55e-06     1.45e-05
    855    30     2.75e-07     2.75e-07     6.96e-06
    855    40     4.63e-07     4.63e-07     1.03e-05
    855    48     4.49e-07     4.49e-07     1.12e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    855    10     2.22e-07     2.22e-07     5.46e-06
    855    20     2.01e-07     2.01e-07     5.46e-06
    855    30     6.13e-08     6.13e-08      4.5e-06
    855    40      2.6e-07      2.6e-07     7.39e-06
    855    50     6.97e-08     6.97e-08     3.85e-06
    855    60      3.8e-08      3.8e-08     2.57e-06
    855    61     1.07e-06     1.07e-06     1.34e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             855 47082.347   0.0025     6.95e-07     6.95e-07     1.05e-05
! Validation        855 47082.347   0.0025     1.48e-07     1.48e-07     4.54e-06
Wall time: 47082.348184083
training
# Epoch batch         loss       loss_e      e/N_mae
    856    10     1.69e-07     1.69e-07     5.89e-06
    856    20     2.44e-07     2.44e-07     6.42e-06
    856    30     1.25e-07     1.25e-07     3.96e-06
    856    40     8.45e-08     8.45e-08     4.71e-06
    856    48     4.23e-08     4.23e-08     3.21e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    856    10     1.29e-07     1.29e-07     4.82e-06
    856    20     2.13e-07     2.13e-07     5.78e-06
    856    30     5.92e-08     5.92e-08     3.53e-06
    856    40        3e-07        3e-07     7.71e-06
    856    50     9.93e-08     9.93e-08     3.85e-06
    856    60     7.19e-08     7.19e-08     3.53e-06
    856    61     1.24e-06     1.24e-06     1.45e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             856 47137.594   0.0025     2.02e-07     2.02e-07     5.78e-06
! Validation        856 47137.594   0.0025     1.48e-07     1.48e-07     4.56e-06
Wall time: 47137.595646583
training
# Epoch batch         loss       loss_e      e/N_mae
    857    10     9.65e-08     9.65e-08     4.28e-06
    857    20     8.74e-08     8.74e-08     3.96e-06
    857    30     1.06e-07     1.06e-07     4.39e-06
    857    40     1.24e-07     1.24e-07     4.71e-06
    857    48     6.87e-08     6.87e-08     4.02e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    857    10     1.48e-07     1.48e-07      4.5e-06
    857    20     1.61e-07     1.61e-07     4.82e-06
    857    30     8.66e-08     8.66e-08     4.82e-06
    857    40     2.81e-07     2.81e-07     7.39e-06
    857    50      3.8e-08      3.8e-08     2.25e-06
    857    60      3.8e-08      3.8e-08     2.57e-06
    857    61     1.26e-06     1.26e-06     1.55e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             857 47192.733   0.0025     1.01e-07     1.01e-07      4.1e-06
! Validation        857 47192.733   0.0025     1.47e-07     1.47e-07     4.39e-06
Wall time: 47192.734319291005
training
# Epoch batch         loss       loss_e      e/N_mae
    858    10      2.2e-07      2.2e-07     6.96e-06
    858    20     1.87e-07     1.87e-07     5.35e-06
    858    30     8.95e-08     8.95e-08     3.96e-06
    858    40     6.41e-08     6.41e-08     3.53e-06
    858    48     1.06e-08     1.06e-08     2.41e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    858    10     2.22e-07     2.22e-07     5.78e-06
    858    20     1.42e-07     1.42e-07     4.18e-06
    858    30     5.92e-08     5.92e-08     3.21e-06
    858    40      2.3e-07      2.3e-07     6.42e-06
    858    50     1.69e-08     1.69e-08     1.61e-06
    858    60     4.65e-08     4.65e-08     2.57e-06
    858    61     1.16e-06     1.16e-06     1.45e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             858 47247.463   0.0025     1.68e-07     1.68e-07     5.24e-06
! Validation        858 47247.463   0.0025     1.47e-07     1.47e-07     4.34e-06
Wall time: 47247.463546291
training
# Epoch batch         loss       loss_e      e/N_mae
    859    10     9.86e-08     9.86e-08     3.64e-06
    859    20     7.33e-08     7.33e-08     3.32e-06
    859    30      3.8e-08      3.8e-08     2.36e-06
    859    40     9.58e-08     9.58e-08     3.64e-06
    859    48     3.86e-07     3.86e-07     9.64e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    859    10     2.56e-07     2.56e-07     5.78e-06
    859    20     1.59e-07     1.59e-07     4.82e-06
    859    30     1.27e-08     1.27e-08     1.61e-06
    859    40     3.11e-07     3.11e-07     8.67e-06
    859    50     3.38e-08     3.38e-08     2.89e-06
    859    60     4.02e-08     4.02e-08     2.89e-06
    859    61     1.37e-06     1.37e-06     1.55e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             859 47302.639   0.0025     1.35e-07     1.35e-07     4.46e-06
! Validation        859 47302.639   0.0025     1.48e-07     1.48e-07     4.36e-06
Wall time: 47302.638834333
training
# Epoch batch         loss       loss_e      e/N_mae
    860    10     1.32e-06     1.32e-06     1.39e-05
    860    20     3.34e-07     3.34e-07      7.5e-06
    860    30     7.43e-07     7.43e-07     9.21e-06
    860    40     1.06e-06     1.06e-06     1.45e-05
    860    48     1.95e-07     1.95e-07     6.42e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    860    10     3.32e-07     3.32e-07     5.46e-06
    860    20     2.26e-07     2.26e-07     6.42e-06
    860    30     2.54e-08     2.54e-08     2.25e-06
    860    40     2.41e-07     2.41e-07     7.07e-06
    860    50     4.02e-08     4.02e-08     2.57e-06
    860    60     2.96e-08     2.96e-08     1.93e-06
    860    61     1.37e-06     1.37e-06     1.55e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             860 47357.722   0.0025     5.99e-07     5.99e-07     9.45e-06
! Validation        860 47357.722   0.0025     1.54e-07     1.54e-07      4.5e-06
Wall time: 47357.723305875
training
# Epoch batch         loss       loss_e      e/N_mae
    861    10     1.59e-07     1.59e-07     5.25e-06
    861    20      1.7e-06      1.7e-06     1.69e-05
    861    30     2.47e-07     2.47e-07     6.42e-06
    861    40     1.04e-07     1.04e-07     4.39e-06
    861    48     2.75e-07     2.75e-07     8.83e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    861    10     1.86e-07     1.86e-07     5.46e-06
    861    20     1.33e-07     1.33e-07      4.5e-06
    861    30     2.11e-08     2.11e-08     2.25e-06
    861    40     3.19e-07     3.19e-07     8.35e-06
    861    50     4.23e-08     4.23e-08     2.89e-06
    861    60     2.32e-08     2.32e-08     1.61e-06
    861    61     1.58e-06     1.58e-06     1.55e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             861 47412.751   0.0025     3.53e-07     3.53e-07     7.19e-06
! Validation        861 47412.751   0.0025     1.55e-07     1.55e-07      4.3e-06
Wall time: 47412.751177583
training
# Epoch batch         loss       loss_e      e/N_mae
    862    10     1.56e-07     1.56e-07     4.93e-06
    862    20     1.48e-07     1.48e-07     5.46e-06
    862    30      8.1e-08      8.1e-08     2.89e-06
    862    40     1.49e-07     1.49e-07     5.68e-06
    862    48     5.28e-08     5.28e-08     3.21e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    862    10     1.29e-07     1.29e-07     4.18e-06
    862    20      1.8e-07      1.8e-07      4.5e-06
    862    30     5.49e-08     5.49e-08     3.85e-06
    862    40     1.59e-07     1.59e-07      6.1e-06
    862    50     2.96e-08     2.96e-08     2.25e-06
    862    60     5.28e-08     5.28e-08     2.89e-06
    862    61     1.54e-06     1.54e-06     1.55e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             862 47467.930   0.0025     1.58e-07     1.58e-07     5.15e-06
! Validation        862 47467.930   0.0025      1.5e-07      1.5e-07      4.3e-06
Wall time: 47467.930646416
training
# Epoch batch         loss       loss_e      e/N_mae
    863    10     2.77e-07     2.77e-07     6.96e-06
    863    20     1.07e-07     1.07e-07     4.07e-06
    863    30     9.37e-08     9.37e-08      4.5e-06
    863    40     2.24e-07     2.24e-07     6.85e-06
    863    48     1.69e-07     1.69e-07     7.23e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    863    10     1.61e-07     1.61e-07      4.5e-06
    863    20     1.18e-07     1.18e-07     4.18e-06
    863    30     3.59e-08     3.59e-08     2.89e-06
    863    40     1.86e-07     1.86e-07     6.42e-06
    863    50     3.38e-08     3.38e-08     2.89e-06
    863    60     7.19e-08     7.19e-08     2.57e-06
    863    61     1.58e-06     1.58e-06     1.55e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             863 47522.944   0.0025     1.56e-07     1.56e-07     5.19e-06
! Validation        863 47522.944   0.0025     1.44e-07     1.44e-07     4.24e-06
Wall time: 47522.945098333
training
# Epoch batch         loss       loss_e      e/N_mae
    864    10     3.74e-07     3.74e-07     7.71e-06
    864    20        5e-08        5e-08     2.89e-06
    864    30      3.8e-08      3.8e-08     2.57e-06
    864    40     3.66e-08     3.66e-08     2.78e-06
    864    48      2.8e-07      2.8e-07     7.23e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    864    10     1.88e-07     1.88e-07      4.5e-06
    864    20     2.35e-07     2.35e-07     5.14e-06
    864    30     2.32e-08     2.32e-08     2.25e-06
    864    40     1.75e-07     1.75e-07      6.1e-06
    864    50     2.96e-08     2.96e-08     2.25e-06
    864    60     2.11e-08     2.11e-08     1.28e-06
    864    61     1.64e-06     1.64e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             864 47577.941   0.0025     1.55e-07     1.55e-07        5e-06
! Validation        864 47577.941   0.0025     1.48e-07     1.48e-07     4.27e-06
Wall time: 47577.941530875
training
# Epoch batch         loss       loss_e      e/N_mae
    865    10     1.26e-07     1.26e-07     4.93e-06
    865    20     4.37e-08     4.37e-08     2.89e-06
    865    30     7.12e-08     7.12e-08     3.11e-06
    865    40     1.05e-07     1.05e-07     4.07e-06
    865    48     9.51e-08     9.51e-08     4.82e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    865    10     1.54e-07     1.54e-07     3.53e-06
    865    20      1.8e-07      1.8e-07      4.5e-06
    865    30     5.92e-08     5.92e-08     3.85e-06
    865    40     1.39e-07     1.39e-07     5.14e-06
    865    50     6.13e-08     6.13e-08     2.89e-06
    865    60     5.28e-08     5.28e-08     2.89e-06
    865    61     1.19e-06     1.19e-06     1.39e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             865 47632.919   0.0025     1.21e-07     1.21e-07     4.39e-06
! Validation        865 47632.919   0.0025     1.47e-07     1.47e-07     4.34e-06
Wall time: 47632.919549583
training
# Epoch batch         loss       loss_e      e/N_mae
    866    10     2.36e-07     2.36e-07      6.1e-06
    866    20     4.37e-08     4.37e-08     2.68e-06
    866    30     1.18e-07     1.18e-07     4.82e-06
    866    40     1.53e-07     1.53e-07     5.25e-06
    866    48     1.06e-07     1.06e-07     5.62e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    866    10      1.9e-07      1.9e-07      4.5e-06
    866    20     2.01e-07     2.01e-07     5.14e-06
    866    30     3.17e-08     3.17e-08     2.89e-06
    866    40     1.46e-07     1.46e-07     5.46e-06
    866    50     4.86e-08     4.86e-08     3.21e-06
    866    60     2.11e-08     2.11e-08     1.93e-06
    866    61     1.44e-06     1.44e-06      1.5e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             866 47688.024   0.0025     1.01e-07     1.01e-07     4.13e-06
! Validation        866 47688.024   0.0025     1.41e-07     1.41e-07     4.13e-06
Wall time: 47688.024697041
training
# Epoch batch         loss       loss_e      e/N_mae
    867    10     6.27e-08     6.27e-08        3e-06
    867    20     2.25e-08     2.25e-08     1.82e-06
    867    30     5.07e-08     5.07e-08        3e-06
    867    40     2.05e-07     2.05e-07     6.42e-06
    867    48     1.06e-08     1.06e-08     1.61e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    867    10      2.3e-07      2.3e-07     5.46e-06
    867    20      1.9e-07      1.9e-07     4.82e-06
    867    30     5.28e-08     5.28e-08     4.18e-06
    867    40     1.42e-07     1.42e-07     5.46e-06
    867    50     3.17e-08     3.17e-08     2.57e-06
    867    60     1.48e-08     1.48e-08     1.61e-06
    867    61     1.13e-06     1.13e-06     1.45e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             867 47743.130   0.0025     9.39e-08     9.39e-08     4.01e-06
! Validation        867 47743.130   0.0025     1.37e-07     1.37e-07     4.26e-06
Wall time: 47743.131090458
! Best model      867    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    868    10     7.61e-08     7.61e-08     2.89e-06
    868    20     3.45e-08     3.45e-08     2.25e-06
    868    30     4.09e-08     4.09e-08     2.68e-06
    868    40     1.66e-07     1.66e-07     5.14e-06
    868    48     1.06e-07     1.06e-07     4.82e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    868    10     1.59e-07     1.59e-07     4.18e-06
    868    20     2.03e-07     2.03e-07     5.46e-06
    868    30     3.17e-08     3.17e-08     2.57e-06
    868    40     1.18e-07     1.18e-07     5.14e-06
    868    50     4.23e-08     4.23e-08     2.89e-06
    868    60     1.27e-08     1.27e-08     1.28e-06
    868    61     1.08e-06     1.08e-06     1.39e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             868 47798.223   0.0025     1.93e-07     1.93e-07     4.79e-06
! Validation        868 47798.223   0.0025     1.37e-07     1.37e-07     4.27e-06
Wall time: 47798.224471
! Best model      868    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    869    10     3.75e-07     3.75e-07     6.85e-06
    869    20     6.81e-07     6.81e-07     9.53e-06
    869    30     1.11e-07     1.11e-07     4.39e-06
    869    40     1.32e-07     1.32e-07      4.6e-06
    869    48     1.32e-07     1.32e-07     4.02e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    869    10     1.99e-07     1.99e-07     5.46e-06
    869    20     1.84e-07     1.84e-07     5.78e-06
    869    30     3.38e-08     3.38e-08     2.89e-06
    869    40     2.47e-07     2.47e-07     7.07e-06
    869    50      1.9e-08      1.9e-08     1.93e-06
    869    60     4.86e-08     4.86e-08     2.89e-06
    869    61     1.13e-06     1.13e-06     1.39e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             869 47853.377   0.0025     2.55e-07     2.55e-07     6.21e-06
! Validation        869 47853.377   0.0025     1.38e-07     1.38e-07      4.2e-06
Wall time: 47853.378465791
training
# Epoch batch         loss       loss_e      e/N_mae
    870    10     8.17e-08     8.17e-08     3.43e-06
    870    20     1.08e-07     1.08e-07     4.28e-06
    870    30     1.33e-07     1.33e-07     4.71e-06
    870    40     1.68e-07     1.68e-07     5.78e-06
    870    48     5.28e-09     5.28e-09     8.03e-07
validation
# Epoch batch         loss       loss_e      e/N_mae
    870    10     1.94e-07     1.94e-07     5.14e-06
    870    20      1.9e-07      1.9e-07     4.82e-06
    870    30     2.75e-08     2.75e-08     1.93e-06
    870    40     2.43e-07     2.43e-07     7.07e-06
    870    50     2.11e-08     2.11e-08     2.25e-06
    870    60     4.65e-08     4.65e-08     2.57e-06
    870    61     1.37e-06     1.37e-06      1.5e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             870 47908.452   0.0025     1.11e-07     1.11e-07     4.38e-06
! Validation        870 47908.452   0.0025     1.41e-07     1.41e-07     4.27e-06
Wall time: 47908.4527805
training
# Epoch batch         loss       loss_e      e/N_mae
    871    10     1.01e-07     1.01e-07     4.71e-06
    871    20     4.86e-08     4.86e-08        3e-06
    871    30     1.28e-07     1.28e-07     4.71e-06
    871    40     7.75e-08     7.75e-08     4.18e-06
    871    48     9.51e-08     9.51e-08     4.82e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    871    10     1.61e-07     1.61e-07      4.5e-06
    871    20     2.49e-07     2.49e-07     5.46e-06
    871    30     9.93e-08     9.93e-08     4.82e-06
    871    40     2.05e-07     2.05e-07     6.42e-06
    871    50     4.02e-08     4.02e-08     3.21e-06
    871    60     4.65e-08     4.65e-08     2.57e-06
    871    61     1.31e-06     1.31e-06     1.45e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             871 47963.621   0.0025      8.8e-08      8.8e-08     3.93e-06
! Validation        871 47963.621   0.0025     1.41e-07     1.41e-07     4.29e-06
Wall time: 47963.622087458
training
# Epoch batch         loss       loss_e      e/N_mae
    872    10     5.99e-08     5.99e-08     3.64e-06
    872    20     1.26e-07     1.26e-07      4.5e-06
    872    30     5.78e-08     5.78e-08     2.68e-06
    872    40     2.15e-07     2.15e-07     6.53e-06
    872    48     6.87e-08     6.87e-08     4.02e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    872    10     2.01e-07     2.01e-07     5.78e-06
    872    20     1.92e-07     1.92e-07      4.5e-06
    872    30     6.34e-08     6.34e-08     3.85e-06
    872    40     2.03e-07     2.03e-07     6.42e-06
    872    50     5.71e-08     5.71e-08     3.85e-06
    872    60     8.03e-08     8.03e-08     3.85e-06
    872    61      1.4e-06      1.4e-06     1.45e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             872 48018.611   0.0025     1.07e-07     1.07e-07     4.25e-06
! Validation        872 48018.611   0.0025     1.32e-07     1.32e-07     4.14e-06
Wall time: 48018.611688833
! Best model      872    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    873    10     7.47e-08     7.47e-08     3.96e-06
    873    20      1.2e-07      1.2e-07     4.18e-06
    873    30     1.16e-07     1.16e-07      4.6e-06
    873    40     8.31e-08     8.31e-08     3.32e-06
    873    48     1.32e-07     1.32e-07     4.02e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    873    10     2.54e-07     2.54e-07     6.75e-06
    873    20     2.49e-07     2.49e-07     5.46e-06
    873    30     5.49e-08     5.49e-08     3.85e-06
    873    40     1.37e-07     1.37e-07     4.82e-06
    873    50     4.65e-08     4.65e-08     2.89e-06
    873    60     5.92e-08     5.92e-08     3.21e-06
    873    61     1.63e-06     1.63e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             873 48073.674   0.0025     1.04e-07     1.04e-07     4.07e-06
! Validation        873 48073.674   0.0025     1.38e-07     1.38e-07     4.09e-06
Wall time: 48073.675014666005
training
# Epoch batch         loss       loss_e      e/N_mae
    874    10     6.06e-08     6.06e-08     3.43e-06
    874    20     1.58e-07     1.58e-07     5.68e-06
    874    30     7.19e-08     7.19e-08     4.39e-06
    874    40     3.95e-08     3.95e-08     2.68e-06
    874    48     2.64e-08     2.64e-08     2.41e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    874    10     2.35e-07     2.35e-07     4.82e-06
    874    20     2.37e-07     2.37e-07     5.46e-06
    874    30     4.02e-08     4.02e-08     3.85e-06
    874    40      2.6e-07      2.6e-07     6.42e-06
    874    50     5.49e-08     5.49e-08     2.89e-06
    874    60     4.86e-08     4.86e-08     2.89e-06
    874    61      1.5e-06      1.5e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             874 48128.657   0.0025     9.49e-08     9.49e-08     4.02e-06
! Validation        874 48128.657   0.0025     1.36e-07     1.36e-07     4.02e-06
Wall time: 48128.658652958
training
# Epoch batch         loss       loss_e      e/N_mae
    875    10     6.27e-08     6.27e-08     3.32e-06
    875    20     1.28e-07     1.28e-07     4.93e-06
    875    30     1.06e-07     1.06e-07      4.6e-06
    875    40     1.82e-07     1.82e-07        6e-06
    875    48     1.32e-07     1.32e-07     4.02e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    875    10     1.67e-07     1.67e-07     5.14e-06
    875    20     1.78e-07     1.78e-07      4.5e-06
    875    30     5.49e-08     5.49e-08     4.18e-06
    875    40      2.3e-07      2.3e-07     6.42e-06
    875    50      3.8e-08      3.8e-08     2.89e-06
    875    60     2.54e-08     2.54e-08     1.93e-06
    875    61      1.5e-06      1.5e-06     1.55e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             875 48183.753   0.0025     1.47e-07     1.47e-07     4.83e-06
! Validation        875 48183.753   0.0025     1.28e-07     1.28e-07     4.02e-06
Wall time: 48183.752968166
! Best model      875    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    876    10      1.3e-07      1.3e-07     4.93e-06
    876    20     8.52e-08     8.52e-08     4.28e-06
    876    30     1.13e-06     1.13e-06     1.42e-05
    876    40     2.93e-07     2.93e-07     7.28e-06
    876    48     4.76e-08     4.76e-08     2.41e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    876    10     1.48e-07     1.48e-07     4.82e-06
    876    20     1.54e-07     1.54e-07      4.5e-06
    876    30     5.49e-08     5.49e-08     3.85e-06
    876    40      1.9e-07      1.9e-07      6.1e-06
    876    50     4.44e-08     4.44e-08     3.21e-06
    876    60     3.17e-08     3.17e-08     2.57e-06
    876    61     1.43e-06     1.43e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             876 48238.850   0.0025     2.51e-07     2.51e-07      6.2e-06
! Validation        876 48238.850   0.0025     1.37e-07     1.37e-07     4.24e-06
Wall time: 48238.851258583
training
# Epoch batch         loss       loss_e      e/N_mae
    877    10     8.03e-08     8.03e-08     3.75e-06
    877    20     2.04e-07     2.04e-07     5.46e-06
    877    30     1.94e-07     1.94e-07     5.57e-06
    877    40     5.59e-07     5.59e-07     1.15e-05
    877    48     8.45e-08     8.45e-08     3.21e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    877    10     1.61e-07     1.61e-07      4.5e-06
    877    20      1.5e-07      1.5e-07     4.82e-06
    877    30     3.59e-08     3.59e-08     3.53e-06
    877    40     2.13e-07     2.13e-07     7.07e-06
    877    50      7.4e-08      7.4e-08     3.85e-06
    877    60     8.45e-09     8.45e-09     1.28e-06
    877    61     1.24e-06     1.24e-06     1.45e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             877 48293.955   0.0025     2.14e-07     2.14e-07      6.1e-06
! Validation        877 48293.955   0.0025      1.3e-07      1.3e-07     4.02e-06
Wall time: 48293.954783625006
training
# Epoch batch         loss       loss_e      e/N_mae
    878    10     2.96e-07     2.96e-07     7.82e-06
    878    20     1.23e-07     1.23e-07     4.39e-06
    878    30     6.76e-08     6.76e-08     3.53e-06
    878    40     8.52e-08     8.52e-08     3.85e-06
    878    48     1.32e-07     1.32e-07     5.62e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    878    10     1.99e-07     1.99e-07     5.14e-06
    878    20     2.01e-07     2.01e-07     5.46e-06
    878    30     4.02e-08     4.02e-08     3.85e-06
    878    40     1.84e-07     1.84e-07     5.78e-06
    878    50     6.55e-08     6.55e-08     3.85e-06
    878    60     3.59e-08     3.59e-08     2.25e-06
    878    61     1.28e-06     1.28e-06     1.55e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             878 48349.227   0.0025     2.61e-07     2.61e-07     6.49e-06
! Validation        878 48349.227   0.0025     1.31e-07     1.31e-07     4.16e-06
Wall time: 48349.228273666005
training
# Epoch batch         loss       loss_e      e/N_mae
    879    10     2.93e-07     2.93e-07     7.71e-06
    879    20     1.68e-07     1.68e-07     5.68e-06
    879    30     1.85e-07     1.85e-07     5.46e-06
    879    40     6.06e-08     6.06e-08     3.21e-06
    879    48     1.06e-07     1.06e-07     4.82e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    879    10     1.42e-07     1.42e-07     4.18e-06
    879    20     2.01e-07     2.01e-07     5.46e-06
    879    30     2.54e-08     2.54e-08     2.57e-06
    879    40     1.42e-07     1.42e-07     4.82e-06
    879    50     4.23e-08     4.23e-08     1.93e-06
    879    60     2.11e-08     2.11e-08     1.93e-06
    879    61     1.33e-06     1.33e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             879 48404.021   0.0025     1.86e-07     1.86e-07     5.41e-06
! Validation        879 48404.021   0.0025      1.3e-07      1.3e-07     3.98e-06
Wall time: 48404.02182375
training
# Epoch batch         loss       loss_e      e/N_mae
    880    10     1.23e-07     1.23e-07     4.18e-06
    880    20     2.54e-08     2.54e-08     2.25e-06
    880    30     1.79e-07     1.79e-07     5.89e-06
    880    40     1.53e-07     1.53e-07     5.89e-06
    880    48     1.32e-07     1.32e-07     6.42e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    880    10     1.12e-07     1.12e-07     3.53e-06
    880    20     1.86e-07     1.86e-07     5.14e-06
    880    30     6.34e-08     6.34e-08     3.85e-06
    880    40     3.06e-07     3.06e-07     8.67e-06
    880    50     8.88e-08     8.88e-08     3.53e-06
    880    60     2.11e-08     2.11e-08     1.93e-06
    880    61     1.18e-06     1.18e-06      1.5e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             880 48459.192   0.0025     1.44e-07     1.44e-07     4.74e-06
! Validation        880 48459.192   0.0025     1.31e-07     1.31e-07     4.12e-06
Wall time: 48459.192852666005
training
# Epoch batch         loss       loss_e      e/N_mae
    881    10     6.21e-07     6.21e-07     9.96e-06
    881    20     2.32e-07     2.32e-07     6.53e-06
    881    30     1.85e-07     1.85e-07     6.75e-06
    881    40     2.33e-07     2.33e-07     5.89e-06
    881    48      9.4e-07      9.4e-07     1.37e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    881    10      1.2e-07      1.2e-07     5.14e-06
    881    20     2.11e-07     2.11e-07     5.78e-06
    881    30     3.59e-08     3.59e-08     2.57e-06
    881    40        3e-07        3e-07     8.35e-06
    881    50      3.8e-08      3.8e-08     2.89e-06
    881    60     3.17e-08     3.17e-08     2.25e-06
    881    61     1.43e-06     1.43e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             881 48514.341   0.0025     3.05e-07     3.05e-07     6.92e-06
! Validation        881 48514.341   0.0025     1.42e-07     1.42e-07     4.25e-06
Wall time: 48514.341251916005
training
# Epoch batch         loss       loss_e      e/N_mae
    882    10     1.04e-06     1.04e-06     1.62e-05
    882    20     3.59e-07     3.59e-07     7.07e-06
    882    30     6.52e-07     6.52e-07     1.14e-05
    882    40     7.63e-07     7.63e-07     1.05e-05
    882    48      5.8e-06      5.8e-06     3.05e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    882    10     1.39e-07     1.39e-07     5.46e-06
    882    20     2.09e-07     2.09e-07      6.1e-06
    882    30     9.72e-08     9.72e-08     5.14e-06
    882    40     2.24e-07     2.24e-07     6.42e-06
    882    50     7.19e-08     7.19e-08     4.18e-06
    882    60     4.02e-08     4.02e-08     2.89e-06
    882    61     1.23e-06     1.23e-06     1.34e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             882 48569.313   0.0025     6.62e-07     6.62e-07     9.68e-06
! Validation        882 48569.313   0.0025     1.41e-07     1.41e-07     4.41e-06
Wall time: 48569.314548208
training
# Epoch batch         loss       loss_e      e/N_mae
    883    10     3.71e-06     3.71e-06     2.73e-05
    883    20     6.15e-06     6.15e-06     3.44e-05
    883    30     3.09e-06     3.09e-06     2.61e-05
    883    40      1.7e-06      1.7e-06     1.72e-05
    883    48     4.76e-07     4.76e-07     1.04e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    883    10      2.3e-07      2.3e-07      6.1e-06
    883    20     2.09e-07     2.09e-07      6.1e-06
    883    30     2.54e-08     2.54e-08     2.25e-06
    883    40     3.64e-07     3.64e-07     8.99e-06
    883    50     1.48e-07     1.48e-07      4.5e-06
    883    60     1.33e-07     1.33e-07      4.5e-06
    883    61     1.33e-06     1.33e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             883 48624.482   0.0025     3.51e-06     3.51e-06     2.27e-05
! Validation        883 48624.482   0.0025     1.89e-07     1.89e-07     5.38e-06
Wall time: 48624.483449750005
training
# Epoch batch         loss       loss_e      e/N_mae
    884    10     5.02e-07     5.02e-07     9.64e-06
    884    20     2.49e-07     2.49e-07      7.5e-06
    884    30     1.97e-07     1.97e-07      6.1e-06
    884    40     1.51e-07     1.51e-07     5.25e-06
    884    48     1.32e-07     1.32e-07     6.42e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    884    10     2.16e-07     2.16e-07      6.1e-06
    884    20     1.73e-07     1.73e-07     3.85e-06
    884    30     4.65e-08     4.65e-08     2.89e-06
    884    40     4.59e-07     4.59e-07     9.96e-06
    884    50     3.11e-07     3.11e-07     7.07e-06
    884    60     8.45e-08     8.45e-08     3.85e-06
    884    61     1.81e-06     1.81e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             884 48679.531   0.0025      3.8e-07      3.8e-07      7.9e-06
! Validation        884 48679.531   0.0025     2.12e-07     2.12e-07     5.42e-06
Wall time: 48679.531492875
training
# Epoch batch         loss       loss_e      e/N_mae
    885    10     2.38e-07     2.38e-07     6.53e-06
    885    20     1.75e-07     1.75e-07     5.46e-06
    885    30     2.59e-07     2.59e-07     6.53e-06
    885    40     2.42e-07     2.42e-07     6.64e-06
    885    48     1.32e-07     1.32e-07     5.62e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    885    10      1.8e-07      1.8e-07     5.46e-06
    885    20     3.17e-07     3.17e-07      6.1e-06
    885    30     5.07e-08     5.07e-08     4.18e-06
    885    40     3.19e-07     3.19e-07     8.67e-06
    885    50     2.43e-07     2.43e-07     6.42e-06
    885    60     2.96e-08     2.96e-08     2.57e-06
    885    61     2.23e-06     2.23e-06     1.98e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             885 48734.632   0.0025     1.93e-07     1.93e-07     5.63e-06
! Validation        885 48734.632   0.0025     2.07e-07     2.07e-07     5.15e-06
Wall time: 48734.632555166005
training
# Epoch batch         loss       loss_e      e/N_mae
    886    10     1.04e-07     1.04e-07     3.64e-06
    886    20     1.14e-07     1.14e-07     4.82e-06
    886    30     1.16e-07     1.16e-07      4.5e-06
    886    40     4.65e-08     4.65e-08     3.11e-06
    886    48     1.06e-08     1.06e-08     1.61e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    886    10     2.51e-07     2.51e-07     6.42e-06
    886    20     2.24e-07     2.24e-07     4.82e-06
    886    30     2.54e-08     2.54e-08     2.57e-06
    886    40     2.28e-07     2.28e-07     7.39e-06
    886    50     1.65e-07     1.65e-07     5.46e-06
    886    60     5.49e-08     5.49e-08     3.21e-06
    886    61     1.91e-06     1.91e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             886 48789.714   0.0025     1.26e-07     1.26e-07     4.55e-06
! Validation        886 48789.714   0.0025     1.81e-07     1.81e-07     4.79e-06
Wall time: 48789.714890166004
training
# Epoch batch         loss       loss_e      e/N_mae
    887    10     9.58e-08     9.58e-08     3.85e-06
    887    20     3.66e-08     3.66e-08     2.68e-06
    887    30     1.56e-07     1.56e-07     5.03e-06
    887    40     1.44e-07     1.44e-07      4.5e-06
    887    48     2.11e-07     2.11e-07     6.42e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    887    10      2.3e-07      2.3e-07     5.46e-06
    887    20     2.18e-07     2.18e-07     4.82e-06
    887    30     6.13e-08     6.13e-08     3.53e-06
    887    40     2.41e-07     2.41e-07     7.39e-06
    887    50     1.73e-07     1.73e-07      6.1e-06
    887    60     5.49e-08     5.49e-08     3.21e-06
    887    61     1.85e-06     1.85e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             887 48844.963   0.0025     1.01e-07     1.01e-07     4.01e-06
! Validation        887 48844.963   0.0025     1.78e-07     1.78e-07     4.85e-06
Wall time: 48844.964454791
training
# Epoch batch         loss       loss_e      e/N_mae
    888    10     8.45e-07     8.45e-07     1.09e-05
    888    20     1.39e-07     1.39e-07     4.82e-06
    888    30     1.06e-07     1.06e-07     3.75e-06
    888    40     1.59e-07     1.59e-07     5.89e-06
    888    48     5.34e-07     5.34e-07     9.64e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    888    10     2.68e-07     2.68e-07      6.1e-06
    888    20     2.68e-07     2.68e-07     5.14e-06
    888    30     7.19e-08     7.19e-08     3.85e-06
    888    40     2.05e-07     2.05e-07     6.42e-06
    888    50     1.42e-07     1.42e-07     5.78e-06
    888    60     7.82e-08     7.82e-08     3.53e-06
    888    61     1.78e-06     1.78e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             888 48899.930   0.0025     1.94e-07     1.94e-07     5.28e-06
! Validation        888 48899.930   0.0025     1.69e-07     1.69e-07     4.42e-06
Wall time: 48899.930927083005
training
# Epoch batch         loss       loss_e      e/N_mae
    889    10     2.73e-07     2.73e-07     7.28e-06
    889    20      1.1e-07      1.1e-07      4.6e-06
    889    30     1.31e-07     1.31e-07     4.82e-06
    889    40     7.26e-08     7.26e-08     3.75e-06
    889    48     2.64e-08     2.64e-08     2.41e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    889    10     2.24e-07     2.24e-07     5.78e-06
    889    20     2.75e-07     2.75e-07     5.46e-06
    889    30     3.38e-08     3.38e-08     3.21e-06
    889    40     1.73e-07     1.73e-07      6.1e-06
    889    50      1.1e-07      1.1e-07     4.82e-06
    889    60     8.03e-08     8.03e-08     3.85e-06
    889    61     1.44e-06     1.44e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             889 48954.923   0.0025     2.15e-07     2.15e-07     5.78e-06
! Validation        889 48954.923   0.0025     1.59e-07     1.59e-07     4.51e-06
Wall time: 48954.924044916
training
# Epoch batch         loss       loss_e      e/N_mae
    890    10     1.18e-07     1.18e-07     4.39e-06
    890    20     1.82e-07     1.82e-07     5.03e-06
    890    30     9.37e-08     9.37e-08     3.85e-06
    890    40     4.02e-08     4.02e-08     2.78e-06
    890    48     5.28e-09     5.28e-09     8.03e-07
validation
# Epoch batch         loss       loss_e      e/N_mae
    890    10     2.47e-07     2.47e-07     4.82e-06
    890    20     1.75e-07     1.75e-07     3.85e-06
    890    30     5.49e-08     5.49e-08     3.85e-06
    890    40     1.99e-07     1.99e-07     6.75e-06
    890    50     4.65e-08     4.65e-08     3.53e-06
    890    60     6.55e-08     6.55e-08     2.89e-06
    890    61     1.19e-06     1.19e-06     1.45e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             890 49010.014   0.0025     1.07e-07     1.07e-07     4.21e-06
! Validation        890 49010.014   0.0025     1.44e-07     1.44e-07     4.37e-06
Wall time: 49010.014592166
training
# Epoch batch         loss       loss_e      e/N_mae
    891    10     6.41e-08     6.41e-08     3.85e-06
    891    20     1.62e-07     1.62e-07     5.35e-06
    891    30      1.1e-07      1.1e-07     4.28e-06
    891    40     2.62e-07     2.62e-07     5.68e-06
    891    48     1.32e-07     1.32e-07     4.02e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    891    10     3.21e-07     3.21e-07     6.42e-06
    891    20      1.2e-07      1.2e-07     3.85e-06
    891    30     8.88e-08     8.88e-08     5.46e-06
    891    40     1.46e-07     1.46e-07     5.46e-06
    891    50     6.97e-08     6.97e-08     3.21e-06
    891    60     1.27e-08     1.27e-08     1.28e-06
    891    61     1.19e-06     1.19e-06     1.45e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             891 49065.142   0.0025     1.14e-07     1.14e-07     4.28e-06
! Validation        891 49065.142   0.0025      1.4e-07      1.4e-07     4.28e-06
Wall time: 49065.142604
training
# Epoch batch         loss       loss_e      e/N_mae
    892    10     9.65e-08     9.65e-08     4.07e-06
    892    20     4.93e-08     4.93e-08     3.21e-06
    892    30     3.87e-08     3.87e-08     2.78e-06
    892    40     6.13e-08     6.13e-08     3.21e-06
    892    48     6.87e-08     6.87e-08     4.02e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    892    10      2.9e-07      2.9e-07     5.46e-06
    892    20     1.54e-07     1.54e-07     3.85e-06
    892    30     6.76e-08     6.76e-08     4.82e-06
    892    40     1.73e-07     1.73e-07     5.78e-06
    892    50     9.09e-08     9.09e-08      4.5e-06
    892    60     2.11e-08     2.11e-08     1.93e-06
    892    61     1.51e-06     1.51e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             892 49120.293   0.0025     7.46e-08     7.46e-08     3.48e-06
! Validation        892 49120.293   0.0025     1.37e-07     1.37e-07     4.11e-06
Wall time: 49120.293240916006
training
# Epoch batch         loss       loss_e      e/N_mae
    893    10     7.61e-08     7.61e-08     3.85e-06
    893    20      1.4e-07      1.4e-07     4.71e-06
    893    30      6.2e-08      6.2e-08     3.32e-06
    893    40     1.11e-07     1.11e-07     4.71e-06
    893    48     5.28e-08     5.28e-08     4.02e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    893    10     2.18e-07     2.18e-07     5.46e-06
    893    20     1.48e-07     1.48e-07     4.18e-06
    893    30     8.24e-08     8.24e-08     5.14e-06
    893    40     2.45e-07     2.45e-07     7.71e-06
    893    50     9.09e-08     9.09e-08      4.5e-06
    893    60     2.54e-08     2.54e-08     1.93e-06
    893    61     1.25e-06     1.25e-06      1.5e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             893 49175.432   0.0025     8.49e-08     8.49e-08      3.8e-06
! Validation        893 49175.432   0.0025     1.35e-07     1.35e-07     4.18e-06
Wall time: 49175.433375875
training
# Epoch batch         loss       loss_e      e/N_mae
    894    10     1.09e-07     1.09e-07      4.6e-06
    894    20     9.51e-08     9.51e-08     3.75e-06
    894    30     7.19e-08     7.19e-08     3.43e-06
    894    40     2.37e-07     2.37e-07     6.32e-06
    894    48     4.49e-07     4.49e-07     1.12e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    894    10     2.16e-07     2.16e-07     5.14e-06
    894    20     1.39e-07     1.39e-07     3.53e-06
    894    30     3.38e-08     3.38e-08     3.21e-06
    894    40     2.01e-07     2.01e-07      6.1e-06
    894    50     9.09e-08     9.09e-08      4.5e-06
    894    60     2.96e-08     2.96e-08     2.57e-06
    894    61     1.19e-06     1.19e-06     1.45e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             894 49230.297   0.0025     9.85e-08     9.85e-08     3.83e-06
! Validation        894 49230.297   0.0025     1.36e-07     1.36e-07     4.25e-06
Wall time: 49230.297526125
training
# Epoch batch         loss       loss_e      e/N_mae
    895    10     5.92e-08     5.92e-08     3.32e-06
    895    20     3.46e-07     3.46e-07     8.14e-06
    895    30     1.42e-07     1.42e-07     5.14e-06
    895    40      2.5e-07      2.5e-07     5.89e-06
    895    48     2.17e-06     2.17e-06     2.41e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    895    10     1.99e-07     1.99e-07     5.46e-06
    895    20     8.88e-08     8.88e-08     3.85e-06
    895    30     4.02e-08     4.02e-08     3.21e-06
    895    40     1.54e-07     1.54e-07     5.78e-06
    895    50     1.16e-07     1.16e-07     5.14e-06
    895    60     4.86e-08     4.86e-08     2.89e-06
    895    61     1.37e-06     1.37e-06     1.55e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             895 49285.380   0.0025     2.77e-07     2.77e-07     6.23e-06
! Validation        895 49285.380   0.0025     1.36e-07     1.36e-07     4.26e-06
Wall time: 49285.381253041
training
# Epoch batch         loss       loss_e      e/N_mae
    896    10     2.63e-07     2.63e-07     5.89e-06
    896    20     4.86e-07     4.86e-07     1.01e-05
    896    30     8.66e-07     8.66e-07     1.17e-05
    896    40     3.34e-07     3.34e-07     6.53e-06
    896    48     5.49e-07     5.49e-07     1.04e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    896    10     2.35e-07     2.35e-07     5.46e-06
    896    20     1.27e-07     1.27e-07      4.5e-06
    896    30     2.96e-08     2.96e-08     3.21e-06
    896    40     1.99e-07     1.99e-07      6.1e-06
    896    50     4.65e-08     4.65e-08     3.53e-06
    896    60     6.55e-08     6.55e-08     3.53e-06
    896    61     1.78e-06     1.78e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             896 49340.552   0.0025      5.7e-07      5.7e-07     9.51e-06
! Validation        896 49340.552   0.0025     1.48e-07     1.48e-07     4.35e-06
Wall time: 49340.552666125004
training
# Epoch batch         loss       loss_e      e/N_mae
    897    10     5.66e-07     5.66e-07     1.07e-05
    897    20     9.86e-07     9.86e-07     1.36e-05
    897    30     1.72e-07     1.72e-07     5.03e-06
    897    40     2.59e-07     2.59e-07     5.14e-06
    897    48      2.8e-07      2.8e-07     7.23e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    897    10     2.87e-07     2.87e-07     6.75e-06
    897    20     8.66e-08     8.66e-08     3.53e-06
    897    30     5.07e-08     5.07e-08     3.53e-06
    897    40     2.62e-07     2.62e-07     7.71e-06
    897    50     9.09e-08     9.09e-08     4.82e-06
    897    60     5.92e-08     5.92e-08     3.21e-06
    897    61     1.59e-06     1.59e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             897 49395.506   0.0025     6.25e-07     6.25e-07     9.92e-06
! Validation        897 49395.506   0.0025     1.35e-07     1.35e-07     4.07e-06
Wall time: 49395.507281583
training
# Epoch batch         loss       loss_e      e/N_mae
    898    10     3.27e-07     3.27e-07      7.6e-06
    898    20     1.05e-07     1.05e-07     3.96e-06
    898    30      1.9e-07      1.9e-07      6.1e-06
    898    40     9.51e-08     9.51e-08      4.5e-06
    898    48     1.37e-07     1.37e-07     4.82e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    898    10     2.94e-07     2.94e-07      6.1e-06
    898    20     1.78e-07     1.78e-07      4.5e-06
    898    30     3.17e-08     3.17e-08     2.57e-06
    898    40     2.77e-07     2.77e-07     7.39e-06
    898    50     1.04e-07     1.04e-07     5.14e-06
    898    60     4.44e-08     4.44e-08     2.25e-06
    898    61     1.58e-06     1.58e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             898 49450.736   0.0025     1.88e-07     1.88e-07     5.57e-06
! Validation        898 49450.736   0.0025     1.42e-07     1.42e-07     4.18e-06
Wall time: 49450.737173916
training
# Epoch batch         loss       loss_e      e/N_mae
    899    10     2.25e-07     2.25e-07     7.39e-06
    899    20     5.96e-07     5.96e-07      9.1e-06
    899    30     9.37e-07     9.37e-07     1.31e-05
    899    40     1.98e-06     1.98e-06     1.85e-05
    899    48     6.13e-07     6.13e-07     1.12e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    899    10     1.59e-07     1.59e-07     4.18e-06
    899    20     1.23e-07     1.23e-07      4.5e-06
    899    30     3.59e-08     3.59e-08     2.57e-06
    899    40     2.68e-07     2.68e-07     6.75e-06
    899    50     1.73e-07     1.73e-07     6.75e-06
    899    60     8.03e-08     8.03e-08     4.18e-06
    899    61     1.84e-06     1.84e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             899 49505.713   0.0025     5.98e-07     5.98e-07     9.63e-06
! Validation        899 49505.713   0.0025     1.36e-07     1.36e-07     4.12e-06
Wall time: 49505.713173625
training
# Epoch batch         loss       loss_e      e/N_mae
    900    10     1.58e-06     1.58e-06     1.83e-05
    900    20     4.05e-07     4.05e-07     8.14e-06
    900    30      2.3e-07      2.3e-07     6.42e-06
    900    40     5.24e-07     5.24e-07     1.05e-05
    900    48     3.59e-07     3.59e-07     8.03e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    900    10     2.43e-07     2.43e-07     5.46e-06
    900    20     2.81e-07     2.81e-07     5.78e-06
    900    30     3.17e-08     3.17e-08     2.89e-06
    900    40     2.49e-07     2.49e-07     7.39e-06
    900    50     6.76e-08     6.76e-08     4.18e-06
    900    60     5.71e-08     5.71e-08     2.89e-06
    900    61     1.19e-06     1.19e-06      1.5e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             900 49560.798   0.0025     5.72e-07     5.72e-07     9.81e-06
! Validation        900 49560.798   0.0025     1.31e-07     1.31e-07     4.34e-06
Wall time: 49560.798918208005
training
# Epoch batch         loss       loss_e      e/N_mae
    901    10     7.35e-07     7.35e-07     1.17e-05
    901    20     3.53e-07     3.53e-07     7.71e-06
    901    30     1.92e-07     1.92e-07     5.89e-06
    901    40     1.52e-07     1.52e-07     5.35e-06
    901    48     4.49e-07     4.49e-07     1.04e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    901    10     2.22e-07     2.22e-07     5.46e-06
    901    20     2.09e-07     2.09e-07      6.1e-06
    901    30     1.06e-08     1.06e-08     9.64e-07
    901    40     2.58e-07     2.58e-07     7.71e-06
    901    50     8.88e-08     8.88e-08     4.18e-06
    901    60     3.17e-08     3.17e-08     2.25e-06
    901    61     1.15e-06     1.15e-06      1.5e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             901 49616.048   0.0025     3.36e-07     3.36e-07     7.26e-06
! Validation        901 49616.048   0.0025     1.35e-07     1.35e-07     4.39e-06
Wall time: 49616.048952791
training
# Epoch batch         loss       loss_e      e/N_mae
    902    10     1.23e-07     1.23e-07     3.96e-06
    902    20     9.93e-08     9.93e-08     3.64e-06
    902    30     1.56e-07     1.56e-07     5.46e-06
    902    40     5.85e-08     5.85e-08     3.64e-06
    902    48     5.28e-09     5.28e-09     8.03e-07
validation
# Epoch batch         loss       loss_e      e/N_mae
    902    10     1.75e-07     1.75e-07     4.82e-06
    902    20     1.92e-07     1.92e-07     5.14e-06
    902    30     1.69e-08     1.69e-08     2.57e-06
    902    40     2.13e-07     2.13e-07     7.07e-06
    902    50     6.34e-08     6.34e-08     3.53e-06
    902    60     6.76e-08     6.76e-08     4.18e-06
    902    61      1.3e-06      1.3e-06      1.5e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             902 49670.999   0.0025     1.35e-07     1.35e-07     4.66e-06
! Validation        902 49670.999   0.0025      1.4e-07      1.4e-07     4.37e-06
Wall time: 49671.000455958005
training
# Epoch batch         loss       loss_e      e/N_mae
    903    10     1.06e-07     1.06e-07     4.71e-06
    903    20     1.73e-07     1.73e-07     5.78e-06
    903    30     9.72e-08     9.72e-08     4.07e-06
    903    40     2.18e-08     2.18e-08     1.93e-06
    903    48     1.32e-07     1.32e-07     6.42e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    903    10     2.09e-07     2.09e-07     4.82e-06
    903    20     2.09e-07     2.09e-07     5.78e-06
    903    30     2.54e-08     2.54e-08     2.25e-06
    903    40     2.37e-07     2.37e-07     7.39e-06
    903    50     6.76e-08     6.76e-08     4.18e-06
    903    60     6.97e-08     6.97e-08     3.53e-06
    903    61     1.44e-06     1.44e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             903 49726.038   0.0025     9.84e-08     9.84e-08     4.07e-06
! Validation        903 49726.038   0.0025     1.41e-07     1.41e-07     4.37e-06
Wall time: 49726.039322375
training
# Epoch batch         loss       loss_e      e/N_mae
    904    10     6.27e-08     6.27e-08     3.21e-06
    904    20     8.38e-08     8.38e-08     4.28e-06
    904    30     7.82e-08     7.82e-08     3.64e-06
    904    40     9.16e-08     9.16e-08     3.85e-06
    904    48     4.76e-08     4.76e-08     3.21e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    904    10     2.22e-07     2.22e-07     5.78e-06
    904    20     2.41e-07     2.41e-07     5.46e-06
    904    30     1.06e-08     1.06e-08     1.28e-06
    904    40      1.2e-07      1.2e-07     5.14e-06
    904    50     4.44e-08     4.44e-08     3.21e-06
    904    60     4.02e-08     4.02e-08     2.89e-06
    904    61     1.19e-06     1.19e-06      1.5e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             904 49780.999   0.0025     9.58e-08     9.58e-08     4.05e-06
! Validation        904 49780.999   0.0025     1.25e-07     1.25e-07     3.98e-06
Wall time: 49780.998853333
! Best model      904    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    905    10     5.21e-08     5.21e-08     2.78e-06
    905    20     4.72e-08     4.72e-08        3e-06
    905    30     1.04e-07     1.04e-07     4.39e-06
    905    40     1.99e-07     1.99e-07     5.14e-06
    905    48     1.53e-07     1.53e-07     6.42e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    905    10     2.98e-07     2.98e-07      6.1e-06
    905    20     2.24e-07     2.24e-07     4.82e-06
    905    30     3.17e-08     3.17e-08     2.57e-06
    905    40     1.27e-07     1.27e-07     4.82e-06
    905    50     6.55e-08     6.55e-08     3.85e-06
    905    60      3.8e-08      3.8e-08     2.57e-06
    905    61      1.5e-06      1.5e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             905 49835.832   0.0025     8.11e-08     8.11e-08     3.63e-06
! Validation        905 49835.832   0.0025     1.37e-07     1.37e-07      4.1e-06
Wall time: 49835.833167458004
training
# Epoch batch         loss       loss_e      e/N_mae
    906    10     2.87e-07     2.87e-07     8.46e-06
    906    20     4.09e-07     4.09e-07     8.99e-06
    906    30      2.3e-07      2.3e-07        6e-06
    906    40     1.63e-07     1.63e-07     4.71e-06
    906    48     5.28e-08     5.28e-08     3.21e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    906    10     3.42e-07     3.42e-07     6.42e-06
    906    20     2.68e-07     2.68e-07     5.14e-06
    906    30     1.27e-08     1.27e-08     1.61e-06
    906    40     1.16e-07     1.16e-07     4.82e-06
    906    50     6.55e-08     6.55e-08     3.85e-06
    906    60     2.96e-08     2.96e-08     2.57e-06
    906    61     1.49e-06     1.49e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             906 49890.871   0.0025     2.43e-07     2.43e-07     6.18e-06
! Validation        906 49890.871   0.0025     1.37e-07     1.37e-07     4.07e-06
Wall time: 49890.870767583
training
# Epoch batch         loss       loss_e      e/N_mae
    907    10     1.08e-07     1.08e-07     3.85e-06
    907    20     2.96e-08     2.96e-08     2.36e-06
    907    30     1.08e-07     1.08e-07     4.28e-06
    907    40     4.93e-08     4.93e-08     2.46e-06
    907    48     5.28e-09     5.28e-09     8.03e-07
validation
# Epoch batch         loss       loss_e      e/N_mae
    907    10     2.09e-07     2.09e-07     4.82e-06
    907    20     1.65e-07     1.65e-07     4.82e-06
    907    30     3.17e-08     3.17e-08     2.57e-06
    907    40     1.65e-07     1.65e-07     5.14e-06
    907    50     8.24e-08     8.24e-08      4.5e-06
    907    60     2.75e-08     2.75e-08     2.25e-06
    907    61     1.43e-06     1.43e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             907 49946.073   0.0025     8.34e-08     8.34e-08     3.64e-06
! Validation        907 49946.073   0.0025     1.31e-07     1.31e-07     4.07e-06
Wall time: 49946.074251583
training
# Epoch batch         loss       loss_e      e/N_mae
    908    10     7.96e-08     7.96e-08     3.96e-06
    908    20     2.37e-07     2.37e-07        6e-06
    908    30     1.01e-07     1.01e-07     3.32e-06
    908    40     1.03e-07     1.03e-07     4.07e-06
    908    48     5.28e-08     5.28e-08     3.21e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    908    10     1.63e-07     1.63e-07     4.82e-06
    908    20     1.92e-07     1.92e-07     5.14e-06
    908    30     1.48e-08     1.48e-08     1.93e-06
    908    40     1.73e-07     1.73e-07     5.78e-06
    908    50      9.3e-08      9.3e-08     4.82e-06
    908    60     7.61e-08     7.61e-08     3.85e-06
    908    61     1.99e-06     1.99e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             908 50001.329   0.0025     1.18e-07     1.18e-07     4.37e-06
! Validation        908 50001.329   0.0025     1.36e-07     1.36e-07     4.07e-06
Wall time: 50001.33024
training
# Epoch batch         loss       loss_e      e/N_mae
    909    10     6.27e-08     6.27e-08     3.21e-06
    909    20      7.4e-08      7.4e-08     3.75e-06
    909    30     4.65e-08     4.65e-08     3.11e-06
    909    40     1.17e-07     1.17e-07     4.82e-06
    909    48     2.11e-07     2.11e-07     7.23e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    909    10     1.44e-07     1.44e-07      4.5e-06
    909    20     2.24e-07     2.24e-07     5.14e-06
    909    30     3.38e-08     3.38e-08     3.21e-06
    909    40     1.44e-07     1.44e-07     5.14e-06
    909    50     1.18e-07     1.18e-07     5.46e-06
    909    60     2.96e-08     2.96e-08     2.89e-06
    909    61     1.62e-06     1.62e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             909 50056.274   0.0025     1.07e-07     1.07e-07     4.25e-06
! Validation        909 50056.274   0.0025     1.31e-07     1.31e-07     4.07e-06
Wall time: 50056.275059666004
training
# Epoch batch         loss       loss_e      e/N_mae
    910    10     2.25e-07     2.25e-07     6.53e-06
    910    20      6.2e-08      6.2e-08     3.32e-06
    910    30     1.25e-07     1.25e-07     4.71e-06
    910    40     6.34e-08     6.34e-08     2.78e-06
    910    48     1.06e-07     1.06e-07     4.82e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    910    10     1.61e-07     1.61e-07      4.5e-06
    910    20     1.84e-07     1.84e-07      4.5e-06
    910    30     4.02e-08     4.02e-08     2.57e-06
    910    40     1.82e-07     1.82e-07     5.78e-06
    910    50     2.11e-08     2.11e-08     1.28e-06
    910    60      3.8e-08      3.8e-08     2.57e-06
    910    61     1.66e-06     1.66e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             910 50111.172   0.0025     1.09e-07     1.09e-07     4.29e-06
! Validation        910 50111.172   0.0025      1.3e-07      1.3e-07     3.81e-06
Wall time: 50111.172894166004
training
# Epoch batch         loss       loss_e      e/N_mae
    911    10     5.57e-08     5.57e-08     3.11e-06
    911    20     3.16e-07     3.16e-07     6.32e-06
    911    30     7.89e-08     7.89e-08     3.32e-06
    911    40     1.08e-07     1.08e-07     4.82e-06
    911    48     6.87e-08     6.87e-08     4.02e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    911    10     1.25e-07     1.25e-07     3.53e-06
    911    20     1.65e-07     1.65e-07     4.82e-06
    911    30     1.27e-08     1.27e-08     1.61e-06
    911    40     2.26e-07     2.26e-07     7.07e-06
    911    50     4.44e-08     4.44e-08     3.21e-06
    911    60     2.32e-08     2.32e-08     2.25e-06
    911    61     1.76e-06     1.76e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             911 50166.301   0.0025     1.27e-07     1.27e-07     4.53e-06
! Validation        911 50166.301   0.0025     1.31e-07     1.31e-07     3.89e-06
Wall time: 50166.301124041005
training
# Epoch batch         loss       loss_e      e/N_mae
    912    10     8.88e-08     8.88e-08     3.85e-06
    912    20     9.86e-08     9.86e-08     3.21e-06
    912    30     2.51e-07     2.51e-07        6e-06
    912    40     1.44e-07     1.44e-07     5.25e-06
    912    48     5.28e-09     5.28e-09     8.03e-07
validation
# Epoch batch         loss       loss_e      e/N_mae
    912    10      1.8e-07      1.8e-07     4.82e-06
    912    20     1.67e-07     1.67e-07     5.46e-06
    912    30     2.11e-08     2.11e-08     2.25e-06
    912    40     1.86e-07     1.86e-07     5.78e-06
    912    50     4.65e-08     4.65e-08     3.53e-06
    912    60     3.17e-08     3.17e-08     2.25e-06
    912    61     1.51e-06     1.51e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             912 50221.434   0.0025     1.32e-07     1.32e-07      4.7e-06
! Validation        912 50221.434   0.0025      1.3e-07      1.3e-07     3.99e-06
Wall time: 50221.435475750004
training
# Epoch batch         loss       loss_e      e/N_mae
    913    10        5e-08        5e-08        3e-06
    913    20     5.64e-08     5.64e-08     3.43e-06
    913    30     8.45e-08     8.45e-08     3.64e-06
    913    40     1.09e-07     1.09e-07     4.39e-06
    913    48     5.28e-09     5.28e-09     8.03e-07
validation
# Epoch batch         loss       loss_e      e/N_mae
    913    10     9.93e-08     9.93e-08     3.53e-06
    913    20     2.07e-07     2.07e-07     5.46e-06
    913    30     2.54e-08     2.54e-08     2.57e-06
    913    40     1.84e-07     1.84e-07      6.1e-06
    913    50     6.34e-08     6.34e-08     3.53e-06
    913    60     2.11e-08     2.11e-08     1.93e-06
    913    61     1.46e-06     1.46e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             913 50276.697   0.0025     7.24e-08     7.24e-08     3.54e-06
! Validation        913 50276.697   0.0025     1.27e-07     1.27e-07     4.02e-06
Wall time: 50276.697662833
training
# Epoch batch         loss       loss_e      e/N_mae
    914    10     1.29e-07     1.29e-07     5.03e-06
    914    20      8.1e-08      8.1e-08     3.96e-06
    914    30     7.68e-08     7.68e-08     3.75e-06
    914    40     8.66e-08     8.66e-08     3.85e-06
    914    48     1.06e-08     1.06e-08     1.61e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    914    10     1.92e-07     1.92e-07     4.82e-06
    914    20     1.46e-07     1.46e-07     4.18e-06
    914    30     3.38e-08     3.38e-08     3.21e-06
    914    40     2.07e-07     2.07e-07     5.78e-06
    914    50     5.28e-08     5.28e-08     3.21e-06
    914    60     1.01e-07     1.01e-07      4.5e-06
    914    61     1.79e-06     1.79e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             914 50331.679   0.0025     8.19e-08     8.19e-08     3.79e-06
! Validation        914 50331.679   0.0025     1.34e-07     1.34e-07     4.08e-06
Wall time: 50331.678833000005
training
# Epoch batch         loss       loss_e      e/N_mae
    915    10      4.3e-08      4.3e-08        3e-06
    915    20     7.04e-08     7.04e-08     3.53e-06
    915    30     9.51e-08     9.51e-08     3.96e-06
    915    40     5.99e-08     5.99e-08        3e-06
    915    48     4.23e-08     4.23e-08     3.21e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    915    10     1.42e-07     1.42e-07     4.18e-06
    915    20      1.9e-07      1.9e-07     5.14e-06
    915    30     4.23e-08     4.23e-08     3.21e-06
    915    40     1.65e-07     1.65e-07     5.14e-06
    915    50     5.71e-08     5.71e-08     3.21e-06
    915    60     2.75e-08     2.75e-08     2.25e-06
    915    61     1.56e-06     1.56e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             915 50386.618   0.0025     8.77e-08     8.77e-08      3.8e-06
! Validation        915 50386.618   0.0025     1.33e-07     1.33e-07     4.04e-06
Wall time: 50386.619761208
training
# Epoch batch         loss       loss_e      e/N_mae
    916    10     9.79e-08     9.79e-08     4.18e-06
    916    20     3.87e-08     3.87e-08     2.46e-06
    916    30     5.21e-08     5.21e-08     2.78e-06
    916    40     7.68e-08     7.68e-08     4.39e-06
    916    48     5.28e-08     5.28e-08     3.21e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    916    10     2.03e-07     2.03e-07     5.46e-06
    916    20      1.1e-07      1.1e-07     3.85e-06
    916    30      1.9e-08      1.9e-08     2.25e-06
    916    40     2.71e-07     2.71e-07     7.39e-06
    916    50     6.13e-08     6.13e-08     3.85e-06
    916    60     1.27e-08     1.27e-08     1.28e-06
    916    61     1.56e-06     1.56e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             916 50441.767   0.0025     8.45e-08     8.45e-08     3.65e-06
! Validation        916 50441.767   0.0025     1.35e-07     1.35e-07     4.02e-06
Wall time: 50441.767369916
training
# Epoch batch         loss       loss_e      e/N_mae
    917    10     5.85e-08     5.85e-08     3.21e-06
    917    20     1.01e-07     1.01e-07     3.85e-06
    917    30     9.09e-08     9.09e-08     4.28e-06
    917    40     5.14e-08     5.14e-08     2.78e-06
    917    48     2.64e-08     2.64e-08     3.21e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    917    10     2.11e-07     2.11e-07     5.14e-06
    917    20     1.27e-07     1.27e-07      4.5e-06
    917    30     2.96e-08     2.96e-08     2.57e-06
    917    40     2.05e-07     2.05e-07     6.42e-06
    917    50     4.65e-08     4.65e-08     2.89e-06
    917    60     8.45e-09     8.45e-09     1.28e-06
    917    61      1.4e-06      1.4e-06      1.5e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             917 50496.815   0.0025     1.02e-07     1.02e-07     4.16e-06
! Validation        917 50496.815   0.0025     1.21e-07     1.21e-07     3.77e-06
Wall time: 50496.815721166
! Best model      917    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    918    10     6.06e-08     6.06e-08     2.89e-06
    918    20     8.59e-08     8.59e-08     3.64e-06
    918    30     5.14e-08     5.14e-08     2.89e-06
    918    40     2.04e-07     2.04e-07     6.21e-06
    918    48     1.53e-07     1.53e-07     5.62e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    918    10     1.61e-07     1.61e-07      4.5e-06
    918    20     1.61e-07     1.61e-07     5.46e-06
    918    30     8.45e-09     8.45e-09     9.64e-07
    918    40     1.69e-07     1.69e-07     5.78e-06
    918    50     6.13e-08     6.13e-08     3.85e-06
    918    60     1.48e-08     1.48e-08     1.93e-06
    918    61     1.51e-06     1.51e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             918 50551.922   0.0025     1.17e-07     1.17e-07     4.14e-06
! Validation        918 50551.922   0.0025     1.25e-07     1.25e-07     3.94e-06
Wall time: 50551.922468583005
training
# Epoch batch         loss       loss_e      e/N_mae
    919    10     1.08e-07     1.08e-07     3.96e-06
    919    20     3.95e-07     3.95e-07     8.78e-06
    919    30     3.59e-07     3.59e-07      7.6e-06
    919    40     2.26e-07     2.26e-07     5.78e-06
    919    48     1.32e-07     1.32e-07     5.62e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    919    10     9.51e-08     9.51e-08     3.53e-06
    919    20     1.16e-07     1.16e-07     3.85e-06
    919    30     1.69e-08     1.69e-08     2.89e-06
    919    40     1.42e-07     1.42e-07     5.46e-06
    919    50      3.8e-08      3.8e-08     2.89e-06
    919    60     6.76e-08     6.76e-08     3.85e-06
    919    61     1.22e-06     1.22e-06     1.55e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             919 50607.015   0.0025     2.26e-07     2.26e-07     6.05e-06
! Validation        919 50607.015   0.0025     1.21e-07     1.21e-07      3.9e-06
Wall time: 50607.01567575
! Best model      919    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    920    10     4.34e-07     4.34e-07     9.74e-06
    920    20     3.87e-07     3.87e-07     8.89e-06
    920    30     2.74e-07     2.74e-07      7.5e-06
    920    40     1.72e-07     1.72e-07     5.35e-06
    920    48     6.13e-07     6.13e-07      1.2e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    920    10     7.19e-08     7.19e-08     3.85e-06
    920    20     5.92e-08     5.92e-08     2.89e-06
    920    30     2.32e-08     2.32e-08     3.21e-06
    920    40     1.37e-07     1.37e-07     4.82e-06
    920    50     5.49e-08     5.49e-08     3.53e-06
    920    60     5.49e-08     5.49e-08     3.21e-06
    920    61     1.54e-06     1.54e-06      1.5e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             920 50661.878   0.0025     3.61e-07     3.61e-07     7.84e-06
! Validation        920 50661.878   0.0025     1.28e-07     1.28e-07        4e-06
Wall time: 50661.878905666
training
# Epoch batch         loss       loss_e      e/N_mae
    921    10     1.62e-06     1.62e-06      1.7e-05
    921    20     1.14e-07     1.14e-07     4.71e-06
    921    30     2.71e-07     2.71e-07     6.32e-06
    921    40     4.14e-07     4.14e-07     8.78e-06
    921    48     2.38e-07     2.38e-07     8.03e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    921    10      1.2e-07      1.2e-07      4.5e-06
    921    20     1.92e-07     1.92e-07     4.82e-06
    921    30     4.02e-08     4.02e-08     2.89e-06
    921    40     2.09e-07     2.09e-07     6.42e-06
    921    50     2.75e-08     2.75e-08     2.57e-06
    921    60     7.61e-08     7.61e-08     3.85e-06
    921    61     1.45e-06     1.45e-06     1.55e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             921 50717.062   0.0025     3.22e-07     3.22e-07     7.11e-06
! Validation        921 50717.062   0.0025     1.32e-07     1.32e-07     4.14e-06
Wall time: 50717.062527208
training
# Epoch batch         loss       loss_e      e/N_mae
    922    10     1.71e-07     1.71e-07     5.03e-06
    922    20     8.93e-07     8.93e-07     1.17e-05
    922    30     3.52e-07     3.52e-07      7.6e-06
    922    40     2.03e-07     2.03e-07     5.14e-06
    922    48     1.37e-07     1.37e-07     4.82e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    922    10     2.01e-07     2.01e-07     5.14e-06
    922    20     1.59e-07     1.59e-07     4.82e-06
    922    30     2.11e-08     2.11e-08     2.89e-06
    922    40     1.99e-07     1.99e-07      6.1e-06
    922    50     4.44e-08     4.44e-08     3.21e-06
    922    60     5.07e-08     5.07e-08     3.21e-06
    922    61     1.68e-06     1.68e-06     1.55e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             922 50772.316   0.0025     3.05e-07     3.05e-07     6.81e-06
! Validation        922 50772.316   0.0025     1.33e-07     1.33e-07     4.11e-06
Wall time: 50772.316283041
training
# Epoch batch         loss       loss_e      e/N_mae
    923    10     1.66e-07     1.66e-07     5.57e-06
    923    20     2.63e-07     2.63e-07     7.39e-06
    923    30     2.58e-07     2.58e-07     6.42e-06
    923    40     3.06e-07     3.06e-07     7.28e-06
    923    48     1.72e-06     1.72e-06     1.61e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    923    10     1.52e-07     1.52e-07     3.85e-06
    923    20     2.18e-07     2.18e-07      4.5e-06
    923    30     1.69e-08     1.69e-08     2.57e-06
    923    40     1.42e-07     1.42e-07     4.82e-06
    923    50     3.17e-08     3.17e-08     2.57e-06
    923    60     6.55e-08     6.55e-08     3.53e-06
    923    61     1.59e-06     1.59e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             923 50827.418   0.0025     2.11e-07     2.11e-07     5.46e-06
! Validation        923 50827.418   0.0025     1.34e-07     1.34e-07     3.99e-06
Wall time: 50827.419821041
training
# Epoch batch         loss       loss_e      e/N_mae
    924    10      1.9e-06      1.9e-06     1.55e-05
    924    20     1.25e-06     1.25e-06     1.43e-05
    924    30     9.76e-07     9.76e-07     1.36e-05
    924    40      9.9e-07      9.9e-07     1.28e-05
    924    48     2.17e-07     2.17e-07     7.23e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    924    10     1.35e-07     1.35e-07     4.82e-06
    924    20      1.5e-07      1.5e-07     5.46e-06
    924    30     3.38e-08     3.38e-08     2.89e-06
    924    40     2.01e-07     2.01e-07     6.42e-06
    924    50     1.25e-07     1.25e-07     5.14e-06
    924    60     2.54e-08     2.54e-08     1.93e-06
    924    61     1.27e-06     1.27e-06     1.45e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             924 50882.666   0.0025     1.74e-06     1.74e-06     1.59e-05
! Validation        924 50882.666   0.0025     1.29e-07     1.29e-07     4.16e-06
Wall time: 50882.667391875
training
# Epoch batch         loss       loss_e      e/N_mae
    925    10      3.1e-07      3.1e-07      7.5e-06
    925    20     3.03e-07     3.03e-07     7.07e-06
    925    30     3.16e-07     3.16e-07     8.14e-06
    925    40      2.2e-07      2.2e-07     6.85e-06
    925    48     2.38e-07     2.38e-07     7.23e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    925    10     2.13e-07     2.13e-07     4.82e-06
    925    20     1.35e-07     1.35e-07     5.14e-06
    925    30     8.45e-08     8.45e-08     4.82e-06
    925    40     1.61e-07     1.61e-07     5.14e-06
    925    50     1.14e-07     1.14e-07     5.46e-06
    925    60     6.34e-09     6.34e-09     9.64e-07
    925    61      1.6e-06      1.6e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             925 50937.631   0.0025     3.39e-07     3.39e-07     7.58e-06
! Validation        925 50937.631   0.0025     1.22e-07     1.22e-07     3.84e-06
Wall time: 50937.630948666
training
# Epoch batch         loss       loss_e      e/N_mae
    926    10     2.47e-07     2.47e-07     5.57e-06
    926    20     3.29e-07     3.29e-07     8.46e-06
    926    30     9.16e-08     9.16e-08      4.6e-06
    926    40     7.89e-08     7.89e-08     3.96e-06
    926    48     3.43e-07     3.43e-07     7.23e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    926    10     2.54e-07     2.54e-07     5.78e-06
    926    20     1.06e-07     1.06e-07     3.21e-06
    926    30     2.54e-08     2.54e-08     2.57e-06
    926    40      1.8e-07      1.8e-07      6.1e-06
    926    50     4.44e-08     4.44e-08     2.89e-06
    926    60     4.65e-08     4.65e-08     2.57e-06
    926    61     1.53e-06     1.53e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             926 50992.746   0.0025     1.89e-07     1.89e-07     5.47e-06
! Validation        926 50992.746   0.0025     1.37e-07     1.37e-07     4.19e-06
Wall time: 50992.747298791
training
# Epoch batch         loss       loss_e      e/N_mae
    927    10     1.67e-07     1.67e-07     5.68e-06
    927    20     1.66e-07     1.66e-07     4.93e-06
    927    30     1.66e-07     1.66e-07     5.25e-06
    927    40     1.25e-07     1.25e-07     4.71e-06
    927    48     1.53e-07     1.53e-07     5.62e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    927    10     2.56e-07     2.56e-07     6.42e-06
    927    20     1.65e-07     1.65e-07     5.78e-06
    927    30     4.86e-08     4.86e-08     3.85e-06
    927    40     1.78e-07     1.78e-07     5.78e-06
    927    50     4.02e-08     4.02e-08     3.21e-06
    927    60     5.49e-08     5.49e-08     3.21e-06
    927    61     1.19e-06     1.19e-06     1.45e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             927 51047.859   0.0025     1.54e-07     1.54e-07     4.95e-06
! Validation        927 51047.859   0.0025     1.21e-07     1.21e-07     3.96e-06
Wall time: 51047.858970583
training
# Epoch batch         loss       loss_e      e/N_mae
    928    10     3.15e-07     3.15e-07     7.39e-06
    928    20     1.32e-07     1.32e-07     4.28e-06
    928    30     2.23e-07     2.23e-07     6.42e-06
    928    40     1.23e-07     1.23e-07     4.82e-06
    928    48     5.28e-07     5.28e-07      1.2e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    928    10     1.97e-07     1.97e-07     4.82e-06
    928    20      2.2e-07      2.2e-07     7.07e-06
    928    30     1.27e-08     1.27e-08     1.61e-06
    928    40     1.46e-07     1.46e-07     4.82e-06
    928    50     7.19e-08     7.19e-08     3.53e-06
    928    60     4.65e-08     4.65e-08     2.57e-06
    928    61     1.53e-06     1.53e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             928 51103.119   0.0025     1.55e-07     1.55e-07     4.99e-06
! Validation        928 51103.119   0.0025     1.37e-07     1.37e-07     4.11e-06
Wall time: 51103.119053708004
training
# Epoch batch         loss       loss_e      e/N_mae
    929    10     3.82e-07     3.82e-07     8.03e-06
    929    20     9.51e-08     9.51e-08     3.75e-06
    929    30     2.43e-07     2.43e-07     5.78e-06
    929    40     1.39e-07     1.39e-07     4.39e-06
    929    48     4.76e-08     4.76e-08     2.41e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    929    10     1.99e-07     1.99e-07     5.46e-06
    929    20     1.67e-07     1.67e-07     5.78e-06
    929    30     4.02e-08     4.02e-08     3.85e-06
    929    40     1.84e-07     1.84e-07     5.78e-06
    929    50     7.82e-08     7.82e-08     3.85e-06
    929    60     4.02e-08     4.02e-08     2.25e-06
    929    61      1.5e-06      1.5e-06     1.55e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             929 51158.135   0.0025     2.25e-07     2.25e-07     5.68e-06
! Validation        929 51158.135   0.0025     1.38e-07     1.38e-07     4.13e-06
Wall time: 51158.135818916
training
# Epoch batch         loss       loss_e      e/N_mae
    930    10     5.21e-08     5.21e-08     3.21e-06
    930    20     1.82e-07     1.82e-07     5.78e-06
    930    30     6.83e-08     6.83e-08     3.85e-06
    930    40      1.5e-07      1.5e-07     4.18e-06
    930    48     2.11e-07     2.11e-07     6.42e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    930    10      1.5e-07      1.5e-07     5.14e-06
    930    20     1.14e-07     1.14e-07     3.85e-06
    930    30     6.13e-08     6.13e-08     3.85e-06
    930    40     9.09e-08     9.09e-08     4.18e-06
    930    50     8.45e-08     8.45e-08     4.18e-06
    930    60     5.49e-08     5.49e-08     3.53e-06
    930    61     1.78e-06     1.78e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             930 51213.188   0.0025     8.55e-08     8.55e-08     3.78e-06
! Validation        930 51213.188   0.0025     1.34e-07     1.34e-07     3.97e-06
Wall time: 51213.188024916
training
# Epoch batch         loss       loss_e      e/N_mae
    931    10     1.24e-07     1.24e-07     5.14e-06
    931    20     9.02e-08     9.02e-08     4.28e-06
    931    30     2.06e-07     2.06e-07     5.68e-06
    931    40     1.25e-07     1.25e-07      4.6e-06
    931    48     8.98e-08     8.98e-08     4.02e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    931    10     1.73e-07     1.73e-07      4.5e-06
    931    20     1.75e-07     1.75e-07      4.5e-06
    931    30     3.38e-08     3.38e-08     3.53e-06
    931    40     1.29e-07     1.29e-07     5.78e-06
    931    50     7.19e-08     7.19e-08     4.18e-06
    931    60     1.48e-08     1.48e-08     1.61e-06
    931    61     1.27e-06     1.27e-06     1.39e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             931 51268.263   0.0025     1.41e-07     1.41e-07     4.77e-06
! Validation        931 51268.263   0.0025     1.23e-07     1.23e-07     3.94e-06
Wall time: 51268.263197625005
training
# Epoch batch         loss       loss_e      e/N_mae
    932    10     4.93e-08     4.93e-08     3.21e-06
    932    20     1.23e-07     1.23e-07     4.28e-06
    932    30     5.57e-08     5.57e-08     3.11e-06
    932    40     7.33e-08     7.33e-08     3.21e-06
    932    48     2.11e-07     2.11e-07     7.23e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    932    10     1.61e-07     1.61e-07      4.5e-06
    932    20     1.86e-07     1.86e-07     5.14e-06
    932    30     3.17e-08     3.17e-08     2.89e-06
    932    40     1.33e-07     1.33e-07     5.46e-06
    932    50     1.48e-08     1.48e-08     1.93e-06
    932    60     5.92e-08     5.92e-08     3.21e-06
    932    61     1.24e-06     1.24e-06     1.45e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             932 51323.277   0.0025     8.13e-08     8.13e-08     3.67e-06
! Validation        932 51323.277   0.0025     1.25e-07     1.25e-07     3.94e-06
Wall time: 51323.276937958
training
# Epoch batch         loss       loss_e      e/N_mae
    933    10     1.11e-07     1.11e-07     4.93e-06
    933    20     8.17e-08     8.17e-08     3.64e-06
    933    30     6.34e-08     6.34e-08     3.64e-06
    933    40     2.64e-07     2.64e-07     6.42e-06
    933    48     4.23e-08     4.23e-08     3.21e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    933    10     1.42e-07     1.42e-07     5.14e-06
    933    20     1.42e-07     1.42e-07     3.85e-06
    933    30     1.06e-08     1.06e-08     1.28e-06
    933    40     1.16e-07     1.16e-07     4.82e-06
    933    50     2.96e-08     2.96e-08     2.89e-06
    933    60     2.11e-08     2.11e-08     1.93e-06
    933    61      1.2e-06      1.2e-06      1.5e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             933 51378.526   0.0025     1.22e-07     1.22e-07     4.49e-06
! Validation        933 51378.526   0.0025     1.19e-07     1.19e-07     3.92e-06
Wall time: 51378.526753708
! Best model      933    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    934    10     4.51e-08     4.51e-08     2.89e-06
    934    20     1.91e-07     1.91e-07     5.46e-06
    934    30     5.78e-08     5.78e-08     3.43e-06
    934    40     5.35e-08     5.35e-08     3.32e-06
    934    48     4.76e-08     4.76e-08     2.41e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    934    10     9.93e-08     9.93e-08     3.53e-06
    934    20     1.42e-07     1.42e-07     4.18e-06
    934    30     1.06e-08     1.06e-08     1.28e-06
    934    40     1.18e-07     1.18e-07     5.14e-06
    934    50     4.02e-08     4.02e-08     3.21e-06
    934    60     4.65e-08     4.65e-08     2.89e-06
    934    61     1.41e-06     1.41e-06     1.55e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             934 51433.699   0.0025     1.18e-07     1.18e-07     4.32e-06
! Validation        934 51433.699   0.0025     1.19e-07     1.19e-07      3.9e-06
Wall time: 51433.699662083
! Best model      934    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    935    10     1.02e-07     1.02e-07     4.28e-06
    935    20     9.72e-08     9.72e-08     4.07e-06
    935    30     7.89e-08     7.89e-08     3.75e-06
    935    40     1.01e-07     1.01e-07     4.39e-06
    935    48     1.06e-07     1.06e-07     5.62e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    935    10     1.18e-07     1.18e-07     4.18e-06
    935    20     1.42e-07     1.42e-07     3.85e-06
    935    30     4.23e-08     4.23e-08     3.21e-06
    935    40     1.48e-07     1.48e-07     5.14e-06
    935    50      7.4e-08      7.4e-08     3.53e-06
    935    60     3.17e-08     3.17e-08     2.57e-06
    935    61     1.37e-06     1.37e-06      1.5e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             935 51488.758   0.0025     9.16e-08     9.16e-08     3.97e-06
! Validation        935 51488.758   0.0025     1.17e-07     1.17e-07     3.95e-06
Wall time: 51488.759148833
! Best model      935    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    936    10     8.17e-08     8.17e-08     4.07e-06
    936    20     6.48e-08     6.48e-08     3.43e-06
    936    30     1.38e-07     1.38e-07     4.82e-06
    936    40     1.17e-07     1.17e-07     3.96e-06
    936    48     5.28e-08     5.28e-08     3.21e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    936    10     1.23e-07     1.23e-07     4.18e-06
    936    20     1.33e-07     1.33e-07     4.82e-06
    936    30     4.65e-08     4.65e-08     4.18e-06
    936    40     1.14e-07     1.14e-07      4.5e-06
    936    50     8.45e-08     8.45e-08     4.18e-06
    936    60      1.9e-08      1.9e-08     1.61e-06
    936    61     1.56e-06     1.56e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             936 51543.788   0.0025      1.2e-07      1.2e-07     4.51e-06
! Validation        936 51543.788   0.0025      1.2e-07      1.2e-07     3.78e-06
Wall time: 51543.789778916005
training
# Epoch batch         loss       loss_e      e/N_mae
    937    10     8.17e-08     8.17e-08     4.18e-06
    937    20     1.36e-07     1.36e-07     5.25e-06
    937    30      1.2e-07      1.2e-07     4.39e-06
    937    40     1.32e-07     1.32e-07     5.03e-06
    937    48     6.87e-08     6.87e-08     4.82e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    937    10     1.42e-07     1.42e-07     4.18e-06
    937    20     1.86e-07     1.86e-07     4.82e-06
    937    30     2.32e-08     2.32e-08     1.93e-06
    937    40     1.56e-07     1.56e-07     5.14e-06
    937    50     8.24e-08     8.24e-08      4.5e-06
    937    60     4.02e-08     4.02e-08     2.89e-06
    937    61     1.19e-06     1.19e-06     1.45e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             937 51599.025   0.0025     8.55e-08     8.55e-08     3.88e-06
! Validation        937 51599.025   0.0025     1.14e-07     1.14e-07     3.75e-06
Wall time: 51599.025748541004
! Best model      937    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    938    10     2.02e-07     2.02e-07     6.21e-06
    938    20     1.96e-07     1.96e-07     5.89e-06
    938    30     7.89e-08     7.89e-08     3.64e-06
    938    40     1.97e-07     1.97e-07        6e-06
    938    48     3.22e-07     3.22e-07     9.64e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    938    10     1.61e-07     1.61e-07      4.5e-06
    938    20     1.25e-07     1.25e-07     4.18e-06
    938    30     2.11e-09     2.11e-09     3.21e-07
    938    40     2.11e-07     2.11e-07     6.42e-06
    938    50     5.71e-08     5.71e-08     3.85e-06
    938    60     5.92e-08     5.92e-08     3.53e-06
    938    61      1.2e-06      1.2e-06     1.55e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             938 51653.964   0.0025     1.42e-07     1.42e-07     4.84e-06
! Validation        938 51653.964   0.0025      1.2e-07      1.2e-07     3.82e-06
Wall time: 51653.963806791005
training
# Epoch batch         loss       loss_e      e/N_mae
    939    10     1.59e-07     1.59e-07     5.14e-06
    939    20     2.41e-07     2.41e-07     6.32e-06
    939    30     1.07e-07     1.07e-07      4.6e-06
    939    40     1.37e-07     1.37e-07      4.5e-06
    939    48     8.93e-07     8.93e-07     1.45e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    939    10     1.16e-07     1.16e-07     4.18e-06
    939    20      1.8e-07      1.8e-07      4.5e-06
    939    30     4.65e-08     4.65e-08     3.85e-06
    939    40     1.08e-07     1.08e-07     4.18e-06
    939    50     4.65e-08     4.65e-08     3.53e-06
    939    60     3.38e-08     3.38e-08     2.89e-06
    939    61     1.64e-06     1.64e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             939 51709.054   0.0025     2.75e-07     2.75e-07     6.42e-06
! Validation        939 51709.054   0.0025     1.25e-07     1.25e-07        4e-06
Wall time: 51709.055301875
training
# Epoch batch         loss       loss_e      e/N_mae
    940    10     2.18e-07     2.18e-07     6.32e-06
    940    20     1.89e-07     1.89e-07     5.46e-06
    940    30     1.66e-07     1.66e-07     5.68e-06
    940    40     1.92e-07     1.92e-07     5.68e-06
    940    48     4.23e-08     4.23e-08     3.21e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    940    10     1.04e-07     1.04e-07     3.53e-06
    940    20     2.16e-07     2.16e-07     4.18e-06
    940    30     2.96e-08     2.96e-08     2.57e-06
    940    40     1.23e-07     1.23e-07     3.85e-06
    940    50     2.75e-08     2.75e-08     2.25e-06
    940    60     4.02e-08     4.02e-08     2.89e-06
    940    61      1.5e-06      1.5e-06     1.55e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             940 51764.237   0.0025     3.39e-07     3.39e-07     7.61e-06
! Validation        940 51764.237   0.0025     1.19e-07     1.19e-07     3.75e-06
Wall time: 51764.237918375
training
# Epoch batch         loss       loss_e      e/N_mae
    941    10     5.89e-07     5.89e-07     1.06e-05
    941    20     1.32e-07     1.32e-07     5.25e-06
    941    30     1.13e-07     1.13e-07     4.39e-06
    941    40     1.42e-07     1.42e-07     4.82e-06
    941    48     2.64e-08     2.64e-08     2.41e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    941    10     1.65e-07     1.65e-07      4.5e-06
    941    20     1.14e-07     1.14e-07     3.53e-06
    941    30     2.32e-08     2.32e-08     1.93e-06
    941    40      1.1e-07      1.1e-07      4.5e-06
    941    50     6.55e-08     6.55e-08     3.85e-06
    941    60     5.71e-08     5.71e-08     3.53e-06
    941    61     9.65e-07     9.65e-07     1.28e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             941 51819.077   0.0025     1.89e-07     1.89e-07     5.47e-06
! Validation        941 51819.077   0.0025     1.14e-07     1.14e-07     3.93e-06
Wall time: 51819.077582875005
training
# Epoch batch         loss       loss_e      e/N_mae
    942    10     1.03e-07     1.03e-07     4.18e-06
    942    20     2.67e-07     2.67e-07     5.68e-06
    942    30     1.19e-07     1.19e-07     5.03e-06
    942    40     1.01e-07     1.01e-07      4.6e-06
    942    48     2.64e-08     2.64e-08     2.41e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    942    10     1.75e-07     1.75e-07     5.46e-06
    942    20     1.14e-07     1.14e-07     3.53e-06
    942    30     2.96e-08     2.96e-08     2.57e-06
    942    40     2.01e-07     2.01e-07     6.42e-06
    942    50     7.19e-08     7.19e-08     4.18e-06
    942    60     3.17e-08     3.17e-08     2.25e-06
    942    61     9.23e-07     9.23e-07     1.28e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             942 51874.157   0.0025     1.39e-07     1.39e-07      4.7e-06
! Validation        942 51874.157   0.0025     1.15e-07     1.15e-07     3.95e-06
Wall time: 51874.157978791
training
# Epoch batch         loss       loss_e      e/N_mae
    943    10     6.55e-08     6.55e-08     4.07e-06
    943    20     3.38e-08     3.38e-08     2.78e-06
    943    30     4.16e-08     4.16e-08     2.68e-06
    943    40     9.79e-08     9.79e-08     3.53e-06
    943    48     5.28e-08     5.28e-08     3.21e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    943    10     1.84e-07     1.84e-07      6.1e-06
    943    20     1.25e-07     1.25e-07      4.5e-06
    943    30     2.54e-08     2.54e-08     2.57e-06
    943    40     2.45e-07     2.45e-07     7.71e-06
    943    50     4.65e-08     4.65e-08     2.89e-06
    943    60     2.32e-08     2.32e-08     2.57e-06
    943    61     9.93e-07     9.93e-07     1.28e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             943 51929.131   0.0025     7.28e-08     7.28e-08      3.5e-06
! Validation        943 51929.131   0.0025     1.17e-07     1.17e-07     3.95e-06
Wall time: 51929.132899833
training
# Epoch batch         loss       loss_e      e/N_mae
    944    10     1.14e-07     1.14e-07      4.5e-06
    944    20     6.97e-08     6.97e-08     3.21e-06
    944    30     8.81e-08     8.81e-08     3.85e-06
    944    40      1.3e-07      1.3e-07     5.14e-06
    944    48     2.11e-08     2.11e-08     1.61e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    944    10     1.52e-07     1.52e-07     5.14e-06
    944    20     1.63e-07     1.63e-07     4.82e-06
    944    30     3.17e-08     3.17e-08     3.21e-06
    944    40     1.92e-07     1.92e-07     6.42e-06
    944    50      3.8e-08      3.8e-08     2.25e-06
    944    60     1.06e-08     1.06e-08     9.64e-07
    944    61     1.38e-06     1.38e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             944 51984.164   0.0025     8.21e-08     8.21e-08     3.82e-06
! Validation        944 51984.164   0.0025     1.22e-07     1.22e-07     3.97e-06
Wall time: 51984.164743625
training
# Epoch batch         loss       loss_e      e/N_mae
    945    10     1.99e-07     1.99e-07     6.64e-06
    945    20     1.01e-07     1.01e-07     3.75e-06
    945    30     1.08e-07     1.08e-07     4.07e-06
    945    40     4.37e-08     4.37e-08     3.11e-06
    945    48      1.8e-07      1.8e-07     7.23e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    945    10     1.23e-07     1.23e-07      4.5e-06
    945    20     1.56e-07     1.56e-07     4.18e-06
    945    30     2.96e-08     2.96e-08     2.89e-06
    945    40     1.63e-07     1.63e-07     5.46e-06
    945    50     2.54e-08     2.54e-08     2.25e-06
    945    60     1.48e-08     1.48e-08     1.93e-06
    945    61     1.07e-06     1.07e-06     1.34e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             945 52039.306   0.0025     1.24e-07     1.24e-07     4.58e-06
! Validation        945 52039.306   0.0025     1.16e-07     1.16e-07     3.93e-06
Wall time: 52039.307365791
training
# Epoch batch         loss       loss_e      e/N_mae
    946    10      1.5e-07      1.5e-07      4.6e-06
    946    20     2.74e-07     2.74e-07     7.71e-06
    946    30     1.27e-07     1.27e-07     4.71e-06
    946    40     1.05e-07     1.05e-07     3.64e-06
    946    48     1.06e-07     1.06e-07     4.82e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    946    10     1.59e-07     1.59e-07     4.18e-06
    946    20     1.88e-07     1.88e-07     4.82e-06
    946    30     3.17e-08     3.17e-08     3.21e-06
    946    40     2.49e-07     2.49e-07     7.07e-06
    946    50     4.65e-08     4.65e-08     2.89e-06
    946    60     1.27e-08     1.27e-08     1.61e-06
    946    61     1.33e-06     1.33e-06     1.55e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             946 52094.218   0.0025     1.96e-07     1.96e-07     5.79e-06
! Validation        946 52094.218   0.0025     1.25e-07     1.25e-07     4.04e-06
Wall time: 52094.219033041
training
# Epoch batch         loss       loss_e      e/N_mae
    947    10     1.13e-07     1.13e-07      4.5e-06
    947    20      3.6e-07      3.6e-07     8.35e-06
    947    30     3.33e-07     3.33e-07     7.82e-06
    947    40     2.42e-07     2.42e-07     7.07e-06
    947    48     2.11e-08     2.11e-08     1.61e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    947    10     1.73e-07     1.73e-07      4.5e-06
    947    20     1.65e-07     1.65e-07     4.82e-06
    947    30     6.34e-09     6.34e-09     1.93e-06
    947    40     1.63e-07     1.63e-07     5.46e-06
    947    50      7.4e-08      7.4e-08     3.85e-06
    947    60     2.96e-08     2.96e-08     2.25e-06
    947    61     1.65e-06     1.65e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             947 52149.242   0.0025     2.26e-07     2.26e-07     6.26e-06
! Validation        947 52149.242   0.0025     1.28e-07     1.28e-07     4.02e-06
Wall time: 52149.243257791
training
# Epoch batch         loss       loss_e      e/N_mae
    948    10     2.19e-07     2.19e-07      6.1e-06
    948    20     1.47e-07     1.47e-07     4.39e-06
    948    30     1.12e-07     1.12e-07     4.39e-06
    948    40      2.4e-07      2.4e-07     6.42e-06
    948    48     9.51e-08     9.51e-08     4.82e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    948    10     1.23e-07     1.23e-07     4.82e-06
    948    20     2.22e-07     2.22e-07     4.82e-06
    948    30     2.96e-08     2.96e-08     3.53e-06
    948    40     1.86e-07     1.86e-07     5.78e-06
    948    50     8.88e-08     8.88e-08     3.53e-06
    948    60     5.49e-08     5.49e-08     3.85e-06
    948    61      1.7e-06      1.7e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             948 52204.453   0.0025      1.6e-07      1.6e-07     5.14e-06
! Validation        948 52204.453   0.0025     1.38e-07     1.38e-07     4.33e-06
Wall time: 52204.454526041
training
# Epoch batch         loss       loss_e      e/N_mae
    949    10     6.83e-08     6.83e-08     3.64e-06
    949    20     1.44e-07     1.44e-07     4.93e-06
    949    30     2.03e-07     2.03e-07     6.21e-06
    949    40     4.92e-07     4.92e-07      9.1e-06
    949    48     1.37e-07     1.37e-07     5.62e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    949    10     1.12e-07     1.12e-07     3.53e-06
    949    20     1.82e-07     1.82e-07      4.5e-06
    949    30     2.96e-08     2.96e-08     2.57e-06
    949    40     1.97e-07     1.97e-07     5.46e-06
    949    50     4.65e-08     4.65e-08     2.89e-06
    949    60     2.11e-08     2.11e-08     2.25e-06
    949    61     1.64e-06     1.64e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             949 52259.664   0.0025     2.31e-07     2.31e-07     6.11e-06
! Validation        949 52259.664   0.0025     1.19e-07     1.19e-07     3.82e-06
Wall time: 52259.664305375
training
# Epoch batch         loss       loss_e      e/N_mae
    950    10      3.2e-07      3.2e-07     7.82e-06
    950    20     2.77e-07     2.77e-07     7.28e-06
    950    30     1.92e-07     1.92e-07      6.1e-06
    950    40     1.42e-07     1.42e-07     5.46e-06
    950    48      1.8e-07      1.8e-07     7.23e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    950    10     1.97e-07     1.97e-07     4.82e-06
    950    20     2.32e-07     2.32e-07     5.78e-06
    950    30     2.75e-08     2.75e-08     2.57e-06
    950    40     1.65e-07     1.65e-07     5.14e-06
    950    50     3.38e-08     3.38e-08     2.89e-06
    950    60     2.32e-08     2.32e-08     2.89e-06
    950    61      1.6e-06      1.6e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             950 52314.778   0.0025      3.1e-07      3.1e-07     7.15e-06
! Validation        950 52314.778   0.0025     1.31e-07     1.31e-07     3.99e-06
Wall time: 52314.778892916
training
# Epoch batch         loss       loss_e      e/N_mae
    951    10     3.57e-07     3.57e-07     7.82e-06
    951    20     1.99e-07     1.99e-07     6.42e-06
    951    30     1.61e-07     1.61e-07     5.78e-06
    951    40     8.24e-08     8.24e-08     3.64e-06
    951    48     4.76e-08     4.76e-08     2.41e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    951    10     1.92e-07     1.92e-07     5.46e-06
    951    20     2.03e-07     2.03e-07      6.1e-06
    951    30     3.17e-08     3.17e-08     2.89e-06
    951    40     1.71e-07     1.71e-07      4.5e-06
    951    50     2.96e-08     2.96e-08     2.89e-06
    951    60     2.75e-08     2.75e-08     1.61e-06
    951    61     1.41e-06     1.41e-06     1.55e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             951 52369.765   0.0025     2.36e-07     2.36e-07     6.12e-06
! Validation        951 52369.765   0.0025     1.16e-07     1.16e-07      3.8e-06
Wall time: 52369.765208833
training
# Epoch batch         loss       loss_e      e/N_mae
    952    10     1.93e-07     1.93e-07     6.32e-06
    952    20     1.13e-07     1.13e-07     4.82e-06
    952    30     8.52e-08     8.52e-08     3.64e-06
    952    40     1.32e-07     1.32e-07     5.57e-06
    952    48     5.28e-09     5.28e-09     8.03e-07
validation
# Epoch batch         loss       loss_e      e/N_mae
    952    10     1.75e-07     1.75e-07     4.82e-06
    952    20      1.9e-07      1.9e-07     5.14e-06
    952    30     4.44e-08     4.44e-08     3.21e-06
    952    40     1.99e-07     1.99e-07     5.46e-06
    952    50     1.27e-08     1.27e-08     1.61e-06
    952    60     8.24e-08     8.24e-08     3.53e-06
    952    61     1.33e-06     1.33e-06     1.55e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             952 52424.871   0.0025     1.12e-07     1.12e-07     4.33e-06
! Validation        952 52424.871   0.0025     1.15e-07     1.15e-07      3.8e-06
Wall time: 52424.87245075
training
# Epoch batch         loss       loss_e      e/N_mae
    953    10     1.34e-07     1.34e-07     5.35e-06
    953    20     8.74e-08     8.74e-08     3.75e-06
    953    30     3.95e-08     3.95e-08     2.36e-06
    953    40     1.38e-07     1.38e-07     3.85e-06
    953    48     1.06e-08     1.06e-08     1.61e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    953    10      1.9e-07      1.9e-07     5.14e-06
    953    20     1.99e-07     1.99e-07     5.46e-06
    953    30     2.32e-08     2.32e-08     1.93e-06
    953    40     1.52e-07     1.52e-07     5.14e-06
    953    50     6.34e-08     6.34e-08     3.53e-06
    953    60     5.07e-08     5.07e-08     2.57e-06
    953    61     1.64e-06     1.64e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             953 52479.905   0.0025     9.03e-08     9.03e-08      3.8e-06
! Validation        953 52479.905   0.0025     1.19e-07     1.19e-07     3.78e-06
Wall time: 52479.906196166005
training
# Epoch batch         loss       loss_e      e/N_mae
    954    10     6.83e-08     6.83e-08     3.64e-06
    954    20     3.45e-08     3.45e-08     2.36e-06
    954    30      6.2e-08      6.2e-08     3.32e-06
    954    40     3.38e-08     3.38e-08     2.25e-06
    954    48     5.28e-09     5.28e-09     8.03e-07
validation
# Epoch batch         loss       loss_e      e/N_mae
    954    10     1.56e-07     1.56e-07     5.14e-06
    954    20      2.3e-07      2.3e-07     5.14e-06
    954    30     2.11e-08     2.11e-08     2.25e-06
    954    40     1.35e-07     1.35e-07      4.5e-06
    954    50     9.09e-08     9.09e-08     4.18e-06
    954    60     6.55e-08     6.55e-08     3.53e-06
    954    61     1.85e-06     1.85e-06     1.87e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             954 52535.021   0.0025     7.12e-08     7.12e-08     3.48e-06
! Validation        954 52535.021   0.0025     1.24e-07     1.24e-07     3.77e-06
Wall time: 52535.021947708
training
# Epoch batch         loss       loss_e      e/N_mae
    955    10     8.66e-08     8.66e-08     4.18e-06
    955    20     3.73e-08     3.73e-08     2.78e-06
    955    30     3.59e-08     3.59e-08     2.78e-06
    955    40     1.16e-07     1.16e-07     4.93e-06
    955    48     4.76e-08     4.76e-08     2.41e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    955    10     1.31e-07     1.31e-07     3.85e-06
    955    20     2.22e-07     2.22e-07     4.82e-06
    955    30     2.11e-08     2.11e-08     2.25e-06
    955    40     9.72e-08     9.72e-08      4.5e-06
    955    50     6.34e-08     6.34e-08     3.53e-06
    955    60     2.96e-08     2.96e-08     1.93e-06
    955    61      1.4e-06      1.4e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             955 52590.222   0.0025     8.38e-08     8.38e-08     3.73e-06
! Validation        955 52590.222   0.0025     1.29e-07     1.29e-07        4e-06
Wall time: 52590.223027125
training
# Epoch batch         loss       loss_e      e/N_mae
    956    10     4.01e-07     4.01e-07     8.14e-06
    956    20     6.72e-07     6.72e-07     1.17e-05
    956    30     5.64e-07     5.64e-07     8.57e-06
    956    40     1.21e-07     1.21e-07     4.18e-06
    956    48     3.06e-07     3.06e-07     8.03e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    956    10     9.72e-08     9.72e-08     3.85e-06
    956    20     2.85e-07     2.85e-07     5.78e-06
    956    30     8.45e-09     8.45e-09     1.61e-06
    956    40     1.97e-07     1.97e-07     5.78e-06
    956    50     9.51e-08     9.51e-08      4.5e-06
    956    60     6.34e-09     6.34e-09     9.64e-07
    956    61      1.7e-06      1.7e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             956 52645.086   0.0025     4.46e-07     4.46e-07     8.29e-06
! Validation        956 52645.086   0.0025     1.32e-07     1.32e-07     4.01e-06
Wall time: 52645.086847708
training
# Epoch batch         loss       loss_e      e/N_mae
    957    10     2.64e-07     2.64e-07     7.28e-06
    957    20     1.61e-07     1.61e-07     5.03e-06
    957    30     2.19e-07     2.19e-07      6.1e-06
    957    40     1.73e-07     1.73e-07        6e-06
    957    48      3.8e-07      3.8e-07     9.64e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    957    10      1.2e-07      1.2e-07     4.18e-06
    957    20     3.53e-07     3.53e-07     7.39e-06
    957    30     1.06e-08     1.06e-08     9.64e-07
    957    40     1.73e-07     1.73e-07     5.14e-06
    957    50     2.32e-08     2.32e-08     1.61e-06
    957    60     2.96e-08     2.96e-08     2.57e-06
    957    61     1.84e-06     1.84e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             957 52700.145   0.0025        2e-07        2e-07      5.8e-06
! Validation        957 52700.145   0.0025     1.34e-07     1.34e-07     3.96e-06
Wall time: 52700.146247375
training
# Epoch batch         loss       loss_e      e/N_mae
    958    10     3.41e-07     3.41e-07     8.14e-06
    958    20      1.5e-07      1.5e-07     5.35e-06
    958    30     8.52e-08     8.52e-08     3.85e-06
    958    40     1.16e-07     1.16e-07     5.25e-06
    958    48     1.32e-07     1.32e-07     6.42e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    958    10     1.27e-07     1.27e-07     3.85e-06
    958    20     3.36e-07     3.36e-07     6.75e-06
    958    30     1.48e-08     1.48e-08     2.25e-06
    958    40     2.18e-07     2.18e-07     7.07e-06
    958    50     6.34e-09     6.34e-09     9.64e-07
    958    60      3.8e-08      3.8e-08     2.89e-06
    958    61     1.53e-06     1.53e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             958 52755.382   0.0025     1.93e-07     1.93e-07     5.77e-06
! Validation        958 52755.382   0.0025     1.34e-07     1.34e-07     4.03e-06
Wall time: 52755.382109875005
training
# Epoch batch         loss       loss_e      e/N_mae
    959    10     2.48e-07     2.48e-07     6.42e-06
    959    20     1.57e-07     1.57e-07     5.25e-06
    959    30     1.94e-07     1.94e-07     5.35e-06
    959    40     2.18e-07     2.18e-07     5.78e-06
    959    48     1.06e-08     1.06e-08     1.61e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    959    10     1.71e-07     1.71e-07     4.18e-06
    959    20     2.94e-07     2.94e-07     6.42e-06
    959    30     1.48e-08     1.48e-08     1.93e-06
    959    40      1.8e-07      1.8e-07      6.1e-06
    959    50     1.69e-08     1.69e-08     2.25e-06
    959    60     8.45e-09     8.45e-09     1.28e-06
    959    61     1.25e-06     1.25e-06      1.5e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             959 52810.535   0.0025     1.24e-07     1.24e-07     4.63e-06
! Validation        959 52810.535   0.0025     1.26e-07     1.26e-07     3.97e-06
Wall time: 52810.535655208005
training
# Epoch batch         loss       loss_e      e/N_mae
    960    10     5.85e-08     5.85e-08     2.89e-06
    960    20      3.8e-08      3.8e-08     2.36e-06
    960    30     4.58e-08     4.58e-08     2.78e-06
    960    40      7.4e-08      7.4e-08     3.75e-06
    960    48     2.64e-08     2.64e-08     2.41e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    960    10     1.73e-07     1.73e-07      4.5e-06
    960    20     2.79e-07     2.79e-07      6.1e-06
    960    30     2.96e-08     2.96e-08     3.21e-06
    960    40     1.73e-07     1.73e-07     5.46e-06
    960    50     2.32e-08     2.32e-08     2.57e-06
    960    60     1.48e-08     1.48e-08     1.61e-06
    960    61      1.5e-06      1.5e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             960 52865.788   0.0025     8.36e-08     8.36e-08     3.77e-06
! Validation        960 52865.788   0.0025     1.32e-07     1.32e-07     4.06e-06
Wall time: 52865.788029166004
training
# Epoch batch         loss       loss_e      e/N_mae
    961    10     1.68e-07     1.68e-07     5.25e-06
    961    20     7.89e-08     7.89e-08     3.64e-06
    961    30      2.4e-07      2.4e-07     6.21e-06
    961    40     1.53e-07     1.53e-07     5.35e-06
    961    48     3.91e-07     3.91e-07     9.64e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    961    10     1.75e-07     1.75e-07     5.14e-06
    961    20     2.83e-07     2.83e-07     5.78e-06
    961    30     4.23e-08     4.23e-08     3.85e-06
    961    40      1.8e-07      1.8e-07      6.1e-06
    961    50     3.59e-08     3.59e-08     2.57e-06
    961    60     5.49e-08     5.49e-08     3.21e-06
    961    61     1.51e-06     1.51e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             961 52920.658   0.0025     1.54e-07     1.54e-07     5.02e-06
! Validation        961 52920.658   0.0025      1.3e-07      1.3e-07        4e-06
Wall time: 52920.6580695
training
# Epoch batch         loss       loss_e      e/N_mae
    962    10     3.06e-07     3.06e-07     8.57e-06
    962    20     1.24e-07     1.24e-07     4.71e-06
    962    30     7.33e-08     7.33e-08     3.64e-06
    962    40     1.35e-07     1.35e-07      4.5e-06
    962    48     3.06e-07     3.06e-07     9.64e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    962    10     1.99e-07     1.99e-07      6.1e-06
    962    20     2.51e-07     2.51e-07      6.1e-06
    962    30     2.96e-08     2.96e-08     3.21e-06
    962    40     1.48e-07     1.48e-07     5.14e-06
    962    50     4.65e-08     4.65e-08     2.89e-06
    962    60     2.96e-08     2.96e-08     1.93e-06
    962    61     1.57e-06     1.57e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             962 52975.665   0.0025     2.02e-07     2.02e-07     5.81e-06
! Validation        962 52975.665   0.0025     1.36e-07     1.36e-07     4.18e-06
Wall time: 52975.666211541
training
# Epoch batch         loss       loss_e      e/N_mae
    963    10     2.06e-07     2.06e-07      6.1e-06
    963    20     2.22e-07     2.22e-07      6.1e-06
    963    30     2.11e-07     2.11e-07      6.1e-06
    963    40      8.1e-08      8.1e-08     3.85e-06
    963    48     2.17e-07     2.17e-07     7.23e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    963    10     1.14e-07     1.14e-07      4.5e-06
    963    20      2.2e-07      2.2e-07     6.75e-06
    963    30     2.96e-08     2.96e-08     2.57e-06
    963    40     2.49e-07     2.49e-07     7.39e-06
    963    50     7.19e-08     7.19e-08     3.53e-06
    963    60     4.65e-08     4.65e-08     2.57e-06
    963    61      1.4e-06      1.4e-06      1.5e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             963 53030.789   0.0025      1.9e-07      1.9e-07     5.51e-06
! Validation        963 53030.789   0.0025     1.32e-07     1.32e-07     4.16e-06
Wall time: 53030.788777875
training
# Epoch batch         loss       loss_e      e/N_mae
    964    10     5.85e-07     5.85e-07     9.32e-06
    964    20     1.03e-06     1.03e-06     1.28e-05
    964    30     5.04e-07     5.04e-07     7.17e-06
    964    40     4.59e-07     4.59e-07     8.46e-06
    964    48     4.76e-08     4.76e-08     2.41e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    964    10     1.33e-07     1.33e-07     4.18e-06
    964    20     1.82e-07     1.82e-07      4.5e-06
    964    30     2.11e-08     2.11e-08     2.57e-06
    964    40     1.46e-07     1.46e-07     5.46e-06
    964    50     7.82e-08     7.82e-08     3.85e-06
    964    60     4.86e-08     4.86e-08     2.89e-06
    964    61     1.04e-06     1.04e-06     1.39e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             964 53085.873   0.0025      4.1e-07      4.1e-07     7.82e-06
! Validation        964 53085.873   0.0025     1.17e-07     1.17e-07     3.97e-06
Wall time: 53085.873961625
training
# Epoch batch         loss       loss_e      e/N_mae
    965    10     3.38e-07     3.38e-07      7.6e-06
    965    20     1.69e-07     1.69e-07     4.82e-06
    965    30     3.02e-07     3.02e-07     6.53e-06
    965    40     1.05e-06     1.05e-06     1.27e-05
    965    48     3.86e-07     3.86e-07     8.83e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    965    10     1.86e-07     1.86e-07     5.78e-06
    965    20     1.33e-07     1.33e-07     4.82e-06
    965    30     2.96e-08     2.96e-08     3.53e-06
    965    40     2.28e-07     2.28e-07     6.75e-06
    965    50     6.34e-08     6.34e-08     3.21e-06
    965    60     6.34e-09     6.34e-09     1.28e-06
    965    61     1.79e-06     1.79e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             965 53140.935   0.0025     3.53e-07     3.53e-07     7.55e-06
! Validation        965 53140.935   0.0025     1.32e-07     1.32e-07     4.03e-06
Wall time: 53140.935869958004
training
# Epoch batch         loss       loss_e      e/N_mae
    966    10     3.02e-07     3.02e-07     7.28e-06
    966    20     1.02e-06     1.02e-06     1.19e-05
    966    30      7.9e-07      7.9e-07     1.16e-05
    966    40     1.52e-07     1.52e-07      4.6e-06
    966    48     5.28e-09     5.28e-09     8.03e-07
validation
# Epoch batch         loss       loss_e      e/N_mae
    966    10     1.23e-07     1.23e-07      4.5e-06
    966    20     1.16e-07     1.16e-07     4.18e-06
    966    30      3.8e-08      3.8e-08     3.53e-06
    966    40     2.75e-07     2.75e-07     6.75e-06
    966    50     6.34e-08     6.34e-08     3.53e-06
    966    60     6.97e-08     6.97e-08     3.85e-06
    966    61     1.71e-06     1.71e-06     1.77e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             966 53195.992   0.0025     5.64e-07     5.64e-07     8.82e-06
! Validation        966 53195.992   0.0025     1.31e-07     1.31e-07     4.14e-06
Wall time: 53195.992620916004
training
# Epoch batch         loss       loss_e      e/N_mae
    967    10     2.28e-06     2.28e-06      1.8e-05
    967    20     5.95e-07     5.95e-07     1.01e-05
    967    30      9.8e-07      9.8e-07     1.37e-05
    967    40     1.48e-06     1.48e-06      1.6e-05
    967    48     4.16e-06     4.16e-06     2.57e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    967    10     1.86e-07     1.86e-07     5.14e-06
    967    20     2.09e-07     2.09e-07     5.78e-06
    967    30     3.17e-08     3.17e-08     2.57e-06
    967    40     2.05e-07     2.05e-07     7.07e-06
    967    50     4.02e-08     4.02e-08     3.53e-06
    967    60     2.75e-08     2.75e-08     2.25e-06
    967    61      1.5e-06      1.5e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             967 53251.165   0.0025     1.52e-06     1.52e-06     1.49e-05
! Validation        967 53251.165   0.0025     1.49e-07     1.49e-07     4.46e-06
Wall time: 53251.166284833
training
# Epoch batch         loss       loss_e      e/N_mae
    968    10     1.22e-05     1.22e-05     4.17e-05
    968    20     4.77e-06     4.77e-06     2.68e-05
    968    30     2.32e-06     2.32e-06     2.13e-05
    968    40     1.16e-06     1.16e-06     1.56e-05
    968    48     1.37e-06     1.37e-06     1.53e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    968    10     2.26e-07     2.26e-07      6.1e-06
    968    20     3.83e-07     3.83e-07     6.75e-06
    968    30     4.23e-08     4.23e-08     2.89e-06
    968    40     5.24e-07     5.24e-07     9.64e-06
    968    50     1.59e-07     1.59e-07     4.18e-06
    968    60     6.13e-08     6.13e-08     3.21e-06
    968    61     1.92e-06     1.92e-06     1.87e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             968 53306.197   0.0025     3.42e-06     3.42e-06     2.28e-05
! Validation        968 53306.197   0.0025     1.85e-07     1.85e-07     5.11e-06
Wall time: 53306.198146708004
training
# Epoch batch         loss       loss_e      e/N_mae
    969    10     1.28e-06     1.28e-06     1.46e-05
    969    20      6.8e-07      6.8e-07     1.24e-05
    969    30        9e-07        9e-07     1.22e-05
    969    40     5.12e-07     5.12e-07     9.74e-06
    969    48     1.32e-07     1.32e-07     4.02e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    969    10     1.25e-07     1.25e-07     4.18e-06
    969    20     3.11e-07     3.11e-07     7.39e-06
    969    30      3.8e-08      3.8e-08     2.89e-06
    969    40     4.63e-07     4.63e-07     8.67e-06
    969    50     1.08e-07     1.08e-07     5.14e-06
    969    60     9.09e-08     9.09e-08     4.82e-06
    969    61     1.91e-06     1.91e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             969 53361.289   0.0025     8.61e-07     8.61e-07     1.18e-05
! Validation        969 53361.289   0.0025     1.73e-07     1.73e-07     4.84e-06
Wall time: 53361.288896833
training
# Epoch batch         loss       loss_e      e/N_mae
    970    10     1.95e-07     1.95e-07     6.21e-06
    970    20     1.46e-07     1.46e-07     5.46e-06
    970    30     1.26e-07     1.26e-07     4.93e-06
    970    40     4.45e-07     4.45e-07     8.46e-06
    970    48     1.06e-07     1.06e-07     4.82e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    970    10     1.78e-07     1.78e-07     3.85e-06
    970    20     3.28e-07     3.28e-07     5.78e-06
    970    30     3.17e-08     3.17e-08     2.89e-06
    970    40      3.7e-07      3.7e-07     8.03e-06
    970    50     1.82e-07     1.82e-07      6.1e-06
    970    60     4.86e-08     4.86e-08     3.53e-06
    970    61     1.63e-06     1.63e-06     1.71e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             970 53416.598   0.0025     1.81e-07     1.81e-07     5.58e-06
! Validation        970 53416.598   0.0025     1.56e-07     1.56e-07     4.55e-06
Wall time: 53416.599021875
training
# Epoch batch         loss       loss_e      e/N_mae
    971    10     1.72e-07     1.72e-07     5.57e-06
    971    20      1.1e-07      1.1e-07     4.39e-06
    971    30     1.54e-07     1.54e-07     5.03e-06
    971    40     9.86e-08     9.86e-08      4.5e-06
    971    48     5.28e-08     5.28e-08     3.21e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    971    10     2.56e-07     2.56e-07     5.78e-06
    971    20     2.03e-07     2.03e-07     5.78e-06
    971    30     1.27e-08     1.27e-08     1.93e-06
    971    40     1.71e-07     1.71e-07     4.82e-06
    971    50     6.76e-08     6.76e-08     4.18e-06
    971    60     3.38e-08     3.38e-08     2.57e-06
    971    61      1.5e-06      1.5e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             971 53471.681   0.0025     1.18e-07     1.18e-07     4.43e-06
! Validation        971 53471.681   0.0025     1.43e-07     1.43e-07     4.47e-06
Wall time: 53471.68234975
training
# Epoch batch         loss       loss_e      e/N_mae
    972    10     1.18e-07     1.18e-07     4.71e-06
    972    20     9.72e-08     9.72e-08      4.5e-06
    972    30     7.75e-08     7.75e-08     3.75e-06
    972    40     5.92e-08     5.92e-08     3.75e-06
    972    48            0            0            0
validation
# Epoch batch         loss       loss_e      e/N_mae
    972    10     2.32e-07     2.32e-07     6.42e-06
    972    20     2.24e-07     2.24e-07     5.14e-06
    972    30     2.96e-08     2.96e-08     3.21e-06
    972    40     2.71e-07     2.71e-07     7.39e-06
    972    50     6.76e-08     6.76e-08     4.18e-06
    972    60     6.13e-08     6.13e-08     2.89e-06
    972    61     1.67e-06     1.67e-06     1.82e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             972 53526.534   0.0025     9.39e-08     9.39e-08     4.14e-06
! Validation        972 53526.534   0.0025     1.38e-07     1.38e-07     4.15e-06
Wall time: 53526.535128083
training
# Epoch batch         loss       loss_e      e/N_mae
    973    10     5.42e-08     5.42e-08     3.11e-06
    973    20     8.59e-08     8.59e-08     3.43e-06
    973    30     4.23e-08     4.23e-08     2.78e-06
    973    40      3.1e-08      3.1e-08     2.36e-06
    973    48     5.28e-09     5.28e-09     8.03e-07
validation
# Epoch batch         loss       loss_e      e/N_mae
    973    10     2.68e-07     2.68e-07     6.42e-06
    973    20     2.77e-07     2.77e-07      6.1e-06
    973    30     1.06e-08     1.06e-08     1.28e-06
    973    40     1.99e-07     1.99e-07     6.42e-06
    973    50     4.65e-08     4.65e-08     2.89e-06
    973    60     4.65e-08     4.65e-08     2.57e-06
    973    61     1.37e-06     1.37e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             973 53581.706   0.0025     7.27e-08     7.27e-08     3.56e-06
! Validation        973 53581.706   0.0025      1.3e-07      1.3e-07     4.04e-06
Wall time: 53581.706810666
training
# Epoch batch         loss       loss_e      e/N_mae
    974    10      4.3e-08      4.3e-08     2.57e-06
    974    20      3.1e-08      3.1e-08     2.57e-06
    974    30     5.78e-08     5.78e-08        3e-06
    974    40     6.48e-08     6.48e-08     3.43e-06
    974    48     2.64e-08     2.64e-08     3.21e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    974    10     2.07e-07     2.07e-07     5.46e-06
    974    20     3.76e-07     3.76e-07     6.42e-06
    974    30     3.59e-08     3.59e-08     3.85e-06
    974    40     2.22e-07     2.22e-07     6.42e-06
    974    50     2.75e-08     2.75e-08     2.57e-06
    974    60     5.71e-08     5.71e-08     2.89e-06
    974    61     1.13e-06     1.13e-06     1.45e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             974 53636.725   0.0025     5.96e-08     5.96e-08     3.16e-06
! Validation        974 53636.725   0.0025     1.26e-07     1.26e-07     4.11e-06
Wall time: 53636.72497675
training
# Epoch batch         loss       loss_e      e/N_mae
    975    10     4.44e-08     4.44e-08     2.78e-06
    975    20     1.09e-07     1.09e-07     3.85e-06
    975    30        5e-08        5e-08     3.11e-06
    975    40      1.2e-07      1.2e-07     4.39e-06
    975    48     5.28e-09     5.28e-09     8.03e-07
validation
# Epoch batch         loss       loss_e      e/N_mae
    975    10     1.65e-07     1.65e-07     4.82e-06
    975    20     3.28e-07     3.28e-07      6.1e-06
    975    30     4.02e-08     4.02e-08     3.85e-06
    975    40     1.48e-07     1.48e-07      4.5e-06
    975    50      3.8e-08      3.8e-08     2.89e-06
    975    60     4.65e-08     4.65e-08     2.57e-06
    975    61     1.09e-06     1.09e-06      1.5e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             975 53691.843   0.0025     7.16e-08     7.16e-08     3.52e-06
! Validation        975 53691.843   0.0025     1.23e-07     1.23e-07     4.16e-06
Wall time: 53691.843265208
training
# Epoch batch         loss       loss_e      e/N_mae
    976    10     5.35e-08     5.35e-08     2.57e-06
    976    20     3.17e-08     3.17e-08     2.46e-06
    976    30     3.59e-08     3.59e-08     2.36e-06
    976    40     1.08e-07     1.08e-07      4.5e-06
    976    48     2.64e-08     2.64e-08     2.41e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    976    10     2.18e-07     2.18e-07     5.78e-06
    976    20     2.32e-07     2.32e-07     5.14e-06
    976    30     6.13e-08     6.13e-08      4.5e-06
    976    40      1.9e-07      1.9e-07     5.78e-06
    976    50     6.55e-08     6.55e-08     3.85e-06
    976    60     3.38e-08     3.38e-08     2.57e-06
    976    61     1.19e-06     1.19e-06     1.45e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             976 53746.977   0.0025     5.78e-08     5.78e-08     3.12e-06
! Validation        976 53746.977   0.0025     1.27e-07     1.27e-07     4.18e-06
Wall time: 53746.977975291
training
# Epoch batch         loss       loss_e      e/N_mae
    977    10     8.95e-08     8.95e-08     4.39e-06
    977    20      4.3e-08      4.3e-08     3.11e-06
    977    30     8.03e-08     8.03e-08     4.18e-06
    977    40     2.06e-07     2.06e-07     6.53e-06
    977    48            0            0            0
validation
# Epoch batch         loss       loss_e      e/N_mae
    977    10     2.18e-07     2.18e-07     4.18e-06
    977    20     1.27e-07     1.27e-07      4.5e-06
    977    30     6.55e-08     6.55e-08      4.5e-06
    977    40     2.32e-07     2.32e-07     7.07e-06
    977    50     8.24e-08     8.24e-08     3.85e-06
    977    60      1.9e-08      1.9e-08     1.61e-06
    977    61     1.15e-06     1.15e-06     1.39e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             977 53801.915   0.0025     8.46e-08     8.46e-08     3.83e-06
! Validation        977 53801.915   0.0025     1.26e-07     1.26e-07     4.08e-06
Wall time: 53801.915776125
training
# Epoch batch         loss       loss_e      e/N_mae
    978    10     8.03e-08     8.03e-08     3.85e-06
    978    20     1.04e-07     1.04e-07     4.07e-06
    978    30     5.99e-08     5.99e-08     3.21e-06
    978    40     3.87e-08     3.87e-08     2.46e-06
    978    48     1.32e-07     1.32e-07     6.42e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    978    10     1.56e-07     1.56e-07     4.82e-06
    978    20     2.24e-07     2.24e-07     5.14e-06
    978    30     3.38e-08     3.38e-08     3.21e-06
    978    40     1.39e-07     1.39e-07      4.5e-06
    978    50     4.23e-08     4.23e-08     2.89e-06
    978    60     1.69e-08     1.69e-08     1.93e-06
    978    61     1.27e-06     1.27e-06     1.45e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             978 53857.095   0.0025     7.53e-08     7.53e-08     3.42e-06
! Validation        978 53857.095   0.0025     1.19e-07     1.19e-07     3.93e-06
Wall time: 53857.09592225
training
# Epoch batch         loss       loss_e      e/N_mae
    979    10     2.82e-08     2.82e-08     2.14e-06
    979    20        5e-08        5e-08     2.78e-06
    979    30     4.16e-08     4.16e-08     2.78e-06
    979    40     4.58e-08     4.58e-08     3.11e-06
    979    48            0            0            0
validation
# Epoch batch         loss       loss_e      e/N_mae
    979    10     1.46e-07     1.46e-07     3.53e-06
    979    20     1.94e-07     1.94e-07     5.14e-06
    979    30      3.8e-08      3.8e-08     3.21e-06
    979    40     1.82e-07     1.82e-07      6.1e-06
    979    50     4.02e-08     4.02e-08     3.21e-06
    979    60     2.96e-08     2.96e-08     2.89e-06
    979    61      1.4e-06      1.4e-06      1.5e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             979 53912.176   0.0025     6.11e-08     6.11e-08     3.13e-06
! Validation        979 53912.176   0.0025     1.18e-07     1.18e-07     3.91e-06
Wall time: 53912.176194625004
training
# Epoch batch         loss       loss_e      e/N_mae
    980    10     8.95e-08     8.95e-08     3.96e-06
    980    20     4.72e-08     4.72e-08     2.36e-06
    980    30     4.86e-08     4.86e-08     2.57e-06
    980    40     8.74e-08     8.74e-08     3.75e-06
    980    48     5.28e-09     5.28e-09     8.03e-07
validation
# Epoch batch         loss       loss_e      e/N_mae
    980    10      1.5e-07      1.5e-07     4.18e-06
    980    20      2.2e-07      2.2e-07      4.5e-06
    980    30     2.11e-08     2.11e-08     2.25e-06
    980    40     1.37e-07     1.37e-07     4.82e-06
    980    50     6.34e-08     6.34e-08     3.53e-06
    980    60     4.02e-08     4.02e-08     2.89e-06
    980    61     1.14e-06     1.14e-06     1.34e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             980 53967.292   0.0025     8.98e-08     8.98e-08     3.75e-06
! Validation        980 53967.292   0.0025     1.17e-07     1.17e-07     3.82e-06
Wall time: 53967.292907041
training
# Epoch batch         loss       loss_e      e/N_mae
    981    10     1.08e-07     1.08e-07     3.85e-06
    981    20     8.52e-08     8.52e-08     4.18e-06
    981    30     7.61e-08     7.61e-08     3.96e-06
    981    40     1.12e-07     1.12e-07     4.28e-06
    981    48      1.8e-07      1.8e-07     6.42e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    981    10      1.5e-07      1.5e-07     4.18e-06
    981    20     1.25e-07     1.25e-07     4.82e-06
    981    30     2.54e-08     2.54e-08     2.25e-06
    981    40     8.24e-08     8.24e-08     3.85e-06
    981    50     7.19e-08     7.19e-08     3.53e-06
    981    60     3.38e-08     3.38e-08     2.57e-06
    981    61     1.07e-06     1.07e-06     1.23e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             981 54022.419   0.0025     1.12e-07     1.12e-07     4.27e-06
! Validation        981 54022.419   0.0025     1.17e-07     1.17e-07     3.92e-06
Wall time: 54022.420274416
training
# Epoch batch         loss       loss_e      e/N_mae
    982    10     4.16e-08     4.16e-08     2.46e-06
    982    20     8.03e-08     8.03e-08     3.75e-06
    982    30     7.04e-08     7.04e-08     3.75e-06
    982    40     2.54e-08     2.54e-08     2.36e-06
    982    48     2.11e-08     2.11e-08     1.61e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    982    10     9.93e-08     9.93e-08     3.53e-06
    982    20     1.48e-07     1.48e-07     4.18e-06
    982    30     1.48e-08     1.48e-08     2.25e-06
    982    40     1.14e-07     1.14e-07      4.5e-06
    982    50     4.44e-08     4.44e-08     2.57e-06
    982    60     1.27e-08     1.27e-08     1.28e-06
    982    61     1.04e-06     1.04e-06     1.45e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             982 54077.240   0.0025     9.09e-08     9.09e-08     3.79e-06
! Validation        982 54077.240   0.0025     1.17e-07     1.17e-07     3.92e-06
Wall time: 54077.241127083005
training
# Epoch batch         loss       loss_e      e/N_mae
    983    10     7.89e-08     7.89e-08     4.07e-06
    983    20     4.93e-08     4.93e-08     2.89e-06
    983    30     8.59e-08     8.59e-08     3.53e-06
    983    40     4.51e-08     4.51e-08     3.21e-06
    983    48     1.32e-07     1.32e-07     5.62e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    983    10     1.08e-07     1.08e-07     4.18e-06
    983    20     1.23e-07     1.23e-07      4.5e-06
    983    30     1.06e-08     1.06e-08     9.64e-07
    983    40     1.48e-07     1.48e-07     5.46e-06
    983    50     8.88e-08     8.88e-08     4.18e-06
    983    60     2.75e-08     2.75e-08     2.25e-06
    983    61     1.19e-06     1.19e-06     1.45e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             983 54132.359   0.0025     6.23e-08     6.23e-08      3.2e-06
! Validation        983 54132.359   0.0025     1.19e-07     1.19e-07     3.97e-06
Wall time: 54132.360009583004
training
# Epoch batch         loss       loss_e      e/N_mae
    984    10     3.73e-08     3.73e-08     2.57e-06
    984    20     1.01e-07     1.01e-07      4.5e-06
    984    30     3.38e-08     3.38e-08     2.14e-06
    984    40     5.42e-08     5.42e-08     2.89e-06
    984    48     2.11e-08     2.11e-08     1.61e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    984    10     9.09e-08     9.09e-08     3.53e-06
    984    20     1.18e-07     1.18e-07     4.18e-06
    984    30     2.11e-08     2.11e-08     2.57e-06
    984    40     1.01e-07     1.01e-07     3.85e-06
    984    50     4.65e-08     4.65e-08     2.89e-06
    984    60     6.13e-08     6.13e-08     3.53e-06
    984    61     1.03e-06     1.03e-06     1.28e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             984 54187.630   0.0025     6.56e-08     6.56e-08     3.35e-06
! Validation        984 54187.630   0.0025     1.15e-07     1.15e-07     3.81e-06
Wall time: 54187.630581875004
training
# Epoch batch         loss       loss_e      e/N_mae
    985    10     5.64e-08     5.64e-08     3.11e-06
    985    20      6.2e-08      6.2e-08     3.32e-06
    985    30     4.44e-08     4.44e-08     2.78e-06
    985    40     4.09e-08     4.09e-08     2.46e-06
    985    48     8.98e-08     8.98e-08     4.82e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    985    10     1.16e-07     1.16e-07     3.53e-06
    985    20     1.94e-07     1.94e-07     5.14e-06
    985    30     1.48e-08     1.48e-08     1.93e-06
    985    40     1.25e-07     1.25e-07     4.82e-06
    985    50     4.86e-08     4.86e-08     3.21e-06
    985    60     4.02e-08     4.02e-08     2.25e-06
    985    61     1.13e-06     1.13e-06     1.39e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             985 54242.763   0.0025     5.64e-08     5.64e-08     3.06e-06
! Validation        985 54242.763   0.0025     1.17e-07     1.17e-07      3.9e-06
Wall time: 54242.762959958
training
# Epoch batch         loss       loss_e      e/N_mae
    986    10     1.94e-07     1.94e-07     6.21e-06
    986    20     8.81e-08     8.81e-08     3.85e-06
    986    30     1.57e-07     1.57e-07     5.35e-06
    986    40     7.12e-08     7.12e-08     3.85e-06
    986    48     4.23e-07     4.23e-07     9.64e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    986    10     1.27e-07     1.27e-07     3.85e-06
    986    20     1.99e-07     1.99e-07     5.14e-06
    986    30     1.27e-08     1.27e-08     1.61e-06
    986    40     1.08e-07     1.08e-07     4.18e-06
    986    50     8.45e-08     8.45e-08     4.18e-06
    986    60     3.59e-08     3.59e-08     2.25e-06
    986    61     1.49e-06     1.49e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             986 54297.829   0.0025     1.06e-07     1.06e-07     4.07e-06
! Validation        986 54297.829   0.0025     1.18e-07     1.18e-07     3.76e-06
Wall time: 54297.829246916
training
# Epoch batch         loss       loss_e      e/N_mae
    987    10     2.71e-07     2.71e-07     6.64e-06
    987    20     1.51e-07     1.51e-07     5.57e-06
    987    30     1.44e-07     1.44e-07     5.46e-06
    987    40     8.52e-08     8.52e-08     4.07e-06
    987    48     1.32e-07     1.32e-07     4.02e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    987    10     1.08e-07     1.08e-07     4.18e-06
    987    20     1.59e-07     1.59e-07      4.5e-06
    987    30     1.48e-08     1.48e-08     1.93e-06
    987    40     1.06e-07     1.06e-07      4.5e-06
    987    50     3.59e-08     3.59e-08     2.57e-06
    987    60     3.59e-08     3.59e-08     2.89e-06
    987    61     1.49e-06     1.49e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             987 54352.942   0.0025     1.31e-07     1.31e-07     4.68e-06
! Validation        987 54352.942   0.0025     1.27e-07     1.27e-07     3.97e-06
Wall time: 54352.944357791
training
# Epoch batch         loss       loss_e      e/N_mae
    988    10     7.33e-08     7.33e-08        3e-06
    988    20     3.17e-08     3.17e-08     2.46e-06
    988    30     5.35e-08     5.35e-08     3.43e-06
    988    40     6.76e-08     6.76e-08     2.89e-06
    988    48     1.06e-07     1.06e-07     4.82e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    988    10     1.67e-07     1.67e-07     4.82e-06
    988    20     1.48e-07     1.48e-07     4.18e-06
    988    30     3.17e-08     3.17e-08     2.89e-06
    988    40     1.23e-07     1.23e-07      4.5e-06
    988    50     2.75e-08     2.75e-08     2.57e-06
    988    60     5.07e-08     5.07e-08     3.53e-06
    988    61     1.31e-06     1.31e-06     1.55e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             988 54408.043   0.0025     6.85e-08     6.85e-08     3.34e-06
! Validation        988 54408.043   0.0025     1.24e-07     1.24e-07     3.92e-06
Wall time: 54408.0435405
training
# Epoch batch         loss       loss_e      e/N_mae
    989    10     5.71e-08     5.71e-08     3.32e-06
    989    20     4.72e-08     4.72e-08     2.78e-06
    989    30     1.58e-07     1.58e-07     5.46e-06
    989    40     7.61e-08     7.61e-08     3.85e-06
    989    48     9.51e-08     9.51e-08     4.82e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    989    10     1.97e-07     1.97e-07     4.82e-06
    989    20     1.82e-07     1.82e-07      4.5e-06
    989    30     2.32e-08     2.32e-08     2.25e-06
    989    40     9.51e-08     9.51e-08     4.18e-06
    989    50     5.71e-08     5.71e-08     3.85e-06
    989    60     4.44e-08     4.44e-08     2.89e-06
    989    61     1.64e-06     1.64e-06     1.66e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             989 54463.334   0.0025     7.63e-08     7.63e-08      3.6e-06
! Validation        989 54463.334   0.0025     1.28e-07     1.28e-07     3.93e-06
Wall time: 54463.334843833
training
# Epoch batch         loss       loss_e      e/N_mae
    990    10     8.45e-08     8.45e-08     4.07e-06
    990    20     5.64e-08     5.64e-08     3.43e-06
    990    30     1.05e-07     1.05e-07      4.5e-06
    990    40      1.8e-07      1.8e-07     5.35e-06
    990    48     5.28e-09     5.28e-09     8.03e-07
validation
# Epoch batch         loss       loss_e      e/N_mae
    990    10     1.73e-07     1.73e-07      6.1e-06
    990    20     1.92e-07     1.92e-07     5.14e-06
    990    30     2.75e-08     2.75e-08     2.89e-06
    990    40      7.4e-08      7.4e-08     3.53e-06
    990    50     4.65e-08     4.65e-08     3.53e-06
    990    60     6.34e-08     6.34e-08     4.18e-06
    990    61     1.45e-06     1.45e-06     1.55e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             990 54518.577   0.0025     8.77e-08     8.77e-08     3.89e-06
! Validation        990 54518.577   0.0025     1.16e-07     1.16e-07     3.77e-06
Wall time: 54518.578354000005
training
# Epoch batch         loss       loss_e      e/N_mae
    991    10     7.04e-08     7.04e-08     3.64e-06
    991    20     1.75e-07     1.75e-07     5.89e-06
    991    30      6.9e-08      6.9e-08     3.21e-06
    991    40     9.51e-08     9.51e-08      4.6e-06
    991    48     5.28e-09     5.28e-09     8.03e-07
validation
# Epoch batch         loss       loss_e      e/N_mae
    991    10     1.37e-07     1.37e-07     4.18e-06
    991    20     1.35e-07     1.35e-07     3.21e-06
    991    30     2.11e-08     2.11e-08     2.57e-06
    991    40     1.08e-07     1.08e-07     4.18e-06
    991    50     4.65e-08     4.65e-08     2.89e-06
    991    60      3.8e-08      3.8e-08     1.93e-06
    991    61     1.19e-06     1.19e-06     1.39e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             991 54573.545   0.0025     8.95e-08     8.95e-08     3.93e-06
! Validation        991 54573.545   0.0025     1.09e-07     1.09e-07     3.58e-06
Wall time: 54573.54578
! Best model      991    0.000
training
# Epoch batch         loss       loss_e      e/N_mae
    992    10     7.26e-08     7.26e-08     3.85e-06
    992    20     7.61e-08     7.61e-08     3.96e-06
    992    30     2.35e-07     2.35e-07      6.1e-06
    992    40     1.66e-07     1.66e-07     5.35e-06
    992    48     9.51e-08     9.51e-08     4.82e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    992    10     1.31e-07     1.31e-07     3.85e-06
    992    20     1.12e-07     1.12e-07     3.53e-06
    992    30      1.9e-08      1.9e-08     2.25e-06
    992    40     1.82e-07     1.82e-07     5.78e-06
    992    50     2.75e-08     2.75e-08     2.57e-06
    992    60     4.86e-08     4.86e-08     2.89e-06
    992    61     1.13e-06     1.13e-06     1.45e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             992 54628.504   0.0025     1.48e-07     1.48e-07     4.91e-06
! Validation        992 54628.504   0.0025     1.11e-07     1.11e-07     3.74e-06
Wall time: 54628.505034916
training
# Epoch batch         loss       loss_e      e/N_mae
    993    10      1.9e-07      1.9e-07     6.32e-06
    993    20     1.05e-07     1.05e-07     4.18e-06
    993    30     1.39e-07     1.39e-07     4.93e-06
    993    40     1.46e-07     1.46e-07     5.46e-06
    993    48     2.38e-07     2.38e-07     8.03e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    993    10      1.2e-07      1.2e-07     4.18e-06
    993    20      7.4e-08      7.4e-08     3.21e-06
    993    30     4.86e-08     4.86e-08     3.53e-06
    993    40     2.62e-07     2.62e-07     7.39e-06
    993    50     4.86e-08     4.86e-08     3.21e-06
    993    60     3.17e-08     3.17e-08     2.25e-06
    993    61     1.37e-06     1.37e-06     1.55e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             993 54683.666   0.0025     1.94e-07     1.94e-07     5.68e-06
! Validation        993 54683.666   0.0025     1.17e-07     1.17e-07      3.8e-06
Wall time: 54683.667264083
training
# Epoch batch         loss       loss_e      e/N_mae
    994    10     2.46e-07     2.46e-07      7.6e-06
    994    20      9.3e-08      9.3e-08     3.64e-06
    994    30     9.37e-08     9.37e-08      4.5e-06
    994    40     1.33e-07     1.33e-07     4.39e-06
    994    48     1.27e-06     1.27e-06     1.53e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    994    10     1.78e-07     1.78e-07     4.82e-06
    994    20     6.13e-08     6.13e-08     2.57e-06
    994    30     4.65e-08     4.65e-08     2.89e-06
    994    40     1.29e-07     1.29e-07     4.82e-06
    994    50     7.82e-08     7.82e-08      4.5e-06
    994    60     8.45e-09     8.45e-09     1.28e-06
    994    61     1.11e-06     1.11e-06     1.34e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             994 54738.794   0.0025     2.49e-07     2.49e-07     6.28e-06
! Validation        994 54738.794   0.0025     1.17e-07     1.17e-07     3.83e-06
Wall time: 54738.794119708
training
# Epoch batch         loss       loss_e      e/N_mae
    995    10     3.13e-06     3.13e-06     2.23e-05
    995    20     8.63e-07     8.63e-07     1.38e-05
    995    30     1.54e-06     1.54e-06     1.56e-05
    995    40     5.76e-07     5.76e-07     9.64e-06
    995    48     1.87e-06     1.87e-06     2.09e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    995    10     1.63e-07     1.63e-07     5.14e-06
    995    20     1.23e-07     1.23e-07      4.5e-06
    995    30     1.08e-07     1.08e-07      4.5e-06
    995    40     1.59e-07     1.59e-07     5.46e-06
    995    50     6.34e-08     6.34e-08     3.53e-06
    995    60     1.48e-08     1.48e-08     1.61e-06
    995    61      1.4e-06      1.4e-06      1.5e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             995 54793.906   0.0025     1.01e-06     1.01e-06     1.23e-05
! Validation        995 54793.906   0.0025     1.28e-07     1.28e-07     4.13e-06
Wall time: 54793.907311458
training
# Epoch batch         loss       loss_e      e/N_mae
    996    10     1.22e-06     1.22e-06     1.51e-05
    996    20     3.61e-07     3.61e-07     7.71e-06
    996    30     3.97e-07     3.97e-07     8.25e-06
    996    40     2.33e-07     2.33e-07     6.85e-06
    996    48     4.23e-08     4.23e-08     3.21e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    996    10     1.73e-07     1.73e-07      4.5e-06
    996    20     1.69e-07     1.69e-07     6.75e-06
    996    30     1.27e-07     1.27e-07     5.14e-06
    996    40     8.88e-08     8.88e-08     3.85e-06
    996    50     6.55e-08     6.55e-08     3.85e-06
    996    60      3.8e-08      3.8e-08     2.57e-06
    996    61     1.27e-06     1.27e-06     1.45e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             996 54849.164   0.0025     4.29e-07     4.29e-07     8.62e-06
! Validation        996 54849.164   0.0025     1.31e-07     1.31e-07     4.27e-06
Wall time: 54849.164926708
training
# Epoch batch         loss       loss_e      e/N_mae
    997    10     2.02e-07     2.02e-07     5.57e-06
    997    20      1.4e-07      1.4e-07     4.93e-06
    997    30     1.87e-07     1.87e-07     5.03e-06
    997    40     1.63e-07     1.63e-07     4.71e-06
    997    48     2.11e-07     2.11e-07     6.42e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    997    10     2.22e-07     2.22e-07     6.42e-06
    997    20     1.18e-07     1.18e-07     5.14e-06
    997    30     5.71e-08     5.71e-08     3.21e-06
    997    40     1.01e-07     1.01e-07      4.5e-06
    997    50     5.92e-08     5.92e-08     3.53e-06
    997    60     5.07e-08     5.07e-08     3.21e-06
    997    61     1.27e-06     1.27e-06     1.45e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             997 54903.973   0.0025     1.94e-07     1.94e-07     5.72e-06
! Validation        997 54903.973   0.0025     1.25e-07     1.25e-07     4.09e-06
Wall time: 54903.9739285
training
# Epoch batch         loss       loss_e      e/N_mae
    998    10     6.85e-07     6.85e-07     8.99e-06
    998    20     2.75e-07     2.75e-07     6.42e-06
    998    30     1.16e-07     1.16e-07     4.28e-06
    998    40     4.93e-08     4.93e-08        3e-06
    998    48     1.32e-07     1.32e-07     5.62e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
    998    10     1.84e-07     1.84e-07     4.18e-06
    998    20     1.75e-07     1.75e-07     4.18e-06
    998    30     5.92e-08     5.92e-08     3.53e-06
    998    40     1.14e-07     1.14e-07      4.5e-06
    998    50     4.23e-08     4.23e-08     2.89e-06
    998    60     4.02e-08     4.02e-08     2.89e-06
    998    61     1.32e-06     1.32e-06     1.61e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             998 54959.128   0.0025     2.28e-07     2.28e-07     5.85e-06
! Validation        998 54959.128   0.0025     1.24e-07     1.24e-07      3.9e-06
Wall time: 54959.128824833
training
# Epoch batch         loss       loss_e      e/N_mae
    999    10     1.28e-07     1.28e-07     4.28e-06
    999    20     4.61e-07     4.61e-07     9.32e-06
    999    30     2.49e-07     2.49e-07      7.5e-06
    999    40     2.07e-07     2.07e-07     5.78e-06
    999    48     4.49e-07     4.49e-07      1.2e-05
validation
# Epoch batch         loss       loss_e      e/N_mae
    999    10     1.48e-07     1.48e-07     3.85e-06
    999    20     1.12e-07     1.12e-07     4.18e-06
    999    30     7.61e-08     7.61e-08     3.53e-06
    999    40      1.1e-07      1.1e-07      4.5e-06
    999    50     1.48e-08     1.48e-08     1.93e-06
    999    60     4.65e-08     4.65e-08     2.57e-06
    999    61     1.72e-06     1.72e-06     1.87e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train             999 55014.193   0.0025     2.96e-07     2.96e-07     6.93e-06
! Validation        999 55014.193   0.0025     1.15e-07     1.15e-07     3.76e-06
Wall time: 55014.193687916006
training
# Epoch batch         loss       loss_e      e/N_mae
   1000    10     2.45e-07     2.45e-07     6.21e-06
   1000    20     3.89e-07     3.89e-07     8.46e-06
   1000    30     1.94e-07     1.94e-07     5.89e-06
   1000    40     2.01e-07     2.01e-07     5.57e-06
   1000    48     9.51e-08     9.51e-08     4.82e-06
validation
# Epoch batch         loss       loss_e      e/N_mae
   1000    10     1.97e-07     1.97e-07     5.78e-06
   1000    20     1.23e-07     1.23e-07      4.5e-06
   1000    30     4.86e-08     4.86e-08     3.21e-06
   1000    40     1.39e-07     1.39e-07      4.5e-06
   1000    50     1.27e-08     1.27e-08     1.61e-06
   1000    60      9.3e-08      9.3e-08      4.5e-06
   1000    61      1.3e-06      1.3e-06     1.55e-05
  Train      #    Epoch      wal       LR       loss_e         loss      e/N_mae
! Train            1000 55069.200   0.0025     2.06e-07     2.06e-07     5.71e-06
! Validation       1000 55069.200   0.0025     1.18e-07     1.18e-07     3.97e-06
Wall time: 55069.201357541
! Stop training: max epochs
Wall time: 55069.218795833
Cumulative wall time: 55069.218795833